{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f870a57-ca26-41eb-b16a-971cc6190d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preparation for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bea6b21e-afb6-4bfa-b25b-dfcbffa64905",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "# import pickle\n",
    "# from tcrpeg.TCRpeg import TCRpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7a6ba8-84bc-4a16-a067-d6842610710d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from BA we have train, validation and test. \n",
    "# merge train and validation \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "416ee3c4-d1d0-49d6-838c-9332d8d9b17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28611/2002924324.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns=columns_to_rename, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Satarting length=  338783\n",
      "Length after removing CDR3.beta len > 30 =  338769\n",
      "Length after removing Epitope len > 30 =  335115\n",
      "Saved fold 0 as allele_fold_0.csv in processed_data/PA_all/allele_fold_0.csv\n",
      "Saved fold 1 as allele_fold_1.csv in processed_data/PA_all/allele_fold_1.csv\n",
      "Saved fold 2 as allele_fold_2.csv in processed_data/PA_all/allele_fold_2.csv\n",
      "Saved fold 3 as allele_fold_3.csv in processed_data/PA_all/allele_fold_3.csv\n",
      "Saved fold 4 as allele_fold_4.csv in processed_data/PA_all/allele_fold_4.csv\n"
     ]
    }
   ],
   "source": [
    "# first for allele. \n",
    "# Select columns, merge train, test and validation, crate 5 folds from which 4 are for gnn training and one for testing.\n",
    "paths_allele = [\"data_for_training/splitted_datasets/allele/beta/train.tsv\", \n",
    "                \"data_for_training/splitted_datasets/allele/beta/validation.tsv\"] #,\n",
    "               # \"data_for_training/splitted_datasets/allele/beta/test.tsv\"]\n",
    "allele_dfs = [pd.read_csv(path, sep='\\t') for path in paths_allele]  # Load all files into a list of DataFrames\n",
    "concatenated_df = pd.concat(allele_dfs, ignore_index=True)  # Concatenate them into a single DataFrame\n",
    "df = concatenated_df[['TRB_CDR3', 'Epitope', 'Binding']] # keep just what is needed\n",
    "\n",
    "columns_to_rename = {\n",
    "    'TRB_CDR3': 'CDR3.beta',\n",
    "    'Binding': 'Label'\n",
    "}\n",
    "df.rename(columns=columns_to_rename, inplace=True)\n",
    "print('Satarting length= ', len(df))\n",
    "df = df[df['CDR3.beta'].apply(len) <= 30] \n",
    "print('Length after removing CDR3.beta len > 30 = ', len(df))\n",
    "df = df[df['Epitope'].apply(len) <= 30] \n",
    "print('Length after removing Epitope len > 30 = ', len(df))\n",
    "\n",
    "# 5. Generate 5 folds for cross-validation and save them in 'processed_data'\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# Loop through each fold and save it as a separate file\n",
    "for fold, (_, fold_index) in enumerate(kf.split(df)):\n",
    "    fold_data = df.iloc[fold_index]\n",
    "    path_save_fold = f\"processed_data/PA_all/allele_fold_{fold}.csv\"\n",
    "    fold_data.to_csv(path_save_fold, index=False)  # Saves each fold\n",
    "    print(f\"Saved fold {fold} as allele_fold_{fold}.csv in {path_save_fold}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1ee3a9d-bf54-4c16-b77e-272abd7bb67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26998/836007490.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns=columns_to_rename, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Satarting length=  305545\n",
      "Length after removing CDR3.beta len > 30 =  305537\n",
      "Length after removing Epitope len > 30 =  301932\n",
      "Saved fold 0 as gene_fold_0.csv in processed_data/PA_all/gene_fold_0.csv\n",
      "Saved fold 1 as gene_fold_1.csv in processed_data/PA_all/gene_fold_1.csv\n",
      "Saved fold 2 as gene_fold_2.csv in processed_data/PA_all/gene_fold_2.csv\n",
      "Saved fold 3 as gene_fold_3.csv in processed_data/PA_all/gene_fold_3.csv\n",
      "Saved fold 4 as gene_fold_4.csv in processed_data/PA_all/gene_fold_4.csv\n"
     ]
    }
   ],
   "source": [
    "# ...and here for 'gene'\n",
    "# Select columns, merge train, test and validation, crate 5 folds from which 4 are for gnn training and one for testing.\n",
    "paths_allele = [\"data_for_training/splitted_datasets/gene/beta/train.tsv\", \n",
    "                \"data_for_training/splitted_datasets/gene/beta/validation.tsv\"] #,\n",
    "               # \"data_for_training/splitted_datasets/gene/beta/test.tsv\"]\n",
    "allele_dfs = [pd.read_csv(path, sep='\\t') for path in paths_allele]  # Load all files into a list of DataFrames\n",
    "concatenated_df = pd.concat(allele_dfs, ignore_index=True)  # Concatenate them into a single DataFrame\n",
    "df = concatenated_df[['TRB_CDR3', 'Epitope', 'Binding']] # keep just what is needed\n",
    "\n",
    "columns_to_rename = {\n",
    "    'TRB_CDR3': 'CDR3.beta',\n",
    "    'Binding': 'Label'\n",
    "}\n",
    "df.rename(columns=columns_to_rename, inplace=True)\n",
    "print('Satarting length= ', len(df))\n",
    "df = df[df['CDR3.beta'].apply(len) <= 30] \n",
    "print('Length after removing CDR3.beta len > 30 = ', len(df))\n",
    "df = df[df['Epitope'].apply(len) <= 30] \n",
    "print('Length after removing Epitope len > 30 = ', len(df))\n",
    "\n",
    "# 5. Generate 5 folds for cross-validation and save them in 'processed_data'\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# Loop through each fold and save it as a separate file\n",
    "for fold, (_, fold_index) in enumerate(kf.split(df)):\n",
    "    fold_data = df.iloc[fold_index]\n",
    "    path_save_fold = f\"processed_data/PA_all/gene_fold_{fold}.csv\"\n",
    "    fold_data.to_csv(path_save_fold, index=False)  # Saves each fold\n",
    "    print(f\"Saved fold {fold} as gene_fold_{fold}.csv in {path_save_fold}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4aafd1a2-5fb0-4b3e-8b51-c791652b3f01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploading dataset to dataset-allele_GNN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:14v0ltc1) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.005 MB of 0.005 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">pretty-grass-1</strong> at: <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN/runs/14v0ltc1' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN/runs/14v0ltc1</a><br/> View project at: <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN</a><br/>Synced 4 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241202_223650-14v0ltc1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:14v0ltc1). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/PA-Cancer-Immunotherapy/GNN/wandb/run-20241202_223801-ow6s52f5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN/runs/ow6s52f5' target=\"_blank\">vibrant-violet-2</a></strong> to <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN/runs/ow6s52f5' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN/runs/ow6s52f5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./processed_data/PA_all)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.333 MB of 18.728 MB uploaded\\r'), FloatProgress(value=0.07116857086404865, max=1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">vibrant-violet-2</strong> at: <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN/runs/ow6s52f5' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN/runs/ow6s52f5</a><br/> View project at: <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN</a><br/>Synced 5 W&B file(s), 0 media file(s), 11 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241202_223801-ow6s52f5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploading dataset to dataset-allele_GNN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/PA-Cancer-Immunotherapy/GNN/wandb/run-20241202_223811-f1r9wbmk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN/runs/f1r9wbmk' target=\"_blank\">trim-pine-3</a></strong> to <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN/runs/f1r9wbmk' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN/runs/f1r9wbmk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./processed_data/PA_all)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.333 MB of 18.728 MB uploaded\\r'), FloatProgress(value=0.07116857086404865, max=1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trim-pine-3</strong> at: <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN/runs/f1r9wbmk' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN/runs/f1r9wbmk</a><br/> View project at: <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN</a><br/>Synced 5 W&B file(s), 0 media file(s), 11 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241202_223811-f1r9wbmk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploading dataset to dataset-allele_GNN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/PA-Cancer-Immunotherapy/GNN/wandb/run-20241202_223817-pc8bzapp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN/runs/pc8bzapp' target=\"_blank\">silvery-haze-4</a></strong> to <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN/runs/pc8bzapp' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN/runs/pc8bzapp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./processed_data/PA_all)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.348 MB of 18.728 MB uploaded\\r'), FloatProgress(value=0.0720029005994708, max=1.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">silvery-haze-4</strong> at: <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN/runs/pc8bzapp' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN/runs/pc8bzapp</a><br/> View project at: <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN</a><br/>Synced 5 W&B file(s), 0 media file(s), 11 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241202_223817-pc8bzapp/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploading dataset to dataset-allele_GNN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/PA-Cancer-Immunotherapy/GNN/wandb/run-20241202_223823-jczh7hhv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN/runs/jczh7hhv' target=\"_blank\">misty-elevator-5</a></strong> to <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN/runs/jczh7hhv' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN/runs/jczh7hhv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./processed_data/PA_all)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.348 MB of 18.728 MB uploaded\\r'), FloatProgress(value=0.0720029005994708, max=1.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">misty-elevator-5</strong> at: <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN/runs/jczh7hhv' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN/runs/jczh7hhv</a><br/> View project at: <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN</a><br/>Synced 5 W&B file(s), 0 media file(s), 11 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241202_223823-jczh7hhv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploading dataset to dataset-allele_GNN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/PA-Cancer-Immunotherapy/GNN/wandb/run-20241202_223829-47hhat5l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN/runs/47hhat5l' target=\"_blank\">likely-pyramid-6</a></strong> to <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN/runs/47hhat5l' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN/runs/47hhat5l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./processed_data/PA_all)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdbe313b7ebd46e3ad7c18ca27e3458b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.348 MB of 18.728 MB uploaded\\r'), FloatProgress(value=0.0720029005994708, max=1.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">likely-pyramid-6</strong> at: <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN/runs/47hhat5l' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN/runs/47hhat5l</a><br/> View project at: <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN</a><br/>Synced 5 W&B file(s), 0 media file(s), 11 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241202_223829-47hhat5l/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploading dataset to dataset-gene_GNN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/PA-Cancer-Immunotherapy/GNN/wandb/run-20241202_223836-f65sdx83</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-gene_GNN/runs/f65sdx83' target=\"_blank\">sandy-dragon-1</a></strong> to <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-gene_GNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-gene_GNN' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-gene_GNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-gene_GNN/runs/f65sdx83' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-gene_GNN/runs/f65sdx83</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./processed_data/PA_all)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.302 MB of 18.728 MB uploaded\\r'), FloatProgress(value=0.06949991139320437, max=1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sandy-dragon-1</strong> at: <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-gene_GNN/runs/f65sdx83' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-gene_GNN/runs/f65sdx83</a><br/> View project at: <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-gene_GNN' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-gene_GNN</a><br/>Synced 4 W&B file(s), 0 media file(s), 14 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241202_223836-f65sdx83/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploading dataset to dataset-gene_GNN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/PA-Cancer-Immunotherapy/GNN/wandb/run-20241202_223844-b6xe6ilq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-gene_GNN/runs/b6xe6ilq' target=\"_blank\">easy-donkey-2</a></strong> to <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-gene_GNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-gene_GNN' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-gene_GNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-gene_GNN/runs/b6xe6ilq' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-gene_GNN/runs/b6xe6ilq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./processed_data/PA_all)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.333 MB of 18.728 MB uploaded\\r'), FloatProgress(value=0.07116857086404865, max=1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">easy-donkey-2</strong> at: <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-gene_GNN/runs/b6xe6ilq' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-gene_GNN/runs/b6xe6ilq</a><br/> View project at: <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-gene_GNN' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-gene_GNN</a><br/>Synced 5 W&B file(s), 0 media file(s), 11 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241202_223844-b6xe6ilq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploading dataset to dataset-gene_GNN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/PA-Cancer-Immunotherapy/GNN/wandb/run-20241202_223850-4qte063k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-gene_GNN/runs/4qte063k' target=\"_blank\">wild-bird-3</a></strong> to <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-gene_GNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-gene_GNN' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-gene_GNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-gene_GNN/runs/4qte063k' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-gene_GNN/runs/4qte063k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./processed_data/PA_all)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.333 MB of 18.728 MB uploaded\\r'), FloatProgress(value=0.07116857086404865, max=1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">wild-bird-3</strong> at: <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-gene_GNN/runs/4qte063k' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-gene_GNN/runs/4qte063k</a><br/> View project at: <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-gene_GNN' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-gene_GNN</a><br/>Synced 5 W&B file(s), 0 media file(s), 11 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241202_223850-4qte063k/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploading dataset to dataset-gene_GNN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/PA-Cancer-Immunotherapy/GNN/wandb/run-20241202_223856-ryqi6s86</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-gene_GNN/runs/ryqi6s86' target=\"_blank\">rare-terrain-4</a></strong> to <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-gene_GNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-gene_GNN' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-gene_GNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-gene_GNN/runs/ryqi6s86' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-gene_GNN/runs/ryqi6s86</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./processed_data/PA_all)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.005 MB of 0.005 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rare-terrain-4</strong> at: <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-gene_GNN/runs/ryqi6s86' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-gene_GNN/runs/ryqi6s86</a><br/> View project at: <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-gene_GNN' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-gene_GNN</a><br/>Synced 5 W&B file(s), 0 media file(s), 11 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241202_223856-ryqi6s86/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploading dataset to dataset-gene_GNN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/PA-Cancer-Immunotherapy/GNN/wandb/run-20241202_223903-4db1pbh9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-gene_GNN/runs/4db1pbh9' target=\"_blank\">colorful-gorge-5</a></strong> to <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-gene_GNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-gene_GNN' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-gene_GNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-gene_GNN/runs/4db1pbh9' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-gene_GNN/runs/4db1pbh9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./processed_data/PA_all)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.348 MB of 18.728 MB uploaded\\r'), FloatProgress(value=0.0720029005994708, max=1.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">colorful-gorge-5</strong> at: <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-gene_GNN/runs/4db1pbh9' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-gene_GNN/runs/4db1pbh9</a><br/> View project at: <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-gene_GNN' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-gene_GNN</a><br/>Synced 5 W&B file(s), 0 media file(s), 11 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241202_223903-4db1pbh9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Datan hochladen auf wandb...  \n",
    "\n",
    "# Done! :)\n",
    "\n",
    "import wandb\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "#/home/ubuntu/PA-Cancer-Immunotherapy/GNN/processed_data/PA_all\n",
    "# upload paired data\n",
    "path_to_data = './processed_data/PA_all' # path zu unseren Daten\n",
    "precisions = [\"allele\", \"gene\"]\n",
    "\n",
    "for precision in precisions:\n",
    "    \n",
    "    main_project_name = f\"dataset-{precision}_GNN\" # das erscheint auf wandb projects \n",
    "    \n",
    "    for i in range(5):\n",
    "        dataset_name = f'{precision}_fold_{i}.csv'\n",
    "        #main_project_name = os.getenv(\"MAIN_PROJECT_NAME\")\n",
    "        print(f\"uploading dataset to {main_project_name}\")\n",
    "        run = wandb.init(project=main_project_name, job_type=\"Upload Dataset\", entity=\"pa_cancerimmunotherapy\")\n",
    "        artifact = wandb.Artifact(name=dataset_name, type=\"dataset\")\n",
    "        artifact.add_dir(path_to_data, name=precision)\n",
    "        run.log_artifact(artifact)\n",
    "        wandb.finish()\n",
    "\n",
    "# %run ./data_scripts/upload_datasets.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a3c7435-d2ab-4153-8f01-676230105a73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100, Loss: 0.6913798, Train Acc: 0.4829, Test Acc: 0.5480, Train AUC: 0.4659, Train APUR: 0.4715, Test AUC: 0.5670, Test AUPR: 0.5589\n",
      "Epoch: 2/100, Loss: 0.6908738, Train Acc: 0.5373, Test Acc: 0.5447, Train AUC: 0.5493, Train APUR: 0.5332, Test AUC: 0.5716, Test AUPR: 0.5640\n",
      "Epoch: 3/100, Loss: 0.6907544, Train Acc: 0.5370, Test Acc: 0.5445, Train AUC: 0.5531, Train APUR: 0.5445, Test AUC: 0.5730, Test AUPR: 0.5645\n",
      "Epoch: 4/100, Loss: 0.6903147, Train Acc: 0.5432, Test Acc: 0.5435, Train AUC: 0.5621, Train APUR: 0.5493, Test AUC: 0.5734, Test AUPR: 0.5651\n",
      "Epoch: 5/100, Loss: 0.6897598, Train Acc: 0.5446, Test Acc: 0.5431, Train AUC: 0.5641, Train APUR: 0.5535, Test AUC: 0.5736, Test AUPR: 0.5658\n",
      "Epoch: 6/100, Loss: 0.6894188, Train Acc: 0.5451, Test Acc: 0.5438, Train AUC: 0.5625, Train APUR: 0.5523, Test AUC: 0.5738, Test AUPR: 0.5663\n",
      "Epoch: 7/100, Loss: 0.6884170, Train Acc: 0.5451, Test Acc: 0.5438, Train AUC: 0.5714, Train APUR: 0.5612, Test AUC: 0.5737, Test AUPR: 0.5664\n",
      "Epoch: 8/100, Loss: 0.6880239, Train Acc: 0.5453, Test Acc: 0.5438, Train AUC: 0.5672, Train APUR: 0.5592, Test AUC: 0.5729, Test AUPR: 0.5662\n",
      "Epoch: 9/100, Loss: 0.6868532, Train Acc: 0.5429, Test Acc: 0.5437, Train AUC: 0.5718, Train APUR: 0.5637, Test AUC: 0.5727, Test AUPR: 0.5665\n",
      "Epoch: 10/100, Loss: 0.6865074, Train Acc: 0.5460, Test Acc: 0.5437, Train AUC: 0.5628, Train APUR: 0.5530, Test AUC: 0.5726, Test AUPR: 0.5665\n",
      "Epoch: 11/100, Loss: 0.6855918, Train Acc: 0.5457, Test Acc: 0.5436, Train AUC: 0.5708, Train APUR: 0.5609, Test AUC: 0.5727, Test AUPR: 0.5666\n",
      "Epoch: 12/100, Loss: 0.6850293, Train Acc: 0.5456, Test Acc: 0.5435, Train AUC: 0.5676, Train APUR: 0.5549, Test AUC: 0.5732, Test AUPR: 0.5670\n",
      "Epoch: 13/100, Loss: 0.6841876, Train Acc: 0.5451, Test Acc: 0.5436, Train AUC: 0.5692, Train APUR: 0.5536, Test AUC: 0.5736, Test AUPR: 0.5675\n",
      "Epoch: 14/100, Loss: 0.6830612, Train Acc: 0.5499, Test Acc: 0.5446, Train AUC: 0.5764, Train APUR: 0.5643, Test AUC: 0.5742, Test AUPR: 0.5673\n",
      "Epoch: 15/100, Loss: 0.6838495, Train Acc: 0.5469, Test Acc: 0.5493, Train AUC: 0.5713, Train APUR: 0.5539, Test AUC: 0.5740, Test AUPR: 0.5659\n",
      "Epoch: 16/100, Loss: 0.6834801, Train Acc: 0.5526, Test Acc: 0.5494, Train AUC: 0.5725, Train APUR: 0.5596, Test AUC: 0.5743, Test AUPR: 0.5641\n",
      "Epoch: 17/100, Loss: 0.6826841, Train Acc: 0.5527, Test Acc: 0.5488, Train AUC: 0.5775, Train APUR: 0.5596, Test AUC: 0.5745, Test AUPR: 0.5626\n",
      "Epoch: 18/100, Loss: 0.6825072, Train Acc: 0.5535, Test Acc: 0.5495, Train AUC: 0.5765, Train APUR: 0.5576, Test AUC: 0.5742, Test AUPR: 0.5607\n",
      "Epoch: 19/100, Loss: 0.6815923, Train Acc: 0.5531, Test Acc: 0.5532, Train AUC: 0.5818, Train APUR: 0.5619, Test AUC: 0.5745, Test AUPR: 0.5592\n",
      "Epoch: 20/100, Loss: 0.6815410, Train Acc: 0.5560, Test Acc: 0.5526, Train AUC: 0.5811, Train APUR: 0.5595, Test AUC: 0.5745, Test AUPR: 0.5565\n",
      "Epoch: 21/100, Loss: 0.6807805, Train Acc: 0.5608, Test Acc: 0.5603, Train AUC: 0.5826, Train APUR: 0.5604, Test AUC: 0.5756, Test AUPR: 0.5553\n",
      "Epoch: 22/100, Loss: 0.6804821, Train Acc: 0.5634, Test Acc: 0.5634, Train AUC: 0.5827, Train APUR: 0.5571, Test AUC: 0.5786, Test AUPR: 0.5568\n",
      "Epoch: 23/100, Loss: 0.6797567, Train Acc: 0.5674, Test Acc: 0.5655, Train AUC: 0.5866, Train APUR: 0.5584, Test AUC: 0.5805, Test AUPR: 0.5574\n",
      "Epoch: 24/100, Loss: 0.6797097, Train Acc: 0.5673, Test Acc: 0.5624, Train AUC: 0.5871, Train APUR: 0.5568, Test AUC: 0.5818, Test AUPR: 0.5573\n",
      "Epoch: 25/100, Loss: 0.6784151, Train Acc: 0.5707, Test Acc: 0.5581, Train AUC: 0.5925, Train APUR: 0.5602, Test AUC: 0.5827, Test AUPR: 0.5577\n",
      "Epoch: 26/100, Loss: 0.6782114, Train Acc: 0.5711, Test Acc: 0.5694, Train AUC: 0.5915, Train APUR: 0.5592, Test AUC: 0.5841, Test AUPR: 0.5586\n",
      "Epoch: 27/100, Loss: 0.6775702, Train Acc: 0.5719, Test Acc: 0.5723, Train AUC: 0.5918, Train APUR: 0.5572, Test AUC: 0.5846, Test AUPR: 0.5588\n",
      "Epoch: 28/100, Loss: 0.6783413, Train Acc: 0.5693, Test Acc: 0.5611, Train AUC: 0.5897, Train APUR: 0.5553, Test AUC: 0.5863, Test AUPR: 0.5593\n",
      "Epoch: 29/100, Loss: 0.6774866, Train Acc: 0.5705, Test Acc: 0.5679, Train AUC: 0.5926, Train APUR: 0.5596, Test AUC: 0.5874, Test AUPR: 0.5599\n",
      "Epoch: 30/100, Loss: 0.6768833, Train Acc: 0.5702, Test Acc: 0.5721, Train AUC: 0.5939, Train APUR: 0.5595, Test AUC: 0.5893, Test AUPR: 0.5610\n",
      "Epoch: 31/100, Loss: 0.6765195, Train Acc: 0.5727, Test Acc: 0.5734, Train AUC: 0.5954, Train APUR: 0.5600, Test AUC: 0.5901, Test AUPR: 0.5616\n",
      "Epoch: 32/100, Loss: 0.6756149, Train Acc: 0.5738, Test Acc: 0.5744, Train AUC: 0.5977, Train APUR: 0.5623, Test AUC: 0.5909, Test AUPR: 0.5623\n",
      "Epoch: 33/100, Loss: 0.6752933, Train Acc: 0.5800, Test Acc: 0.5718, Train AUC: 0.5985, Train APUR: 0.5637, Test AUC: 0.5921, Test AUPR: 0.5637\n",
      "Epoch: 34/100, Loss: 0.6766388, Train Acc: 0.5723, Test Acc: 0.5744, Train AUC: 0.5996, Train APUR: 0.5644, Test AUC: 0.5936, Test AUPR: 0.5644\n",
      "Epoch: 35/100, Loss: 0.6748909, Train Acc: 0.5762, Test Acc: 0.5747, Train AUC: 0.6008, Train APUR: 0.5655, Test AUC: 0.5946, Test AUPR: 0.5655\n",
      "Epoch: 36/100, Loss: 0.6741127, Train Acc: 0.5804, Test Acc: 0.5747, Train AUC: 0.6041, Train APUR: 0.5687, Test AUC: 0.5953, Test AUPR: 0.5667\n",
      "Epoch: 37/100, Loss: 0.6734696, Train Acc: 0.5855, Test Acc: 0.5685, Train AUC: 0.6041, Train APUR: 0.5705, Test AUC: 0.5965, Test AUPR: 0.5688\n",
      "Epoch: 38/100, Loss: 0.6744186, Train Acc: 0.5774, Test Acc: 0.5826, Train AUC: 0.6089, Train APUR: 0.5752, Test AUC: 0.5976, Test AUPR: 0.5695\n",
      "Epoch: 39/100, Loss: 0.6725702, Train Acc: 0.5816, Test Acc: 0.5698, Train AUC: 0.6081, Train APUR: 0.5737, Test AUC: 0.5979, Test AUPR: 0.5693\n",
      "Epoch: 40/100, Loss: 0.6743649, Train Acc: 0.5739, Test Acc: 0.5851, Train AUC: 0.6073, Train APUR: 0.5746, Test AUC: 0.5996, Test AUPR: 0.5720\n",
      "Epoch: 41/100, Loss: 0.6728442, Train Acc: 0.5804, Test Acc: 0.5761, Train AUC: 0.6070, Train APUR: 0.5772, Test AUC: 0.6000, Test AUPR: 0.5743\n",
      "Epoch: 42/100, Loss: 0.6721276, Train Acc: 0.5810, Test Acc: 0.5648, Train AUC: 0.6089, Train APUR: 0.5778, Test AUC: 0.6008, Test AUPR: 0.5752\n",
      "Epoch: 43/100, Loss: 0.6729255, Train Acc: 0.5754, Test Acc: 0.5781, Train AUC: 0.6097, Train APUR: 0.5793, Test AUC: 0.6003, Test AUPR: 0.5737\n",
      "Epoch: 44/100, Loss: 0.6713779, Train Acc: 0.5873, Test Acc: 0.5775, Train AUC: 0.6136, Train APUR: 0.5810, Test AUC: 0.5973, Test AUPR: 0.5702\n",
      "Epoch: 45/100, Loss: 0.6712780, Train Acc: 0.5854, Test Acc: 0.5749, Train AUC: 0.6118, Train APUR: 0.5781, Test AUC: 0.5970, Test AUPR: 0.5701\n",
      "Epoch: 46/100, Loss: 0.6719930, Train Acc: 0.5791, Test Acc: 0.5778, Train AUC: 0.6122, Train APUR: 0.5793, Test AUC: 0.6001, Test AUPR: 0.5749\n",
      "Epoch: 47/100, Loss: 0.6694916, Train Acc: 0.5845, Test Acc: 0.5649, Train AUC: 0.6147, Train APUR: 0.5834, Test AUC: 0.6008, Test AUPR: 0.5771\n",
      "Epoch: 48/100, Loss: 0.6713797, Train Acc: 0.5809, Test Acc: 0.5779, Train AUC: 0.6146, Train APUR: 0.5830, Test AUC: 0.6018, Test AUPR: 0.5778\n",
      "Epoch: 49/100, Loss: 0.6697705, Train Acc: 0.5850, Test Acc: 0.5834, Train AUC: 0.6150, Train APUR: 0.5848, Test AUC: 0.6014, Test AUPR: 0.5764\n",
      "Epoch: 50/100, Loss: 0.6691467, Train Acc: 0.5871, Test Acc: 0.5836, Train AUC: 0.6161, Train APUR: 0.5850, Test AUC: 0.6009, Test AUPR: 0.5748\n",
      "Epoch: 51/100, Loss: 0.6689920, Train Acc: 0.5920, Test Acc: 0.5861, Train AUC: 0.6165, Train APUR: 0.5830, Test AUC: 0.6027, Test AUPR: 0.5776\n",
      "Epoch: 52/100, Loss: 0.6687905, Train Acc: 0.5939, Test Acc: 0.5791, Train AUC: 0.6167, Train APUR: 0.5847, Test AUC: 0.6049, Test AUPR: 0.5817\n",
      "Epoch: 53/100, Loss: 0.6676027, Train Acc: 0.5919, Test Acc: 0.5781, Train AUC: 0.6203, Train APUR: 0.5884, Test AUC: 0.6059, Test AUPR: 0.5848\n",
      "Epoch: 54/100, Loss: 0.6672943, Train Acc: 0.5954, Test Acc: 0.5785, Train AUC: 0.6203, Train APUR: 0.5912, Test AUC: 0.6066, Test AUPR: 0.5871\n",
      "Epoch: 55/100, Loss: 0.6672546, Train Acc: 0.5881, Test Acc: 0.5803, Train AUC: 0.6214, Train APUR: 0.5947, Test AUC: 0.6065, Test AUPR: 0.5853\n",
      "Epoch: 56/100, Loss: 0.6670760, Train Acc: 0.5885, Test Acc: 0.5860, Train AUC: 0.6198, Train APUR: 0.5925, Test AUC: 0.6035, Test AUPR: 0.5802\n",
      "Epoch: 57/100, Loss: 0.6667529, Train Acc: 0.5939, Test Acc: 0.5803, Train AUC: 0.6222, Train APUR: 0.5931, Test AUC: 0.5997, Test AUPR: 0.5758\n",
      "Epoch: 58/100, Loss: 0.6668141, Train Acc: 0.5927, Test Acc: 0.5676, Train AUC: 0.6235, Train APUR: 0.5922, Test AUC: 0.6039, Test AUPR: 0.5833\n",
      "Epoch: 59/100, Loss: 0.6658254, Train Acc: 0.5932, Test Acc: 0.5595, Train AUC: 0.6249, Train APUR: 0.5951, Test AUC: 0.6058, Test AUPR: 0.5868\n",
      "Epoch: 60/100, Loss: 0.6671573, Train Acc: 0.5858, Test Acc: 0.5837, Train AUC: 0.6245, Train APUR: 0.5962, Test AUC: 0.6044, Test AUPR: 0.5815\n",
      "Epoch: 61/100, Loss: 0.6655414, Train Acc: 0.5940, Test Acc: 0.5809, Train AUC: 0.6245, Train APUR: 0.5957, Test AUC: 0.6048, Test AUPR: 0.5804\n",
      "Epoch: 62/100, Loss: 0.6652154, Train Acc: 0.5982, Test Acc: 0.5837, Train AUC: 0.6250, Train APUR: 0.5953, Test AUC: 0.6084, Test AUPR: 0.5851\n",
      "Epoch: 63/100, Loss: 0.6644046, Train Acc: 0.5964, Test Acc: 0.5817, Train AUC: 0.6269, Train APUR: 0.6007, Test AUC: 0.6108, Test AUPR: 0.5918\n",
      "Epoch: 64/100, Loss: 0.6639109, Train Acc: 0.5977, Test Acc: 0.5801, Train AUC: 0.6287, Train APUR: 0.6021, Test AUC: 0.6116, Test AUPR: 0.5947\n",
      "Epoch: 65/100, Loss: 0.6641242, Train Acc: 0.5933, Test Acc: 0.5861, Train AUC: 0.6298, Train APUR: 0.6047, Test AUC: 0.6107, Test AUPR: 0.5911\n",
      "Epoch: 66/100, Loss: 0.6633145, Train Acc: 0.5983, Test Acc: 0.5834, Train AUC: 0.6303, Train APUR: 0.6031, Test AUC: 0.6069, Test AUPR: 0.5849\n",
      "Epoch: 67/100, Loss: 0.6636307, Train Acc: 0.5951, Test Acc: 0.5819, Train AUC: 0.6308, Train APUR: 0.6027, Test AUC: 0.6054, Test AUPR: 0.5826\n",
      "Epoch: 68/100, Loss: 0.6642543, Train Acc: 0.5967, Test Acc: 0.5707, Train AUC: 0.6274, Train APUR: 0.5970, Test AUC: 0.6092, Test AUPR: 0.5901\n",
      "Epoch: 69/100, Loss: 0.6624378, Train Acc: 0.5956, Test Acc: 0.5614, Train AUC: 0.6331, Train APUR: 0.6058, Test AUC: 0.6108, Test AUPR: 0.5960\n",
      "Epoch: 70/100, Loss: 0.6637833, Train Acc: 0.5916, Test Acc: 0.5862, Train AUC: 0.6333, Train APUR: 0.6085, Test AUC: 0.6099, Test AUPR: 0.5920\n",
      "Epoch: 71/100, Loss: 0.6627810, Train Acc: 0.5945, Test Acc: 0.5815, Train AUC: 0.6309, Train APUR: 0.6056, Test AUC: 0.6061, Test AUPR: 0.5855\n",
      "Epoch: 72/100, Loss: 0.6628733, Train Acc: 0.5951, Test Acc: 0.5841, Train AUC: 0.6301, Train APUR: 0.6031, Test AUC: 0.6096, Test AUPR: 0.5907\n",
      "Epoch: 73/100, Loss: 0.6619238, Train Acc: 0.5943, Test Acc: 0.5801, Train AUC: 0.6315, Train APUR: 0.6070, Test AUC: 0.6117, Test AUPR: 0.5978\n",
      "Epoch: 74/100, Loss: 0.6616455, Train Acc: 0.5953, Test Acc: 0.5801, Train AUC: 0.6348, Train APUR: 0.6110, Test AUC: 0.6115, Test AUPR: 0.5978\n",
      "Epoch: 75/100, Loss: 0.6621450, Train Acc: 0.5964, Test Acc: 0.5870, Train AUC: 0.6346, Train APUR: 0.6115, Test AUC: 0.6107, Test AUPR: 0.5919\n",
      "Epoch: 76/100, Loss: 0.6611257, Train Acc: 0.5975, Test Acc: 0.5855, Train AUC: 0.6339, Train APUR: 0.6066, Test AUC: 0.6102, Test AUPR: 0.5908\n",
      "Epoch: 77/100, Loss: 0.6607129, Train Acc: 0.5986, Test Acc: 0.5797, Train AUC: 0.6353, Train APUR: 0.6077, Test AUC: 0.6133, Test AUPR: 0.5992\n",
      "Epoch: 78/100, Loss: 0.6612910, Train Acc: 0.5981, Test Acc: 0.5810, Train AUC: 0.6366, Train APUR: 0.6119, Test AUC: 0.6140, Test AUPR: 0.6002\n",
      "Epoch: 79/100, Loss: 0.6602734, Train Acc: 0.5990, Test Acc: 0.5860, Train AUC: 0.6381, Train APUR: 0.6120, Test AUC: 0.6128, Test AUPR: 0.5963\n",
      "Epoch: 80/100, Loss: 0.6593429, Train Acc: 0.6001, Test Acc: 0.5818, Train AUC: 0.6384, Train APUR: 0.6121, Test AUC: 0.6086, Test AUPR: 0.5908\n",
      "Epoch: 81/100, Loss: 0.6607382, Train Acc: 0.5925, Test Acc: 0.5845, Train AUC: 0.6335, Train APUR: 0.6083, Test AUC: 0.6140, Test AUPR: 0.5988\n",
      "Epoch: 82/100, Loss: 0.6592289, Train Acc: 0.5980, Test Acc: 0.5785, Train AUC: 0.6382, Train APUR: 0.6118, Test AUC: 0.6149, Test AUPR: 0.6015\n",
      "Epoch: 83/100, Loss: 0.6598763, Train Acc: 0.5974, Test Acc: 0.5817, Train AUC: 0.6387, Train APUR: 0.6136, Test AUC: 0.6143, Test AUPR: 0.5996\n",
      "Epoch: 84/100, Loss: 0.6587296, Train Acc: 0.5982, Test Acc: 0.5849, Train AUC: 0.6410, Train APUR: 0.6171, Test AUC: 0.6094, Test AUPR: 0.5915\n",
      "Epoch: 85/100, Loss: 0.6598869, Train Acc: 0.5952, Test Acc: 0.5874, Train AUC: 0.6357, Train APUR: 0.6104, Test AUC: 0.6135, Test AUPR: 0.5971\n",
      "Epoch: 86/100, Loss: 0.6593367, Train Acc: 0.5974, Test Acc: 0.5785, Train AUC: 0.6369, Train APUR: 0.6141, Test AUC: 0.6167, Test AUPR: 0.6063\n",
      "Epoch: 87/100, Loss: 0.6590322, Train Acc: 0.5991, Test Acc: 0.5774, Train AUC: 0.6404, Train APUR: 0.6172, Test AUC: 0.6168, Test AUPR: 0.6071\n",
      "Epoch: 88/100, Loss: 0.6588451, Train Acc: 0.5998, Test Acc: 0.5809, Train AUC: 0.6427, Train APUR: 0.6181, Test AUC: 0.6165, Test AUPR: 0.6032\n",
      "Epoch: 89/100, Loss: 0.6574593, Train Acc: 0.6025, Test Acc: 0.5812, Train AUC: 0.6441, Train APUR: 0.6191, Test AUC: 0.6101, Test AUPR: 0.5951\n",
      "Epoch: 90/100, Loss: 0.6583136, Train Acc: 0.5984, Test Acc: 0.5824, Train AUC: 0.6397, Train APUR: 0.6161, Test AUC: 0.6134, Test AUPR: 0.5993\n",
      "Epoch: 91/100, Loss: 0.6570519, Train Acc: 0.6039, Test Acc: 0.5805, Train AUC: 0.6434, Train APUR: 0.6194, Test AUC: 0.6164, Test AUPR: 0.6047\n",
      "Epoch: 92/100, Loss: 0.6571069, Train Acc: 0.5987, Test Acc: 0.5844, Train AUC: 0.6451, Train APUR: 0.6219, Test AUC: 0.6168, Test AUPR: 0.6042\n",
      "Epoch: 93/100, Loss: 0.6562879, Train Acc: 0.6009, Test Acc: 0.5863, Train AUC: 0.6478, Train APUR: 0.6235, Test AUC: 0.6130, Test AUPR: 0.6000\n",
      "Epoch: 94/100, Loss: 0.6575832, Train Acc: 0.6002, Test Acc: 0.5803, Train AUC: 0.6424, Train APUR: 0.6165, Test AUC: 0.6161, Test AUPR: 0.6047\n",
      "Epoch: 95/100, Loss: 0.6555882, Train Acc: 0.6017, Test Acc: 0.5723, Train AUC: 0.6461, Train APUR: 0.6232, Test AUC: 0.6192, Test AUPR: 0.6103\n",
      "Epoch: 96/100, Loss: 0.6562384, Train Acc: 0.6018, Test Acc: 0.5822, Train AUC: 0.6473, Train APUR: 0.6234, Test AUC: 0.6208, Test AUPR: 0.6118\n",
      "Epoch: 97/100, Loss: 0.6546418, Train Acc: 0.6037, Test Acc: 0.5872, Train AUC: 0.6491, Train APUR: 0.6259, Test AUC: 0.6192, Test AUPR: 0.6081\n",
      "Epoch: 98/100, Loss: 0.6551092, Train Acc: 0.6025, Test Acc: 0.5780, Train AUC: 0.6466, Train APUR: 0.6224, Test AUC: 0.6169, Test AUPR: 0.6055\n",
      "Epoch: 99/100, Loss: 0.6554468, Train Acc: 0.6001, Test Acc: 0.5770, Train AUC: 0.6468, Train APUR: 0.6250, Test AUC: 0.6166, Test AUPR: 0.6049\n",
      "Epoch: 100/100, Loss: 0.6535923, Train Acc: 0.6021, Test Acc: 0.5784, Train AUC: 0.6497, Train APUR: 0.6259, Test AUC: 0.6163, Test AUPR: 0.6052\n",
      "/home/ubuntu/PA-Cancer-Immunotherapy/GNN/train_pa.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(configs['save_model']))\n",
      "Test Acc: 0.5822, Test AUC: 0.6208, Test AUPR: 0.6118\n"
     ]
    }
   ],
   "source": [
    "# train with PA_all  # this was the run with allele\n",
    "\n",
    "! python train_pa.py --gpu 0 --configs_path configs/PA_all.yml --droup_out 0.1 --split StrictTCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23cd3d47-215c-4762-b7f0-46a4c2ba5828",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100, Loss: 0.6930730, Train Acc: 0.5085, Test Acc: 0.5160, Train AUC: 0.5068, Train APUR: 0.5043, Test AUC: 0.5850, Test AUPR: 0.5800\n",
      "Epoch: 2/100, Loss: 0.6909082, Train Acc: 0.5075, Test Acc: 0.5532, Train AUC: 0.5672, Train APUR: 0.5582, Test AUC: 0.5862, Test AUPR: 0.5833\n",
      "Epoch: 3/100, Loss: 0.6868373, Train Acc: 0.5432, Test Acc: 0.5519, Train AUC: 0.5729, Train APUR: 0.5675, Test AUC: 0.5898, Test AUPR: 0.5846\n",
      "Epoch: 4/100, Loss: 0.6838281, Train Acc: 0.5514, Test Acc: 0.5633, Train AUC: 0.5828, Train APUR: 0.5747, Test AUC: 0.5927, Test AUPR: 0.5862\n",
      "Epoch: 5/100, Loss: 0.6821342, Train Acc: 0.5621, Test Acc: 0.5646, Train AUC: 0.5890, Train APUR: 0.5791, Test AUC: 0.5954, Test AUPR: 0.5881\n",
      "Epoch: 6/100, Loss: 0.6814213, Train Acc: 0.5656, Test Acc: 0.5708, Train AUC: 0.5923, Train APUR: 0.5813, Test AUC: 0.6011, Test AUPR: 0.5920\n",
      "Epoch: 7/100, Loss: 0.6792936, Train Acc: 0.5726, Test Acc: 0.5761, Train AUC: 0.6008, Train APUR: 0.5855, Test AUC: 0.6087, Test AUPR: 0.5946\n",
      "Epoch: 8/100, Loss: 0.6770731, Train Acc: 0.5771, Test Acc: 0.5903, Train AUC: 0.6093, Train APUR: 0.5923, Test AUC: 0.6122, Test AUPR: 0.5957\n",
      "Epoch: 9/100, Loss: 0.6756787, Train Acc: 0.5841, Test Acc: 0.5750, Train AUC: 0.6137, Train APUR: 0.5947, Test AUC: 0.6122, Test AUPR: 0.5961\n",
      "Epoch: 10/100, Loss: 0.6753013, Train Acc: 0.5802, Test Acc: 0.5823, Train AUC: 0.6155, Train APUR: 0.5973, Test AUC: 0.6147, Test AUPR: 0.5996\n",
      "Epoch: 11/100, Loss: 0.6736215, Train Acc: 0.5887, Test Acc: 0.5917, Train AUC: 0.6183, Train APUR: 0.5980, Test AUC: 0.6165, Test AUPR: 0.6033\n",
      "Epoch: 12/100, Loss: 0.6723514, Train Acc: 0.5915, Test Acc: 0.5996, Train AUC: 0.6211, Train APUR: 0.6068, Test AUC: 0.6202, Test AUPR: 0.6068\n",
      "Epoch: 13/100, Loss: 0.6706187, Train Acc: 0.5907, Test Acc: 0.5925, Train AUC: 0.6237, Train APUR: 0.6082, Test AUC: 0.6215, Test AUPR: 0.6095\n",
      "Epoch: 14/100, Loss: 0.6694645, Train Acc: 0.5981, Test Acc: 0.5901, Train AUC: 0.6256, Train APUR: 0.6103, Test AUC: 0.6221, Test AUPR: 0.6129\n",
      "Epoch: 15/100, Loss: 0.6703067, Train Acc: 0.5911, Test Acc: 0.5884, Train AUC: 0.6250, Train APUR: 0.6099, Test AUC: 0.6192, Test AUPR: 0.6141\n",
      "Epoch: 16/100, Loss: 0.6689724, Train Acc: 0.5977, Test Acc: 0.5827, Train AUC: 0.6284, Train APUR: 0.6150, Test AUC: 0.6194, Test AUPR: 0.6143\n",
      "Epoch: 17/100, Loss: 0.6671967, Train Acc: 0.5972, Test Acc: 0.5911, Train AUC: 0.6317, Train APUR: 0.6166, Test AUC: 0.6229, Test AUPR: 0.6164\n",
      "Epoch: 18/100, Loss: 0.6681672, Train Acc: 0.6021, Test Acc: 0.5944, Train AUC: 0.6310, Train APUR: 0.6166, Test AUC: 0.6284, Test AUPR: 0.6207\n",
      "Epoch: 19/100, Loss: 0.6670921, Train Acc: 0.5905, Test Acc: 0.6033, Train AUC: 0.6337, Train APUR: 0.6205, Test AUC: 0.6293, Test AUPR: 0.6226\n",
      "Epoch: 20/100, Loss: 0.6650544, Train Acc: 0.5999, Test Acc: 0.5899, Train AUC: 0.6364, Train APUR: 0.6224, Test AUC: 0.6295, Test AUPR: 0.6235\n",
      "Epoch: 21/100, Loss: 0.6647564, Train Acc: 0.5988, Test Acc: 0.6021, Train AUC: 0.6376, Train APUR: 0.6243, Test AUC: 0.6307, Test AUPR: 0.6245\n",
      "Epoch: 22/100, Loss: 0.6638080, Train Acc: 0.6019, Test Acc: 0.5919, Train AUC: 0.6389, Train APUR: 0.6263, Test AUC: 0.6302, Test AUPR: 0.6241\n",
      "Epoch: 23/100, Loss: 0.6636184, Train Acc: 0.5975, Test Acc: 0.5956, Train AUC: 0.6395, Train APUR: 0.6262, Test AUC: 0.6316, Test AUPR: 0.6255\n",
      "Epoch: 24/100, Loss: 0.6619596, Train Acc: 0.6041, Test Acc: 0.6020, Train AUC: 0.6450, Train APUR: 0.6306, Test AUC: 0.6338, Test AUPR: 0.6275\n",
      "Epoch: 25/100, Loss: 0.6612729, Train Acc: 0.6109, Test Acc: 0.6084, Train AUC: 0.6466, Train APUR: 0.6304, Test AUC: 0.6360, Test AUPR: 0.6289\n",
      "Epoch: 26/100, Loss: 0.6619926, Train Acc: 0.6098, Test Acc: 0.6048, Train AUC: 0.6471, Train APUR: 0.6305, Test AUC: 0.6369, Test AUPR: 0.6290\n",
      "Epoch: 27/100, Loss: 0.6592633, Train Acc: 0.6211, Test Acc: 0.5994, Train AUC: 0.6495, Train APUR: 0.6319, Test AUC: 0.6367, Test AUPR: 0.6287\n",
      "Epoch: 28/100, Loss: 0.6604926, Train Acc: 0.6031, Test Acc: 0.6075, Train AUC: 0.6479, Train APUR: 0.6314, Test AUC: 0.6382, Test AUPR: 0.6302\n",
      "Epoch: 29/100, Loss: 0.6578593, Train Acc: 0.6199, Test Acc: 0.5986, Train AUC: 0.6516, Train APUR: 0.6357, Test AUC: 0.6397, Test AUPR: 0.6322\n",
      "Epoch: 30/100, Loss: 0.6576760, Train Acc: 0.6182, Test Acc: 0.5998, Train AUC: 0.6522, Train APUR: 0.6349, Test AUC: 0.6411, Test AUPR: 0.6319\n",
      "Epoch: 31/100, Loss: 0.6567603, Train Acc: 0.6246, Test Acc: 0.6160, Train AUC: 0.6545, Train APUR: 0.6367, Test AUC: 0.6407, Test AUPR: 0.6302\n",
      "Epoch: 32/100, Loss: 0.6554651, Train Acc: 0.6242, Test Acc: 0.6036, Train AUC: 0.6594, Train APUR: 0.6404, Test AUC: 0.6407, Test AUPR: 0.6286\n",
      "Epoch: 33/100, Loss: 0.6554048, Train Acc: 0.6228, Test Acc: 0.6063, Train AUC: 0.6616, Train APUR: 0.6390, Test AUC: 0.6422, Test AUPR: 0.6285\n",
      "Epoch: 34/100, Loss: 0.6532395, Train Acc: 0.6235, Test Acc: 0.6114, Train AUC: 0.6643, Train APUR: 0.6417, Test AUC: 0.6443, Test AUPR: 0.6311\n",
      "Epoch: 35/100, Loss: 0.6511807, Train Acc: 0.6282, Test Acc: 0.6061, Train AUC: 0.6674, Train APUR: 0.6436, Test AUC: 0.6463, Test AUPR: 0.6335\n",
      "Epoch: 36/100, Loss: 0.6511626, Train Acc: 0.6290, Test Acc: 0.6198, Train AUC: 0.6690, Train APUR: 0.6446, Test AUC: 0.6467, Test AUPR: 0.6332\n",
      "Epoch: 37/100, Loss: 0.6526999, Train Acc: 0.6279, Test Acc: 0.6167, Train AUC: 0.6622, Train APUR: 0.6394, Test AUC: 0.6464, Test AUPR: 0.6304\n",
      "Epoch: 38/100, Loss: 0.6485513, Train Acc: 0.6302, Test Acc: 0.6147, Train AUC: 0.6703, Train APUR: 0.6464, Test AUC: 0.6445, Test AUPR: 0.6256\n",
      "Epoch: 39/100, Loss: 0.6472168, Train Acc: 0.6291, Test Acc: 0.6075, Train AUC: 0.6731, Train APUR: 0.6491, Test AUC: 0.6444, Test AUPR: 0.6262\n",
      "Epoch: 40/100, Loss: 0.6505466, Train Acc: 0.6253, Test Acc: 0.6155, Train AUC: 0.6743, Train APUR: 0.6498, Test AUC: 0.6525, Test AUPR: 0.6304\n",
      "Epoch: 41/100, Loss: 0.6468245, Train Acc: 0.6231, Test Acc: 0.6225, Train AUC: 0.6753, Train APUR: 0.6482, Test AUC: 0.6550, Test AUPR: 0.6361\n",
      "Epoch: 42/100, Loss: 0.6449354, Train Acc: 0.6305, Test Acc: 0.6216, Train AUC: 0.6770, Train APUR: 0.6518, Test AUC: 0.6554, Test AUPR: 0.6387\n",
      "Epoch: 43/100, Loss: 0.6426818, Train Acc: 0.6308, Test Acc: 0.6193, Train AUC: 0.6778, Train APUR: 0.6532, Test AUC: 0.6518, Test AUPR: 0.6342\n",
      "Epoch: 44/100, Loss: 0.6443030, Train Acc: 0.6301, Test Acc: 0.6227, Train AUC: 0.6761, Train APUR: 0.6534, Test AUC: 0.6558, Test AUPR: 0.6355\n",
      "Epoch: 45/100, Loss: 0.6437520, Train Acc: 0.6339, Test Acc: 0.6182, Train AUC: 0.6820, Train APUR: 0.6587, Test AUC: 0.6552, Test AUPR: 0.6310\n",
      "Epoch: 46/100, Loss: 0.6406979, Train Acc: 0.6374, Test Acc: 0.6193, Train AUC: 0.6852, Train APUR: 0.6585, Test AUC: 0.6633, Test AUPR: 0.6369\n",
      "Epoch: 47/100, Loss: 0.6408461, Train Acc: 0.6386, Test Acc: 0.6297, Train AUC: 0.6889, Train APUR: 0.6617, Test AUC: 0.6667, Test AUPR: 0.6421\n",
      "Epoch: 48/100, Loss: 0.6367350, Train Acc: 0.6421, Test Acc: 0.6245, Train AUC: 0.6919, Train APUR: 0.6676, Test AUC: 0.6656, Test AUPR: 0.6436\n",
      "Epoch: 49/100, Loss: 0.6366402, Train Acc: 0.6420, Test Acc: 0.6264, Train AUC: 0.6908, Train APUR: 0.6674, Test AUC: 0.6661, Test AUPR: 0.6465\n",
      "Epoch: 50/100, Loss: 0.6335527, Train Acc: 0.6429, Test Acc: 0.6261, Train AUC: 0.6921, Train APUR: 0.6686, Test AUC: 0.6659, Test AUPR: 0.6472\n",
      "Epoch: 51/100, Loss: 0.6320442, Train Acc: 0.6441, Test Acc: 0.6189, Train AUC: 0.6954, Train APUR: 0.6711, Test AUC: 0.6624, Test AUPR: 0.6438\n",
      "Epoch: 52/100, Loss: 0.6298603, Train Acc: 0.6447, Test Acc: 0.6282, Train AUC: 0.7000, Train APUR: 0.6794, Test AUC: 0.6666, Test AUPR: 0.6420\n",
      "Epoch: 53/100, Loss: 0.6292436, Train Acc: 0.6498, Test Acc: 0.6353, Train AUC: 0.7026, Train APUR: 0.6777, Test AUC: 0.6775, Test AUPR: 0.6493\n",
      "Epoch: 54/100, Loss: 0.6258828, Train Acc: 0.6555, Test Acc: 0.6354, Train AUC: 0.7079, Train APUR: 0.6808, Test AUC: 0.6813, Test AUPR: 0.6534\n",
      "Epoch: 55/100, Loss: 0.6245579, Train Acc: 0.6562, Test Acc: 0.6353, Train AUC: 0.7093, Train APUR: 0.6814, Test AUC: 0.6804, Test AUPR: 0.6636\n",
      "Epoch: 56/100, Loss: 0.6202205, Train Acc: 0.6562, Test Acc: 0.6354, Train AUC: 0.7112, Train APUR: 0.6941, Test AUC: 0.6794, Test AUPR: 0.6656\n",
      "Epoch: 57/100, Loss: 0.6186257, Train Acc: 0.6578, Test Acc: 0.6273, Train AUC: 0.7139, Train APUR: 0.6944, Test AUC: 0.6808, Test AUPR: 0.6742\n",
      "Epoch: 58/100, Loss: 0.6168846, Train Acc: 0.6629, Test Acc: 0.6374, Train AUC: 0.7190, Train APUR: 0.6990, Test AUC: 0.6889, Test AUPR: 0.6764\n",
      "Epoch: 59/100, Loss: 0.6124884, Train Acc: 0.6638, Test Acc: 0.6282, Train AUC: 0.7239, Train APUR: 0.7113, Test AUC: 0.6711, Test AUPR: 0.6510\n",
      "Epoch: 60/100, Loss: 0.6181316, Train Acc: 0.6577, Test Acc: 0.6411, Train AUC: 0.7156, Train APUR: 0.6984, Test AUC: 0.6933, Test AUPR: 0.6720\n",
      "Epoch: 61/100, Loss: 0.6125612, Train Acc: 0.6653, Test Acc: 0.6442, Train AUC: 0.7257, Train APUR: 0.7122, Test AUC: 0.6917, Test AUPR: 0.6762\n",
      "Epoch: 62/100, Loss: 0.6105561, Train Acc: 0.6667, Test Acc: 0.6364, Train AUC: 0.7263, Train APUR: 0.7166, Test AUC: 0.6841, Test AUPR: 0.6645\n",
      "Epoch: 63/100, Loss: 0.6108255, Train Acc: 0.6640, Test Acc: 0.6407, Train AUC: 0.7262, Train APUR: 0.7135, Test AUC: 0.6902, Test AUPR: 0.6720\n",
      "Epoch: 64/100, Loss: 0.6073554, Train Acc: 0.6679, Test Acc: 0.6387, Train AUC: 0.7292, Train APUR: 0.7116, Test AUC: 0.6935, Test AUPR: 0.6858\n",
      "Epoch: 65/100, Loss: 0.6065052, Train Acc: 0.6682, Test Acc: 0.6471, Train AUC: 0.7298, Train APUR: 0.7198, Test AUC: 0.6966, Test AUPR: 0.6868\n",
      "Epoch: 66/100, Loss: 0.6008146, Train Acc: 0.6733, Test Acc: 0.6433, Train AUC: 0.7364, Train APUR: 0.7263, Test AUC: 0.6902, Test AUPR: 0.6734\n",
      "Epoch: 67/100, Loss: 0.6014638, Train Acc: 0.6730, Test Acc: 0.6429, Train AUC: 0.7373, Train APUR: 0.7233, Test AUC: 0.6886, Test AUPR: 0.6690\n",
      "Epoch: 68/100, Loss: 0.6004107, Train Acc: 0.6731, Test Acc: 0.6514, Train AUC: 0.7361, Train APUR: 0.7210, Test AUC: 0.7026, Test AUPR: 0.6830\n",
      "Epoch: 69/100, Loss: 0.5943121, Train Acc: 0.6793, Test Acc: 0.6477, Train AUC: 0.7448, Train APUR: 0.7331, Test AUC: 0.6997, Test AUPR: 0.6830\n",
      "Epoch: 70/100, Loss: 0.5999552, Train Acc: 0.6741, Test Acc: 0.6479, Train AUC: 0.7379, Train APUR: 0.7239, Test AUC: 0.6998, Test AUPR: 0.6806\n",
      "Epoch: 71/100, Loss: 0.5976701, Train Acc: 0.6771, Test Acc: 0.6480, Train AUC: 0.7423, Train APUR: 0.7224, Test AUC: 0.6987, Test AUPR: 0.6832\n",
      "Epoch: 72/100, Loss: 0.5929148, Train Acc: 0.6802, Test Acc: 0.6506, Train AUC: 0.7450, Train APUR: 0.7360, Test AUC: 0.7009, Test AUPR: 0.6896\n",
      "Epoch: 73/100, Loss: 0.5934104, Train Acc: 0.6775, Test Acc: 0.6503, Train AUC: 0.7445, Train APUR: 0.7340, Test AUC: 0.7033, Test AUPR: 0.6931\n",
      "Epoch: 74/100, Loss: 0.5948230, Train Acc: 0.6766, Test Acc: 0.6490, Train AUC: 0.7428, Train APUR: 0.7328, Test AUC: 0.6985, Test AUPR: 0.6833\n",
      "Epoch: 75/100, Loss: 0.5903751, Train Acc: 0.6812, Test Acc: 0.6441, Train AUC: 0.7471, Train APUR: 0.7355, Test AUC: 0.6920, Test AUPR: 0.6747\n",
      "Epoch: 76/100, Loss: 0.5881001, Train Acc: 0.6830, Test Acc: 0.6497, Train AUC: 0.7494, Train APUR: 0.7386, Test AUC: 0.7006, Test AUPR: 0.6807\n",
      "Epoch: 77/100, Loss: 0.5864278, Train Acc: 0.6838, Test Acc: 0.6540, Train AUC: 0.7514, Train APUR: 0.7412, Test AUC: 0.7053, Test AUPR: 0.6864\n",
      "Epoch: 78/100, Loss: 0.5881544, Train Acc: 0.6844, Test Acc: 0.6507, Train AUC: 0.7495, Train APUR: 0.7378, Test AUC: 0.7028, Test AUPR: 0.6880\n",
      "Epoch: 79/100, Loss: 0.5860891, Train Acc: 0.6834, Test Acc: 0.6505, Train AUC: 0.7509, Train APUR: 0.7429, Test AUC: 0.7018, Test AUPR: 0.6875\n",
      "Epoch: 80/100, Loss: 0.5852823, Train Acc: 0.6853, Test Acc: 0.6493, Train AUC: 0.7526, Train APUR: 0.7456, Test AUC: 0.6994, Test AUPR: 0.6851\n",
      "Epoch: 81/100, Loss: 0.5903831, Train Acc: 0.6801, Test Acc: 0.6540, Train AUC: 0.7477, Train APUR: 0.7362, Test AUC: 0.7083, Test AUPR: 0.6955\n",
      "Epoch: 82/100, Loss: 0.5819846, Train Acc: 0.6878, Test Acc: 0.6515, Train AUC: 0.7559, Train APUR: 0.7482, Test AUC: 0.7086, Test AUPR: 0.6920\n",
      "Epoch: 83/100, Loss: 0.5865391, Train Acc: 0.6829, Test Acc: 0.6470, Train AUC: 0.7513, Train APUR: 0.7428, Test AUC: 0.6962, Test AUPR: 0.6710\n",
      "Epoch: 84/100, Loss: 0.5874899, Train Acc: 0.6850, Test Acc: 0.6484, Train AUC: 0.7515, Train APUR: 0.7368, Test AUC: 0.6992, Test AUPR: 0.6745\n",
      "Epoch: 85/100, Loss: 0.5848590, Train Acc: 0.6850, Test Acc: 0.6532, Train AUC: 0.7538, Train APUR: 0.7406, Test AUC: 0.7093, Test AUPR: 0.6896\n",
      "Epoch: 86/100, Loss: 0.5807278, Train Acc: 0.6881, Test Acc: 0.6561, Train AUC: 0.7583, Train APUR: 0.7486, Test AUC: 0.7101, Test AUPR: 0.6927\n",
      "Epoch: 87/100, Loss: 0.5770624, Train Acc: 0.6906, Test Acc: 0.6499, Train AUC: 0.7608, Train APUR: 0.7527, Test AUC: 0.7079, Test AUPR: 0.6933\n",
      "Epoch: 88/100, Loss: 0.5809769, Train Acc: 0.6891, Test Acc: 0.6523, Train AUC: 0.7577, Train APUR: 0.7496, Test AUC: 0.7069, Test AUPR: 0.6946\n",
      "Epoch: 89/100, Loss: 0.5772478, Train Acc: 0.6905, Test Acc: 0.6545, Train AUC: 0.7607, Train APUR: 0.7530, Test AUC: 0.7083, Test AUPR: 0.6970\n",
      "Epoch: 90/100, Loss: 0.5788757, Train Acc: 0.6888, Test Acc: 0.6534, Train AUC: 0.7583, Train APUR: 0.7510, Test AUC: 0.7092, Test AUPR: 0.6946\n",
      "Epoch: 91/100, Loss: 0.5749969, Train Acc: 0.6929, Test Acc: 0.6533, Train AUC: 0.7629, Train APUR: 0.7553, Test AUC: 0.7062, Test AUPR: 0.6881\n",
      "Epoch: 92/100, Loss: 0.5769843, Train Acc: 0.6901, Test Acc: 0.6534, Train AUC: 0.7605, Train APUR: 0.7535, Test AUC: 0.7084, Test AUPR: 0.6888\n",
      "Epoch: 93/100, Loss: 0.5749431, Train Acc: 0.6910, Test Acc: 0.6567, Train AUC: 0.7627, Train APUR: 0.7555, Test AUC: 0.7110, Test AUPR: 0.6905\n",
      "Epoch: 94/100, Loss: 0.5806580, Train Acc: 0.6874, Test Acc: 0.6545, Train AUC: 0.7572, Train APUR: 0.7480, Test AUC: 0.7062, Test AUPR: 0.6918\n",
      "Epoch: 95/100, Loss: 0.5814598, Train Acc: 0.6861, Test Acc: 0.6433, Train AUC: 0.7556, Train APUR: 0.7479, Test AUC: 0.6943, Test AUPR: 0.6778\n",
      "Epoch: 96/100, Loss: 0.5860921, Train Acc: 0.6836, Test Acc: 0.6550, Train AUC: 0.7533, Train APUR: 0.7480, Test AUC: 0.7079, Test AUPR: 0.6928\n",
      "Epoch: 97/100, Loss: 0.5746452, Train Acc: 0.6936, Test Acc: 0.6572, Train AUC: 0.7632, Train APUR: 0.7566, Test AUC: 0.7175, Test AUPR: 0.7051\n",
      "Epoch: 98/100, Loss: 0.5751089, Train Acc: 0.6909, Test Acc: 0.6553, Train AUC: 0.7631, Train APUR: 0.7573, Test AUC: 0.7146, Test AUPR: 0.7027\n",
      "Epoch: 99/100, Loss: 0.5806788, Train Acc: 0.6843, Test Acc: 0.6492, Train AUC: 0.7557, Train APUR: 0.7499, Test AUC: 0.7007, Test AUPR: 0.6819\n",
      "Epoch: 100/100, Loss: 0.5774605, Train Acc: 0.6915, Test Acc: 0.6504, Train AUC: 0.7613, Train APUR: 0.7527, Test AUC: 0.6991, Test AUPR: 0.6772\n",
      "/home/ubuntu/PA-Cancer-Immunotherapy/GNN/train_pa.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(configs['save_model']))\n",
      "Test Acc: 0.6572, Test AUC: 0.7175, Test AUPR: 0.7051\n"
     ]
    }
   ],
   "source": [
    "# train with PA_all_gene \n",
    "# new in this run: in the train_pa file:  without \"args.w_aucloss * aucm_loss.to(device)\" ; without \"pos_weight=pos_weight\"\n",
    "\n",
    "! python train_pa.py --gpu 0 --configs_path configs/PA_all_gene.yml --droup_out 0.1 --split StrictTCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c19dc87-8cb8-4d15-9e5d-e556cce4aed9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100, Loss: 0.6932896, Train Acc: 0.5012, Test Acc: 0.5542, Train AUC: 0.5008, Train APUR: 0.5013, Test AUC: 0.5835, Test AUPR: 0.5811\n",
      "Epoch: 2/100, Loss: 0.6891400, Train Acc: 0.5461, Test Acc: 0.5518, Train AUC: 0.5601, Train APUR: 0.5539, Test AUC: 0.5932, Test AUPR: 0.5925\n",
      "Epoch: 3/100, Loss: 0.6866821, Train Acc: 0.5408, Test Acc: 0.5612, Train AUC: 0.5790, Train APUR: 0.5714, Test AUC: 0.5946, Test AUPR: 0.5931\n",
      "Epoch: 4/100, Loss: 0.6837597, Train Acc: 0.5545, Test Acc: 0.5675, Train AUC: 0.5889, Train APUR: 0.5832, Test AUC: 0.5994, Test AUPR: 0.5972\n",
      "Epoch: 5/100, Loss: 0.6804011, Train Acc: 0.5688, Test Acc: 0.5689, Train AUC: 0.5954, Train APUR: 0.5917, Test AUC: 0.6023, Test AUPR: 0.5991\n",
      "Epoch: 6/100, Loss: 0.6791258, Train Acc: 0.5719, Test Acc: 0.5746, Train AUC: 0.5971, Train APUR: 0.5888, Test AUC: 0.6058, Test AUPR: 0.6030\n",
      "Epoch: 7/100, Loss: 0.6775180, Train Acc: 0.5759, Test Acc: 0.5784, Train AUC: 0.6032, Train APUR: 0.5935, Test AUC: 0.6101, Test AUPR: 0.6031\n",
      "Epoch: 8/100, Loss: 0.6753121, Train Acc: 0.5813, Test Acc: 0.5802, Train AUC: 0.6108, Train APUR: 0.5982, Test AUC: 0.6140, Test AUPR: 0.6039\n",
      "Epoch: 9/100, Loss: 0.6737475, Train Acc: 0.5853, Test Acc: 0.5848, Train AUC: 0.6184, Train APUR: 0.6008, Test AUC: 0.6147, Test AUPR: 0.6038\n",
      "Epoch: 10/100, Loss: 0.6729410, Train Acc: 0.5827, Test Acc: 0.5855, Train AUC: 0.6180, Train APUR: 0.6004, Test AUC: 0.6171, Test AUPR: 0.6060\n",
      "Epoch: 11/100, Loss: 0.6714128, Train Acc: 0.5915, Test Acc: 0.5877, Train AUC: 0.6223, Train APUR: 0.6044, Test AUC: 0.6173, Test AUPR: 0.6079\n",
      "Epoch: 12/100, Loss: 0.6698006, Train Acc: 0.5886, Test Acc: 0.5956, Train AUC: 0.6250, Train APUR: 0.6100, Test AUC: 0.6190, Test AUPR: 0.6104\n",
      "Epoch: 13/100, Loss: 0.6696424, Train Acc: 0.5963, Test Acc: 0.5992, Train AUC: 0.6257, Train APUR: 0.6099, Test AUC: 0.6209, Test AUPR: 0.6131\n",
      "Epoch: 14/100, Loss: 0.6681031, Train Acc: 0.5963, Test Acc: 0.5976, Train AUC: 0.6277, Train APUR: 0.6132, Test AUC: 0.6232, Test AUPR: 0.6139\n",
      "Epoch: 15/100, Loss: 0.6679080, Train Acc: 0.6008, Test Acc: 0.6017, Train AUC: 0.6304, Train APUR: 0.6145, Test AUC: 0.6253, Test AUPR: 0.6153\n",
      "Epoch: 16/100, Loss: 0.6673688, Train Acc: 0.5965, Test Acc: 0.5972, Train AUC: 0.6304, Train APUR: 0.6149, Test AUC: 0.6270, Test AUPR: 0.6178\n",
      "Epoch: 17/100, Loss: 0.6664549, Train Acc: 0.5993, Test Acc: 0.5998, Train AUC: 0.6322, Train APUR: 0.6170, Test AUC: 0.6290, Test AUPR: 0.6205\n",
      "Epoch: 18/100, Loss: 0.6657390, Train Acc: 0.6012, Test Acc: 0.5942, Train AUC: 0.6335, Train APUR: 0.6186, Test AUC: 0.6278, Test AUPR: 0.6214\n",
      "Epoch: 19/100, Loss: 0.6653745, Train Acc: 0.5937, Test Acc: 0.5953, Train AUC: 0.6365, Train APUR: 0.6220, Test AUC: 0.6283, Test AUPR: 0.6228\n",
      "Epoch: 20/100, Loss: 0.6639268, Train Acc: 0.6055, Test Acc: 0.5998, Train AUC: 0.6378, Train APUR: 0.6235, Test AUC: 0.6284, Test AUPR: 0.6233\n",
      "Epoch: 21/100, Loss: 0.6638339, Train Acc: 0.6087, Test Acc: 0.5977, Train AUC: 0.6397, Train APUR: 0.6262, Test AUC: 0.6292, Test AUPR: 0.6239\n",
      "Epoch: 22/100, Loss: 0.6627342, Train Acc: 0.6061, Test Acc: 0.5886, Train AUC: 0.6416, Train APUR: 0.6267, Test AUC: 0.6288, Test AUPR: 0.6236\n",
      "Epoch: 23/100, Loss: 0.6632317, Train Acc: 0.5956, Test Acc: 0.5974, Train AUC: 0.6420, Train APUR: 0.6281, Test AUC: 0.6319, Test AUPR: 0.6277\n",
      "Epoch: 24/100, Loss: 0.6610227, Train Acc: 0.6128, Test Acc: 0.5999, Train AUC: 0.6450, Train APUR: 0.6301, Test AUC: 0.6348, Test AUPR: 0.6303\n",
      "Epoch: 25/100, Loss: 0.6605592, Train Acc: 0.6124, Test Acc: 0.5977, Train AUC: 0.6461, Train APUR: 0.6307, Test AUC: 0.6363, Test AUPR: 0.6313\n",
      "Epoch: 26/100, Loss: 0.6611976, Train Acc: 0.6047, Test Acc: 0.6081, Train AUC: 0.6465, Train APUR: 0.6299, Test AUC: 0.6366, Test AUPR: 0.6314\n",
      "Epoch: 27/100, Loss: 0.6588849, Train Acc: 0.6153, Test Acc: 0.5987, Train AUC: 0.6488, Train APUR: 0.6328, Test AUC: 0.6346, Test AUPR: 0.6300\n",
      "Epoch: 28/100, Loss: 0.6616908, Train Acc: 0.6110, Test Acc: 0.6009, Train AUC: 0.6490, Train APUR: 0.6305, Test AUC: 0.6315, Test AUPR: 0.6266\n",
      "Epoch: 29/100, Loss: 0.6581058, Train Acc: 0.6130, Test Acc: 0.6045, Train AUC: 0.6526, Train APUR: 0.6365, Test AUC: 0.6330, Test AUPR: 0.6266\n",
      "Epoch: 30/100, Loss: 0.6566592, Train Acc: 0.6222, Test Acc: 0.6039, Train AUC: 0.6554, Train APUR: 0.6388, Test AUC: 0.6340, Test AUPR: 0.6280\n",
      "Epoch: 31/100, Loss: 0.6567227, Train Acc: 0.6145, Test Acc: 0.6070, Train AUC: 0.6555, Train APUR: 0.6389, Test AUC: 0.6364, Test AUPR: 0.6307\n",
      "Epoch: 32/100, Loss: 0.6551608, Train Acc: 0.6225, Test Acc: 0.6055, Train AUC: 0.6588, Train APUR: 0.6401, Test AUC: 0.6376, Test AUPR: 0.6319\n",
      "Epoch: 33/100, Loss: 0.6546198, Train Acc: 0.6235, Test Acc: 0.6063, Train AUC: 0.6606, Train APUR: 0.6412, Test AUC: 0.6399, Test AUPR: 0.6323\n",
      "Epoch: 34/100, Loss: 0.6548712, Train Acc: 0.6193, Test Acc: 0.6129, Train AUC: 0.6614, Train APUR: 0.6380, Test AUC: 0.6422, Test AUPR: 0.6361\n",
      "Epoch: 35/100, Loss: 0.6521393, Train Acc: 0.6264, Test Acc: 0.5984, Train AUC: 0.6629, Train APUR: 0.6420, Test AUC: 0.6423, Test AUPR: 0.6370\n",
      "Epoch: 36/100, Loss: 0.6523327, Train Acc: 0.6231, Test Acc: 0.6003, Train AUC: 0.6652, Train APUR: 0.6459, Test AUC: 0.6411, Test AUPR: 0.6337\n",
      "Epoch: 37/100, Loss: 0.6512578, Train Acc: 0.6277, Test Acc: 0.6108, Train AUC: 0.6673, Train APUR: 0.6469, Test AUC: 0.6379, Test AUPR: 0.6295\n",
      "Epoch: 38/100, Loss: 0.6502134, Train Acc: 0.6271, Test Acc: 0.6075, Train AUC: 0.6693, Train APUR: 0.6490, Test AUC: 0.6372, Test AUPR: 0.6280\n",
      "Epoch: 39/100, Loss: 0.6496376, Train Acc: 0.6277, Test Acc: 0.6126, Train AUC: 0.6714, Train APUR: 0.6510, Test AUC: 0.6399, Test AUPR: 0.6305\n",
      "Epoch: 40/100, Loss: 0.6479855, Train Acc: 0.6291, Test Acc: 0.6029, Train AUC: 0.6722, Train APUR: 0.6493, Test AUC: 0.6450, Test AUPR: 0.6350\n",
      "Epoch: 41/100, Loss: 0.6467752, Train Acc: 0.6284, Test Acc: 0.5955, Train AUC: 0.6751, Train APUR: 0.6512, Test AUC: 0.6474, Test AUPR: 0.6368\n",
      "Epoch: 42/100, Loss: 0.6459772, Train Acc: 0.6274, Test Acc: 0.6119, Train AUC: 0.6770, Train APUR: 0.6524, Test AUC: 0.6439, Test AUPR: 0.6358\n",
      "Epoch: 43/100, Loss: 0.6436356, Train Acc: 0.6324, Test Acc: 0.6087, Train AUC: 0.6770, Train APUR: 0.6532, Test AUC: 0.6400, Test AUPR: 0.6320\n",
      "Epoch: 44/100, Loss: 0.6455224, Train Acc: 0.6192, Test Acc: 0.6145, Train AUC: 0.6747, Train APUR: 0.6530, Test AUC: 0.6489, Test AUPR: 0.6381\n",
      "Epoch: 45/100, Loss: 0.6410230, Train Acc: 0.6357, Test Acc: 0.6094, Train AUC: 0.6848, Train APUR: 0.6620, Test AUC: 0.6511, Test AUPR: 0.6405\n",
      "Epoch: 46/100, Loss: 0.6425951, Train Acc: 0.6331, Test Acc: 0.6190, Train AUC: 0.6835, Train APUR: 0.6612, Test AUC: 0.6537, Test AUPR: 0.6418\n",
      "Epoch: 47/100, Loss: 0.6394213, Train Acc: 0.6362, Test Acc: 0.6230, Train AUC: 0.6850, Train APUR: 0.6609, Test AUC: 0.6536, Test AUPR: 0.6411\n",
      "Epoch: 48/100, Loss: 0.6363739, Train Acc: 0.6372, Test Acc: 0.6220, Train AUC: 0.6877, Train APUR: 0.6663, Test AUC: 0.6521, Test AUPR: 0.6393\n",
      "Epoch: 49/100, Loss: 0.6363259, Train Acc: 0.6386, Test Acc: 0.6232, Train AUC: 0.6887, Train APUR: 0.6676, Test AUC: 0.6508, Test AUPR: 0.6394\n",
      "Epoch: 50/100, Loss: 0.6348185, Train Acc: 0.6408, Test Acc: 0.5826, Train AUC: 0.6909, Train APUR: 0.6699, Test AUC: 0.6487, Test AUPR: 0.6317\n",
      "Epoch: 51/100, Loss: 0.6326449, Train Acc: 0.6445, Test Acc: 0.6096, Train AUC: 0.6980, Train APUR: 0.6760, Test AUC: 0.6487, Test AUPR: 0.6290\n",
      "Epoch: 52/100, Loss: 0.6332139, Train Acc: 0.6496, Test Acc: 0.6169, Train AUC: 0.6980, Train APUR: 0.6719, Test AUC: 0.6483, Test AUPR: 0.6315\n",
      "Epoch: 53/100, Loss: 0.6320325, Train Acc: 0.6464, Test Acc: 0.6215, Train AUC: 0.7000, Train APUR: 0.6755, Test AUC: 0.6571, Test AUPR: 0.6419\n",
      "Epoch: 54/100, Loss: 0.6293505, Train Acc: 0.6488, Test Acc: 0.6138, Train AUC: 0.7008, Train APUR: 0.6779, Test AUC: 0.6630, Test AUPR: 0.6506\n",
      "Epoch: 55/100, Loss: 0.6259662, Train Acc: 0.6526, Test Acc: 0.6192, Train AUC: 0.7065, Train APUR: 0.6849, Test AUC: 0.6644, Test AUPR: 0.6497\n",
      "Epoch: 56/100, Loss: 0.6235703, Train Acc: 0.6575, Test Acc: 0.6274, Train AUC: 0.7090, Train APUR: 0.6849, Test AUC: 0.6581, Test AUPR: 0.6409\n",
      "Epoch: 57/100, Loss: 0.6218879, Train Acc: 0.6566, Test Acc: 0.6298, Train AUC: 0.7108, Train APUR: 0.6905, Test AUC: 0.6568, Test AUPR: 0.6414\n",
      "Epoch: 58/100, Loss: 0.6206766, Train Acc: 0.6580, Test Acc: 0.6359, Train AUC: 0.7166, Train APUR: 0.6970, Test AUC: 0.6687, Test AUPR: 0.6484\n",
      "Epoch: 59/100, Loss: 0.6147440, Train Acc: 0.6663, Test Acc: 0.6257, Train AUC: 0.7211, Train APUR: 0.7022, Test AUC: 0.6720, Test AUPR: 0.6526\n",
      "Epoch: 60/100, Loss: 0.6180409, Train Acc: 0.6594, Test Acc: 0.6260, Train AUC: 0.7168, Train APUR: 0.6944, Test AUC: 0.6757, Test AUPR: 0.6667\n",
      "Epoch: 61/100, Loss: 0.6174073, Train Acc: 0.6595, Test Acc: 0.6107, Train AUC: 0.7186, Train APUR: 0.7065, Test AUC: 0.6597, Test AUPR: 0.6431\n",
      "Epoch: 62/100, Loss: 0.6167800, Train Acc: 0.6569, Test Acc: 0.6335, Train AUC: 0.7184, Train APUR: 0.7005, Test AUC: 0.6784, Test AUPR: 0.6601\n",
      "Epoch: 63/100, Loss: 0.6073170, Train Acc: 0.6682, Test Acc: 0.6265, Train AUC: 0.7290, Train APUR: 0.7171, Test AUC: 0.6771, Test AUPR: 0.6584\n",
      "Epoch: 64/100, Loss: 0.6151075, Train Acc: 0.6618, Test Acc: 0.6310, Train AUC: 0.7219, Train APUR: 0.6996, Test AUC: 0.6824, Test AUPR: 0.6614\n",
      "Epoch: 65/100, Loss: 0.6065078, Train Acc: 0.6697, Test Acc: 0.6300, Train AUC: 0.7324, Train APUR: 0.7152, Test AUC: 0.6750, Test AUPR: 0.6574\n",
      "Epoch: 66/100, Loss: 0.6053009, Train Acc: 0.6697, Test Acc: 0.6385, Train AUC: 0.7302, Train APUR: 0.7190, Test AUC: 0.6871, Test AUPR: 0.6749\n",
      "Epoch: 67/100, Loss: 0.6042853, Train Acc: 0.6707, Test Acc: 0.6443, Train AUC: 0.7353, Train APUR: 0.7236, Test AUC: 0.6893, Test AUPR: 0.6809\n",
      "Epoch: 68/100, Loss: 0.6035404, Train Acc: 0.6724, Test Acc: 0.6361, Train AUC: 0.7341, Train APUR: 0.7253, Test AUC: 0.6864, Test AUPR: 0.6750\n",
      "Epoch: 69/100, Loss: 0.5985900, Train Acc: 0.6743, Test Acc: 0.6294, Train AUC: 0.7392, Train APUR: 0.7286, Test AUC: 0.6781, Test AUPR: 0.6651\n",
      "Epoch: 70/100, Loss: 0.5987753, Train Acc: 0.6741, Test Acc: 0.6425, Train AUC: 0.7379, Train APUR: 0.7270, Test AUC: 0.6894, Test AUPR: 0.6772\n",
      "Epoch: 71/100, Loss: 0.5947831, Train Acc: 0.6762, Test Acc: 0.6360, Train AUC: 0.7424, Train APUR: 0.7342, Test AUC: 0.6804, Test AUPR: 0.6725\n",
      "Epoch: 72/100, Loss: 0.6034443, Train Acc: 0.6672, Test Acc: 0.6378, Train AUC: 0.7308, Train APUR: 0.7240, Test AUC: 0.6857, Test AUPR: 0.6742\n",
      "Epoch: 73/100, Loss: 0.5972027, Train Acc: 0.6719, Test Acc: 0.6387, Train AUC: 0.7405, Train APUR: 0.7349, Test AUC: 0.6839, Test AUPR: 0.6727\n",
      "Epoch: 74/100, Loss: 0.5937535, Train Acc: 0.6766, Test Acc: 0.6256, Train AUC: 0.7429, Train APUR: 0.7373, Test AUC: 0.6889, Test AUPR: 0.6800\n",
      "Epoch: 75/100, Loss: 0.5976163, Train Acc: 0.6723, Test Acc: 0.6304, Train AUC: 0.7415, Train APUR: 0.7335, Test AUC: 0.6848, Test AUPR: 0.6741\n",
      "Epoch: 76/100, Loss: 0.5899683, Train Acc: 0.6793, Test Acc: 0.6215, Train AUC: 0.7479, Train APUR: 0.7399, Test AUC: 0.6688, Test AUPR: 0.6579\n",
      "Epoch: 77/100, Loss: 0.5997893, Train Acc: 0.6695, Test Acc: 0.6417, Train AUC: 0.7388, Train APUR: 0.7308, Test AUC: 0.6891, Test AUPR: 0.6764\n",
      "Epoch: 78/100, Loss: 0.5894284, Train Acc: 0.6775, Test Acc: 0.6455, Train AUC: 0.7480, Train APUR: 0.7422, Test AUC: 0.6930, Test AUPR: 0.6805\n",
      "Epoch: 79/100, Loss: 0.5903152, Train Acc: 0.6753, Test Acc: 0.6422, Train AUC: 0.7447, Train APUR: 0.7397, Test AUC: 0.6903, Test AUPR: 0.6767\n",
      "Epoch: 80/100, Loss: 0.5895517, Train Acc: 0.6799, Test Acc: 0.6453, Train AUC: 0.7471, Train APUR: 0.7419, Test AUC: 0.6919, Test AUPR: 0.6761\n",
      "Epoch: 81/100, Loss: 0.5868825, Train Acc: 0.6826, Test Acc: 0.6458, Train AUC: 0.7496, Train APUR: 0.7439, Test AUC: 0.6955, Test AUPR: 0.6764\n",
      "Epoch: 82/100, Loss: 0.5864597, Train Acc: 0.6835, Test Acc: 0.6472, Train AUC: 0.7512, Train APUR: 0.7413, Test AUC: 0.6959, Test AUPR: 0.6769\n",
      "Epoch: 83/100, Loss: 0.5872343, Train Acc: 0.6821, Test Acc: 0.6460, Train AUC: 0.7508, Train APUR: 0.7437, Test AUC: 0.6952, Test AUPR: 0.6758\n",
      "Epoch: 84/100, Loss: 0.5838297, Train Acc: 0.6855, Test Acc: 0.6456, Train AUC: 0.7537, Train APUR: 0.7465, Test AUC: 0.6982, Test AUPR: 0.6790\n",
      "Epoch: 85/100, Loss: 0.5847166, Train Acc: 0.6850, Test Acc: 0.6434, Train AUC: 0.7537, Train APUR: 0.7458, Test AUC: 0.6963, Test AUPR: 0.6787\n",
      "Epoch: 86/100, Loss: 0.5833093, Train Acc: 0.6859, Test Acc: 0.6424, Train AUC: 0.7544, Train APUR: 0.7489, Test AUC: 0.6958, Test AUPR: 0.6860\n",
      "Epoch: 87/100, Loss: 0.5843000, Train Acc: 0.6853, Test Acc: 0.6436, Train AUC: 0.7538, Train APUR: 0.7468, Test AUC: 0.6911, Test AUPR: 0.6827\n",
      "Epoch: 88/100, Loss: 0.5862678, Train Acc: 0.6813, Test Acc: 0.6447, Train AUC: 0.7492, Train APUR: 0.7452, Test AUC: 0.6920, Test AUPR: 0.6791\n",
      "Epoch: 89/100, Loss: 0.5832164, Train Acc: 0.6853, Test Acc: 0.6520, Train AUC: 0.7539, Train APUR: 0.7477, Test AUC: 0.7042, Test AUPR: 0.6918\n",
      "Epoch: 90/100, Loss: 0.5787955, Train Acc: 0.6892, Test Acc: 0.6521, Train AUC: 0.7583, Train APUR: 0.7527, Test AUC: 0.7050, Test AUPR: 0.6907\n",
      "Epoch: 91/100, Loss: 0.5832466, Train Acc: 0.6841, Test Acc: 0.6416, Train AUC: 0.7534, Train APUR: 0.7462, Test AUC: 0.6853, Test AUPR: 0.6665\n",
      "Epoch: 92/100, Loss: 0.5874858, Train Acc: 0.6832, Test Acc: 0.6506, Train AUC: 0.7509, Train APUR: 0.7418, Test AUC: 0.7027, Test AUPR: 0.6884\n",
      "Epoch: 93/100, Loss: 0.5785189, Train Acc: 0.6883, Test Acc: 0.6540, Train AUC: 0.7590, Train APUR: 0.7536, Test AUC: 0.7084, Test AUPR: 0.6962\n",
      "Epoch: 94/100, Loss: 0.5814149, Train Acc: 0.6874, Test Acc: 0.6443, Train AUC: 0.7565, Train APUR: 0.7513, Test AUC: 0.6915, Test AUPR: 0.6766\n",
      "Epoch: 95/100, Loss: 0.5808325, Train Acc: 0.6876, Test Acc: 0.6488, Train AUC: 0.7560, Train APUR: 0.7501, Test AUC: 0.6988, Test AUPR: 0.6849\n",
      "Epoch: 96/100, Loss: 0.5766627, Train Acc: 0.6894, Test Acc: 0.6515, Train AUC: 0.7601, Train APUR: 0.7552, Test AUC: 0.7026, Test AUPR: 0.6898\n",
      "Epoch: 97/100, Loss: 0.5819153, Train Acc: 0.6852, Test Acc: 0.6484, Train AUC: 0.7543, Train APUR: 0.7495, Test AUC: 0.6972, Test AUPR: 0.6814\n",
      "Epoch: 98/100, Loss: 0.5776218, Train Acc: 0.6905, Test Acc: 0.6486, Train AUC: 0.7598, Train APUR: 0.7538, Test AUC: 0.7015, Test AUPR: 0.6876\n",
      "Epoch: 99/100, Loss: 0.5740125, Train Acc: 0.6925, Test Acc: 0.6491, Train AUC: 0.7634, Train APUR: 0.7580, Test AUC: 0.7017, Test AUPR: 0.6881\n",
      "Epoch: 100/100, Loss: 0.5745165, Train Acc: 0.6922, Test Acc: 0.6508, Train AUC: 0.7629, Train APUR: 0.7564, Test AUC: 0.7015, Test AUPR: 0.6865\n",
      "/home/ubuntu/PA-Cancer-Immunotherapy/GNN/train_pa.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(configs['save_model']))\n",
      "Test Acc: 0.6540, Test AUC: 0.7084, Test AUPR: 0.6962\n"
     ]
    }
   ],
   "source": [
    "# train with PA_all_gene \n",
    "# new in this run: in the train_pa file:  without \"args.w_aucloss * aucm_loss.to(device)\" ; without \"pos_weight=pos_weight\"\n",
    "# AND: using embeddings created with tcrpeg trained with both cdr3 and epitope\n",
    "\n",
    "! python train_pa.py --gpu 0 --configs_path configs/PA_all_gene.yml --droup_out 0.1 --split StrictTCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb11a5ff-7708-4663-8874-39a6db2e6acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to compare with...from below:\n",
    "# Test Acc: 0.6460, Test AUC: 0.7038, Test AUPR: 0.6919"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffcb1630-29e6-4d9a-8507-0da838efee05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(gpu=0, lr=0.001, epochs=100, w_celoss=1, w_aucloss=0, add_same_type_edges=False, dynamic_graph=False, dynamic_ratio=0.05, droup_out=0.1, positive_weights=1, dynamic_epochs=30, distance_threshold=10, configs_path='configs/PA_all_allele.yml', split='StrictTCR', dataset='pMTnet')\n",
      "Epoch: 1/100, Loss: 0.6936490, Train Acc: 0.5003, Test Acc: 0.5047, Train AUC: 0.5014, Train APUR: 0.5045, Test AUC: 0.5942, Test AUPR: 0.5897\n",
      "Epoch: 2/100, Loss: 0.6930482, Train Acc: 0.5018, Test Acc: 0.5682, Train AUC: 0.5731, Train APUR: 0.5626, Test AUC: 0.5949, Test AUPR: 0.5931\n",
      "Epoch: 3/100, Loss: 0.6888506, Train Acc: 0.5586, Test Acc: 0.5560, Train AUC: 0.5841, Train APUR: 0.5764, Test AUC: 0.5983, Test AUPR: 0.5955\n",
      "Epoch: 4/100, Loss: 0.6863489, Train Acc: 0.5540, Test Acc: 0.5697, Train AUC: 0.5931, Train APUR: 0.5806, Test AUC: 0.6006, Test AUPR: 0.5959\n",
      "Epoch: 5/100, Loss: 0.6823230, Train Acc: 0.5705, Test Acc: 0.5709, Train AUC: 0.6006, Train APUR: 0.5914, Test AUC: 0.6013, Test AUPR: 0.5956\n",
      "Epoch: 6/100, Loss: 0.6811928, Train Acc: 0.5604, Test Acc: 0.5725, Train AUC: 0.5973, Train APUR: 0.5856, Test AUC: 0.6024, Test AUPR: 0.5949\n",
      "Epoch: 7/100, Loss: 0.6779369, Train Acc: 0.5731, Test Acc: 0.5725, Train AUC: 0.6052, Train APUR: 0.5874, Test AUC: 0.6040, Test AUPR: 0.5928\n",
      "Epoch: 8/100, Loss: 0.6777546, Train Acc: 0.5744, Test Acc: 0.5748, Train AUC: 0.6041, Train APUR: 0.5862, Test AUC: 0.6072, Test AUPR: 0.5956\n",
      "Epoch: 9/100, Loss: 0.6779459, Train Acc: 0.5811, Test Acc: 0.5809, Train AUC: 0.6109, Train APUR: 0.5893, Test AUC: 0.6124, Test AUPR: 0.5990\n",
      "Epoch: 10/100, Loss: 0.6731699, Train Acc: 0.5859, Test Acc: 0.5845, Train AUC: 0.6153, Train APUR: 0.5948, Test AUC: 0.6180, Test AUPR: 0.6015\n",
      "Epoch: 11/100, Loss: 0.6723903, Train Acc: 0.5876, Test Acc: 0.5938, Train AUC: 0.6207, Train APUR: 0.5968, Test AUC: 0.6193, Test AUPR: 0.6024\n",
      "Epoch: 12/100, Loss: 0.6706770, Train Acc: 0.5926, Test Acc: 0.5833, Train AUC: 0.6256, Train APUR: 0.6026, Test AUC: 0.6181, Test AUPR: 0.6013\n",
      "Epoch: 13/100, Loss: 0.6708099, Train Acc: 0.5861, Test Acc: 0.5866, Train AUC: 0.6242, Train APUR: 0.5981, Test AUC: 0.6202, Test AUPR: 0.6032\n",
      "Epoch: 14/100, Loss: 0.6688290, Train Acc: 0.5948, Test Acc: 0.5947, Train AUC: 0.6300, Train APUR: 0.6035, Test AUC: 0.6239, Test AUPR: 0.6081\n",
      "Epoch: 15/100, Loss: 0.6668516, Train Acc: 0.6036, Test Acc: 0.5909, Train AUC: 0.6317, Train APUR: 0.6086, Test AUC: 0.6270, Test AUPR: 0.6132\n",
      "Epoch: 16/100, Loss: 0.6675407, Train Acc: 0.5950, Test Acc: 0.6015, Train AUC: 0.6322, Train APUR: 0.6096, Test AUC: 0.6287, Test AUPR: 0.6157\n",
      "Epoch: 17/100, Loss: 0.6649955, Train Acc: 0.6050, Test Acc: 0.5988, Train AUC: 0.6351, Train APUR: 0.6101, Test AUC: 0.6298, Test AUPR: 0.6176\n",
      "Epoch: 18/100, Loss: 0.6645507, Train Acc: 0.6030, Test Acc: 0.6038, Train AUC: 0.6369, Train APUR: 0.6154, Test AUC: 0.6309, Test AUPR: 0.6193\n",
      "Epoch: 19/100, Loss: 0.6633465, Train Acc: 0.6055, Test Acc: 0.5956, Train AUC: 0.6389, Train APUR: 0.6159, Test AUC: 0.6329, Test AUPR: 0.6209\n",
      "Epoch: 20/100, Loss: 0.6641344, Train Acc: 0.6027, Test Acc: 0.6094, Train AUC: 0.6406, Train APUR: 0.6225, Test AUC: 0.6343, Test AUPR: 0.6222\n",
      "Epoch: 21/100, Loss: 0.6611978, Train Acc: 0.6103, Test Acc: 0.6055, Train AUC: 0.6423, Train APUR: 0.6248, Test AUC: 0.6360, Test AUPR: 0.6248\n",
      "Epoch: 22/100, Loss: 0.6609500, Train Acc: 0.6089, Test Acc: 0.6066, Train AUC: 0.6445, Train APUR: 0.6254, Test AUC: 0.6385, Test AUPR: 0.6288\n",
      "Epoch: 23/100, Loss: 0.6594664, Train Acc: 0.6133, Test Acc: 0.6077, Train AUC: 0.6475, Train APUR: 0.6278, Test AUC: 0.6403, Test AUPR: 0.6316\n",
      "Epoch: 24/100, Loss: 0.6590491, Train Acc: 0.6105, Test Acc: 0.6070, Train AUC: 0.6490, Train APUR: 0.6279, Test AUC: 0.6404, Test AUPR: 0.6320\n",
      "Epoch: 25/100, Loss: 0.6573333, Train Acc: 0.6122, Test Acc: 0.6034, Train AUC: 0.6510, Train APUR: 0.6319, Test AUC: 0.6371, Test AUPR: 0.6302\n",
      "Epoch: 26/100, Loss: 0.6567357, Train Acc: 0.6102, Test Acc: 0.6049, Train AUC: 0.6527, Train APUR: 0.6339, Test AUC: 0.6372, Test AUPR: 0.6302\n",
      "Epoch: 27/100, Loss: 0.6556519, Train Acc: 0.6150, Test Acc: 0.6057, Train AUC: 0.6548, Train APUR: 0.6357, Test AUC: 0.6399, Test AUPR: 0.6309\n",
      "Epoch: 28/100, Loss: 0.6548594, Train Acc: 0.6133, Test Acc: 0.6112, Train AUC: 0.6570, Train APUR: 0.6388, Test AUC: 0.6407, Test AUPR: 0.6308\n",
      "Epoch: 29/100, Loss: 0.6536727, Train Acc: 0.6141, Test Acc: 0.6091, Train AUC: 0.6571, Train APUR: 0.6397, Test AUC: 0.6403, Test AUPR: 0.6301\n",
      "Epoch: 30/100, Loss: 0.6526599, Train Acc: 0.6147, Test Acc: 0.6030, Train AUC: 0.6597, Train APUR: 0.6415, Test AUC: 0.6420, Test AUPR: 0.6320\n",
      "Epoch: 31/100, Loss: 0.6518559, Train Acc: 0.6215, Test Acc: 0.6087, Train AUC: 0.6622, Train APUR: 0.6424, Test AUC: 0.6458, Test AUPR: 0.6360\n",
      "Epoch: 32/100, Loss: 0.6499871, Train Acc: 0.6235, Test Acc: 0.6086, Train AUC: 0.6662, Train APUR: 0.6460, Test AUC: 0.6480, Test AUPR: 0.6390\n",
      "Epoch: 33/100, Loss: 0.6492683, Train Acc: 0.6217, Test Acc: 0.6122, Train AUC: 0.6662, Train APUR: 0.6453, Test AUC: 0.6458, Test AUPR: 0.6366\n",
      "Epoch: 34/100, Loss: 0.6485117, Train Acc: 0.6238, Test Acc: 0.6056, Train AUC: 0.6690, Train APUR: 0.6458, Test AUC: 0.6413, Test AUPR: 0.6308\n",
      "Epoch: 35/100, Loss: 0.6493654, Train Acc: 0.6195, Test Acc: 0.5766, Train AUC: 0.6685, Train APUR: 0.6486, Test AUC: 0.6460, Test AUPR: 0.6337\n",
      "Epoch: 36/100, Loss: 0.6466514, Train Acc: 0.6174, Test Acc: 0.5808, Train AUC: 0.6757, Train APUR: 0.6548, Test AUC: 0.6468, Test AUPR: 0.6342\n",
      "Epoch: 37/100, Loss: 0.6446078, Train Acc: 0.6227, Test Acc: 0.6129, Train AUC: 0.6767, Train APUR: 0.6537, Test AUC: 0.6467, Test AUPR: 0.6362\n",
      "Epoch: 38/100, Loss: 0.6434554, Train Acc: 0.6301, Test Acc: 0.6128, Train AUC: 0.6777, Train APUR: 0.6542, Test AUC: 0.6470, Test AUPR: 0.6359\n",
      "Epoch: 39/100, Loss: 0.6421142, Train Acc: 0.6316, Test Acc: 0.6031, Train AUC: 0.6785, Train APUR: 0.6549, Test AUC: 0.6491, Test AUPR: 0.6343\n",
      "Epoch: 40/100, Loss: 0.6414933, Train Acc: 0.6289, Test Acc: 0.5913, Train AUC: 0.6810, Train APUR: 0.6588, Test AUC: 0.6496, Test AUPR: 0.6331\n",
      "Epoch: 41/100, Loss: 0.6396660, Train Acc: 0.6283, Test Acc: 0.6180, Train AUC: 0.6830, Train APUR: 0.6602, Test AUC: 0.6502, Test AUPR: 0.6331\n",
      "Epoch: 42/100, Loss: 0.6379995, Train Acc: 0.6341, Test Acc: 0.6061, Train AUC: 0.6869, Train APUR: 0.6620, Test AUC: 0.6500, Test AUPR: 0.6337\n",
      "Epoch: 43/100, Loss: 0.6367451, Train Acc: 0.6359, Test Acc: 0.5944, Train AUC: 0.6890, Train APUR: 0.6643, Test AUC: 0.6472, Test AUPR: 0.6340\n",
      "Epoch: 44/100, Loss: 0.6367634, Train Acc: 0.6388, Test Acc: 0.5888, Train AUC: 0.6892, Train APUR: 0.6651, Test AUC: 0.6475, Test AUPR: 0.6365\n",
      "Epoch: 45/100, Loss: 0.6342456, Train Acc: 0.6334, Test Acc: 0.5942, Train AUC: 0.6907, Train APUR: 0.6668, Test AUC: 0.6498, Test AUPR: 0.6374\n",
      "Epoch: 46/100, Loss: 0.6330569, Train Acc: 0.6351, Test Acc: 0.6135, Train AUC: 0.6923, Train APUR: 0.6687, Test AUC: 0.6495, Test AUPR: 0.6320\n",
      "Epoch: 47/100, Loss: 0.6309868, Train Acc: 0.6424, Test Acc: 0.6106, Train AUC: 0.6982, Train APUR: 0.6717, Test AUC: 0.6465, Test AUPR: 0.6287\n",
      "Epoch: 48/100, Loss: 0.6295362, Train Acc: 0.6431, Test Acc: 0.6014, Train AUC: 0.6987, Train APUR: 0.6737, Test AUC: 0.6502, Test AUPR: 0.6326\n",
      "Epoch: 49/100, Loss: 0.6282649, Train Acc: 0.6452, Test Acc: 0.6094, Train AUC: 0.7015, Train APUR: 0.6759, Test AUC: 0.6570, Test AUPR: 0.6425\n",
      "Epoch: 50/100, Loss: 0.6279516, Train Acc: 0.6496, Test Acc: 0.6092, Train AUC: 0.7028, Train APUR: 0.6754, Test AUC: 0.6543, Test AUPR: 0.6400\n",
      "Epoch: 51/100, Loss: 0.6262997, Train Acc: 0.6467, Test Acc: 0.6091, Train AUC: 0.7025, Train APUR: 0.6779, Test AUC: 0.6540, Test AUPR: 0.6360\n",
      "Epoch: 52/100, Loss: 0.6238717, Train Acc: 0.6536, Test Acc: 0.6076, Train AUC: 0.7090, Train APUR: 0.6839, Test AUC: 0.6479, Test AUPR: 0.6307\n",
      "Epoch: 53/100, Loss: 0.6228711, Train Acc: 0.6564, Test Acc: 0.5951, Train AUC: 0.7125, Train APUR: 0.6861, Test AUC: 0.6381, Test AUPR: 0.6274\n",
      "Epoch: 54/100, Loss: 0.6222505, Train Acc: 0.6523, Test Acc: 0.5989, Train AUC: 0.7091, Train APUR: 0.6891, Test AUC: 0.6504, Test AUPR: 0.6380\n",
      "Epoch: 55/100, Loss: 0.6222043, Train Acc: 0.6567, Test Acc: 0.6092, Train AUC: 0.7113, Train APUR: 0.6870, Test AUC: 0.6523, Test AUPR: 0.6413\n",
      "Epoch: 56/100, Loss: 0.6175835, Train Acc: 0.6578, Test Acc: 0.6023, Train AUC: 0.7166, Train APUR: 0.6959, Test AUC: 0.6363, Test AUPR: 0.6279\n",
      "Epoch: 57/100, Loss: 0.6229786, Train Acc: 0.6492, Test Acc: 0.6059, Train AUC: 0.7084, Train APUR: 0.6882, Test AUC: 0.6596, Test AUPR: 0.6478\n",
      "Epoch: 58/100, Loss: 0.6152426, Train Acc: 0.6615, Test Acc: 0.6058, Train AUC: 0.7205, Train APUR: 0.6950, Test AUC: 0.6588, Test AUPR: 0.6439\n",
      "Epoch: 59/100, Loss: 0.6226837, Train Acc: 0.6544, Test Acc: 0.6116, Train AUC: 0.7120, Train APUR: 0.6885, Test AUC: 0.6513, Test AUPR: 0.6365\n",
      "Epoch: 60/100, Loss: 0.6144066, Train Acc: 0.6625, Test Acc: 0.5957, Train AUC: 0.7195, Train APUR: 0.7002, Test AUC: 0.6361, Test AUPR: 0.6257\n",
      "Epoch: 61/100, Loss: 0.6199492, Train Acc: 0.6558, Test Acc: 0.6153, Train AUC: 0.7144, Train APUR: 0.6934, Test AUC: 0.6601, Test AUPR: 0.6413\n",
      "Epoch: 62/100, Loss: 0.6129762, Train Acc: 0.6654, Test Acc: 0.6048, Train AUC: 0.7252, Train APUR: 0.7015, Test AUC: 0.6618, Test AUPR: 0.6469\n",
      "Epoch: 63/100, Loss: 0.6155160, Train Acc: 0.6594, Test Acc: 0.6176, Train AUC: 0.7220, Train APUR: 0.6995, Test AUC: 0.6614, Test AUPR: 0.6507\n",
      "Epoch: 64/100, Loss: 0.6087337, Train Acc: 0.6662, Test Acc: 0.6204, Train AUC: 0.7267, Train APUR: 0.7067, Test AUC: 0.6581, Test AUPR: 0.6475\n",
      "Epoch: 65/100, Loss: 0.6109155, Train Acc: 0.6654, Test Acc: 0.6266, Train AUC: 0.7251, Train APUR: 0.7079, Test AUC: 0.6636, Test AUPR: 0.6526\n",
      "Epoch: 66/100, Loss: 0.6064987, Train Acc: 0.6708, Test Acc: 0.5818, Train AUC: 0.7331, Train APUR: 0.7171, Test AUC: 0.6551, Test AUPR: 0.6457\n",
      "Epoch: 67/100, Loss: 0.6043339, Train Acc: 0.6692, Test Acc: 0.5751, Train AUC: 0.7354, Train APUR: 0.7178, Test AUC: 0.6434, Test AUPR: 0.6335\n",
      "Epoch: 68/100, Loss: 0.6058922, Train Acc: 0.6660, Test Acc: 0.5988, Train AUC: 0.7330, Train APUR: 0.7126, Test AUC: 0.6508, Test AUPR: 0.6390\n",
      "Epoch: 69/100, Loss: 0.6007074, Train Acc: 0.6734, Test Acc: 0.6191, Train AUC: 0.7374, Train APUR: 0.7182, Test AUC: 0.6567, Test AUPR: 0.6432\n",
      "Epoch: 70/100, Loss: 0.6021779, Train Acc: 0.6752, Test Acc: 0.6150, Train AUC: 0.7383, Train APUR: 0.7190, Test AUC: 0.6588, Test AUPR: 0.6455\n",
      "Epoch: 71/100, Loss: 0.5985572, Train Acc: 0.6780, Test Acc: 0.6066, Train AUC: 0.7413, Train APUR: 0.7217, Test AUC: 0.6634, Test AUPR: 0.6463\n",
      "Epoch: 72/100, Loss: 0.5971461, Train Acc: 0.6776, Test Acc: 0.6103, Train AUC: 0.7445, Train APUR: 0.7246, Test AUC: 0.6643, Test AUPR: 0.6475\n",
      "Epoch: 73/100, Loss: 0.5982404, Train Acc: 0.6779, Test Acc: 0.6009, Train AUC: 0.7432, Train APUR: 0.7271, Test AUC: 0.6540, Test AUPR: 0.6420\n",
      "Epoch: 74/100, Loss: 0.5943700, Train Acc: 0.6803, Test Acc: 0.5905, Train AUC: 0.7473, Train APUR: 0.7319, Test AUC: 0.6525, Test AUPR: 0.6404\n",
      "Epoch: 75/100, Loss: 0.5963053, Train Acc: 0.6732, Test Acc: 0.6204, Train AUC: 0.7427, Train APUR: 0.7269, Test AUC: 0.6664, Test AUPR: 0.6511\n",
      "Epoch: 76/100, Loss: 0.5934761, Train Acc: 0.6792, Test Acc: 0.6248, Train AUC: 0.7455, Train APUR: 0.7247, Test AUC: 0.6701, Test AUPR: 0.6582\n",
      "Epoch: 77/100, Loss: 0.5919976, Train Acc: 0.6840, Test Acc: 0.6283, Train AUC: 0.7470, Train APUR: 0.7290, Test AUC: 0.6691, Test AUPR: 0.6574\n",
      "Epoch: 78/100, Loss: 0.5920004, Train Acc: 0.6820, Test Acc: 0.6200, Train AUC: 0.7471, Train APUR: 0.7298, Test AUC: 0.6664, Test AUPR: 0.6536\n",
      "Epoch: 79/100, Loss: 0.5899962, Train Acc: 0.6831, Test Acc: 0.5989, Train AUC: 0.7520, Train APUR: 0.7388, Test AUC: 0.6578, Test AUPR: 0.6454\n",
      "Epoch: 80/100, Loss: 0.5881596, Train Acc: 0.6816, Test Acc: 0.5957, Train AUC: 0.7538, Train APUR: 0.7401, Test AUC: 0.6566, Test AUPR: 0.6445\n",
      "Epoch: 81/100, Loss: 0.5876577, Train Acc: 0.6785, Test Acc: 0.6226, Train AUC: 0.7539, Train APUR: 0.7408, Test AUC: 0.6706, Test AUPR: 0.6561\n",
      "Epoch: 82/100, Loss: 0.5871167, Train Acc: 0.6828, Test Acc: 0.6221, Train AUC: 0.7535, Train APUR: 0.7431, Test AUC: 0.6657, Test AUPR: 0.6508\n",
      "Epoch: 83/100, Loss: 0.5861448, Train Acc: 0.6884, Test Acc: 0.6231, Train AUC: 0.7547, Train APUR: 0.7428, Test AUC: 0.6675, Test AUPR: 0.6532\n",
      "Epoch: 84/100, Loss: 0.5835283, Train Acc: 0.6908, Test Acc: 0.6297, Train AUC: 0.7568, Train APUR: 0.7447, Test AUC: 0.6746, Test AUPR: 0.6612\n",
      "Epoch: 85/100, Loss: 0.5833016, Train Acc: 0.6911, Test Acc: 0.6138, Train AUC: 0.7578, Train APUR: 0.7463, Test AUC: 0.6751, Test AUPR: 0.6678\n",
      "Epoch: 86/100, Loss: 0.5794650, Train Acc: 0.6882, Test Acc: 0.5913, Train AUC: 0.7632, Train APUR: 0.7556, Test AUC: 0.6638, Test AUPR: 0.6595\n",
      "Epoch: 87/100, Loss: 0.5814611, Train Acc: 0.6853, Test Acc: 0.6147, Train AUC: 0.7593, Train APUR: 0.7514, Test AUC: 0.6635, Test AUPR: 0.6521\n",
      "Epoch: 88/100, Loss: 0.5774757, Train Acc: 0.6910, Test Acc: 0.6164, Train AUC: 0.7649, Train APUR: 0.7568, Test AUC: 0.6661, Test AUPR: 0.6477\n",
      "Epoch: 89/100, Loss: 0.5788646, Train Acc: 0.6888, Test Acc: 0.6097, Train AUC: 0.7632, Train APUR: 0.7542, Test AUC: 0.6652, Test AUPR: 0.6445\n",
      "Epoch: 90/100, Loss: 0.5791593, Train Acc: 0.6911, Test Acc: 0.6217, Train AUC: 0.7624, Train APUR: 0.7432, Test AUC: 0.6740, Test AUPR: 0.6539\n",
      "Epoch: 91/100, Loss: 0.5715981, Train Acc: 0.6950, Test Acc: 0.6232, Train AUC: 0.7706, Train APUR: 0.7637, Test AUC: 0.6685, Test AUPR: 0.6564\n",
      "Epoch: 92/100, Loss: 0.5758286, Train Acc: 0.6912, Test Acc: 0.6266, Train AUC: 0.7686, Train APUR: 0.7638, Test AUC: 0.6731, Test AUPR: 0.6612\n",
      "Epoch: 93/100, Loss: 0.5731969, Train Acc: 0.6931, Test Acc: 0.6225, Train AUC: 0.7700, Train APUR: 0.7631, Test AUC: 0.6824, Test AUPR: 0.6690\n",
      "Epoch: 94/100, Loss: 0.5715327, Train Acc: 0.6923, Test Acc: 0.6358, Train AUC: 0.7698, Train APUR: 0.7649, Test AUC: 0.6853, Test AUPR: 0.6689\n",
      "Epoch: 95/100, Loss: 0.5704764, Train Acc: 0.6989, Test Acc: 0.6357, Train AUC: 0.7705, Train APUR: 0.7637, Test AUC: 0.6800, Test AUPR: 0.6637\n",
      "Epoch: 96/100, Loss: 0.5709136, Train Acc: 0.6984, Test Acc: 0.6332, Train AUC: 0.7706, Train APUR: 0.7610, Test AUC: 0.6861, Test AUPR: 0.6759\n",
      "Epoch: 97/100, Loss: 0.5758517, Train Acc: 0.6867, Test Acc: 0.6165, Train AUC: 0.7648, Train APUR: 0.7661, Test AUC: 0.6691, Test AUPR: 0.6557\n",
      "Epoch: 98/100, Loss: 0.5781586, Train Acc: 0.6884, Test Acc: 0.6155, Train AUC: 0.7641, Train APUR: 0.7577, Test AUC: 0.6819, Test AUPR: 0.6656\n",
      "Epoch: 99/100, Loss: 0.5652913, Train Acc: 0.6946, Test Acc: 0.6236, Train AUC: 0.7778, Train APUR: 0.7689, Test AUC: 0.6828, Test AUPR: 0.6673\n",
      "Epoch: 100/100, Loss: 0.5697231, Train Acc: 0.6925, Test Acc: 0.6278, Train AUC: 0.7717, Train APUR: 0.7694, Test AUC: 0.6740, Test AUPR: 0.6585\n",
      "/home/ubuntu/PA-Cancer-Immunotherapy/GNN/train_pa.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(configs['save_model']))\n",
      "Test Acc: 0.6332, Test AUC: 0.6861, Test AUPR: 0.6759\n"
     ]
    }
   ],
   "source": [
    "# train with PA_all_allele \n",
    "# new in this run: in the train_pa file:  without \"args.w_aucloss * aucm_loss.to(device)\" ; without \"pos_weight=pos_weight\"\n",
    "# AND: using embeddings created with tcrpeg trained with both cdr3 and epitope\n",
    "\n",
    "! python train_pa.py --gpu 0 --configs_path configs/PA_all_allele.yml --droup_out 0.1 --split StrictTCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a31e4fe8-010a-4216-ae7b-219e8f131472",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(gpu=0, lr=0.001, epochs=100, w_celoss=1, w_aucloss=0, add_same_type_edges=False, dynamic_graph=False, dynamic_ratio=0.05, droup_out=0.1, positive_weights=1, dynamic_epochs=30, distance_threshold=10, configs_path='configs/PA_all_allele.yml', split='StrictTCR', dataset='pMTnet')\n",
      "models/PA_all/allele_embeddings.pkl\n",
      "['allele_fold_0.csv', 'allele_fold_1.csv', 'allele_fold_2.csv', 'allele_fold_3.csv']\n",
      "['allele_fold_4.csv']\n",
      "Epoch: 1/100, Loss: 0.6931294, Train Acc: 0.5021, Test Acc: 0.5409, Train AUC: 0.5067, Train APUR: 0.5076, Test AUC: 0.5641, Test AUPR: 0.5554\n",
      "Epoch: 2/100, Loss: 0.6927062, Train Acc: 0.5423, Test Acc: 0.5432, Train AUC: 0.5587, Train APUR: 0.5369, Test AUC: 0.5704, Test AUPR: 0.5625\n",
      "Epoch: 3/100, Loss: 0.6924415, Train Acc: 0.5393, Test Acc: 0.5428, Train AUC: 0.5640, Train APUR: 0.5497, Test AUC: 0.5708, Test AUPR: 0.5616\n",
      "Epoch: 4/100, Loss: 0.6919569, Train Acc: 0.5442, Test Acc: 0.5424, Train AUC: 0.5672, Train APUR: 0.5496, Test AUC: 0.5701, Test AUPR: 0.5604\n",
      "Epoch: 5/100, Loss: 0.6913627, Train Acc: 0.5456, Test Acc: 0.5436, Train AUC: 0.5662, Train APUR: 0.5499, Test AUC: 0.5682, Test AUPR: 0.5584\n",
      "Epoch: 6/100, Loss: 0.6907263, Train Acc: 0.5430, Test Acc: 0.5435, Train AUC: 0.5667, Train APUR: 0.5540, Test AUC: 0.5676, Test AUPR: 0.5580\n",
      "Epoch: 7/100, Loss: 0.6897939, Train Acc: 0.5456, Test Acc: 0.5435, Train AUC: 0.5690, Train APUR: 0.5540, Test AUC: 0.5675, Test AUPR: 0.5584\n",
      "Epoch: 8/100, Loss: 0.6891215, Train Acc: 0.5466, Test Acc: 0.5444, Train AUC: 0.5683, Train APUR: 0.5509, Test AUC: 0.5676, Test AUPR: 0.5585\n",
      "Epoch: 9/100, Loss: 0.6879091, Train Acc: 0.5453, Test Acc: 0.5443, Train AUC: 0.5716, Train APUR: 0.5572, Test AUC: 0.5679, Test AUPR: 0.5588\n",
      "Epoch: 10/100, Loss: 0.6878959, Train Acc: 0.5482, Test Acc: 0.5497, Train AUC: 0.5635, Train APUR: 0.5475, Test AUC: 0.5692, Test AUPR: 0.5606\n",
      "Epoch: 11/100, Loss: 0.6865515, Train Acc: 0.5521, Test Acc: 0.5496, Train AUC: 0.5700, Train APUR: 0.5524, Test AUC: 0.5697, Test AUPR: 0.5616\n",
      "Epoch: 12/100, Loss: 0.6865321, Train Acc: 0.5517, Test Acc: 0.5493, Train AUC: 0.5671, Train APUR: 0.5497, Test AUC: 0.5698, Test AUPR: 0.5610\n",
      "Epoch: 13/100, Loss: 0.6858210, Train Acc: 0.5503, Test Acc: 0.5495, Train AUC: 0.5719, Train APUR: 0.5555, Test AUC: 0.5705, Test AUPR: 0.5611\n",
      "Epoch: 14/100, Loss: 0.6853812, Train Acc: 0.5533, Test Acc: 0.5495, Train AUC: 0.5730, Train APUR: 0.5537, Test AUC: 0.5712, Test AUPR: 0.5608\n",
      "Epoch: 15/100, Loss: 0.6857321, Train Acc: 0.5523, Test Acc: 0.5497, Train AUC: 0.5716, Train APUR: 0.5529, Test AUC: 0.5715, Test AUPR: 0.5607\n",
      "Epoch: 16/100, Loss: 0.6855177, Train Acc: 0.5535, Test Acc: 0.5495, Train AUC: 0.5721, Train APUR: 0.5526, Test AUC: 0.5719, Test AUPR: 0.5597\n",
      "Epoch: 17/100, Loss: 0.6850938, Train Acc: 0.5529, Test Acc: 0.5493, Train AUC: 0.5739, Train APUR: 0.5547, Test AUC: 0.5733, Test AUPR: 0.5603\n",
      "Epoch: 18/100, Loss: 0.6843870, Train Acc: 0.5526, Test Acc: 0.5522, Train AUC: 0.5772, Train APUR: 0.5552, Test AUC: 0.5740, Test AUPR: 0.5585\n",
      "Epoch: 19/100, Loss: 0.6837073, Train Acc: 0.5548, Test Acc: 0.5552, Train AUC: 0.5811, Train APUR: 0.5629, Test AUC: 0.5765, Test AUPR: 0.5593\n",
      "Epoch: 20/100, Loss: 0.6835620, Train Acc: 0.5571, Test Acc: 0.5583, Train AUC: 0.5799, Train APUR: 0.5592, Test AUC: 0.5774, Test AUPR: 0.5574\n",
      "Epoch: 21/100, Loss: 0.6826701, Train Acc: 0.5616, Test Acc: 0.5606, Train AUC: 0.5827, Train APUR: 0.5563, Test AUC: 0.5785, Test AUPR: 0.5567\n",
      "Epoch: 22/100, Loss: 0.6822349, Train Acc: 0.5639, Test Acc: 0.5647, Train AUC: 0.5854, Train APUR: 0.5570, Test AUC: 0.5802, Test AUPR: 0.5572\n",
      "Epoch: 23/100, Loss: 0.6820077, Train Acc: 0.5647, Test Acc: 0.5627, Train AUC: 0.5855, Train APUR: 0.5560, Test AUC: 0.5816, Test AUPR: 0.5577\n",
      "Epoch: 24/100, Loss: 0.6807979, Train Acc: 0.5691, Test Acc: 0.5644, Train AUC: 0.5913, Train APUR: 0.5614, Test AUC: 0.5825, Test AUPR: 0.5581\n",
      "Epoch: 25/100, Loss: 0.6807291, Train Acc: 0.5673, Test Acc: 0.5634, Train AUC: 0.5893, Train APUR: 0.5588, Test AUC: 0.5842, Test AUPR: 0.5587\n",
      "Epoch: 26/100, Loss: 0.6806046, Train Acc: 0.5684, Test Acc: 0.5626, Train AUC: 0.5903, Train APUR: 0.5585, Test AUC: 0.5859, Test AUPR: 0.5592\n",
      "Epoch: 27/100, Loss: 0.6799611, Train Acc: 0.5705, Test Acc: 0.5706, Train AUC: 0.5921, Train APUR: 0.5591, Test AUC: 0.5871, Test AUPR: 0.5600\n",
      "Epoch: 28/100, Loss: 0.6809171, Train Acc: 0.5683, Test Acc: 0.5680, Train AUC: 0.5893, Train APUR: 0.5553, Test AUC: 0.5887, Test AUPR: 0.5609\n",
      "Epoch: 29/100, Loss: 0.6793398, Train Acc: 0.5712, Test Acc: 0.5682, Train AUC: 0.5938, Train APUR: 0.5609, Test AUC: 0.5903, Test AUPR: 0.5620\n",
      "Epoch: 30/100, Loss: 0.6783671, Train Acc: 0.5767, Test Acc: 0.5678, Train AUC: 0.5981, Train APUR: 0.5657, Test AUC: 0.5920, Test AUPR: 0.5635\n",
      "Epoch: 31/100, Loss: 0.6788487, Train Acc: 0.5727, Test Acc: 0.5719, Train AUC: 0.5956, Train APUR: 0.5617, Test AUC: 0.5935, Test AUPR: 0.5649\n",
      "Epoch: 32/100, Loss: 0.6781099, Train Acc: 0.5768, Test Acc: 0.5741, Train AUC: 0.5970, Train APUR: 0.5606, Test AUC: 0.5954, Test AUPR: 0.5660\n",
      "Epoch: 33/100, Loss: 0.6775299, Train Acc: 0.5803, Test Acc: 0.5749, Train AUC: 0.6000, Train APUR: 0.5655, Test AUC: 0.5966, Test AUPR: 0.5667\n",
      "Epoch: 34/100, Loss: 0.6764212, Train Acc: 0.5779, Test Acc: 0.5736, Train AUC: 0.6037, Train APUR: 0.5685, Test AUC: 0.5972, Test AUPR: 0.5666\n",
      "Epoch: 35/100, Loss: 0.6767429, Train Acc: 0.5799, Test Acc: 0.5827, Train AUC: 0.6039, Train APUR: 0.5661, Test AUC: 0.5973, Test AUPR: 0.5672\n",
      "Epoch: 36/100, Loss: 0.6759349, Train Acc: 0.5834, Test Acc: 0.5788, Train AUC: 0.6062, Train APUR: 0.5700, Test AUC: 0.5983, Test AUPR: 0.5683\n",
      "Epoch: 37/100, Loss: 0.6751117, Train Acc: 0.5855, Test Acc: 0.5848, Train AUC: 0.6081, Train APUR: 0.5737, Test AUC: 0.5999, Test AUPR: 0.5697\n",
      "Epoch: 38/100, Loss: 0.6760079, Train Acc: 0.5845, Test Acc: 0.5783, Train AUC: 0.6065, Train APUR: 0.5740, Test AUC: 0.6020, Test AUPR: 0.5715\n",
      "Epoch: 39/100, Loss: 0.6753138, Train Acc: 0.5860, Test Acc: 0.5784, Train AUC: 0.6096, Train APUR: 0.5748, Test AUC: 0.6031, Test AUPR: 0.5741\n",
      "Epoch: 40/100, Loss: 0.6740097, Train Acc: 0.5878, Test Acc: 0.5776, Train AUC: 0.6104, Train APUR: 0.5770, Test AUC: 0.6024, Test AUPR: 0.5754\n",
      "Epoch: 41/100, Loss: 0.6753556, Train Acc: 0.5798, Test Acc: 0.5802, Train AUC: 0.6095, Train APUR: 0.5805, Test AUC: 0.6040, Test AUPR: 0.5762\n",
      "Epoch: 42/100, Loss: 0.6737085, Train Acc: 0.5860, Test Acc: 0.5840, Train AUC: 0.6100, Train APUR: 0.5782, Test AUC: 0.6051, Test AUPR: 0.5757\n",
      "Epoch: 43/100, Loss: 0.6739553, Train Acc: 0.5865, Test Acc: 0.5836, Train AUC: 0.6109, Train APUR: 0.5788, Test AUC: 0.6046, Test AUPR: 0.5745\n",
      "Epoch: 44/100, Loss: 0.6736469, Train Acc: 0.5879, Test Acc: 0.5837, Train AUC: 0.6146, Train APUR: 0.5798, Test AUC: 0.6045, Test AUPR: 0.5752\n",
      "Epoch: 45/100, Loss: 0.6720501, Train Acc: 0.5920, Test Acc: 0.5661, Train AUC: 0.6156, Train APUR: 0.5798, Test AUC: 0.6042, Test AUPR: 0.5758\n",
      "Epoch: 46/100, Loss: 0.6725926, Train Acc: 0.5855, Test Acc: 0.5815, Train AUC: 0.6160, Train APUR: 0.5816, Test AUC: 0.6057, Test AUPR: 0.5762\n",
      "Epoch: 47/100, Loss: 0.6712266, Train Acc: 0.5914, Test Acc: 0.5816, Train AUC: 0.6171, Train APUR: 0.5820, Test AUC: 0.6062, Test AUPR: 0.5754\n",
      "Epoch: 48/100, Loss: 0.6724573, Train Acc: 0.5887, Test Acc: 0.5886, Train AUC: 0.6164, Train APUR: 0.5802, Test AUC: 0.6070, Test AUPR: 0.5764\n",
      "Epoch: 49/100, Loss: 0.6713036, Train Acc: 0.5954, Test Acc: 0.5826, Train AUC: 0.6174, Train APUR: 0.5836, Test AUC: 0.6077, Test AUPR: 0.5784\n",
      "Epoch: 50/100, Loss: 0.6715305, Train Acc: 0.5887, Test Acc: 0.5825, Train AUC: 0.6187, Train APUR: 0.5849, Test AUC: 0.6083, Test AUPR: 0.5794\n",
      "Epoch: 51/100, Loss: 0.6712252, Train Acc: 0.5903, Test Acc: 0.5903, Train AUC: 0.6177, Train APUR: 0.5846, Test AUC: 0.6087, Test AUPR: 0.5788\n",
      "Epoch: 52/100, Loss: 0.6712600, Train Acc: 0.5988, Test Acc: 0.5787, Train AUC: 0.6185, Train APUR: 0.5842, Test AUC: 0.6084, Test AUPR: 0.5782\n",
      "Epoch: 53/100, Loss: 0.6712765, Train Acc: 0.5898, Test Acc: 0.5877, Train AUC: 0.6208, Train APUR: 0.5842, Test AUC: 0.6095, Test AUPR: 0.5815\n",
      "Epoch: 54/100, Loss: 0.6699792, Train Acc: 0.5978, Test Acc: 0.5824, Train AUC: 0.6200, Train APUR: 0.5863, Test AUC: 0.6087, Test AUPR: 0.5832\n",
      "Epoch: 55/100, Loss: 0.6705809, Train Acc: 0.5908, Test Acc: 0.5815, Train AUC: 0.6206, Train APUR: 0.5884, Test AUC: 0.6092, Test AUPR: 0.5833\n",
      "Epoch: 56/100, Loss: 0.6719416, Train Acc: 0.5843, Test Acc: 0.5845, Train AUC: 0.6162, Train APUR: 0.5823, Test AUC: 0.6101, Test AUPR: 0.5814\n",
      "Epoch: 57/100, Loss: 0.6691981, Train Acc: 0.5960, Test Acc: 0.5830, Train AUC: 0.6210, Train APUR: 0.5857, Test AUC: 0.6074, Test AUPR: 0.5774\n",
      "Epoch: 58/100, Loss: 0.6698154, Train Acc: 0.5956, Test Acc: 0.5852, Train AUC: 0.6219, Train APUR: 0.5853, Test AUC: 0.6046, Test AUPR: 0.5755\n",
      "Epoch: 59/100, Loss: 0.6692529, Train Acc: 0.5948, Test Acc: 0.5873, Train AUC: 0.6221, Train APUR: 0.5831, Test AUC: 0.6067, Test AUPR: 0.5779\n",
      "Epoch: 60/100, Loss: 0.6686579, Train Acc: 0.5986, Test Acc: 0.5578, Train AUC: 0.6243, Train APUR: 0.5860, Test AUC: 0.6095, Test AUPR: 0.5807\n",
      "Epoch: 61/100, Loss: 0.6687335, Train Acc: 0.5958, Test Acc: 0.5842, Train AUC: 0.6245, Train APUR: 0.5865, Test AUC: 0.6108, Test AUPR: 0.5824\n",
      "Epoch: 62/100, Loss: 0.6676987, Train Acc: 0.5942, Test Acc: 0.5941, Train AUC: 0.6253, Train APUR: 0.5895, Test AUC: 0.6105, Test AUPR: 0.5821\n",
      "Epoch: 63/100, Loss: 0.6666901, Train Acc: 0.6019, Test Acc: 0.5917, Train AUC: 0.6263, Train APUR: 0.5897, Test AUC: 0.6108, Test AUPR: 0.5828\n",
      "Epoch: 64/100, Loss: 0.6668966, Train Acc: 0.6013, Test Acc: 0.5926, Train AUC: 0.6263, Train APUR: 0.5908, Test AUC: 0.6124, Test AUPR: 0.5852\n",
      "Epoch: 65/100, Loss: 0.6672211, Train Acc: 0.5983, Test Acc: 0.5876, Train AUC: 0.6256, Train APUR: 0.5925, Test AUC: 0.6141, Test AUPR: 0.5890\n",
      "Epoch: 66/100, Loss: 0.6665536, Train Acc: 0.5986, Test Acc: 0.5851, Train AUC: 0.6276, Train APUR: 0.5938, Test AUC: 0.6146, Test AUPR: 0.5908\n",
      "Epoch: 67/100, Loss: 0.6667768, Train Acc: 0.5949, Test Acc: 0.5895, Train AUC: 0.6289, Train APUR: 0.5964, Test AUC: 0.6128, Test AUPR: 0.5873\n",
      "Epoch: 68/100, Loss: 0.6664855, Train Acc: 0.6028, Test Acc: 0.5873, Train AUC: 0.6266, Train APUR: 0.5914, Test AUC: 0.6107, Test AUPR: 0.5843\n",
      "Epoch: 69/100, Loss: 0.6656838, Train Acc: 0.5982, Test Acc: 0.5890, Train AUC: 0.6295, Train APUR: 0.5957, Test AUC: 0.6133, Test AUPR: 0.5887\n",
      "Epoch: 70/100, Loss: 0.6648955, Train Acc: 0.6024, Test Acc: 0.5853, Train AUC: 0.6310, Train APUR: 0.5970, Test AUC: 0.6156, Test AUPR: 0.5935\n",
      "Epoch: 71/100, Loss: 0.6653309, Train Acc: 0.6028, Test Acc: 0.5836, Train AUC: 0.6307, Train APUR: 0.5995, Test AUC: 0.6158, Test AUPR: 0.5940\n",
      "Epoch: 72/100, Loss: 0.6649832, Train Acc: 0.5989, Test Acc: 0.5931, Train AUC: 0.6308, Train APUR: 0.6020, Test AUC: 0.6148, Test AUPR: 0.5913\n",
      "Epoch: 73/100, Loss: 0.6651635, Train Acc: 0.5961, Test Acc: 0.5925, Train AUC: 0.6298, Train APUR: 0.5988, Test AUC: 0.6137, Test AUPR: 0.5894\n",
      "Epoch: 74/100, Loss: 0.6649598, Train Acc: 0.6041, Test Acc: 0.5916, Train AUC: 0.6307, Train APUR: 0.6004, Test AUC: 0.6147, Test AUPR: 0.5944\n",
      "Epoch: 75/100, Loss: 0.6638724, Train Acc: 0.6012, Test Acc: 0.5885, Train AUC: 0.6341, Train APUR: 0.6052, Test AUC: 0.6135, Test AUPR: 0.5951\n",
      "Epoch: 76/100, Loss: 0.6645837, Train Acc: 0.6030, Test Acc: 0.5879, Train AUC: 0.6331, Train APUR: 0.6040, Test AUC: 0.6103, Test AUPR: 0.5919\n",
      "Epoch: 77/100, Loss: 0.6634616, Train Acc: 0.6025, Test Acc: 0.5884, Train AUC: 0.6336, Train APUR: 0.6040, Test AUC: 0.6100, Test AUPR: 0.5909\n",
      "Epoch: 78/100, Loss: 0.6629851, Train Acc: 0.6044, Test Acc: 0.5911, Train AUC: 0.6348, Train APUR: 0.6065, Test AUC: 0.6123, Test AUPR: 0.5932\n",
      "Epoch: 79/100, Loss: 0.6629288, Train Acc: 0.6026, Test Acc: 0.5721, Train AUC: 0.6345, Train APUR: 0.6041, Test AUC: 0.6179, Test AUPR: 0.6009\n",
      "Epoch: 80/100, Loss: 0.6630146, Train Acc: 0.5981, Test Acc: 0.5872, Train AUC: 0.6382, Train APUR: 0.6119, Test AUC: 0.6176, Test AUPR: 0.5992\n",
      "Epoch: 81/100, Loss: 0.6628191, Train Acc: 0.6000, Test Acc: 0.5943, Train AUC: 0.6366, Train APUR: 0.6098, Test AUC: 0.6171, Test AUPR: 0.5969\n",
      "Epoch: 82/100, Loss: 0.6625527, Train Acc: 0.6018, Test Acc: 0.5873, Train AUC: 0.6348, Train APUR: 0.6075, Test AUC: 0.6185, Test AUPR: 0.6022\n",
      "Epoch: 83/100, Loss: 0.6630532, Train Acc: 0.5946, Test Acc: 0.5877, Train AUC: 0.6333, Train APUR: 0.6095, Test AUC: 0.6187, Test AUPR: 0.6030\n",
      "Epoch: 84/100, Loss: 0.6617735, Train Acc: 0.6025, Test Acc: 0.5927, Train AUC: 0.6392, Train APUR: 0.6143, Test AUC: 0.6145, Test AUPR: 0.5961\n",
      "Epoch: 85/100, Loss: 0.6618185, Train Acc: 0.6040, Test Acc: 0.5911, Train AUC: 0.6369, Train APUR: 0.6100, Test AUC: 0.6102, Test AUPR: 0.5904\n",
      "Epoch: 86/100, Loss: 0.6613206, Train Acc: 0.6021, Test Acc: 0.5826, Train AUC: 0.6371, Train APUR: 0.6099, Test AUC: 0.6138, Test AUPR: 0.5957\n",
      "Epoch: 87/100, Loss: 0.6610299, Train Acc: 0.6042, Test Acc: 0.5808, Train AUC: 0.6395, Train APUR: 0.6129, Test AUC: 0.6165, Test AUPR: 0.5984\n",
      "Epoch: 88/100, Loss: 0.6597199, Train Acc: 0.6024, Test Acc: 0.5901, Train AUC: 0.6422, Train APUR: 0.6154, Test AUC: 0.6161, Test AUPR: 0.5977\n",
      "Epoch: 89/100, Loss: 0.6600105, Train Acc: 0.6054, Test Acc: 0.5890, Train AUC: 0.6434, Train APUR: 0.6172, Test AUC: 0.6121, Test AUPR: 0.5925\n",
      "Epoch: 90/100, Loss: 0.6609970, Train Acc: 0.6024, Test Acc: 0.5896, Train AUC: 0.6393, Train APUR: 0.6123, Test AUC: 0.6194, Test AUPR: 0.6043\n",
      "Epoch: 91/100, Loss: 0.6592382, Train Acc: 0.6005, Test Acc: 0.5800, Train AUC: 0.6437, Train APUR: 0.6175, Test AUC: 0.6197, Test AUPR: 0.6070\n",
      "Epoch: 92/100, Loss: 0.6599700, Train Acc: 0.5997, Test Acc: 0.5892, Train AUC: 0.6443, Train APUR: 0.6215, Test AUC: 0.6161, Test AUPR: 0.6023\n",
      "Epoch: 93/100, Loss: 0.6582910, Train Acc: 0.6056, Test Acc: 0.5855, Train AUC: 0.6448, Train APUR: 0.6213, Test AUC: 0.6096, Test AUPR: 0.5956\n",
      "Epoch: 94/100, Loss: 0.6613006, Train Acc: 0.5993, Test Acc: 0.5868, Train AUC: 0.6393, Train APUR: 0.6134, Test AUC: 0.6175, Test AUPR: 0.6047\n",
      "Epoch: 95/100, Loss: 0.6587820, Train Acc: 0.6059, Test Acc: 0.5768, Train AUC: 0.6458, Train APUR: 0.6219, Test AUC: 0.6170, Test AUPR: 0.6056\n",
      "Epoch: 96/100, Loss: 0.6616133, Train Acc: 0.5979, Test Acc: 0.5821, Train AUC: 0.6452, Train APUR: 0.6218, Test AUC: 0.6143, Test AUPR: 0.6018\n",
      "Epoch: 97/100, Loss: 0.6581273, Train Acc: 0.6029, Test Acc: 0.5861, Train AUC: 0.6452, Train APUR: 0.6223, Test AUC: 0.6088, Test AUPR: 0.5939\n",
      "Epoch: 98/100, Loss: 0.6597854, Train Acc: 0.5998, Test Acc: 0.5878, Train AUC: 0.6411, Train APUR: 0.6171, Test AUC: 0.6146, Test AUPR: 0.6005\n",
      "Epoch: 99/100, Loss: 0.6574198, Train Acc: 0.6043, Test Acc: 0.5845, Train AUC: 0.6455, Train APUR: 0.6229, Test AUC: 0.6208, Test AUPR: 0.6086\n",
      "Epoch: 100/100, Loss: 0.6577955, Train Acc: 0.6005, Test Acc: 0.5800, Train AUC: 0.6472, Train APUR: 0.6262, Test AUC: 0.6205, Test AUPR: 0.6092\n",
      "/home/ubuntu/PA-Cancer-Immunotherapy/GNN/train_pa.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(configs['save_model']))\n",
      "Test Acc: 0.5845, Test AUC: 0.6208, Test AUPR: 0.6086\n"
     ]
    }
   ],
   "source": [
    "# this is the same code line as above, but the embeddings used are without training of the trcpeg model. \n",
    "# Result: training the tcrpeg model delivers better results!!!\n",
    "\n",
    "! python train_pa.py --gpu 0 --configs_path configs/PA_all_allele.yml --droup_out 0.1 --split StrictTCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "401635f3-a725-4332-bf8b-bdc3806f806c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(gpu=0, lr=0.001, epochs=100, w_celoss=1, w_aucloss=0, add_same_type_edges=False, dynamic_graph=False, dynamic_ratio=0.05, droup_out=0.1, positive_weights=1, dynamic_epochs=30, distance_threshold=10, configs_path='configs/PA_all_allele.yml', split='StrictTCR', dataset='pMTnet')\n",
      "models/PA_all/allele_embeddings.pkl\n",
      "['allele_fold_0.csv', 'allele_fold_1.csv', 'allele_fold_2.csv', 'allele_fold_3.csv']\n",
      "['allele_fold_4.csv']\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "# the same as above, but checking the paths!\n",
    "\n",
    "! python train_pa.py --gpu 0 --configs_path configs/PA_all_allele.yml --droup_out 0.1 --split StrictTCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3462548a-3e12-4ff8-846d-64df5feef7ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49776754-7aed-4ba7-b6e6-927120530b5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(gpu=0, lr=0.001, epochs=100, w_celoss=1, w_aucloss=0, add_same_type_edges=False, dynamic_graph=False, dynamic_ratio=0.05, droup_out=0.1, positive_weights=1, dynamic_epochs=30, distance_threshold=10, configs_path='configs/PA_all_allele.yml', split='StrictTCR', dataset='pMTnet')\n",
      "models/PA_all/allele_embeddings.pkl\n",
      "['allele_fold_0.csv', 'allele_fold_1.csv', 'allele_fold_2.csv', 'allele_fold_3.csv']\n",
      "['allele_fold_4.csv']\n",
      "Epoch: 1/100, Loss: 0.6931294, Train Acc: 0.5021, Test Acc: 0.5409, Train AUC: 0.5067, Train APUR: 0.5076, Test AUC: 0.5641, Test AUPR: 0.5554\n",
      "Epoch: 2/100, Loss: 0.6927062, Train Acc: 0.5423, Test Acc: 0.5432, Train AUC: 0.5587, Train APUR: 0.5369, Test AUC: 0.5704, Test AUPR: 0.5625\n",
      "Epoch: 3/100, Loss: 0.6924415, Train Acc: 0.5393, Test Acc: 0.5428, Train AUC: 0.5640, Train APUR: 0.5497, Test AUC: 0.5708, Test AUPR: 0.5616\n",
      "Epoch: 4/100, Loss: 0.6919569, Train Acc: 0.5442, Test Acc: 0.5424, Train AUC: 0.5672, Train APUR: 0.5496, Test AUC: 0.5701, Test AUPR: 0.5604\n",
      "Epoch: 5/100, Loss: 0.6913627, Train Acc: 0.5456, Test Acc: 0.5436, Train AUC: 0.5662, Train APUR: 0.5499, Test AUC: 0.5682, Test AUPR: 0.5584\n",
      "Epoch: 6/100, Loss: 0.6907263, Train Acc: 0.5430, Test Acc: 0.5435, Train AUC: 0.5667, Train APUR: 0.5540, Test AUC: 0.5676, Test AUPR: 0.5580\n",
      "Epoch: 7/100, Loss: 0.6897939, Train Acc: 0.5456, Test Acc: 0.5435, Train AUC: 0.5690, Train APUR: 0.5540, Test AUC: 0.5675, Test AUPR: 0.5584\n",
      "Epoch: 8/100, Loss: 0.6891215, Train Acc: 0.5466, Test Acc: 0.5444, Train AUC: 0.5683, Train APUR: 0.5509, Test AUC: 0.5676, Test AUPR: 0.5585\n",
      "Epoch: 9/100, Loss: 0.6879091, Train Acc: 0.5453, Test Acc: 0.5443, Train AUC: 0.5716, Train APUR: 0.5572, Test AUC: 0.5679, Test AUPR: 0.5588\n",
      "Epoch: 10/100, Loss: 0.6878960, Train Acc: 0.5482, Test Acc: 0.5497, Train AUC: 0.5635, Train APUR: 0.5475, Test AUC: 0.5692, Test AUPR: 0.5606\n",
      "Epoch: 11/100, Loss: 0.6865515, Train Acc: 0.5521, Test Acc: 0.5496, Train AUC: 0.5700, Train APUR: 0.5524, Test AUC: 0.5697, Test AUPR: 0.5616\n",
      "Epoch: 12/100, Loss: 0.6865324, Train Acc: 0.5517, Test Acc: 0.5493, Train AUC: 0.5671, Train APUR: 0.5497, Test AUC: 0.5698, Test AUPR: 0.5610\n",
      "Epoch: 13/100, Loss: 0.6858211, Train Acc: 0.5503, Test Acc: 0.5495, Train AUC: 0.5719, Train APUR: 0.5555, Test AUC: 0.5705, Test AUPR: 0.5611\n",
      "Epoch: 14/100, Loss: 0.6853812, Train Acc: 0.5533, Test Acc: 0.5495, Train AUC: 0.5730, Train APUR: 0.5537, Test AUC: 0.5712, Test AUPR: 0.5608\n",
      "Epoch: 15/100, Loss: 0.6857305, Train Acc: 0.5523, Test Acc: 0.5497, Train AUC: 0.5716, Train APUR: 0.5529, Test AUC: 0.5715, Test AUPR: 0.5607\n",
      "Epoch: 16/100, Loss: 0.6855171, Train Acc: 0.5535, Test Acc: 0.5494, Train AUC: 0.5721, Train APUR: 0.5526, Test AUC: 0.5719, Test AUPR: 0.5596\n",
      "Epoch: 17/100, Loss: 0.6850896, Train Acc: 0.5529, Test Acc: 0.5493, Train AUC: 0.5740, Train APUR: 0.5548, Test AUC: 0.5733, Test AUPR: 0.5602\n",
      "Epoch: 18/100, Loss: 0.6843891, Train Acc: 0.5526, Test Acc: 0.5522, Train AUC: 0.5772, Train APUR: 0.5553, Test AUC: 0.5740, Test AUPR: 0.5584\n",
      "Epoch: 19/100, Loss: 0.6837066, Train Acc: 0.5547, Test Acc: 0.5552, Train AUC: 0.5811, Train APUR: 0.5630, Test AUC: 0.5765, Test AUPR: 0.5592\n",
      "Epoch: 20/100, Loss: 0.6835502, Train Acc: 0.5573, Test Acc: 0.5579, Train AUC: 0.5800, Train APUR: 0.5593, Test AUC: 0.5773, Test AUPR: 0.5572\n",
      "Epoch: 21/100, Loss: 0.6826710, Train Acc: 0.5616, Test Acc: 0.5606, Train AUC: 0.5828, Train APUR: 0.5564, Test AUC: 0.5784, Test AUPR: 0.5566\n",
      "Epoch: 22/100, Loss: 0.6822360, Train Acc: 0.5642, Test Acc: 0.5646, Train AUC: 0.5854, Train APUR: 0.5570, Test AUC: 0.5801, Test AUPR: 0.5571\n",
      "Epoch: 23/100, Loss: 0.6820218, Train Acc: 0.5646, Test Acc: 0.5627, Train AUC: 0.5855, Train APUR: 0.5561, Test AUC: 0.5815, Test AUPR: 0.5577\n",
      "Epoch: 24/100, Loss: 0.6808009, Train Acc: 0.5692, Test Acc: 0.5643, Train AUC: 0.5912, Train APUR: 0.5615, Test AUC: 0.5824, Test AUPR: 0.5581\n",
      "Epoch: 25/100, Loss: 0.6807297, Train Acc: 0.5674, Test Acc: 0.5636, Train AUC: 0.5893, Train APUR: 0.5588, Test AUC: 0.5841, Test AUPR: 0.5586\n",
      "Epoch: 26/100, Loss: 0.6806128, Train Acc: 0.5684, Test Acc: 0.5628, Train AUC: 0.5902, Train APUR: 0.5584, Test AUC: 0.5858, Test AUPR: 0.5592\n",
      "Epoch: 27/100, Loss: 0.6799619, Train Acc: 0.5704, Test Acc: 0.5706, Train AUC: 0.5921, Train APUR: 0.5590, Test AUC: 0.5871, Test AUPR: 0.5600\n",
      "Epoch: 28/100, Loss: 0.6809167, Train Acc: 0.5684, Test Acc: 0.5682, Train AUC: 0.5892, Train APUR: 0.5553, Test AUC: 0.5887, Test AUPR: 0.5609\n",
      "Epoch: 29/100, Loss: 0.6793451, Train Acc: 0.5711, Test Acc: 0.5679, Train AUC: 0.5938, Train APUR: 0.5609, Test AUC: 0.5904, Test AUPR: 0.5620\n",
      "Epoch: 30/100, Loss: 0.6783608, Train Acc: 0.5766, Test Acc: 0.5676, Train AUC: 0.5981, Train APUR: 0.5656, Test AUC: 0.5920, Test AUPR: 0.5634\n",
      "Epoch: 31/100, Loss: 0.6788571, Train Acc: 0.5728, Test Acc: 0.5719, Train AUC: 0.5955, Train APUR: 0.5615, Test AUC: 0.5935, Test AUPR: 0.5648\n",
      "Epoch: 32/100, Loss: 0.6780865, Train Acc: 0.5768, Test Acc: 0.5742, Train AUC: 0.5971, Train APUR: 0.5607, Test AUC: 0.5953, Test AUPR: 0.5658\n",
      "Epoch: 33/100, Loss: 0.6775333, Train Acc: 0.5803, Test Acc: 0.5751, Train AUC: 0.6001, Train APUR: 0.5655, Test AUC: 0.5965, Test AUPR: 0.5664\n",
      "Epoch: 34/100, Loss: 0.6764495, Train Acc: 0.5782, Test Acc: 0.5726, Train AUC: 0.6037, Train APUR: 0.5684, Test AUC: 0.5970, Test AUPR: 0.5665\n",
      "Epoch: 35/100, Loss: 0.6768377, Train Acc: 0.5797, Test Acc: 0.5824, Train AUC: 0.6038, Train APUR: 0.5661, Test AUC: 0.5973, Test AUPR: 0.5672\n",
      "Epoch: 36/100, Loss: 0.6760150, Train Acc: 0.5833, Test Acc: 0.5781, Train AUC: 0.6058, Train APUR: 0.5696, Test AUC: 0.5983, Test AUPR: 0.5684\n",
      "Epoch: 37/100, Loss: 0.6751527, Train Acc: 0.5852, Test Acc: 0.5852, Train AUC: 0.6080, Train APUR: 0.5737, Test AUC: 0.5999, Test AUPR: 0.5698\n",
      "Epoch: 38/100, Loss: 0.6760009, Train Acc: 0.5843, Test Acc: 0.5781, Train AUC: 0.6067, Train APUR: 0.5741, Test AUC: 0.6020, Test AUPR: 0.5715\n",
      "Epoch: 39/100, Loss: 0.6753665, Train Acc: 0.5860, Test Acc: 0.5790, Train AUC: 0.6095, Train APUR: 0.5747, Test AUC: 0.6033, Test AUPR: 0.5742\n",
      "Epoch: 40/100, Loss: 0.6740214, Train Acc: 0.5882, Test Acc: 0.5777, Train AUC: 0.6105, Train APUR: 0.5768, Test AUC: 0.6025, Test AUPR: 0.5755\n",
      "Epoch: 41/100, Loss: 0.6752405, Train Acc: 0.5801, Test Acc: 0.5807, Train AUC: 0.6097, Train APUR: 0.5806, Test AUC: 0.6041, Test AUPR: 0.5764\n",
      "Epoch: 42/100, Loss: 0.6737434, Train Acc: 0.5858, Test Acc: 0.5836, Train AUC: 0.6099, Train APUR: 0.5782, Test AUC: 0.6050, Test AUPR: 0.5758\n",
      "Epoch: 43/100, Loss: 0.6739596, Train Acc: 0.5859, Test Acc: 0.5848, Train AUC: 0.6107, Train APUR: 0.5788, Test AUC: 0.6047, Test AUPR: 0.5746\n",
      "Epoch: 44/100, Loss: 0.6736334, Train Acc: 0.5891, Test Acc: 0.5842, Train AUC: 0.6144, Train APUR: 0.5798, Test AUC: 0.6047, Test AUPR: 0.5752\n",
      "Epoch: 45/100, Loss: 0.6720529, Train Acc: 0.5920, Test Acc: 0.5677, Train AUC: 0.6155, Train APUR: 0.5799, Test AUC: 0.6045, Test AUPR: 0.5758\n",
      "Epoch: 46/100, Loss: 0.6725094, Train Acc: 0.5859, Test Acc: 0.5814, Train AUC: 0.6160, Train APUR: 0.5816, Test AUC: 0.6059, Test AUPR: 0.5761\n",
      "Epoch: 47/100, Loss: 0.6712596, Train Acc: 0.5912, Test Acc: 0.5814, Train AUC: 0.6172, Train APUR: 0.5820, Test AUC: 0.6062, Test AUPR: 0.5750\n",
      "Epoch: 48/100, Loss: 0.6724205, Train Acc: 0.5881, Test Acc: 0.5873, Train AUC: 0.6165, Train APUR: 0.5799, Test AUC: 0.6069, Test AUPR: 0.5760\n",
      "Epoch: 49/100, Loss: 0.6713394, Train Acc: 0.5956, Test Acc: 0.5824, Train AUC: 0.6174, Train APUR: 0.5834, Test AUC: 0.6077, Test AUPR: 0.5785\n",
      "Epoch: 50/100, Loss: 0.6715065, Train Acc: 0.5884, Test Acc: 0.5823, Train AUC: 0.6188, Train APUR: 0.5848, Test AUC: 0.6083, Test AUPR: 0.5796\n",
      "Epoch: 51/100, Loss: 0.6712433, Train Acc: 0.5901, Test Acc: 0.5901, Train AUC: 0.6176, Train APUR: 0.5845, Test AUC: 0.6088, Test AUPR: 0.5791\n",
      "Epoch: 52/100, Loss: 0.6712077, Train Acc: 0.5972, Test Acc: 0.5797, Train AUC: 0.6185, Train APUR: 0.5844, Test AUC: 0.6085, Test AUPR: 0.5783\n",
      "Epoch: 53/100, Loss: 0.6713772, Train Acc: 0.5907, Test Acc: 0.5879, Train AUC: 0.6207, Train APUR: 0.5842, Test AUC: 0.6096, Test AUPR: 0.5814\n",
      "Epoch: 54/100, Loss: 0.6699810, Train Acc: 0.5981, Test Acc: 0.5826, Train AUC: 0.6200, Train APUR: 0.5862, Test AUC: 0.6089, Test AUPR: 0.5834\n",
      "Epoch: 55/100, Loss: 0.6705434, Train Acc: 0.5908, Test Acc: 0.5816, Train AUC: 0.6206, Train APUR: 0.5885, Test AUC: 0.6094, Test AUPR: 0.5835\n",
      "Epoch: 56/100, Loss: 0.6721610, Train Acc: 0.5834, Test Acc: 0.5849, Train AUC: 0.6160, Train APUR: 0.5819, Test AUC: 0.6103, Test AUPR: 0.5815\n",
      "Epoch: 57/100, Loss: 0.6692085, Train Acc: 0.5963, Test Acc: 0.5834, Train AUC: 0.6212, Train APUR: 0.5858, Test AUC: 0.6071, Test AUPR: 0.5772\n",
      "Epoch: 58/100, Loss: 0.6698318, Train Acc: 0.5953, Test Acc: 0.5846, Train AUC: 0.6218, Train APUR: 0.5850, Test AUC: 0.6046, Test AUPR: 0.5755\n",
      "Epoch: 59/100, Loss: 0.6693010, Train Acc: 0.5941, Test Acc: 0.5871, Train AUC: 0.6221, Train APUR: 0.5831, Test AUC: 0.6070, Test AUPR: 0.5781\n",
      "Epoch: 60/100, Loss: 0.6685703, Train Acc: 0.5993, Test Acc: 0.5624, Train AUC: 0.6242, Train APUR: 0.5861, Test AUC: 0.6098, Test AUPR: 0.5812\n",
      "Epoch: 61/100, Loss: 0.6686283, Train Acc: 0.5961, Test Acc: 0.5824, Train AUC: 0.6245, Train APUR: 0.5867, Test AUC: 0.6109, Test AUPR: 0.5828\n",
      "Epoch: 62/100, Loss: 0.6677466, Train Acc: 0.5936, Test Acc: 0.5930, Train AUC: 0.6253, Train APUR: 0.5897, Test AUC: 0.6106, Test AUPR: 0.5825\n",
      "Epoch: 63/100, Loss: 0.6667452, Train Acc: 0.6013, Test Acc: 0.5922, Train AUC: 0.6262, Train APUR: 0.5899, Test AUC: 0.6106, Test AUPR: 0.5828\n",
      "Epoch: 64/100, Loss: 0.6668633, Train Acc: 0.6007, Test Acc: 0.5929, Train AUC: 0.6264, Train APUR: 0.5910, Test AUC: 0.6121, Test AUPR: 0.5850\n",
      "Epoch: 65/100, Loss: 0.6672578, Train Acc: 0.5986, Test Acc: 0.5881, Train AUC: 0.6255, Train APUR: 0.5923, Test AUC: 0.6138, Test AUPR: 0.5886\n",
      "Epoch: 66/100, Loss: 0.6665344, Train Acc: 0.5994, Test Acc: 0.5859, Train AUC: 0.6276, Train APUR: 0.5936, Test AUC: 0.6143, Test AUPR: 0.5905\n",
      "Epoch: 67/100, Loss: 0.6667242, Train Acc: 0.5951, Test Acc: 0.5896, Train AUC: 0.6289, Train APUR: 0.5962, Test AUC: 0.6127, Test AUPR: 0.5877\n",
      "Epoch: 68/100, Loss: 0.6663969, Train Acc: 0.6028, Test Acc: 0.5878, Train AUC: 0.6268, Train APUR: 0.5916, Test AUC: 0.6108, Test AUPR: 0.5850\n",
      "Epoch: 69/100, Loss: 0.6656346, Train Acc: 0.5984, Test Acc: 0.5888, Train AUC: 0.6294, Train APUR: 0.5960, Test AUC: 0.6131, Test AUPR: 0.5893\n",
      "Epoch: 70/100, Loss: 0.6649349, Train Acc: 0.6022, Test Acc: 0.5864, Train AUC: 0.6310, Train APUR: 0.5971, Test AUC: 0.6156, Test AUPR: 0.5941\n",
      "Epoch: 71/100, Loss: 0.6652703, Train Acc: 0.6030, Test Acc: 0.5845, Train AUC: 0.6309, Train APUR: 0.5998, Test AUC: 0.6157, Test AUPR: 0.5945\n",
      "Epoch: 72/100, Loss: 0.6648486, Train Acc: 0.6000, Test Acc: 0.5935, Train AUC: 0.6310, Train APUR: 0.6022, Test AUC: 0.6150, Test AUPR: 0.5920\n",
      "Epoch: 73/100, Loss: 0.6650127, Train Acc: 0.5973, Test Acc: 0.5922, Train AUC: 0.6303, Train APUR: 0.5995, Test AUC: 0.6141, Test AUPR: 0.5903\n",
      "Epoch: 74/100, Loss: 0.6648737, Train Acc: 0.6043, Test Acc: 0.5913, Train AUC: 0.6309, Train APUR: 0.6005, Test AUC: 0.6149, Test AUPR: 0.5948\n",
      "Epoch: 75/100, Loss: 0.6638988, Train Acc: 0.6008, Test Acc: 0.5882, Train AUC: 0.6341, Train APUR: 0.6056, Test AUC: 0.6138, Test AUPR: 0.5951\n",
      "Epoch: 76/100, Loss: 0.6645536, Train Acc: 0.6030, Test Acc: 0.5877, Train AUC: 0.6333, Train APUR: 0.6045, Test AUC: 0.6099, Test AUPR: 0.5903\n",
      "Epoch: 77/100, Loss: 0.6633705, Train Acc: 0.6030, Test Acc: 0.5881, Train AUC: 0.6335, Train APUR: 0.6038, Test AUC: 0.6095, Test AUPR: 0.5892\n",
      "Epoch: 78/100, Loss: 0.6629818, Train Acc: 0.6044, Test Acc: 0.5907, Train AUC: 0.6348, Train APUR: 0.6066, Test AUC: 0.6124, Test AUPR: 0.5929\n",
      "Epoch: 79/100, Loss: 0.6626906, Train Acc: 0.6033, Test Acc: 0.5716, Train AUC: 0.6350, Train APUR: 0.6048, Test AUC: 0.6179, Test AUPR: 0.6012\n",
      "Epoch: 80/100, Loss: 0.6631411, Train Acc: 0.5978, Test Acc: 0.5949, Train AUC: 0.6383, Train APUR: 0.6124, Test AUC: 0.6171, Test AUPR: 0.5984\n",
      "Epoch: 81/100, Loss: 0.6627546, Train Acc: 0.5993, Test Acc: 0.5952, Train AUC: 0.6363, Train APUR: 0.6099, Test AUC: 0.6168, Test AUPR: 0.5965\n",
      "Epoch: 82/100, Loss: 0.6626214, Train Acc: 0.6020, Test Acc: 0.5862, Train AUC: 0.6346, Train APUR: 0.6076, Test AUC: 0.6183, Test AUPR: 0.6029\n",
      "Epoch: 83/100, Loss: 0.6632152, Train Acc: 0.5943, Test Acc: 0.5873, Train AUC: 0.6328, Train APUR: 0.6092, Test AUC: 0.6187, Test AUPR: 0.6038\n",
      "Epoch: 84/100, Loss: 0.6617801, Train Acc: 0.6024, Test Acc: 0.5925, Train AUC: 0.6390, Train APUR: 0.6145, Test AUC: 0.6150, Test AUPR: 0.5971\n",
      "Epoch: 85/100, Loss: 0.6618902, Train Acc: 0.6037, Test Acc: 0.5916, Train AUC: 0.6367, Train APUR: 0.6103, Test AUC: 0.6104, Test AUPR: 0.5913\n",
      "Epoch: 86/100, Loss: 0.6613237, Train Acc: 0.6012, Test Acc: 0.5831, Train AUC: 0.6373, Train APUR: 0.6104, Test AUC: 0.6145, Test AUPR: 0.5966\n",
      "Epoch: 87/100, Loss: 0.6609654, Train Acc: 0.6043, Test Acc: 0.5707, Train AUC: 0.6397, Train APUR: 0.6133, Test AUC: 0.6169, Test AUPR: 0.5990\n",
      "Epoch: 88/100, Loss: 0.6598329, Train Acc: 0.6008, Test Acc: 0.5860, Train AUC: 0.6422, Train APUR: 0.6157, Test AUC: 0.6153, Test AUPR: 0.5968\n",
      "Epoch: 89/100, Loss: 0.6600068, Train Acc: 0.6043, Test Acc: 0.5894, Train AUC: 0.6431, Train APUR: 0.6170, Test AUC: 0.6109, Test AUPR: 0.5909\n",
      "Epoch: 90/100, Loss: 0.6611285, Train Acc: 0.6025, Test Acc: 0.5894, Train AUC: 0.6390, Train APUR: 0.6119, Test AUC: 0.6192, Test AUPR: 0.6038\n",
      "Epoch: 91/100, Loss: 0.6592937, Train Acc: 0.6003, Test Acc: 0.5815, Train AUC: 0.6436, Train APUR: 0.6177, Test AUC: 0.6199, Test AUPR: 0.6074\n",
      "Epoch: 92/100, Loss: 0.6599339, Train Acc: 0.6003, Test Acc: 0.5898, Train AUC: 0.6445, Train APUR: 0.6218, Test AUC: 0.6166, Test AUPR: 0.6030\n",
      "Epoch: 93/100, Loss: 0.6582453, Train Acc: 0.6058, Test Acc: 0.5867, Train AUC: 0.6447, Train APUR: 0.6215, Test AUC: 0.6100, Test AUPR: 0.5959\n",
      "Epoch: 94/100, Loss: 0.6612644, Train Acc: 0.6005, Test Acc: 0.5871, Train AUC: 0.6394, Train APUR: 0.6137, Test AUC: 0.6172, Test AUPR: 0.6044\n",
      "Epoch: 95/100, Loss: 0.6587679, Train Acc: 0.6061, Test Acc: 0.5792, Train AUC: 0.6453, Train APUR: 0.6218, Test AUC: 0.6170, Test AUPR: 0.6058\n",
      "Epoch: 96/100, Loss: 0.6618380, Train Acc: 0.5984, Test Acc: 0.5842, Train AUC: 0.6449, Train APUR: 0.6217, Test AUC: 0.6154, Test AUPR: 0.6031\n",
      "Epoch: 97/100, Loss: 0.6580868, Train Acc: 0.6035, Test Acc: 0.5861, Train AUC: 0.6460, Train APUR: 0.6232, Test AUC: 0.6091, Test AUPR: 0.5942\n",
      "Epoch: 98/100, Loss: 0.6596202, Train Acc: 0.6001, Test Acc: 0.5883, Train AUC: 0.6412, Train APUR: 0.6175, Test AUC: 0.6139, Test AUPR: 0.5997\n",
      "Epoch: 99/100, Loss: 0.6575543, Train Acc: 0.6041, Test Acc: 0.5844, Train AUC: 0.6449, Train APUR: 0.6230, Test AUC: 0.6208, Test AUPR: 0.6086\n",
      "Epoch: 100/100, Loss: 0.6574734, Train Acc: 0.6008, Test Acc: 0.5805, Train AUC: 0.6474, Train APUR: 0.6268, Test AUC: 0.6206, Test AUPR: 0.6094\n",
      "/home/ubuntu/PA-Cancer-Immunotherapy/GNN/train_pa.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(configs['save_model']))\n",
      "Test Acc: 0.5844, Test AUC: 0.6208, Test AUPR: 0.6086\n"
     ]
    }
   ],
   "source": [
    "# train with PA_all_allele \n",
    "# new in this run: in the train_pa file:  without \"args.w_aucloss * aucm_loss.to(device)\" ; without \"pos_weight=pos_weight\"\n",
    "# AND: using embeddings with just created_model tcrpeg, no training \n",
    "\n",
    "! python train_pa.py --gpu 0 --configs_path configs/PA_all_allele.yml --droup_out 0.1 --split StrictTCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634e5008-d5fd-4e97-842e-3d0763fbfb64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a579f5d-3da8-4da4-9493-078d11edfae9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(gpu=0, lr=0.001, epochs=100, w_celoss=1, w_aucloss=0, add_same_type_edges=False, dynamic_graph=False, dynamic_ratio=0.05, droup_out=0.1, positive_weights=1, dynamic_epochs=30, distance_threshold=10, configs_path='configs/PA_all_gene.yml', split='StrictTCR', dataset='pMTnet')\n",
      "models/PA_all/gene_embeddings.pkl\n",
      "['gene_fold_0.csv', 'gene_fold_1.csv', 'gene_fold_2.csv', 'gene_fold_3.csv']\n",
      "['gene_fold_4.csv']\n",
      "Epoch: 1/100, Loss: 0.6931685, Train Acc: 0.5008, Test Acc: 0.5366, Train AUC: 0.5002, Train APUR: 0.5043, Test AUC: 0.5745, Test AUPR: 0.5689\n",
      "Epoch: 2/100, Loss: 0.6928357, Train Acc: 0.5223, Test Acc: 0.5430, Train AUC: 0.5470, Train APUR: 0.5356, Test AUC: 0.5765, Test AUPR: 0.5694\n",
      "Epoch: 3/100, Loss: 0.6925907, Train Acc: 0.5344, Test Acc: 0.5462, Train AUC: 0.5503, Train APUR: 0.5325, Test AUC: 0.5770, Test AUPR: 0.5674\n",
      "Epoch: 4/100, Loss: 0.6921002, Train Acc: 0.5452, Test Acc: 0.5468, Train AUC: 0.5662, Train APUR: 0.5501, Test AUC: 0.5768, Test AUPR: 0.5664\n",
      "Epoch: 5/100, Loss: 0.6918445, Train Acc: 0.5456, Test Acc: 0.5470, Train AUC: 0.5571, Train APUR: 0.5428, Test AUC: 0.5773, Test AUPR: 0.5664\n",
      "Epoch: 6/100, Loss: 0.6912230, Train Acc: 0.5467, Test Acc: 0.5471, Train AUC: 0.5618, Train APUR: 0.5463, Test AUC: 0.5773, Test AUPR: 0.5660\n",
      "Epoch: 7/100, Loss: 0.6904729, Train Acc: 0.5478, Test Acc: 0.5471, Train AUC: 0.5656, Train APUR: 0.5469, Test AUC: 0.5773, Test AUPR: 0.5659\n",
      "Epoch: 8/100, Loss: 0.6897247, Train Acc: 0.5480, Test Acc: 0.5472, Train AUC: 0.5689, Train APUR: 0.5577, Test AUC: 0.5770, Test AUPR: 0.5660\n",
      "Epoch: 9/100, Loss: 0.6891531, Train Acc: 0.5471, Test Acc: 0.5472, Train AUC: 0.5671, Train APUR: 0.5463, Test AUC: 0.5770, Test AUPR: 0.5660\n",
      "Epoch: 10/100, Loss: 0.6879909, Train Acc: 0.5482, Test Acc: 0.5472, Train AUC: 0.5715, Train APUR: 0.5593, Test AUC: 0.5773, Test AUPR: 0.5667\n",
      "Epoch: 11/100, Loss: 0.6878283, Train Acc: 0.5479, Test Acc: 0.5470, Train AUC: 0.5678, Train APUR: 0.5520, Test AUC: 0.5773, Test AUPR: 0.5670\n",
      "Epoch: 12/100, Loss: 0.6867944, Train Acc: 0.5477, Test Acc: 0.5468, Train AUC: 0.5680, Train APUR: 0.5561, Test AUC: 0.5775, Test AUPR: 0.5676\n",
      "Epoch: 13/100, Loss: 0.6860777, Train Acc: 0.5481, Test Acc: 0.5468, Train AUC: 0.5696, Train APUR: 0.5549, Test AUC: 0.5779, Test AUPR: 0.5681\n",
      "Epoch: 14/100, Loss: 0.6857353, Train Acc: 0.5473, Test Acc: 0.5471, Train AUC: 0.5686, Train APUR: 0.5522, Test AUC: 0.5773, Test AUPR: 0.5675\n",
      "Epoch: 15/100, Loss: 0.6856281, Train Acc: 0.5479, Test Acc: 0.5472, Train AUC: 0.5724, Train APUR: 0.5632, Test AUC: 0.5772, Test AUPR: 0.5669\n",
      "Epoch: 16/100, Loss: 0.6850947, Train Acc: 0.5512, Test Acc: 0.5465, Train AUC: 0.5755, Train APUR: 0.5638, Test AUC: 0.5767, Test AUPR: 0.5659\n",
      "Epoch: 17/100, Loss: 0.6842049, Train Acc: 0.5481, Test Acc: 0.5500, Train AUC: 0.5793, Train APUR: 0.5656, Test AUC: 0.5772, Test AUPR: 0.5654\n",
      "Epoch: 18/100, Loss: 0.6850663, Train Acc: 0.5508, Test Acc: 0.5527, Train AUC: 0.5733, Train APUR: 0.5588, Test AUC: 0.5780, Test AUPR: 0.5648\n",
      "Epoch: 19/100, Loss: 0.6841007, Train Acc: 0.5527, Test Acc: 0.5547, Train AUC: 0.5790, Train APUR: 0.5655, Test AUC: 0.5786, Test AUPR: 0.5635\n",
      "Epoch: 20/100, Loss: 0.6835452, Train Acc: 0.5543, Test Acc: 0.5546, Train AUC: 0.5809, Train APUR: 0.5650, Test AUC: 0.5793, Test AUPR: 0.5623\n",
      "Epoch: 21/100, Loss: 0.6829212, Train Acc: 0.5591, Test Acc: 0.5557, Train AUC: 0.5845, Train APUR: 0.5663, Test AUC: 0.5803, Test AUPR: 0.5618\n",
      "Epoch: 22/100, Loss: 0.6828686, Train Acc: 0.5618, Test Acc: 0.5567, Train AUC: 0.5843, Train APUR: 0.5652, Test AUC: 0.5813, Test AUPR: 0.5613\n",
      "Epoch: 23/100, Loss: 0.6823099, Train Acc: 0.5647, Test Acc: 0.5596, Train AUC: 0.5874, Train APUR: 0.5678, Test AUC: 0.5832, Test AUPR: 0.5614\n",
      "Epoch: 24/100, Loss: 0.6826687, Train Acc: 0.5615, Test Acc: 0.5617, Train AUC: 0.5839, Train APUR: 0.5636, Test AUC: 0.5850, Test AUPR: 0.5618\n",
      "Epoch: 25/100, Loss: 0.6820622, Train Acc: 0.5621, Test Acc: 0.5618, Train AUC: 0.5868, Train APUR: 0.5663, Test AUC: 0.5867, Test AUPR: 0.5626\n",
      "Epoch: 26/100, Loss: 0.6804594, Train Acc: 0.5687, Test Acc: 0.5706, Train AUC: 0.5956, Train APUR: 0.5747, Test AUC: 0.5880, Test AUPR: 0.5636\n",
      "Epoch: 27/100, Loss: 0.6809038, Train Acc: 0.5685, Test Acc: 0.5736, Train AUC: 0.5927, Train APUR: 0.5694, Test AUC: 0.5892, Test AUPR: 0.5645\n",
      "Epoch: 28/100, Loss: 0.6799772, Train Acc: 0.5774, Test Acc: 0.5653, Train AUC: 0.5960, Train APUR: 0.5731, Test AUC: 0.5905, Test AUPR: 0.5652\n",
      "Epoch: 29/100, Loss: 0.6792901, Train Acc: 0.5704, Test Acc: 0.5669, Train AUC: 0.5979, Train APUR: 0.5736, Test AUC: 0.5919, Test AUPR: 0.5662\n",
      "Epoch: 30/100, Loss: 0.6795507, Train Acc: 0.5688, Test Acc: 0.5797, Train AUC: 0.5950, Train APUR: 0.5715, Test AUC: 0.5936, Test AUPR: 0.5671\n",
      "Epoch: 31/100, Loss: 0.6792904, Train Acc: 0.5786, Test Acc: 0.5825, Train AUC: 0.5961, Train APUR: 0.5738, Test AUC: 0.5954, Test AUPR: 0.5685\n",
      "Epoch: 32/100, Loss: 0.6788583, Train Acc: 0.5764, Test Acc: 0.5826, Train AUC: 0.5982, Train APUR: 0.5725, Test AUC: 0.5967, Test AUPR: 0.5694\n",
      "Epoch: 33/100, Loss: 0.6785932, Train Acc: 0.5790, Test Acc: 0.5843, Train AUC: 0.5991, Train APUR: 0.5735, Test AUC: 0.5977, Test AUPR: 0.5699\n",
      "Epoch: 34/100, Loss: 0.6777434, Train Acc: 0.5797, Test Acc: 0.5830, Train AUC: 0.6021, Train APUR: 0.5777, Test AUC: 0.5985, Test AUPR: 0.5704\n",
      "Epoch: 35/100, Loss: 0.6778840, Train Acc: 0.5813, Test Acc: 0.5829, Train AUC: 0.6014, Train APUR: 0.5764, Test AUC: 0.6000, Test AUPR: 0.5717\n",
      "Epoch: 36/100, Loss: 0.6770365, Train Acc: 0.5782, Test Acc: 0.5769, Train AUC: 0.6051, Train APUR: 0.5785, Test AUC: 0.5998, Test AUPR: 0.5724\n",
      "Epoch: 37/100, Loss: 0.6779711, Train Acc: 0.5771, Test Acc: 0.5824, Train AUC: 0.6013, Train APUR: 0.5778, Test AUC: 0.5992, Test AUPR: 0.5721\n",
      "Epoch: 38/100, Loss: 0.6768382, Train Acc: 0.5820, Test Acc: 0.5796, Train AUC: 0.6051, Train APUR: 0.5789, Test AUC: 0.5993, Test AUPR: 0.5732\n",
      "Epoch: 39/100, Loss: 0.6771106, Train Acc: 0.5825, Test Acc: 0.5748, Train AUC: 0.6031, Train APUR: 0.5789, Test AUC: 0.6002, Test AUPR: 0.5744\n",
      "Epoch: 40/100, Loss: 0.6761799, Train Acc: 0.5851, Test Acc: 0.5794, Train AUC: 0.6063, Train APUR: 0.5824, Test AUC: 0.6021, Test AUPR: 0.5758\n",
      "Epoch: 41/100, Loss: 0.6765978, Train Acc: 0.5820, Test Acc: 0.5811, Train AUC: 0.6060, Train APUR: 0.5826, Test AUC: 0.6033, Test AUPR: 0.5775\n",
      "Epoch: 42/100, Loss: 0.6758869, Train Acc: 0.5838, Test Acc: 0.5842, Train AUC: 0.6076, Train APUR: 0.5829, Test AUC: 0.6043, Test AUPR: 0.5789\n",
      "Epoch: 43/100, Loss: 0.6753411, Train Acc: 0.5825, Test Acc: 0.5803, Train AUC: 0.6083, Train APUR: 0.5835, Test AUC: 0.6049, Test AUPR: 0.5794\n",
      "Epoch: 44/100, Loss: 0.6755716, Train Acc: 0.5842, Test Acc: 0.5839, Train AUC: 0.6087, Train APUR: 0.5857, Test AUC: 0.6058, Test AUPR: 0.5805\n",
      "Epoch: 45/100, Loss: 0.6741192, Train Acc: 0.5878, Test Acc: 0.5844, Train AUC: 0.6130, Train APUR: 0.5881, Test AUC: 0.6058, Test AUPR: 0.5809\n",
      "Epoch: 46/100, Loss: 0.6748233, Train Acc: 0.5873, Test Acc: 0.5853, Train AUC: 0.6114, Train APUR: 0.5869, Test AUC: 0.6062, Test AUPR: 0.5817\n",
      "Epoch: 47/100, Loss: 0.6741717, Train Acc: 0.5844, Test Acc: 0.5872, Train AUC: 0.6119, Train APUR: 0.5876, Test AUC: 0.6060, Test AUPR: 0.5812\n",
      "Epoch: 48/100, Loss: 0.6741770, Train Acc: 0.5878, Test Acc: 0.5826, Train AUC: 0.6125, Train APUR: 0.5901, Test AUC: 0.6053, Test AUPR: 0.5801\n",
      "Epoch: 49/100, Loss: 0.6736709, Train Acc: 0.5874, Test Acc: 0.5801, Train AUC: 0.6130, Train APUR: 0.5879, Test AUC: 0.6042, Test AUPR: 0.5792\n",
      "Epoch: 50/100, Loss: 0.6740865, Train Acc: 0.5833, Test Acc: 0.5860, Train AUC: 0.6123, Train APUR: 0.5892, Test AUC: 0.6042, Test AUPR: 0.5791\n",
      "Epoch: 51/100, Loss: 0.6737190, Train Acc: 0.5908, Test Acc: 0.5822, Train AUC: 0.6144, Train APUR: 0.5894, Test AUC: 0.6064, Test AUPR: 0.5811\n",
      "Epoch: 52/100, Loss: 0.6730291, Train Acc: 0.5837, Test Acc: 0.5891, Train AUC: 0.6155, Train APUR: 0.5905, Test AUC: 0.6081, Test AUPR: 0.5829\n",
      "Epoch: 53/100, Loss: 0.6737883, Train Acc: 0.5907, Test Acc: 0.5809, Train AUC: 0.6128, Train APUR: 0.5896, Test AUC: 0.6081, Test AUPR: 0.5843\n",
      "Epoch: 54/100, Loss: 0.6744825, Train Acc: 0.5832, Test Acc: 0.5851, Train AUC: 0.6113, Train APUR: 0.5848, Test AUC: 0.6093, Test AUPR: 0.5846\n",
      "Epoch: 55/100, Loss: 0.6731288, Train Acc: 0.5922, Test Acc: 0.5910, Train AUC: 0.6164, Train APUR: 0.5926, Test AUC: 0.6091, Test AUPR: 0.5837\n",
      "Epoch: 56/100, Loss: 0.6726298, Train Acc: 0.5906, Test Acc: 0.5883, Train AUC: 0.6168, Train APUR: 0.5919, Test AUC: 0.6085, Test AUPR: 0.5827\n",
      "Epoch: 57/100, Loss: 0.6723451, Train Acc: 0.5901, Test Acc: 0.5810, Train AUC: 0.6173, Train APUR: 0.5939, Test AUC: 0.6074, Test AUPR: 0.5815\n",
      "Epoch: 58/100, Loss: 0.6725409, Train Acc: 0.5845, Test Acc: 0.5873, Train AUC: 0.6168, Train APUR: 0.5916, Test AUC: 0.6086, Test AUPR: 0.5820\n",
      "Epoch: 59/100, Loss: 0.6720155, Train Acc: 0.5905, Test Acc: 0.5882, Train AUC: 0.6174, Train APUR: 0.5901, Test AUC: 0.6096, Test AUPR: 0.5821\n",
      "Epoch: 60/100, Loss: 0.6724010, Train Acc: 0.5922, Test Acc: 0.5809, Train AUC: 0.6190, Train APUR: 0.5920, Test AUC: 0.6094, Test AUPR: 0.5821\n",
      "Epoch: 61/100, Loss: 0.6729893, Train Acc: 0.5849, Test Acc: 0.5903, Train AUC: 0.6172, Train APUR: 0.5916, Test AUC: 0.6093, Test AUPR: 0.5819\n",
      "Epoch: 62/100, Loss: 0.6716251, Train Acc: 0.6007, Test Acc: 0.5824, Train AUC: 0.6201, Train APUR: 0.5921, Test AUC: 0.6099, Test AUPR: 0.5837\n",
      "Epoch: 63/100, Loss: 0.6720080, Train Acc: 0.5872, Test Acc: 0.5879, Train AUC: 0.6181, Train APUR: 0.5932, Test AUC: 0.6103, Test AUPR: 0.5840\n",
      "Epoch: 64/100, Loss: 0.6711575, Train Acc: 0.5940, Test Acc: 0.5905, Train AUC: 0.6196, Train APUR: 0.5943, Test AUC: 0.6099, Test AUPR: 0.5823\n",
      "Epoch: 65/100, Loss: 0.6718065, Train Acc: 0.5923, Test Acc: 0.5923, Train AUC: 0.6186, Train APUR: 0.5924, Test AUC: 0.6099, Test AUPR: 0.5820\n",
      "Epoch: 66/100, Loss: 0.6707919, Train Acc: 0.5962, Test Acc: 0.5891, Train AUC: 0.6201, Train APUR: 0.5929, Test AUC: 0.6096, Test AUPR: 0.5812\n",
      "Epoch: 67/100, Loss: 0.6714495, Train Acc: 0.5965, Test Acc: 0.5895, Train AUC: 0.6193, Train APUR: 0.5931, Test AUC: 0.6094, Test AUPR: 0.5805\n",
      "Epoch: 68/100, Loss: 0.6713873, Train Acc: 0.5924, Test Acc: 0.5802, Train AUC: 0.6197, Train APUR: 0.5924, Test AUC: 0.6081, Test AUPR: 0.5793\n",
      "Epoch: 69/100, Loss: 0.6729768, Train Acc: 0.5832, Test Acc: 0.5922, Train AUC: 0.6174, Train APUR: 0.5898, Test AUC: 0.6103, Test AUPR: 0.5827\n",
      "Epoch: 70/100, Loss: 0.6710389, Train Acc: 0.5980, Test Acc: 0.5825, Train AUC: 0.6211, Train APUR: 0.5929, Test AUC: 0.6105, Test AUPR: 0.5845\n",
      "Epoch: 71/100, Loss: 0.6726013, Train Acc: 0.5843, Test Acc: 0.5914, Train AUC: 0.6180, Train APUR: 0.5914, Test AUC: 0.6106, Test AUPR: 0.5839\n",
      "Epoch: 72/100, Loss: 0.6706759, Train Acc: 0.5986, Test Acc: 0.5918, Train AUC: 0.6230, Train APUR: 0.5927, Test AUC: 0.6107, Test AUPR: 0.5837\n",
      "Epoch: 73/100, Loss: 0.6704471, Train Acc: 0.6023, Test Acc: 0.5836, Train AUC: 0.6228, Train APUR: 0.5953, Test AUC: 0.6110, Test AUPR: 0.5840\n",
      "Epoch: 74/100, Loss: 0.6709794, Train Acc: 0.5935, Test Acc: 0.5822, Train AUC: 0.6212, Train APUR: 0.5915, Test AUC: 0.6112, Test AUPR: 0.5836\n",
      "Epoch: 75/100, Loss: 0.6698623, Train Acc: 0.5976, Test Acc: 0.5888, Train AUC: 0.6227, Train APUR: 0.5917, Test AUC: 0.6099, Test AUPR: 0.5815\n",
      "Epoch: 76/100, Loss: 0.6698093, Train Acc: 0.6005, Test Acc: 0.5856, Train AUC: 0.6233, Train APUR: 0.5929, Test AUC: 0.6094, Test AUPR: 0.5802\n",
      "Epoch: 77/100, Loss: 0.6704925, Train Acc: 0.5974, Test Acc: 0.5893, Train AUC: 0.6208, Train APUR: 0.5930, Test AUC: 0.6096, Test AUPR: 0.5801\n",
      "Epoch: 78/100, Loss: 0.6692393, Train Acc: 0.6032, Test Acc: 0.5901, Train AUC: 0.6233, Train APUR: 0.5935, Test AUC: 0.6090, Test AUPR: 0.5791\n",
      "Epoch: 79/100, Loss: 0.6690124, Train Acc: 0.6041, Test Acc: 0.5895, Train AUC: 0.6239, Train APUR: 0.5940, Test AUC: 0.6084, Test AUPR: 0.5781\n",
      "Epoch: 80/100, Loss: 0.6697173, Train Acc: 0.6000, Test Acc: 0.5909, Train AUC: 0.6228, Train APUR: 0.5927, Test AUC: 0.6091, Test AUPR: 0.5790\n",
      "Epoch: 81/100, Loss: 0.6691219, Train Acc: 0.5988, Test Acc: 0.5871, Train AUC: 0.6241, Train APUR: 0.5946, Test AUC: 0.6098, Test AUPR: 0.5794\n",
      "Epoch: 82/100, Loss: 0.6685938, Train Acc: 0.5972, Test Acc: 0.5910, Train AUC: 0.6258, Train APUR: 0.5951, Test AUC: 0.6118, Test AUPR: 0.5834\n",
      "Epoch: 83/100, Loss: 0.6689665, Train Acc: 0.6043, Test Acc: 0.5846, Train AUC: 0.6243, Train APUR: 0.5964, Test AUC: 0.6128, Test AUPR: 0.5858\n",
      "Epoch: 84/100, Loss: 0.6689388, Train Acc: 0.5970, Test Acc: 0.5908, Train AUC: 0.6246, Train APUR: 0.5949, Test AUC: 0.6124, Test AUPR: 0.5849\n",
      "Epoch: 85/100, Loss: 0.6681048, Train Acc: 0.6033, Test Acc: 0.5912, Train AUC: 0.6258, Train APUR: 0.5936, Test AUC: 0.6111, Test AUPR: 0.5820\n",
      "Epoch: 86/100, Loss: 0.6683093, Train Acc: 0.6027, Test Acc: 0.5928, Train AUC: 0.6257, Train APUR: 0.5950, Test AUC: 0.6106, Test AUPR: 0.5824\n",
      "Epoch: 87/100, Loss: 0.6683688, Train Acc: 0.6048, Test Acc: 0.5919, Train AUC: 0.6262, Train APUR: 0.5932, Test AUC: 0.6107, Test AUPR: 0.5837\n",
      "Epoch: 88/100, Loss: 0.6685519, Train Acc: 0.6010, Test Acc: 0.5877, Train AUC: 0.6276, Train APUR: 0.5962, Test AUC: 0.6113, Test AUPR: 0.5847\n",
      "Epoch: 89/100, Loss: 0.6696979, Train Acc: 0.5881, Test Acc: 0.5883, Train AUC: 0.6244, Train APUR: 0.5948, Test AUC: 0.6150, Test AUPR: 0.5927\n",
      "Epoch: 90/100, Loss: 0.6676794, Train Acc: 0.6038, Test Acc: 0.5841, Train AUC: 0.6279, Train APUR: 0.5996, Test AUC: 0.6158, Test AUPR: 0.5955\n",
      "Epoch: 91/100, Loss: 0.6696094, Train Acc: 0.5917, Test Acc: 0.5918, Train AUC: 0.6246, Train APUR: 0.5975, Test AUC: 0.6143, Test AUPR: 0.5913\n",
      "Epoch: 92/100, Loss: 0.6677584, Train Acc: 0.6063, Test Acc: 0.5857, Train AUC: 0.6268, Train APUR: 0.6014, Test AUC: 0.6120, Test AUPR: 0.5862\n",
      "Epoch: 93/100, Loss: 0.6679305, Train Acc: 0.6045, Test Acc: 0.5878, Train AUC: 0.6270, Train APUR: 0.5985, Test AUC: 0.6107, Test AUPR: 0.5868\n",
      "Epoch: 94/100, Loss: 0.6680219, Train Acc: 0.6007, Test Acc: 0.5876, Train AUC: 0.6266, Train APUR: 0.5992, Test AUC: 0.6079, Test AUPR: 0.5861\n",
      "Epoch: 95/100, Loss: 0.6687937, Train Acc: 0.5914, Test Acc: 0.5896, Train AUC: 0.6246, Train APUR: 0.5922, Test AUC: 0.6130, Test AUPR: 0.5916\n",
      "Epoch: 96/100, Loss: 0.6673055, Train Acc: 0.6059, Test Acc: 0.5938, Train AUC: 0.6291, Train APUR: 0.6006, Test AUC: 0.6142, Test AUPR: 0.5916\n",
      "Epoch: 97/100, Loss: 0.6669556, Train Acc: 0.6064, Test Acc: 0.5939, Train AUC: 0.6282, Train APUR: 0.6004, Test AUC: 0.6139, Test AUPR: 0.5905\n",
      "Epoch: 98/100, Loss: 0.6670148, Train Acc: 0.6070, Test Acc: 0.5906, Train AUC: 0.6285, Train APUR: 0.6009, Test AUC: 0.6147, Test AUPR: 0.5936\n",
      "Epoch: 99/100, Loss: 0.6669962, Train Acc: 0.6036, Test Acc: 0.5943, Train AUC: 0.6284, Train APUR: 0.6010, Test AUC: 0.6163, Test AUPR: 0.5973\n",
      "Epoch: 100/100, Loss: 0.6668876, Train Acc: 0.6024, Test Acc: 0.5887, Train AUC: 0.6293, Train APUR: 0.6011, Test AUC: 0.6139, Test AUPR: 0.5938\n",
      "/home/ubuntu/PA-Cancer-Immunotherapy/GNN/train_pa.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(configs['save_model']))\n",
      "Test Acc: 0.5943, Test AUC: 0.6163, Test AUPR: 0.5973\n"
     ]
    }
   ],
   "source": [
    "# train with PA_all_gene \n",
    "# new in this run: in the train_pa file:  without \"args.w_aucloss * aucm_loss.to(device)\" ; without \"pos_weight=pos_weight\"\n",
    "# AND: using embeddings with just created_model tcrpeg, no training \n",
    "\n",
    "! python train_pa.py --gpu 0 --configs_path configs/PA_all_gene.yml --droup_out 0.1 --split StrictTCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81642a64-0d96-4b26-aa02-39fe28d6dbad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa96f00-6d81-4381-834d-bdaea8f8ec9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd62bac4-6d8f-4443-a850-9b3d91a03f81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(gpu=0, lr=0.001, epochs=100, w_celoss=1, w_aucloss=0, add_same_type_edges=False, dynamic_graph=False, dynamic_ratio=0.05, droup_out=0.1, positive_weights=1, dynamic_epochs=30, distance_threshold=10, configs_path='configs/PA_all_gene.yml', split='StrictTCR', dataset='pMTnet')\n",
      "embeddings_path:   models/PA_all/gene_and_allele_embeddings.pkl\n",
      "train_file_list:   ['gene_fold_0.csv', 'gene_fold_1.csv', 'gene_fold_2.csv', 'gene_fold_3.csv']\n",
      "test_file_list:   ['gene_fold_4.csv']\n",
      "Epoch: 1/100, Loss: 0.6931127, Train Acc: 0.5071, Test Acc: 0.5335, Train AUC: 0.5063, Train APUR: 0.5050, Test AUC: 0.5882, Test AUPR: 0.5800\n",
      "Epoch: 2/100, Loss: 0.6904224, Train Acc: 0.5185, Test Acc: 0.5525, Train AUC: 0.5700, Train APUR: 0.5530, Test AUC: 0.5915, Test AUPR: 0.5869\n",
      "Epoch: 3/100, Loss: 0.6880704, Train Acc: 0.5456, Test Acc: 0.5722, Train AUC: 0.5836, Train APUR: 0.5736, Test AUC: 0.5976, Test AUPR: 0.5934\n",
      "Epoch: 4/100, Loss: 0.6837313, Train Acc: 0.5707, Test Acc: 0.5686, Train AUC: 0.5914, Train APUR: 0.5767, Test AUC: 0.6007, Test AUPR: 0.5947\n",
      "Epoch: 5/100, Loss: 0.6811043, Train Acc: 0.5687, Test Acc: 0.5743, Train AUC: 0.5919, Train APUR: 0.5823, Test AUC: 0.6026, Test AUPR: 0.5953\n",
      "Epoch: 6/100, Loss: 0.6796641, Train Acc: 0.5746, Test Acc: 0.5756, Train AUC: 0.5986, Train APUR: 0.5858, Test AUC: 0.6055, Test AUPR: 0.5970\n",
      "Epoch: 7/100, Loss: 0.6776628, Train Acc: 0.5773, Test Acc: 0.5795, Train AUC: 0.6041, Train APUR: 0.5926, Test AUC: 0.6099, Test AUPR: 0.6007\n",
      "Epoch: 8/100, Loss: 0.6746356, Train Acc: 0.5808, Test Acc: 0.5799, Train AUC: 0.6120, Train APUR: 0.6034, Test AUC: 0.6114, Test AUPR: 0.6019\n",
      "Epoch: 9/100, Loss: 0.6734982, Train Acc: 0.5809, Test Acc: 0.5834, Train AUC: 0.6147, Train APUR: 0.6030, Test AUC: 0.6136, Test AUPR: 0.6032\n",
      "Epoch: 10/100, Loss: 0.6724921, Train Acc: 0.5868, Test Acc: 0.5898, Train AUC: 0.6183, Train APUR: 0.6033, Test AUC: 0.6144, Test AUPR: 0.6041\n",
      "Epoch: 11/100, Loss: 0.6716064, Train Acc: 0.5893, Test Acc: 0.5917, Train AUC: 0.6211, Train APUR: 0.6094, Test AUC: 0.6153, Test AUPR: 0.6055\n",
      "Epoch: 12/100, Loss: 0.6699256, Train Acc: 0.5911, Test Acc: 0.5853, Train AUC: 0.6248, Train APUR: 0.6117, Test AUC: 0.6173, Test AUPR: 0.6072\n",
      "Epoch: 13/100, Loss: 0.6706237, Train Acc: 0.5942, Test Acc: 0.5873, Train AUC: 0.6255, Train APUR: 0.6125, Test AUC: 0.6186, Test AUPR: 0.6090\n",
      "Epoch: 14/100, Loss: 0.6688560, Train Acc: 0.5926, Test Acc: 0.5885, Train AUC: 0.6269, Train APUR: 0.6145, Test AUC: 0.6197, Test AUPR: 0.6105\n",
      "Epoch: 15/100, Loss: 0.6691566, Train Acc: 0.5924, Test Acc: 0.5935, Train AUC: 0.6287, Train APUR: 0.6161, Test AUC: 0.6220, Test AUPR: 0.6124\n",
      "Epoch: 16/100, Loss: 0.6670355, Train Acc: 0.6003, Test Acc: 0.5858, Train AUC: 0.6306, Train APUR: 0.6175, Test AUC: 0.6229, Test AUPR: 0.6131\n",
      "Epoch: 17/100, Loss: 0.6678818, Train Acc: 0.5968, Test Acc: 0.5916, Train AUC: 0.6322, Train APUR: 0.6181, Test AUC: 0.6242, Test AUPR: 0.6149\n",
      "Epoch: 18/100, Loss: 0.6660258, Train Acc: 0.5995, Test Acc: 0.5939, Train AUC: 0.6336, Train APUR: 0.6205, Test AUC: 0.6256, Test AUPR: 0.6170\n",
      "Epoch: 19/100, Loss: 0.6663419, Train Acc: 0.5981, Test Acc: 0.5999, Train AUC: 0.6339, Train APUR: 0.6210, Test AUC: 0.6268, Test AUPR: 0.6182\n",
      "Epoch: 20/100, Loss: 0.6659622, Train Acc: 0.6015, Test Acc: 0.5936, Train AUC: 0.6357, Train APUR: 0.6215, Test AUC: 0.6276, Test AUPR: 0.6184\n",
      "Epoch: 21/100, Loss: 0.6645932, Train Acc: 0.6040, Test Acc: 0.5921, Train AUC: 0.6366, Train APUR: 0.6242, Test AUC: 0.6280, Test AUPR: 0.6182\n",
      "Epoch: 22/100, Loss: 0.6648501, Train Acc: 0.6029, Test Acc: 0.5943, Train AUC: 0.6374, Train APUR: 0.6244, Test AUC: 0.6293, Test AUPR: 0.6195\n",
      "Epoch: 23/100, Loss: 0.6638305, Train Acc: 0.6050, Test Acc: 0.6031, Train AUC: 0.6386, Train APUR: 0.6242, Test AUC: 0.6310, Test AUPR: 0.6214\n",
      "Epoch: 24/100, Loss: 0.6632036, Train Acc: 0.6018, Test Acc: 0.6014, Train AUC: 0.6397, Train APUR: 0.6273, Test AUC: 0.6319, Test AUPR: 0.6219\n",
      "Epoch: 25/100, Loss: 0.6631722, Train Acc: 0.6046, Test Acc: 0.6029, Train AUC: 0.6393, Train APUR: 0.6260, Test AUC: 0.6317, Test AUPR: 0.6214\n",
      "Epoch: 26/100, Loss: 0.6630946, Train Acc: 0.6019, Test Acc: 0.5985, Train AUC: 0.6399, Train APUR: 0.6257, Test AUC: 0.6309, Test AUPR: 0.6213\n",
      "Epoch: 27/100, Loss: 0.6619451, Train Acc: 0.6100, Test Acc: 0.5959, Train AUC: 0.6417, Train APUR: 0.6280, Test AUC: 0.6309, Test AUPR: 0.6220\n",
      "Epoch: 28/100, Loss: 0.6619158, Train Acc: 0.6039, Test Acc: 0.5953, Train AUC: 0.6416, Train APUR: 0.6281, Test AUC: 0.6307, Test AUPR: 0.6222\n",
      "Epoch: 29/100, Loss: 0.6618210, Train Acc: 0.6044, Test Acc: 0.6002, Train AUC: 0.6427, Train APUR: 0.6284, Test AUC: 0.6315, Test AUPR: 0.6225\n",
      "Epoch: 30/100, Loss: 0.6611304, Train Acc: 0.6100, Test Acc: 0.5994, Train AUC: 0.6448, Train APUR: 0.6289, Test AUC: 0.6328, Test AUPR: 0.6240\n",
      "Epoch: 31/100, Loss: 0.6603701, Train Acc: 0.6092, Test Acc: 0.6004, Train AUC: 0.6460, Train APUR: 0.6318, Test AUC: 0.6344, Test AUPR: 0.6260\n",
      "Epoch: 32/100, Loss: 0.6603183, Train Acc: 0.6115, Test Acc: 0.6050, Train AUC: 0.6476, Train APUR: 0.6334, Test AUC: 0.6354, Test AUPR: 0.6264\n",
      "Epoch: 33/100, Loss: 0.6596040, Train Acc: 0.6121, Test Acc: 0.6002, Train AUC: 0.6465, Train APUR: 0.6323, Test AUC: 0.6363, Test AUPR: 0.6263\n",
      "Epoch: 34/100, Loss: 0.6595545, Train Acc: 0.6111, Test Acc: 0.6062, Train AUC: 0.6480, Train APUR: 0.6322, Test AUC: 0.6369, Test AUPR: 0.6275\n",
      "Epoch: 35/100, Loss: 0.6584848, Train Acc: 0.6119, Test Acc: 0.5970, Train AUC: 0.6494, Train APUR: 0.6348, Test AUC: 0.6375, Test AUPR: 0.6295\n",
      "Epoch: 36/100, Loss: 0.6579310, Train Acc: 0.6110, Test Acc: 0.5974, Train AUC: 0.6505, Train APUR: 0.6358, Test AUC: 0.6380, Test AUPR: 0.6305\n",
      "Epoch: 37/100, Loss: 0.6581351, Train Acc: 0.6110, Test Acc: 0.6063, Train AUC: 0.6512, Train APUR: 0.6365, Test AUC: 0.6380, Test AUPR: 0.6293\n",
      "Epoch: 38/100, Loss: 0.6568306, Train Acc: 0.6126, Test Acc: 0.6045, Train AUC: 0.6526, Train APUR: 0.6375, Test AUC: 0.6386, Test AUPR: 0.6290\n",
      "Epoch: 39/100, Loss: 0.6571821, Train Acc: 0.6098, Test Acc: 0.6019, Train AUC: 0.6527, Train APUR: 0.6368, Test AUC: 0.6414, Test AUPR: 0.6325\n",
      "Epoch: 40/100, Loss: 0.6557275, Train Acc: 0.6169, Test Acc: 0.5998, Train AUC: 0.6546, Train APUR: 0.6397, Test AUC: 0.6435, Test AUPR: 0.6348\n",
      "Epoch: 41/100, Loss: 0.6554295, Train Acc: 0.6150, Test Acc: 0.6053, Train AUC: 0.6565, Train APUR: 0.6413, Test AUC: 0.6442, Test AUPR: 0.6351\n",
      "Epoch: 42/100, Loss: 0.6544973, Train Acc: 0.6192, Test Acc: 0.6093, Train AUC: 0.6579, Train APUR: 0.6419, Test AUC: 0.6441, Test AUPR: 0.6348\n",
      "Epoch: 43/100, Loss: 0.6539235, Train Acc: 0.6109, Test Acc: 0.6131, Train AUC: 0.6583, Train APUR: 0.6437, Test AUC: 0.6472, Test AUPR: 0.6382\n",
      "Epoch: 44/100, Loss: 0.6524876, Train Acc: 0.6205, Test Acc: 0.6126, Train AUC: 0.6616, Train APUR: 0.6470, Test AUC: 0.6484, Test AUPR: 0.6401\n",
      "Epoch: 45/100, Loss: 0.6519037, Train Acc: 0.6220, Test Acc: 0.6169, Train AUC: 0.6634, Train APUR: 0.6485, Test AUC: 0.6504, Test AUPR: 0.6407\n",
      "Epoch: 46/100, Loss: 0.6513864, Train Acc: 0.6185, Test Acc: 0.6176, Train AUC: 0.6639, Train APUR: 0.6492, Test AUC: 0.6511, Test AUPR: 0.6419\n",
      "Epoch: 47/100, Loss: 0.6496140, Train Acc: 0.6249, Test Acc: 0.6099, Train AUC: 0.6675, Train APUR: 0.6516, Test AUC: 0.6509, Test AUPR: 0.6433\n",
      "Epoch: 48/100, Loss: 0.6489478, Train Acc: 0.6239, Test Acc: 0.6177, Train AUC: 0.6674, Train APUR: 0.6535, Test AUC: 0.6553, Test AUPR: 0.6466\n",
      "Epoch: 49/100, Loss: 0.6473658, Train Acc: 0.6290, Test Acc: 0.6244, Train AUC: 0.6719, Train APUR: 0.6563, Test AUC: 0.6590, Test AUPR: 0.6481\n",
      "Epoch: 50/100, Loss: 0.6465612, Train Acc: 0.6294, Test Acc: 0.6210, Train AUC: 0.6745, Train APUR: 0.6580, Test AUC: 0.6589, Test AUPR: 0.6476\n",
      "Epoch: 51/100, Loss: 0.6456189, Train Acc: 0.6267, Test Acc: 0.6211, Train AUC: 0.6723, Train APUR: 0.6570, Test AUC: 0.6640, Test AUPR: 0.6529\n",
      "Epoch: 52/100, Loss: 0.6444039, Train Acc: 0.6340, Test Acc: 0.6283, Train AUC: 0.6786, Train APUR: 0.6614, Test AUC: 0.6635, Test AUPR: 0.6530\n",
      "Epoch: 53/100, Loss: 0.6427529, Train Acc: 0.6386, Test Acc: 0.6254, Train AUC: 0.6815, Train APUR: 0.6640, Test AUC: 0.6624, Test AUPR: 0.6494\n",
      "Epoch: 54/100, Loss: 0.6424055, Train Acc: 0.6357, Test Acc: 0.6209, Train AUC: 0.6803, Train APUR: 0.6642, Test AUC: 0.6700, Test AUPR: 0.6566\n",
      "Epoch: 55/100, Loss: 0.6432036, Train Acc: 0.6370, Test Acc: 0.6293, Train AUC: 0.6872, Train APUR: 0.6684, Test AUC: 0.6711, Test AUPR: 0.6566\n",
      "Epoch: 56/100, Loss: 0.6383684, Train Acc: 0.6426, Test Acc: 0.6288, Train AUC: 0.6899, Train APUR: 0.6722, Test AUC: 0.6660, Test AUPR: 0.6529\n",
      "Epoch: 57/100, Loss: 0.6387933, Train Acc: 0.6398, Test Acc: 0.6309, Train AUC: 0.6860, Train APUR: 0.6711, Test AUC: 0.6717, Test AUPR: 0.6601\n",
      "Epoch: 58/100, Loss: 0.6355939, Train Acc: 0.6447, Test Acc: 0.6274, Train AUC: 0.6943, Train APUR: 0.6774, Test AUC: 0.6735, Test AUPR: 0.6605\n",
      "Epoch: 59/100, Loss: 0.6331277, Train Acc: 0.6477, Test Acc: 0.6310, Train AUC: 0.6969, Train APUR: 0.6787, Test AUC: 0.6737, Test AUPR: 0.6596\n",
      "Epoch: 60/100, Loss: 0.6326645, Train Acc: 0.6469, Test Acc: 0.6327, Train AUC: 0.6949, Train APUR: 0.6799, Test AUC: 0.6759, Test AUPR: 0.6671\n",
      "Epoch: 61/100, Loss: 0.6308182, Train Acc: 0.6473, Test Acc: 0.6358, Train AUC: 0.7002, Train APUR: 0.6861, Test AUC: 0.6809, Test AUPR: 0.6682\n",
      "Epoch: 62/100, Loss: 0.6278385, Train Acc: 0.6510, Test Acc: 0.6266, Train AUC: 0.7039, Train APUR: 0.6869, Test AUC: 0.6796, Test AUPR: 0.6650\n",
      "Epoch: 63/100, Loss: 0.6283169, Train Acc: 0.6483, Test Acc: 0.6325, Train AUC: 0.7040, Train APUR: 0.6868, Test AUC: 0.6790, Test AUPR: 0.6712\n",
      "Epoch: 64/100, Loss: 0.6272745, Train Acc: 0.6494, Test Acc: 0.6335, Train AUC: 0.7052, Train APUR: 0.6928, Test AUC: 0.6808, Test AUPR: 0.6704\n",
      "Epoch: 65/100, Loss: 0.6263847, Train Acc: 0.6486, Test Acc: 0.6366, Train AUC: 0.7073, Train APUR: 0.6931, Test AUC: 0.6869, Test AUPR: 0.6762\n",
      "Epoch: 66/100, Loss: 0.6210442, Train Acc: 0.6550, Test Acc: 0.6322, Train AUC: 0.7126, Train APUR: 0.6983, Test AUC: 0.6872, Test AUPR: 0.6774\n",
      "Epoch: 67/100, Loss: 0.6229073, Train Acc: 0.6534, Test Acc: 0.6373, Train AUC: 0.7124, Train APUR: 0.6997, Test AUC: 0.6845, Test AUPR: 0.6710\n",
      "Epoch: 68/100, Loss: 0.6203143, Train Acc: 0.6554, Test Acc: 0.6354, Train AUC: 0.7135, Train APUR: 0.6979, Test AUC: 0.6889, Test AUPR: 0.6794\n",
      "Epoch: 69/100, Loss: 0.6196333, Train Acc: 0.6531, Test Acc: 0.6363, Train AUC: 0.7171, Train APUR: 0.7037, Test AUC: 0.6888, Test AUPR: 0.6734\n",
      "Epoch: 70/100, Loss: 0.6182359, Train Acc: 0.6576, Test Acc: 0.6228, Train AUC: 0.7161, Train APUR: 0.7001, Test AUC: 0.6862, Test AUPR: 0.6698\n",
      "Epoch: 71/100, Loss: 0.6200758, Train Acc: 0.6534, Test Acc: 0.6373, Train AUC: 0.7181, Train APUR: 0.7057, Test AUC: 0.6849, Test AUPR: 0.6729\n",
      "Epoch: 72/100, Loss: 0.6153033, Train Acc: 0.6592, Test Acc: 0.6355, Train AUC: 0.7187, Train APUR: 0.7071, Test AUC: 0.6907, Test AUPR: 0.6823\n",
      "Epoch: 73/100, Loss: 0.6166918, Train Acc: 0.6553, Test Acc: 0.6427, Train AUC: 0.7219, Train APUR: 0.7125, Test AUC: 0.6962, Test AUPR: 0.6864\n",
      "Epoch: 74/100, Loss: 0.6142595, Train Acc: 0.6581, Test Acc: 0.6256, Train AUC: 0.7204, Train APUR: 0.7111, Test AUC: 0.6804, Test AUPR: 0.6661\n",
      "Epoch: 75/100, Loss: 0.6236032, Train Acc: 0.6525, Test Acc: 0.6400, Train AUC: 0.7124, Train APUR: 0.6997, Test AUC: 0.6976, Test AUPR: 0.6852\n",
      "Epoch: 76/100, Loss: 0.6102676, Train Acc: 0.6613, Test Acc: 0.6409, Train AUC: 0.7259, Train APUR: 0.7173, Test AUC: 0.6921, Test AUPR: 0.6791\n",
      "Epoch: 77/100, Loss: 0.6118404, Train Acc: 0.6614, Test Acc: 0.6343, Train AUC: 0.7233, Train APUR: 0.7144, Test AUC: 0.6847, Test AUPR: 0.6708\n",
      "Epoch: 78/100, Loss: 0.6119859, Train Acc: 0.6607, Test Acc: 0.6400, Train AUC: 0.7254, Train APUR: 0.7145, Test AUC: 0.6885, Test AUPR: 0.6732\n",
      "Epoch: 79/100, Loss: 0.6065272, Train Acc: 0.6656, Test Acc: 0.6344, Train AUC: 0.7297, Train APUR: 0.7207, Test AUC: 0.6925, Test AUPR: 0.6726\n",
      "Epoch: 80/100, Loss: 0.6063060, Train Acc: 0.6669, Test Acc: 0.6267, Train AUC: 0.7313, Train APUR: 0.7226, Test AUC: 0.6918, Test AUPR: 0.6728\n",
      "Epoch: 81/100, Loss: 0.6086344, Train Acc: 0.6611, Test Acc: 0.6419, Train AUC: 0.7275, Train APUR: 0.7209, Test AUC: 0.6871, Test AUPR: 0.6703\n",
      "Epoch: 82/100, Loss: 0.6043755, Train Acc: 0.6680, Test Acc: 0.6425, Train AUC: 0.7309, Train APUR: 0.7209, Test AUC: 0.6912, Test AUPR: 0.6761\n",
      "Epoch: 83/100, Loss: 0.6059771, Train Acc: 0.6672, Test Acc: 0.6438, Train AUC: 0.7312, Train APUR: 0.7187, Test AUC: 0.6961, Test AUPR: 0.6839\n",
      "Epoch: 84/100, Loss: 0.6056282, Train Acc: 0.6652, Test Acc: 0.6436, Train AUC: 0.7299, Train APUR: 0.7227, Test AUC: 0.6961, Test AUPR: 0.6870\n",
      "Epoch: 85/100, Loss: 0.6005023, Train Acc: 0.6712, Test Acc: 0.6370, Train AUC: 0.7357, Train APUR: 0.7282, Test AUC: 0.6934, Test AUPR: 0.6846\n",
      "Epoch: 86/100, Loss: 0.6024675, Train Acc: 0.6703, Test Acc: 0.6426, Train AUC: 0.7350, Train APUR: 0.7269, Test AUC: 0.6954, Test AUPR: 0.6850\n",
      "Epoch: 87/100, Loss: 0.6002107, Train Acc: 0.6716, Test Acc: 0.6456, Train AUC: 0.7364, Train APUR: 0.7283, Test AUC: 0.6984, Test AUPR: 0.6875\n",
      "Epoch: 88/100, Loss: 0.5980178, Train Acc: 0.6747, Test Acc: 0.6431, Train AUC: 0.7393, Train APUR: 0.7322, Test AUC: 0.6947, Test AUPR: 0.6844\n",
      "Epoch: 89/100, Loss: 0.5982599, Train Acc: 0.6717, Test Acc: 0.6474, Train AUC: 0.7414, Train APUR: 0.7342, Test AUC: 0.7005, Test AUPR: 0.6892\n",
      "Epoch: 90/100, Loss: 0.5954056, Train Acc: 0.6749, Test Acc: 0.6432, Train AUC: 0.7416, Train APUR: 0.7352, Test AUC: 0.7025, Test AUPR: 0.6871\n",
      "Epoch: 91/100, Loss: 0.5963219, Train Acc: 0.6727, Test Acc: 0.6397, Train AUC: 0.7407, Train APUR: 0.7333, Test AUC: 0.7009, Test AUPR: 0.6868\n",
      "Epoch: 92/100, Loss: 0.5995139, Train Acc: 0.6696, Test Acc: 0.6415, Train AUC: 0.7376, Train APUR: 0.7317, Test AUC: 0.6903, Test AUPR: 0.6769\n",
      "Epoch: 93/100, Loss: 0.5991519, Train Acc: 0.6723, Test Acc: 0.6417, Train AUC: 0.7366, Train APUR: 0.7280, Test AUC: 0.6956, Test AUPR: 0.6853\n",
      "Epoch: 94/100, Loss: 0.5943472, Train Acc: 0.6750, Test Acc: 0.6293, Train AUC: 0.7447, Train APUR: 0.7385, Test AUC: 0.6758, Test AUPR: 0.6603\n",
      "Epoch: 95/100, Loss: 0.6108191, Train Acc: 0.6578, Test Acc: 0.6413, Train AUC: 0.7195, Train APUR: 0.7137, Test AUC: 0.6922, Test AUPR: 0.6802\n",
      "Epoch: 96/100, Loss: 0.5936548, Train Acc: 0.6758, Test Acc: 0.6301, Train AUC: 0.7432, Train APUR: 0.7369, Test AUC: 0.6793, Test AUPR: 0.6650\n",
      "Epoch: 97/100, Loss: 0.6093484, Train Acc: 0.6635, Test Acc: 0.6460, Train AUC: 0.7267, Train APUR: 0.7167, Test AUC: 0.7038, Test AUPR: 0.6919\n",
      "Epoch: 98/100, Loss: 0.5918167, Train Acc: 0.6761, Test Acc: 0.6452, Train AUC: 0.7465, Train APUR: 0.7431, Test AUC: 0.6978, Test AUPR: 0.6843\n",
      "Epoch: 99/100, Loss: 0.6027306, Train Acc: 0.6665, Test Acc: 0.6466, Train AUC: 0.7324, Train APUR: 0.7288, Test AUC: 0.7002, Test AUPR: 0.6893\n",
      "Epoch: 100/100, Loss: 0.5892898, Train Acc: 0.6798, Test Acc: 0.6346, Train AUC: 0.7491, Train APUR: 0.7439, Test AUC: 0.6816, Test AUPR: 0.6678\n",
      "/home/ubuntu/PA-Cancer-Immunotherapy/GNN/train_pa.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(configs['save_model']))\n",
      "Test Acc: 0.6460, Test AUC: 0.7038, Test AUPR: 0.6919\n"
     ]
    }
   ],
   "source": [
    "# Next experiment:\n",
    "# generate embeddings with the trained tcrpeg model, but separately for cdr3 and for epitope. \n",
    "# In fact I can one training for cdr3 of both allele and gen and another training for epitopes.\n",
    "# This will be done in the embeddings_gnn file and run the model here:\n",
    "\n",
    "! python train_pa.py --gpu 0 --configs_path configs/PA_all_gene.yml --droup_out 0.1 --split StrictTCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c434fd-8311-4e23-9b6c-36c3ca9076a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0aacb5f-41ba-4f8f-8668-d6150ee0552b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(gpu=0, lr=0.001, epochs=200, w_celoss=1, w_aucloss=0, add_same_type_edges=False, dynamic_graph=False, dynamic_ratio=0.05, droup_out=0.1, positive_weights=1, dynamic_epochs=30, distance_threshold=10, configs_path='configs/PA_all_gene.yml', split='StrictTCR', dataset='pMTnet')\n",
      "embeddings_path:   models/PA_all/gene_and_allele_embeddings.pkl\n",
      "train_file_list:   ['gene_fold_0.csv', 'gene_fold_1.csv', 'gene_fold_2.csv', 'gene_fold_3.csv']\n",
      "test_file_list:   ['gene_fold_4.csv']\n",
      "Epoch: 1/200, Loss: 0.6931127, Train Acc: 0.5071, Test Acc: 0.5335, Train AUC: 0.5063, Train APUR: 0.5050, Test AUC: 0.5882, Test AUPR: 0.5800\n",
      "Epoch: 2/200, Loss: 0.6904224, Train Acc: 0.5185, Test Acc: 0.5525, Train AUC: 0.5700, Train APUR: 0.5530, Test AUC: 0.5915, Test AUPR: 0.5869\n",
      "Epoch: 3/200, Loss: 0.6880704, Train Acc: 0.5456, Test Acc: 0.5722, Train AUC: 0.5836, Train APUR: 0.5736, Test AUC: 0.5976, Test AUPR: 0.5934\n",
      "Epoch: 4/200, Loss: 0.6837314, Train Acc: 0.5707, Test Acc: 0.5686, Train AUC: 0.5914, Train APUR: 0.5767, Test AUC: 0.6007, Test AUPR: 0.5947\n",
      "Epoch: 5/200, Loss: 0.6811045, Train Acc: 0.5687, Test Acc: 0.5743, Train AUC: 0.5919, Train APUR: 0.5823, Test AUC: 0.6026, Test AUPR: 0.5953\n",
      "Epoch: 6/200, Loss: 0.6796639, Train Acc: 0.5746, Test Acc: 0.5756, Train AUC: 0.5986, Train APUR: 0.5858, Test AUC: 0.6055, Test AUPR: 0.5970\n",
      "Epoch: 7/200, Loss: 0.6776619, Train Acc: 0.5774, Test Acc: 0.5795, Train AUC: 0.6041, Train APUR: 0.5926, Test AUC: 0.6099, Test AUPR: 0.6007\n",
      "Epoch: 8/200, Loss: 0.6746354, Train Acc: 0.5808, Test Acc: 0.5800, Train AUC: 0.6120, Train APUR: 0.6034, Test AUC: 0.6114, Test AUPR: 0.6019\n",
      "Epoch: 9/200, Loss: 0.6734993, Train Acc: 0.5809, Test Acc: 0.5834, Train AUC: 0.6147, Train APUR: 0.6030, Test AUC: 0.6136, Test AUPR: 0.6032\n",
      "Epoch: 10/200, Loss: 0.6724920, Train Acc: 0.5868, Test Acc: 0.5898, Train AUC: 0.6183, Train APUR: 0.6033, Test AUC: 0.6144, Test AUPR: 0.6041\n",
      "Epoch: 11/200, Loss: 0.6716057, Train Acc: 0.5893, Test Acc: 0.5917, Train AUC: 0.6211, Train APUR: 0.6094, Test AUC: 0.6153, Test AUPR: 0.6055\n",
      "Epoch: 12/200, Loss: 0.6699283, Train Acc: 0.5911, Test Acc: 0.5853, Train AUC: 0.6248, Train APUR: 0.6117, Test AUC: 0.6173, Test AUPR: 0.6072\n",
      "Epoch: 13/200, Loss: 0.6706296, Train Acc: 0.5943, Test Acc: 0.5873, Train AUC: 0.6255, Train APUR: 0.6125, Test AUC: 0.6187, Test AUPR: 0.6090\n",
      "Epoch: 14/200, Loss: 0.6688595, Train Acc: 0.5926, Test Acc: 0.5885, Train AUC: 0.6269, Train APUR: 0.6145, Test AUC: 0.6197, Test AUPR: 0.6105\n",
      "Epoch: 15/200, Loss: 0.6691557, Train Acc: 0.5924, Test Acc: 0.5935, Train AUC: 0.6287, Train APUR: 0.6161, Test AUC: 0.6220, Test AUPR: 0.6124\n",
      "Epoch: 16/200, Loss: 0.6670452, Train Acc: 0.6004, Test Acc: 0.5855, Train AUC: 0.6306, Train APUR: 0.6174, Test AUC: 0.6228, Test AUPR: 0.6131\n",
      "Epoch: 17/200, Loss: 0.6678755, Train Acc: 0.5967, Test Acc: 0.5916, Train AUC: 0.6322, Train APUR: 0.6181, Test AUC: 0.6242, Test AUPR: 0.6149\n",
      "Epoch: 18/200, Loss: 0.6660317, Train Acc: 0.5994, Test Acc: 0.5937, Train AUC: 0.6336, Train APUR: 0.6205, Test AUC: 0.6256, Test AUPR: 0.6170\n",
      "Epoch: 19/200, Loss: 0.6663425, Train Acc: 0.5981, Test Acc: 0.5995, Train AUC: 0.6339, Train APUR: 0.6210, Test AUC: 0.6268, Test AUPR: 0.6182\n",
      "Epoch: 20/200, Loss: 0.6659570, Train Acc: 0.6015, Test Acc: 0.5936, Train AUC: 0.6357, Train APUR: 0.6215, Test AUC: 0.6276, Test AUPR: 0.6184\n",
      "Epoch: 21/200, Loss: 0.6645957, Train Acc: 0.6040, Test Acc: 0.5922, Train AUC: 0.6366, Train APUR: 0.6242, Test AUC: 0.6280, Test AUPR: 0.6182\n",
      "Epoch: 22/200, Loss: 0.6648300, Train Acc: 0.6027, Test Acc: 0.5943, Train AUC: 0.6375, Train APUR: 0.6245, Test AUC: 0.6293, Test AUPR: 0.6195\n",
      "Epoch: 23/200, Loss: 0.6638355, Train Acc: 0.6046, Test Acc: 0.6018, Train AUC: 0.6386, Train APUR: 0.6242, Test AUC: 0.6311, Test AUPR: 0.6214\n",
      "Epoch: 24/200, Loss: 0.6631842, Train Acc: 0.6021, Test Acc: 0.5979, Train AUC: 0.6398, Train APUR: 0.6274, Test AUC: 0.6320, Test AUPR: 0.6220\n",
      "Epoch: 25/200, Loss: 0.6631885, Train Acc: 0.6039, Test Acc: 0.6044, Train AUC: 0.6393, Train APUR: 0.6260, Test AUC: 0.6318, Test AUPR: 0.6214\n",
      "Epoch: 26/200, Loss: 0.6630847, Train Acc: 0.6023, Test Acc: 0.5974, Train AUC: 0.6400, Train APUR: 0.6258, Test AUC: 0.6309, Test AUPR: 0.6213\n",
      "Epoch: 27/200, Loss: 0.6619447, Train Acc: 0.6100, Test Acc: 0.5958, Train AUC: 0.6418, Train APUR: 0.6280, Test AUC: 0.6309, Test AUPR: 0.6221\n",
      "Epoch: 28/200, Loss: 0.6619032, Train Acc: 0.6040, Test Acc: 0.5954, Train AUC: 0.6417, Train APUR: 0.6281, Test AUC: 0.6307, Test AUPR: 0.6222\n",
      "Epoch: 29/200, Loss: 0.6618460, Train Acc: 0.6041, Test Acc: 0.5995, Train AUC: 0.6426, Train APUR: 0.6283, Test AUC: 0.6314, Test AUPR: 0.6224\n",
      "Epoch: 30/200, Loss: 0.6611227, Train Acc: 0.6098, Test Acc: 0.5981, Train AUC: 0.6448, Train APUR: 0.6290, Test AUC: 0.6327, Test AUPR: 0.6240\n",
      "Epoch: 31/200, Loss: 0.6604084, Train Acc: 0.6089, Test Acc: 0.6005, Train AUC: 0.6460, Train APUR: 0.6318, Test AUC: 0.6344, Test AUPR: 0.6261\n",
      "Epoch: 32/200, Loss: 0.6603175, Train Acc: 0.6116, Test Acc: 0.6049, Train AUC: 0.6476, Train APUR: 0.6334, Test AUC: 0.6356, Test AUPR: 0.6264\n",
      "Epoch: 33/200, Loss: 0.6596313, Train Acc: 0.6120, Test Acc: 0.5995, Train AUC: 0.6465, Train APUR: 0.6322, Test AUC: 0.6364, Test AUPR: 0.6264\n",
      "Epoch: 34/200, Loss: 0.6595142, Train Acc: 0.6107, Test Acc: 0.6063, Train AUC: 0.6480, Train APUR: 0.6322, Test AUC: 0.6370, Test AUPR: 0.6276\n",
      "Epoch: 35/200, Loss: 0.6585268, Train Acc: 0.6117, Test Acc: 0.5975, Train AUC: 0.6493, Train APUR: 0.6347, Test AUC: 0.6377, Test AUPR: 0.6295\n",
      "Epoch: 36/200, Loss: 0.6579711, Train Acc: 0.6101, Test Acc: 0.5977, Train AUC: 0.6504, Train APUR: 0.6358, Test AUC: 0.6382, Test AUPR: 0.6306\n",
      "Epoch: 37/200, Loss: 0.6580921, Train Acc: 0.6109, Test Acc: 0.6058, Train AUC: 0.6512, Train APUR: 0.6366, Test AUC: 0.6381, Test AUPR: 0.6293\n",
      "Epoch: 38/200, Loss: 0.6567833, Train Acc: 0.6129, Test Acc: 0.6039, Train AUC: 0.6526, Train APUR: 0.6376, Test AUC: 0.6385, Test AUPR: 0.6288\n",
      "Epoch: 39/200, Loss: 0.6572314, Train Acc: 0.6087, Test Acc: 0.6030, Train AUC: 0.6528, Train APUR: 0.6368, Test AUC: 0.6414, Test AUPR: 0.6325\n",
      "Epoch: 40/200, Loss: 0.6557077, Train Acc: 0.6168, Test Acc: 0.6002, Train AUC: 0.6547, Train APUR: 0.6398, Test AUC: 0.6436, Test AUPR: 0.6349\n",
      "Epoch: 41/200, Loss: 0.6554666, Train Acc: 0.6148, Test Acc: 0.6047, Train AUC: 0.6565, Train APUR: 0.6413, Test AUC: 0.6443, Test AUPR: 0.6352\n",
      "Epoch: 42/200, Loss: 0.6545444, Train Acc: 0.6195, Test Acc: 0.6099, Train AUC: 0.6579, Train APUR: 0.6419, Test AUC: 0.6440, Test AUPR: 0.6349\n",
      "Epoch: 43/200, Loss: 0.6539824, Train Acc: 0.6113, Test Acc: 0.6124, Train AUC: 0.6582, Train APUR: 0.6437, Test AUC: 0.6471, Test AUPR: 0.6382\n",
      "Epoch: 44/200, Loss: 0.6525692, Train Acc: 0.6204, Test Acc: 0.6131, Train AUC: 0.6612, Train APUR: 0.6469, Test AUC: 0.6485, Test AUPR: 0.6403\n",
      "Epoch: 45/200, Loss: 0.6519380, Train Acc: 0.6227, Test Acc: 0.6181, Train AUC: 0.6635, Train APUR: 0.6486, Test AUC: 0.6505, Test AUPR: 0.6410\n",
      "Epoch: 46/200, Loss: 0.6514667, Train Acc: 0.6182, Test Acc: 0.6177, Train AUC: 0.6637, Train APUR: 0.6492, Test AUC: 0.6507, Test AUPR: 0.6416\n",
      "Epoch: 47/200, Loss: 0.6497159, Train Acc: 0.6244, Test Acc: 0.6100, Train AUC: 0.6672, Train APUR: 0.6513, Test AUC: 0.6503, Test AUPR: 0.6428\n",
      "Epoch: 48/200, Loss: 0.6489914, Train Acc: 0.6235, Test Acc: 0.6174, Train AUC: 0.6670, Train APUR: 0.6533, Test AUC: 0.6551, Test AUPR: 0.6466\n",
      "Epoch: 49/200, Loss: 0.6475590, Train Acc: 0.6284, Test Acc: 0.6248, Train AUC: 0.6718, Train APUR: 0.6563, Test AUC: 0.6589, Test AUPR: 0.6480\n",
      "Epoch: 50/200, Loss: 0.6465383, Train Acc: 0.6297, Test Acc: 0.6212, Train AUC: 0.6743, Train APUR: 0.6580, Test AUC: 0.6587, Test AUPR: 0.6473\n",
      "Epoch: 51/200, Loss: 0.6456652, Train Acc: 0.6273, Test Acc: 0.6234, Train AUC: 0.6724, Train APUR: 0.6570, Test AUC: 0.6645, Test AUPR: 0.6527\n",
      "Epoch: 52/200, Loss: 0.6441269, Train Acc: 0.6346, Test Acc: 0.6283, Train AUC: 0.6787, Train APUR: 0.6617, Test AUC: 0.6642, Test AUPR: 0.6529\n",
      "Epoch: 53/200, Loss: 0.6429979, Train Acc: 0.6384, Test Acc: 0.6257, Train AUC: 0.6816, Train APUR: 0.6632, Test AUC: 0.6633, Test AUPR: 0.6501\n",
      "Epoch: 54/200, Loss: 0.6416121, Train Acc: 0.6366, Test Acc: 0.6204, Train AUC: 0.6810, Train APUR: 0.6648, Test AUC: 0.6703, Test AUPR: 0.6566\n",
      "Epoch: 55/200, Loss: 0.6430464, Train Acc: 0.6366, Test Acc: 0.6317, Train AUC: 0.6871, Train APUR: 0.6682, Test AUC: 0.6709, Test AUPR: 0.6571\n",
      "Epoch: 56/200, Loss: 0.6381247, Train Acc: 0.6431, Test Acc: 0.6286, Train AUC: 0.6901, Train APUR: 0.6727, Test AUC: 0.6665, Test AUPR: 0.6535\n",
      "Epoch: 57/200, Loss: 0.6385827, Train Acc: 0.6406, Test Acc: 0.6273, Train AUC: 0.6869, Train APUR: 0.6716, Test AUC: 0.6705, Test AUPR: 0.6590\n",
      "Epoch: 58/200, Loss: 0.6363748, Train Acc: 0.6431, Test Acc: 0.6263, Train AUC: 0.6934, Train APUR: 0.6759, Test AUC: 0.6732, Test AUPR: 0.6599\n",
      "Epoch: 59/200, Loss: 0.6333075, Train Acc: 0.6476, Test Acc: 0.6319, Train AUC: 0.6965, Train APUR: 0.6780, Test AUC: 0.6738, Test AUPR: 0.6604\n",
      "Epoch: 60/200, Loss: 0.6326331, Train Acc: 0.6474, Test Acc: 0.6331, Train AUC: 0.6951, Train APUR: 0.6803, Test AUC: 0.6772, Test AUPR: 0.6682\n",
      "Epoch: 61/200, Loss: 0.6303516, Train Acc: 0.6477, Test Acc: 0.6324, Train AUC: 0.7010, Train APUR: 0.6862, Test AUC: 0.6805, Test AUPR: 0.6660\n",
      "Epoch: 62/200, Loss: 0.6280671, Train Acc: 0.6505, Test Acc: 0.6301, Train AUC: 0.7039, Train APUR: 0.6860, Test AUC: 0.6801, Test AUPR: 0.6669\n",
      "Epoch: 63/200, Loss: 0.6272024, Train Acc: 0.6500, Test Acc: 0.6328, Train AUC: 0.7046, Train APUR: 0.6876, Test AUC: 0.6784, Test AUPR: 0.6714\n",
      "Epoch: 64/200, Loss: 0.6275628, Train Acc: 0.6489, Test Acc: 0.6345, Train AUC: 0.7053, Train APUR: 0.6927, Test AUC: 0.6809, Test AUPR: 0.6708\n",
      "Epoch: 65/200, Loss: 0.6251044, Train Acc: 0.6508, Test Acc: 0.6327, Train AUC: 0.7078, Train APUR: 0.6935, Test AUC: 0.6868, Test AUPR: 0.6757\n",
      "Epoch: 66/200, Loss: 0.6218966, Train Acc: 0.6546, Test Acc: 0.6367, Train AUC: 0.7124, Train APUR: 0.6983, Test AUC: 0.6878, Test AUPR: 0.6776\n",
      "Epoch: 67/200, Loss: 0.6213272, Train Acc: 0.6553, Test Acc: 0.6363, Train AUC: 0.7130, Train APUR: 0.7003, Test AUC: 0.6838, Test AUPR: 0.6697\n",
      "Epoch: 68/200, Loss: 0.6211404, Train Acc: 0.6556, Test Acc: 0.6397, Train AUC: 0.7132, Train APUR: 0.6977, Test AUC: 0.6903, Test AUPR: 0.6791\n",
      "Epoch: 69/200, Loss: 0.6178099, Train Acc: 0.6555, Test Acc: 0.6342, Train AUC: 0.7177, Train APUR: 0.7036, Test AUC: 0.6884, Test AUPR: 0.6726\n",
      "Epoch: 70/200, Loss: 0.6185018, Train Acc: 0.6574, Test Acc: 0.6323, Train AUC: 0.7156, Train APUR: 0.6997, Test AUC: 0.6863, Test AUPR: 0.6767\n",
      "Epoch: 71/200, Loss: 0.6163751, Train Acc: 0.6586, Test Acc: 0.6363, Train AUC: 0.7195, Train APUR: 0.7079, Test AUC: 0.6835, Test AUPR: 0.6749\n",
      "Epoch: 72/200, Loss: 0.6153663, Train Acc: 0.6584, Test Acc: 0.6411, Train AUC: 0.7196, Train APUR: 0.7094, Test AUC: 0.6916, Test AUPR: 0.6830\n",
      "Epoch: 73/200, Loss: 0.6129713, Train Acc: 0.6612, Test Acc: 0.6392, Train AUC: 0.7230, Train APUR: 0.7134, Test AUC: 0.6954, Test AUPR: 0.6826\n",
      "Epoch: 74/200, Loss: 0.6119744, Train Acc: 0.6613, Test Acc: 0.6345, Train AUC: 0.7240, Train APUR: 0.7115, Test AUC: 0.6869, Test AUPR: 0.6727\n",
      "Epoch: 75/200, Loss: 0.6169121, Train Acc: 0.6582, Test Acc: 0.6380, Train AUC: 0.7184, Train APUR: 0.7069, Test AUC: 0.6895, Test AUPR: 0.6783\n",
      "Epoch: 76/200, Loss: 0.6186389, Train Acc: 0.6514, Test Acc: 0.6401, Train AUC: 0.7130, Train APUR: 0.7060, Test AUC: 0.6893, Test AUPR: 0.6769\n",
      "Epoch: 77/200, Loss: 0.6082573, Train Acc: 0.6645, Test Acc: 0.6369, Train AUC: 0.7274, Train APUR: 0.7182, Test AUC: 0.6878, Test AUPR: 0.6740\n",
      "Epoch: 78/200, Loss: 0.6085179, Train Acc: 0.6660, Test Acc: 0.6368, Train AUC: 0.7278, Train APUR: 0.7158, Test AUC: 0.6913, Test AUPR: 0.6815\n",
      "Epoch: 79/200, Loss: 0.6060295, Train Acc: 0.6668, Test Acc: 0.6416, Train AUC: 0.7314, Train APUR: 0.7233, Test AUC: 0.6902, Test AUPR: 0.6809\n",
      "Epoch: 80/200, Loss: 0.6037592, Train Acc: 0.6686, Test Acc: 0.6427, Train AUC: 0.7332, Train APUR: 0.7260, Test AUC: 0.6902, Test AUPR: 0.6781\n",
      "Epoch: 81/200, Loss: 0.6040342, Train Acc: 0.6668, Test Acc: 0.6429, Train AUC: 0.7321, Train APUR: 0.7249, Test AUC: 0.6905, Test AUPR: 0.6725\n",
      "Epoch: 82/200, Loss: 0.6020959, Train Acc: 0.6691, Test Acc: 0.6427, Train AUC: 0.7335, Train APUR: 0.7239, Test AUC: 0.6965, Test AUPR: 0.6760\n",
      "Epoch: 83/200, Loss: 0.6032714, Train Acc: 0.6687, Test Acc: 0.6453, Train AUC: 0.7332, Train APUR: 0.7206, Test AUC: 0.6969, Test AUPR: 0.6841\n",
      "Epoch: 84/200, Loss: 0.6006860, Train Acc: 0.6703, Test Acc: 0.6434, Train AUC: 0.7353, Train APUR: 0.7273, Test AUC: 0.6928, Test AUPR: 0.6852\n",
      "Epoch: 85/200, Loss: 0.6009697, Train Acc: 0.6710, Test Acc: 0.6426, Train AUC: 0.7352, Train APUR: 0.7286, Test AUC: 0.6935, Test AUPR: 0.6832\n",
      "Epoch: 86/200, Loss: 0.5992443, Train Acc: 0.6723, Test Acc: 0.6448, Train AUC: 0.7370, Train APUR: 0.7296, Test AUC: 0.6973, Test AUPR: 0.6867\n",
      "Epoch: 87/200, Loss: 0.5997155, Train Acc: 0.6721, Test Acc: 0.6417, Train AUC: 0.7373, Train APUR: 0.7292, Test AUC: 0.6906, Test AUPR: 0.6802\n",
      "Epoch: 88/200, Loss: 0.6014338, Train Acc: 0.6715, Test Acc: 0.6472, Train AUC: 0.7348, Train APUR: 0.7273, Test AUC: 0.7029, Test AUPR: 0.6932\n",
      "Epoch: 89/200, Loss: 0.6015322, Train Acc: 0.6662, Test Acc: 0.6428, Train AUC: 0.7348, Train APUR: 0.7294, Test AUC: 0.6949, Test AUPR: 0.6830\n",
      "Epoch: 90/200, Loss: 0.5967261, Train Acc: 0.6739, Test Acc: 0.6422, Train AUC: 0.7394, Train APUR: 0.7318, Test AUC: 0.6985, Test AUPR: 0.6853\n",
      "Epoch: 91/200, Loss: 0.5953955, Train Acc: 0.6747, Test Acc: 0.6373, Train AUC: 0.7415, Train APUR: 0.7331, Test AUC: 0.6888, Test AUPR: 0.6732\n",
      "Epoch: 92/200, Loss: 0.6048722, Train Acc: 0.6648, Test Acc: 0.6422, Train AUC: 0.7276, Train APUR: 0.7217, Test AUC: 0.6931, Test AUPR: 0.6807\n",
      "Epoch: 93/200, Loss: 0.5950131, Train Acc: 0.6762, Test Acc: 0.6373, Train AUC: 0.7419, Train APUR: 0.7345, Test AUC: 0.6854, Test AUPR: 0.6719\n",
      "Epoch: 94/200, Loss: 0.6039229, Train Acc: 0.6677, Test Acc: 0.6403, Train AUC: 0.7325, Train APUR: 0.7247, Test AUC: 0.6947, Test AUPR: 0.6802\n",
      "Epoch: 95/200, Loss: 0.5982032, Train Acc: 0.6705, Test Acc: 0.6440, Train AUC: 0.7399, Train APUR: 0.7358, Test AUC: 0.6999, Test AUPR: 0.6871\n",
      "Epoch: 96/200, Loss: 0.5978053, Train Acc: 0.6710, Test Acc: 0.6407, Train AUC: 0.7391, Train APUR: 0.7363, Test AUC: 0.6899, Test AUPR: 0.6773\n",
      "Epoch: 97/200, Loss: 0.5989925, Train Acc: 0.6717, Test Acc: 0.6419, Train AUC: 0.7378, Train APUR: 0.7282, Test AUC: 0.6910, Test AUPR: 0.6796\n",
      "Epoch: 98/200, Loss: 0.5964397, Train Acc: 0.6723, Test Acc: 0.6497, Train AUC: 0.7404, Train APUR: 0.7334, Test AUC: 0.7047, Test AUPR: 0.6941\n",
      "Epoch: 99/200, Loss: 0.5915670, Train Acc: 0.6758, Test Acc: 0.6450, Train AUC: 0.7451, Train APUR: 0.7413, Test AUC: 0.7028, Test AUPR: 0.6920\n",
      "Epoch: 100/200, Loss: 0.5952285, Train Acc: 0.6727, Test Acc: 0.6393, Train AUC: 0.7405, Train APUR: 0.7351, Test AUC: 0.6930, Test AUPR: 0.6812\n",
      "Epoch: 101/200, Loss: 0.5962013, Train Acc: 0.6745, Test Acc: 0.6450, Train AUC: 0.7409, Train APUR: 0.7331, Test AUC: 0.6989, Test AUPR: 0.6910\n",
      "Epoch: 102/200, Loss: 0.5877054, Train Acc: 0.6801, Test Acc: 0.6484, Train AUC: 0.7497, Train APUR: 0.7457, Test AUC: 0.7042, Test AUPR: 0.6965\n",
      "Epoch: 103/200, Loss: 0.5889748, Train Acc: 0.6784, Test Acc: 0.6497, Train AUC: 0.7490, Train APUR: 0.7455, Test AUC: 0.7061, Test AUPR: 0.6989\n",
      "Epoch: 104/200, Loss: 0.5881390, Train Acc: 0.6791, Test Acc: 0.6421, Train AUC: 0.7487, Train APUR: 0.7456, Test AUC: 0.6986, Test AUPR: 0.6887\n",
      "Epoch: 105/200, Loss: 0.5893163, Train Acc: 0.6793, Test Acc: 0.6439, Train AUC: 0.7491, Train APUR: 0.7427, Test AUC: 0.6995, Test AUPR: 0.6878\n",
      "Epoch: 106/200, Loss: 0.5863187, Train Acc: 0.6805, Test Acc: 0.6452, Train AUC: 0.7527, Train APUR: 0.7488, Test AUC: 0.7020, Test AUPR: 0.6901\n",
      "Epoch: 107/200, Loss: 0.5850543, Train Acc: 0.6823, Test Acc: 0.6453, Train AUC: 0.7529, Train APUR: 0.7491, Test AUC: 0.7039, Test AUPR: 0.6926\n",
      "Epoch: 108/200, Loss: 0.5855946, Train Acc: 0.6809, Test Acc: 0.6468, Train AUC: 0.7535, Train APUR: 0.7502, Test AUC: 0.7028, Test AUPR: 0.6910\n",
      "Epoch: 109/200, Loss: 0.5836195, Train Acc: 0.6832, Test Acc: 0.6456, Train AUC: 0.7537, Train APUR: 0.7496, Test AUC: 0.7032, Test AUPR: 0.6900\n",
      "Epoch: 110/200, Loss: 0.5847842, Train Acc: 0.6813, Test Acc: 0.6494, Train AUC: 0.7541, Train APUR: 0.7501, Test AUC: 0.7067, Test AUPR: 0.6984\n",
      "Epoch: 111/200, Loss: 0.5852482, Train Acc: 0.6803, Test Acc: 0.6475, Train AUC: 0.7512, Train APUR: 0.7485, Test AUC: 0.7013, Test AUPR: 0.6949\n",
      "Epoch: 112/200, Loss: 0.5823935, Train Acc: 0.6850, Test Acc: 0.6446, Train AUC: 0.7560, Train APUR: 0.7525, Test AUC: 0.6999, Test AUPR: 0.6932\n",
      "Epoch: 113/200, Loss: 0.5825719, Train Acc: 0.6845, Test Acc: 0.6501, Train AUC: 0.7558, Train APUR: 0.7533, Test AUC: 0.7076, Test AUPR: 0.7006\n",
      "Epoch: 114/200, Loss: 0.5794615, Train Acc: 0.6859, Test Acc: 0.6472, Train AUC: 0.7571, Train APUR: 0.7552, Test AUC: 0.7094, Test AUPR: 0.7019\n",
      "Epoch: 115/200, Loss: 0.5815290, Train Acc: 0.6840, Test Acc: 0.6434, Train AUC: 0.7561, Train APUR: 0.7547, Test AUC: 0.7044, Test AUPR: 0.6985\n",
      "Epoch: 116/200, Loss: 0.5808303, Train Acc: 0.6831, Test Acc: 0.6488, Train AUC: 0.7564, Train APUR: 0.7538, Test AUC: 0.7063, Test AUPR: 0.7016\n",
      "Epoch: 117/200, Loss: 0.5779155, Train Acc: 0.6859, Test Acc: 0.6504, Train AUC: 0.7589, Train APUR: 0.7579, Test AUC: 0.7081, Test AUPR: 0.7029\n",
      "Epoch: 118/200, Loss: 0.5786093, Train Acc: 0.6880, Test Acc: 0.6508, Train AUC: 0.7611, Train APUR: 0.7590, Test AUC: 0.7072, Test AUPR: 0.7021\n",
      "Epoch: 119/200, Loss: 0.5786404, Train Acc: 0.6878, Test Acc: 0.6481, Train AUC: 0.7599, Train APUR: 0.7573, Test AUC: 0.7028, Test AUPR: 0.6977\n",
      "Epoch: 120/200, Loss: 0.5806778, Train Acc: 0.6856, Test Acc: 0.6488, Train AUC: 0.7566, Train APUR: 0.7529, Test AUC: 0.7083, Test AUPR: 0.7029\n",
      "Epoch: 121/200, Loss: 0.5805531, Train Acc: 0.6841, Test Acc: 0.6496, Train AUC: 0.7571, Train APUR: 0.7555, Test AUC: 0.7078, Test AUPR: 0.7024\n",
      "Epoch: 122/200, Loss: 0.5756981, Train Acc: 0.6888, Test Acc: 0.6488, Train AUC: 0.7618, Train APUR: 0.7603, Test AUC: 0.7044, Test AUPR: 0.6990\n",
      "Epoch: 123/200, Loss: 0.5781327, Train Acc: 0.6882, Test Acc: 0.6516, Train AUC: 0.7599, Train APUR: 0.7556, Test AUC: 0.7100, Test AUPR: 0.7053\n",
      "Epoch: 124/200, Loss: 0.5767671, Train Acc: 0.6874, Test Acc: 0.6477, Train AUC: 0.7598, Train APUR: 0.7591, Test AUC: 0.7024, Test AUPR: 0.6963\n",
      "Epoch: 125/200, Loss: 0.5755914, Train Acc: 0.6891, Test Acc: 0.6449, Train AUC: 0.7618, Train APUR: 0.7602, Test AUC: 0.7047, Test AUPR: 0.6977\n",
      "Epoch: 126/200, Loss: 0.5762071, Train Acc: 0.6882, Test Acc: 0.6494, Train AUC: 0.7615, Train APUR: 0.7583, Test AUC: 0.7107, Test AUPR: 0.7055\n",
      "Epoch: 127/200, Loss: 0.5801209, Train Acc: 0.6825, Test Acc: 0.6483, Train AUC: 0.7555, Train APUR: 0.7564, Test AUC: 0.7040, Test AUPR: 0.6972\n",
      "Epoch: 128/200, Loss: 0.5778653, Train Acc: 0.6878, Test Acc: 0.6471, Train AUC: 0.7601, Train APUR: 0.7573, Test AUC: 0.7024, Test AUPR: 0.6962\n",
      "Epoch: 129/200, Loss: 0.5803788, Train Acc: 0.6859, Test Acc: 0.6478, Train AUC: 0.7575, Train APUR: 0.7535, Test AUC: 0.7042, Test AUPR: 0.6980\n",
      "Epoch: 130/200, Loss: 0.5810016, Train Acc: 0.6820, Test Acc: 0.6533, Train AUC: 0.7545, Train APUR: 0.7546, Test AUC: 0.7118, Test AUPR: 0.7049\n",
      "Epoch: 131/200, Loss: 0.5727543, Train Acc: 0.6920, Test Acc: 0.6380, Train AUC: 0.7661, Train APUR: 0.7670, Test AUC: 0.6898, Test AUPR: 0.6802\n",
      "Epoch: 132/200, Loss: 0.5889950, Train Acc: 0.6811, Test Acc: 0.6548, Train AUC: 0.7503, Train APUR: 0.7468, Test AUC: 0.7122, Test AUPR: 0.7048\n",
      "Epoch: 133/200, Loss: 0.5718678, Train Acc: 0.6918, Test Acc: 0.6553, Train AUC: 0.7665, Train APUR: 0.7666, Test AUC: 0.7125, Test AUPR: 0.7057\n",
      "Epoch: 134/200, Loss: 0.5803820, Train Acc: 0.6839, Test Acc: 0.6491, Train AUC: 0.7569, Train APUR: 0.7564, Test AUC: 0.7031, Test AUPR: 0.6967\n",
      "Epoch: 135/200, Loss: 0.5749190, Train Acc: 0.6894, Test Acc: 0.6486, Train AUC: 0.7626, Train APUR: 0.7620, Test AUC: 0.7060, Test AUPR: 0.6995\n",
      "Epoch: 136/200, Loss: 0.5751124, Train Acc: 0.6909, Test Acc: 0.6477, Train AUC: 0.7632, Train APUR: 0.7602, Test AUC: 0.7063, Test AUPR: 0.7011\n",
      "Epoch: 137/200, Loss: 0.5729292, Train Acc: 0.6894, Test Acc: 0.6494, Train AUC: 0.7633, Train APUR: 0.7638, Test AUC: 0.7095, Test AUPR: 0.7057\n",
      "Epoch: 138/200, Loss: 0.5742699, Train Acc: 0.6901, Test Acc: 0.6463, Train AUC: 0.7632, Train APUR: 0.7626, Test AUC: 0.7015, Test AUPR: 0.6966\n",
      "Epoch: 139/200, Loss: 0.5749508, Train Acc: 0.6893, Test Acc: 0.6507, Train AUC: 0.7626, Train APUR: 0.7609, Test AUC: 0.7058, Test AUPR: 0.7008\n",
      "Epoch: 140/200, Loss: 0.5696869, Train Acc: 0.6940, Test Acc: 0.6513, Train AUC: 0.7687, Train APUR: 0.7687, Test AUC: 0.7103, Test AUPR: 0.7031\n",
      "Epoch: 141/200, Loss: 0.5745150, Train Acc: 0.6896, Test Acc: 0.6513, Train AUC: 0.7638, Train APUR: 0.7624, Test AUC: 0.7099, Test AUPR: 0.7018\n",
      "Epoch: 142/200, Loss: 0.5689775, Train Acc: 0.6938, Test Acc: 0.6456, Train AUC: 0.7692, Train APUR: 0.7676, Test AUC: 0.7005, Test AUPR: 0.6939\n",
      "Epoch: 143/200, Loss: 0.5789067, Train Acc: 0.6880, Test Acc: 0.6553, Train AUC: 0.7605, Train APUR: 0.7588, Test AUC: 0.7154, Test AUPR: 0.7117\n",
      "Epoch: 144/200, Loss: 0.5709224, Train Acc: 0.6916, Test Acc: 0.6516, Train AUC: 0.7659, Train APUR: 0.7677, Test AUC: 0.7101, Test AUPR: 0.7053\n",
      "Epoch: 145/200, Loss: 0.5763973, Train Acc: 0.6857, Test Acc: 0.6380, Train AUC: 0.7590, Train APUR: 0.7599, Test AUC: 0.6942, Test AUPR: 0.6870\n",
      "Epoch: 146/200, Loss: 0.5808604, Train Acc: 0.6854, Test Acc: 0.6477, Train AUC: 0.7577, Train APUR: 0.7549, Test AUC: 0.7055, Test AUPR: 0.7008\n",
      "Epoch: 147/200, Loss: 0.5685744, Train Acc: 0.6952, Test Acc: 0.6523, Train AUC: 0.7701, Train APUR: 0.7689, Test AUC: 0.7109, Test AUPR: 0.7068\n",
      "Epoch: 148/200, Loss: 0.5770853, Train Acc: 0.6850, Test Acc: 0.6558, Train AUC: 0.7592, Train APUR: 0.7599, Test AUC: 0.7151, Test AUPR: 0.7113\n",
      "Epoch: 149/200, Loss: 0.5662482, Train Acc: 0.6955, Test Acc: 0.6450, Train AUC: 0.7728, Train APUR: 0.7735, Test AUC: 0.7001, Test AUPR: 0.6936\n",
      "Epoch: 150/200, Loss: 0.5726763, Train Acc: 0.6902, Test Acc: 0.6497, Train AUC: 0.7649, Train APUR: 0.7636, Test AUC: 0.7103, Test AUPR: 0.7040\n",
      "Epoch: 151/200, Loss: 0.5668979, Train Acc: 0.6955, Test Acc: 0.6533, Train AUC: 0.7713, Train APUR: 0.7702, Test AUC: 0.7146, Test AUPR: 0.7100\n",
      "Epoch: 152/200, Loss: 0.5720059, Train Acc: 0.6901, Test Acc: 0.6539, Train AUC: 0.7653, Train APUR: 0.7680, Test AUC: 0.7138, Test AUPR: 0.7079\n",
      "Epoch: 153/200, Loss: 0.5638361, Train Acc: 0.7000, Test Acc: 0.6470, Train AUC: 0.7744, Train APUR: 0.7738, Test AUC: 0.7025, Test AUPR: 0.6960\n",
      "Epoch: 154/200, Loss: 0.5717927, Train Acc: 0.6921, Test Acc: 0.6556, Train AUC: 0.7673, Train APUR: 0.7660, Test AUC: 0.7141, Test AUPR: 0.7083\n",
      "Epoch: 155/200, Loss: 0.5655153, Train Acc: 0.6991, Test Acc: 0.6536, Train AUC: 0.7746, Train APUR: 0.7739, Test AUC: 0.7157, Test AUPR: 0.7115\n",
      "Epoch: 156/200, Loss: 0.5678155, Train Acc: 0.6934, Test Acc: 0.6540, Train AUC: 0.7699, Train APUR: 0.7709, Test AUC: 0.7170, Test AUPR: 0.7135\n",
      "Epoch: 157/200, Loss: 0.5660327, Train Acc: 0.6958, Test Acc: 0.6500, Train AUC: 0.7727, Train APUR: 0.7725, Test AUC: 0.7078, Test AUPR: 0.7056\n",
      "Epoch: 158/200, Loss: 0.5680606, Train Acc: 0.6939, Test Acc: 0.6540, Train AUC: 0.7697, Train APUR: 0.7701, Test AUC: 0.7133, Test AUPR: 0.7119\n",
      "Epoch: 159/200, Loss: 0.5623680, Train Acc: 0.6984, Test Acc: 0.6576, Train AUC: 0.7747, Train APUR: 0.7764, Test AUC: 0.7186, Test AUPR: 0.7167\n",
      "Epoch: 160/200, Loss: 0.5665754, Train Acc: 0.6953, Test Acc: 0.6533, Train AUC: 0.7707, Train APUR: 0.7711, Test AUC: 0.7102, Test AUPR: 0.7064\n",
      "Epoch: 161/200, Loss: 0.5631195, Train Acc: 0.6991, Test Acc: 0.6506, Train AUC: 0.7751, Train APUR: 0.7747, Test AUC: 0.7101, Test AUPR: 0.7059\n",
      "Epoch: 162/200, Loss: 0.5638957, Train Acc: 0.6987, Test Acc: 0.6567, Train AUC: 0.7742, Train APUR: 0.7741, Test AUC: 0.7192, Test AUPR: 0.7160\n",
      "Epoch: 163/200, Loss: 0.5644819, Train Acc: 0.6951, Test Acc: 0.6572, Train AUC: 0.7711, Train APUR: 0.7726, Test AUC: 0.7179, Test AUPR: 0.7147\n",
      "Epoch: 164/200, Loss: 0.5610095, Train Acc: 0.6967, Test Acc: 0.6493, Train AUC: 0.7756, Train APUR: 0.7780, Test AUC: 0.7063, Test AUPR: 0.7021\n",
      "Epoch: 165/200, Loss: 0.5654140, Train Acc: 0.6968, Test Acc: 0.6550, Train AUC: 0.7726, Train APUR: 0.7723, Test AUC: 0.7144, Test AUPR: 0.7118\n",
      "Epoch: 166/200, Loss: 0.5607743, Train Acc: 0.7000, Test Acc: 0.6539, Train AUC: 0.7763, Train APUR: 0.7782, Test AUC: 0.7135, Test AUPR: 0.7099\n",
      "Epoch: 167/200, Loss: 0.5695270, Train Acc: 0.6955, Test Acc: 0.6542, Train AUC: 0.7693, Train APUR: 0.7717, Test AUC: 0.7135, Test AUPR: 0.7101\n",
      "Epoch: 168/200, Loss: 0.5629380, Train Acc: 0.6984, Test Acc: 0.6490, Train AUC: 0.7743, Train APUR: 0.7748, Test AUC: 0.7051, Test AUPR: 0.6998\n",
      "Epoch: 169/200, Loss: 0.5675076, Train Acc: 0.6964, Test Acc: 0.6576, Train AUC: 0.7712, Train APUR: 0.7697, Test AUC: 0.7164, Test AUPR: 0.7126\n",
      "Epoch: 170/200, Loss: 0.5650574, Train Acc: 0.6955, Test Acc: 0.6578, Train AUC: 0.7728, Train APUR: 0.7741, Test AUC: 0.7183, Test AUPR: 0.7156\n",
      "Epoch: 171/200, Loss: 0.5632030, Train Acc: 0.6959, Test Acc: 0.6488, Train AUC: 0.7733, Train APUR: 0.7753, Test AUC: 0.7064, Test AUPR: 0.7022\n",
      "Epoch: 172/200, Loss: 0.5668247, Train Acc: 0.6963, Test Acc: 0.6537, Train AUC: 0.7716, Train APUR: 0.7722, Test AUC: 0.7131, Test AUPR: 0.7103\n",
      "Epoch: 173/200, Loss: 0.5620347, Train Acc: 0.6985, Test Acc: 0.6499, Train AUC: 0.7761, Train APUR: 0.7780, Test AUC: 0.7153, Test AUPR: 0.7141\n",
      "Epoch: 174/200, Loss: 0.5645990, Train Acc: 0.6959, Test Acc: 0.6488, Train AUC: 0.7736, Train APUR: 0.7756, Test AUC: 0.7085, Test AUPR: 0.7069\n",
      "Epoch: 175/200, Loss: 0.5602775, Train Acc: 0.7003, Test Acc: 0.6508, Train AUC: 0.7783, Train APUR: 0.7796, Test AUC: 0.7061, Test AUPR: 0.7034\n",
      "Epoch: 176/200, Loss: 0.5605413, Train Acc: 0.7012, Test Acc: 0.6600, Train AUC: 0.7777, Train APUR: 0.7778, Test AUC: 0.7210, Test AUPR: 0.7192\n",
      "Epoch: 177/200, Loss: 0.5567334, Train Acc: 0.7041, Test Acc: 0.6590, Train AUC: 0.7809, Train APUR: 0.7818, Test AUC: 0.7216, Test AUPR: 0.7197\n",
      "Epoch: 178/200, Loss: 0.5572287, Train Acc: 0.7016, Test Acc: 0.6526, Train AUC: 0.7790, Train APUR: 0.7810, Test AUC: 0.7136, Test AUPR: 0.7097\n",
      "Epoch: 179/200, Loss: 0.5578189, Train Acc: 0.7024, Test Acc: 0.6542, Train AUC: 0.7799, Train APUR: 0.7811, Test AUC: 0.7166, Test AUPR: 0.7128\n",
      "Epoch: 180/200, Loss: 0.5548660, Train Acc: 0.7039, Test Acc: 0.6564, Train AUC: 0.7831, Train APUR: 0.7851, Test AUC: 0.7171, Test AUPR: 0.7146\n",
      "Epoch: 181/200, Loss: 0.5547739, Train Acc: 0.7036, Test Acc: 0.6568, Train AUC: 0.7831, Train APUR: 0.7850, Test AUC: 0.7173, Test AUPR: 0.7157\n",
      "Epoch: 182/200, Loss: 0.5536991, Train Acc: 0.7051, Test Acc: 0.6559, Train AUC: 0.7850, Train APUR: 0.7867, Test AUC: 0.7167, Test AUPR: 0.7141\n",
      "Epoch: 183/200, Loss: 0.5542994, Train Acc: 0.7056, Test Acc: 0.6564, Train AUC: 0.7840, Train APUR: 0.7848, Test AUC: 0.7218, Test AUPR: 0.7201\n",
      "Epoch: 184/200, Loss: 0.5513309, Train Acc: 0.7072, Test Acc: 0.6527, Train AUC: 0.7861, Train APUR: 0.7876, Test AUC: 0.7201, Test AUPR: 0.7182\n",
      "Epoch: 185/200, Loss: 0.5574217, Train Acc: 0.7009, Test Acc: 0.6551, Train AUC: 0.7814, Train APUR: 0.7838, Test AUC: 0.7149, Test AUPR: 0.7109\n",
      "Epoch: 186/200, Loss: 0.5542564, Train Acc: 0.7042, Test Acc: 0.6526, Train AUC: 0.7834, Train APUR: 0.7853, Test AUC: 0.7120, Test AUPR: 0.7084\n",
      "Epoch: 187/200, Loss: 0.5548704, Train Acc: 0.7044, Test Acc: 0.6566, Train AUC: 0.7835, Train APUR: 0.7856, Test AUC: 0.7204, Test AUPR: 0.7185\n",
      "Epoch: 188/200, Loss: 0.5542536, Train Acc: 0.7030, Test Acc: 0.6590, Train AUC: 0.7849, Train APUR: 0.7875, Test AUC: 0.7204, Test AUPR: 0.7188\n",
      "Epoch: 189/200, Loss: 0.5524957, Train Acc: 0.7069, Test Acc: 0.6537, Train AUC: 0.7856, Train APUR: 0.7863, Test AUC: 0.7183, Test AUPR: 0.7159\n",
      "Epoch: 190/200, Loss: 0.5535514, Train Acc: 0.7044, Test Acc: 0.6576, Train AUC: 0.7854, Train APUR: 0.7876, Test AUC: 0.7241, Test AUPR: 0.7228\n",
      "Epoch: 191/200, Loss: 0.5542478, Train Acc: 0.7037, Test Acc: 0.6526, Train AUC: 0.7837, Train APUR: 0.7875, Test AUC: 0.7100, Test AUPR: 0.7055\n",
      "Epoch: 192/200, Loss: 0.5543351, Train Acc: 0.7068, Test Acc: 0.6580, Train AUC: 0.7843, Train APUR: 0.7844, Test AUC: 0.7196, Test AUPR: 0.7157\n",
      "Epoch: 193/200, Loss: 0.5517974, Train Acc: 0.7067, Test Acc: 0.6589, Train AUC: 0.7878, Train APUR: 0.7900, Test AUC: 0.7203, Test AUPR: 0.7177\n",
      "Epoch: 194/200, Loss: 0.5520166, Train Acc: 0.7065, Test Acc: 0.6532, Train AUC: 0.7856, Train APUR: 0.7888, Test AUC: 0.7153, Test AUPR: 0.7142\n",
      "Epoch: 195/200, Loss: 0.5534445, Train Acc: 0.7046, Test Acc: 0.6489, Train AUC: 0.7847, Train APUR: 0.7861, Test AUC: 0.7109, Test AUPR: 0.7108\n",
      "Epoch: 196/200, Loss: 0.5530702, Train Acc: 0.7038, Test Acc: 0.6598, Train AUC: 0.7850, Train APUR: 0.7879, Test AUC: 0.7194, Test AUPR: 0.7200\n",
      "Epoch: 197/200, Loss: 0.5500090, Train Acc: 0.7100, Test Acc: 0.6590, Train AUC: 0.7892, Train APUR: 0.7913, Test AUC: 0.7189, Test AUPR: 0.7185\n",
      "Epoch: 198/200, Loss: 0.5537366, Train Acc: 0.7048, Test Acc: 0.6523, Train AUC: 0.7855, Train APUR: 0.7879, Test AUC: 0.7092, Test AUPR: 0.7072\n",
      "Epoch: 199/200, Loss: 0.5517897, Train Acc: 0.7068, Test Acc: 0.6555, Train AUC: 0.7862, Train APUR: 0.7877, Test AUC: 0.7172, Test AUPR: 0.7156\n",
      "Epoch: 200/200, Loss: 0.5492738, Train Acc: 0.7083, Test Acc: 0.6554, Train AUC: 0.7886, Train APUR: 0.7902, Test AUC: 0.7244, Test AUPR: 0.7244\n",
      "/home/ubuntu/PA-Cancer-Immunotherapy/GNN/train_pa.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(configs['save_model']))\n",
      "Test Acc: 0.6554, Test AUC: 0.7244, Test AUPR: 0.7244\n"
     ]
    }
   ],
   "source": [
    "# Running the above but double epochs:\n",
    "# generate embeddings with the trained tcrpeg model, but separately for cdr3 and for epitope. \n",
    "# epochs 200\n",
    "! python train_pa.py --gpu 0 --configs_path configs/PA_all_gene.yml --droup_out 0.1 --split StrictTCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc33ed9-b5eb-4665-92a9-8e631ad0b88b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3bdb2d-1c61-4a41-96c1-05119c41d092",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8819d015-9b7b-4942-a9a7-74f25390c292",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(gpu=0, lr=0.001, epochs=100, w_celoss=1, w_aucloss=0, add_same_type_edges=False, dynamic_graph=False, dynamic_ratio=0.05, droup_out=0.1, positive_weights=1, dynamic_epochs=30, distance_threshold=10, configs_path='configs/PA_all_gene.yml', split='StrictTCR', dataset='pMTnet')\n",
      "PROJECT_NAME: dataset-gene_GNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfrohoari\u001b[0m (\u001b[33mpa_cancerimmunotherapy\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/ubuntu/PA-Cancer-Immunotherapy/GNN/wandb/run-20241203_234127-htr152ra\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mscarlet-dust-8\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-gene_GNN\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-gene_GNN/runs/htr152ra\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   10 of 10 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   10 of 10 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   10 of 10 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   10 of 10 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   10 of 10 files downloaded.  \n",
      "embeddings_path:   models/PA_all/gene_and_allele_embeddings.pkl\n",
      "train_file_list:   ['gene_fold_0.csv', 'gene_fold_1.csv', 'gene_fold_2.csv', 'gene_fold_3.csv']\n",
      "test_file_list:   ['gene_fold_4.csv']\n",
      "wandb logger initialisiert\n",
      "Epoch: 1/100, Loss: 0.6931127, Train Acc: 0.5071, Test Acc: 0.5335, Train AUC: 0.5063, Train APUR: 0.5050, Test AUC: 0.5882, Test AUPR: 0.5800\n",
      "Epoch: 2/100, Loss: 0.6904224, Train Acc: 0.5185, Test Acc: 0.5525, Train AUC: 0.5700, Train APUR: 0.5530, Test AUC: 0.5915, Test AUPR: 0.5869\n",
      "Epoch: 3/100, Loss: 0.6880704, Train Acc: 0.5456, Test Acc: 0.5722, Train AUC: 0.5836, Train APUR: 0.5736, Test AUC: 0.5976, Test AUPR: 0.5934\n",
      "Epoch: 4/100, Loss: 0.6837313, Train Acc: 0.5707, Test Acc: 0.5686, Train AUC: 0.5914, Train APUR: 0.5767, Test AUC: 0.6007, Test AUPR: 0.5947\n",
      "Epoch: 5/100, Loss: 0.6811043, Train Acc: 0.5687, Test Acc: 0.5743, Train AUC: 0.5919, Train APUR: 0.5823, Test AUC: 0.6026, Test AUPR: 0.5953\n",
      "Epoch: 6/100, Loss: 0.6796637, Train Acc: 0.5746, Test Acc: 0.5757, Train AUC: 0.5986, Train APUR: 0.5858, Test AUC: 0.6055, Test AUPR: 0.5970\n",
      "Epoch: 7/100, Loss: 0.6776624, Train Acc: 0.5773, Test Acc: 0.5795, Train AUC: 0.6041, Train APUR: 0.5926, Test AUC: 0.6099, Test AUPR: 0.6007\n",
      "Epoch: 8/100, Loss: 0.6746349, Train Acc: 0.5809, Test Acc: 0.5799, Train AUC: 0.6120, Train APUR: 0.6034, Test AUC: 0.6114, Test AUPR: 0.6019\n",
      "Epoch: 9/100, Loss: 0.6734979, Train Acc: 0.5809, Test Acc: 0.5834, Train AUC: 0.6147, Train APUR: 0.6030, Test AUC: 0.6136, Test AUPR: 0.6032\n",
      "Epoch: 10/100, Loss: 0.6724912, Train Acc: 0.5868, Test Acc: 0.5898, Train AUC: 0.6183, Train APUR: 0.6033, Test AUC: 0.6144, Test AUPR: 0.6041\n",
      "Epoch: 11/100, Loss: 0.6716076, Train Acc: 0.5894, Test Acc: 0.5916, Train AUC: 0.6211, Train APUR: 0.6095, Test AUC: 0.6153, Test AUPR: 0.6055\n",
      "Epoch: 12/100, Loss: 0.6699234, Train Acc: 0.5911, Test Acc: 0.5851, Train AUC: 0.6248, Train APUR: 0.6117, Test AUC: 0.6172, Test AUPR: 0.6072\n",
      "Epoch: 13/100, Loss: 0.6706291, Train Acc: 0.5943, Test Acc: 0.5873, Train AUC: 0.6255, Train APUR: 0.6125, Test AUC: 0.6186, Test AUPR: 0.6090\n",
      "Epoch: 14/100, Loss: 0.6688637, Train Acc: 0.5925, Test Acc: 0.5886, Train AUC: 0.6269, Train APUR: 0.6145, Test AUC: 0.6197, Test AUPR: 0.6105\n",
      "Epoch: 15/100, Loss: 0.6691626, Train Acc: 0.5924, Test Acc: 0.5935, Train AUC: 0.6287, Train APUR: 0.6161, Test AUC: 0.6220, Test AUPR: 0.6124\n",
      "Epoch: 16/100, Loss: 0.6670384, Train Acc: 0.6003, Test Acc: 0.5859, Train AUC: 0.6306, Train APUR: 0.6174, Test AUC: 0.6229, Test AUPR: 0.6131\n",
      "Epoch: 17/100, Loss: 0.6678834, Train Acc: 0.5970, Test Acc: 0.5918, Train AUC: 0.6321, Train APUR: 0.6181, Test AUC: 0.6242, Test AUPR: 0.6149\n",
      "Epoch: 18/100, Loss: 0.6660366, Train Acc: 0.5994, Test Acc: 0.5942, Train AUC: 0.6335, Train APUR: 0.6205, Test AUC: 0.6256, Test AUPR: 0.6170\n",
      "Epoch: 19/100, Loss: 0.6663361, Train Acc: 0.5981, Test Acc: 0.6004, Train AUC: 0.6339, Train APUR: 0.6210, Test AUC: 0.6267, Test AUPR: 0.6182\n",
      "Epoch: 20/100, Loss: 0.6659508, Train Acc: 0.6017, Test Acc: 0.5938, Train AUC: 0.6357, Train APUR: 0.6215, Test AUC: 0.6276, Test AUPR: 0.6184\n",
      "Epoch: 21/100, Loss: 0.6645948, Train Acc: 0.6040, Test Acc: 0.5924, Train AUC: 0.6366, Train APUR: 0.6242, Test AUC: 0.6279, Test AUPR: 0.6182\n",
      "Epoch: 22/100, Loss: 0.6648300, Train Acc: 0.6026, Test Acc: 0.5941, Train AUC: 0.6375, Train APUR: 0.6244, Test AUC: 0.6292, Test AUPR: 0.6194\n",
      "Epoch: 23/100, Loss: 0.6638399, Train Acc: 0.6051, Test Acc: 0.6030, Train AUC: 0.6386, Train APUR: 0.6242, Test AUC: 0.6309, Test AUPR: 0.6213\n",
      "Epoch: 24/100, Loss: 0.6631854, Train Acc: 0.6020, Test Acc: 0.6018, Train AUC: 0.6397, Train APUR: 0.6274, Test AUC: 0.6319, Test AUPR: 0.6218\n",
      "Epoch: 25/100, Loss: 0.6631977, Train Acc: 0.6043, Test Acc: 0.6022, Train AUC: 0.6393, Train APUR: 0.6259, Test AUC: 0.6318, Test AUPR: 0.6214\n",
      "Epoch: 26/100, Loss: 0.6631364, Train Acc: 0.6005, Test Acc: 0.5979, Train AUC: 0.6398, Train APUR: 0.6257, Test AUC: 0.6309, Test AUPR: 0.6213\n",
      "Epoch: 27/100, Loss: 0.6619334, Train Acc: 0.6098, Test Acc: 0.5958, Train AUC: 0.6418, Train APUR: 0.6280, Test AUC: 0.6308, Test AUPR: 0.6220\n",
      "Epoch: 28/100, Loss: 0.6619223, Train Acc: 0.6038, Test Acc: 0.5952, Train AUC: 0.6416, Train APUR: 0.6281, Test AUC: 0.6306, Test AUPR: 0.6221\n",
      "Epoch: 29/100, Loss: 0.6618259, Train Acc: 0.6042, Test Acc: 0.6016, Train AUC: 0.6426, Train APUR: 0.6283, Test AUC: 0.6312, Test AUPR: 0.6223\n",
      "Epoch: 30/100, Loss: 0.6611795, Train Acc: 0.6102, Test Acc: 0.5995, Train AUC: 0.6447, Train APUR: 0.6288, Test AUC: 0.6328, Test AUPR: 0.6240\n",
      "Epoch: 31/100, Loss: 0.6603983, Train Acc: 0.6090, Test Acc: 0.6012, Train AUC: 0.6461, Train APUR: 0.6318, Test AUC: 0.6343, Test AUPR: 0.6259\n",
      "Epoch: 32/100, Loss: 0.6603943, Train Acc: 0.6115, Test Acc: 0.6053, Train AUC: 0.6476, Train APUR: 0.6333, Test AUC: 0.6354, Test AUPR: 0.6264\n",
      "Epoch: 33/100, Loss: 0.6596522, Train Acc: 0.6119, Test Acc: 0.6017, Train AUC: 0.6465, Train APUR: 0.6323, Test AUC: 0.6363, Test AUPR: 0.6263\n",
      "Epoch: 34/100, Loss: 0.6594993, Train Acc: 0.6117, Test Acc: 0.6049, Train AUC: 0.6479, Train APUR: 0.6321, Test AUC: 0.6370, Test AUPR: 0.6273\n",
      "Epoch: 35/100, Loss: 0.6586455, Train Acc: 0.6108, Test Acc: 0.5975, Train AUC: 0.6492, Train APUR: 0.6346, Test AUC: 0.6376, Test AUPR: 0.6293\n",
      "Epoch: 36/100, Loss: 0.6579183, Train Acc: 0.6112, Test Acc: 0.5961, Train AUC: 0.6505, Train APUR: 0.6356, Test AUC: 0.6381, Test AUPR: 0.6307\n",
      "Epoch: 37/100, Loss: 0.6583296, Train Acc: 0.6103, Test Acc: 0.6037, Train AUC: 0.6511, Train APUR: 0.6365, Test AUC: 0.6385, Test AUPR: 0.6299\n",
      "Epoch: 38/100, Loss: 0.6568076, Train Acc: 0.6132, Test Acc: 0.6039, Train AUC: 0.6526, Train APUR: 0.6376, Test AUC: 0.6387, Test AUPR: 0.6287\n",
      "Epoch: 39/100, Loss: 0.6573775, Train Acc: 0.6086, Test Acc: 0.6060, Train AUC: 0.6526, Train APUR: 0.6365, Test AUC: 0.6411, Test AUPR: 0.6319\n",
      "Epoch: 40/100, Loss: 0.6558181, Train Acc: 0.6166, Test Acc: 0.6001, Train AUC: 0.6545, Train APUR: 0.6394, Test AUC: 0.6436, Test AUPR: 0.6348\n",
      "Epoch: 41/100, Loss: 0.6555166, Train Acc: 0.6146, Test Acc: 0.6020, Train AUC: 0.6563, Train APUR: 0.6411, Test AUC: 0.6445, Test AUPR: 0.6356\n",
      "Epoch: 42/100, Loss: 0.6546879, Train Acc: 0.6190, Test Acc: 0.6106, Train AUC: 0.6577, Train APUR: 0.6419, Test AUC: 0.6440, Test AUPR: 0.6351\n",
      "Epoch: 43/100, Loss: 0.6538835, Train Acc: 0.6119, Test Acc: 0.6128, Train AUC: 0.6581, Train APUR: 0.6437, Test AUC: 0.6470, Test AUPR: 0.6377\n",
      "Epoch: 44/100, Loss: 0.6525605, Train Acc: 0.6203, Test Acc: 0.6144, Train AUC: 0.6612, Train APUR: 0.6466, Test AUC: 0.6488, Test AUPR: 0.6402\n",
      "Epoch: 45/100, Loss: 0.6518538, Train Acc: 0.6227, Test Acc: 0.6185, Train AUC: 0.6634, Train APUR: 0.6485, Test AUC: 0.6509, Test AUPR: 0.6414\n",
      "Epoch: 46/100, Loss: 0.6514000, Train Acc: 0.6189, Test Acc: 0.6180, Train AUC: 0.6639, Train APUR: 0.6493, Test AUC: 0.6513, Test AUPR: 0.6421\n",
      "Epoch: 47/100, Loss: 0.6496244, Train Acc: 0.6255, Test Acc: 0.6135, Train AUC: 0.6673, Train APUR: 0.6515, Test AUC: 0.6504, Test AUPR: 0.6427\n",
      "Epoch: 48/100, Loss: 0.6488180, Train Acc: 0.6243, Test Acc: 0.6170, Train AUC: 0.6669, Train APUR: 0.6531, Test AUC: 0.6554, Test AUPR: 0.6469\n",
      "Epoch: 49/100, Loss: 0.6476923, Train Acc: 0.6281, Test Acc: 0.6244, Train AUC: 0.6716, Train APUR: 0.6561, Test AUC: 0.6591, Test AUPR: 0.6483\n",
      "Epoch: 50/100, Loss: 0.6464186, Train Acc: 0.6300, Test Acc: 0.6196, Train AUC: 0.6744, Train APUR: 0.6580, Test AUC: 0.6578, Test AUPR: 0.6466\n",
      "Epoch: 51/100, Loss: 0.6459758, Train Acc: 0.6255, Test Acc: 0.6232, Train AUC: 0.6715, Train APUR: 0.6563, Test AUC: 0.6646, Test AUPR: 0.6532\n",
      "Epoch: 52/100, Loss: 0.6441503, Train Acc: 0.6352, Test Acc: 0.6285, Train AUC: 0.6790, Train APUR: 0.6616, Test AUC: 0.6636, Test AUPR: 0.6530\n",
      "Epoch: 53/100, Loss: 0.6430781, Train Acc: 0.6387, Test Acc: 0.6251, Train AUC: 0.6815, Train APUR: 0.6635, Test AUC: 0.6623, Test AUPR: 0.6496\n",
      "Epoch: 54/100, Loss: 0.6421837, Train Acc: 0.6365, Test Acc: 0.6211, Train AUC: 0.6801, Train APUR: 0.6641, Test AUC: 0.6704, Test AUPR: 0.6567\n",
      "Epoch: 55/100, Loss: 0.6427088, Train Acc: 0.6372, Test Acc: 0.6317, Train AUC: 0.6873, Train APUR: 0.6686, Test AUC: 0.6712, Test AUPR: 0.6576\n",
      "Epoch: 56/100, Loss: 0.6388770, Train Acc: 0.6433, Test Acc: 0.6283, Train AUC: 0.6902, Train APUR: 0.6729, Test AUC: 0.6661, Test AUPR: 0.6528\n",
      "Epoch: 57/100, Loss: 0.6388251, Train Acc: 0.6397, Test Acc: 0.6275, Train AUC: 0.6860, Train APUR: 0.6711, Test AUC: 0.6716, Test AUPR: 0.6592\n",
      "Epoch: 58/100, Loss: 0.6354448, Train Acc: 0.6435, Test Acc: 0.6270, Train AUC: 0.6941, Train APUR: 0.6767, Test AUC: 0.6732, Test AUPR: 0.6606\n",
      "Epoch: 59/100, Loss: 0.6335493, Train Acc: 0.6468, Test Acc: 0.6319, Train AUC: 0.6970, Train APUR: 0.6789, Test AUC: 0.6729, Test AUPR: 0.6587\n",
      "Epoch: 60/100, Loss: 0.6332657, Train Acc: 0.6466, Test Acc: 0.6342, Train AUC: 0.6940, Train APUR: 0.6788, Test AUC: 0.6782, Test AUPR: 0.6671\n",
      "Epoch: 61/100, Loss: 0.6296954, Train Acc: 0.6488, Test Acc: 0.6336, Train AUC: 0.7012, Train APUR: 0.6860, Test AUC: 0.6807, Test AUPR: 0.6663\n",
      "Epoch: 62/100, Loss: 0.6288586, Train Acc: 0.6495, Test Acc: 0.6297, Train AUC: 0.7032, Train APUR: 0.6853, Test AUC: 0.6792, Test AUPR: 0.6644\n",
      "Epoch: 63/100, Loss: 0.6277393, Train Acc: 0.6494, Test Acc: 0.6332, Train AUC: 0.7034, Train APUR: 0.6863, Test AUC: 0.6789, Test AUPR: 0.6712\n",
      "Epoch: 64/100, Loss: 0.6271644, Train Acc: 0.6493, Test Acc: 0.6361, Train AUC: 0.7062, Train APUR: 0.6936, Test AUC: 0.6817, Test AUPR: 0.6716\n",
      "Epoch: 65/100, Loss: 0.6238481, Train Acc: 0.6533, Test Acc: 0.6314, Train AUC: 0.7093, Train APUR: 0.6948, Test AUC: 0.6856, Test AUPR: 0.6749\n",
      "Epoch: 66/100, Loss: 0.6218868, Train Acc: 0.6543, Test Acc: 0.6383, Train AUC: 0.7121, Train APUR: 0.6978, Test AUC: 0.6865, Test AUPR: 0.6778\n",
      "Epoch: 67/100, Loss: 0.6212285, Train Acc: 0.6548, Test Acc: 0.6356, Train AUC: 0.7124, Train APUR: 0.7000, Test AUC: 0.6827, Test AUPR: 0.6693\n",
      "Epoch: 68/100, Loss: 0.6209705, Train Acc: 0.6551, Test Acc: 0.6389, Train AUC: 0.7133, Train APUR: 0.6984, Test AUC: 0.6901, Test AUPR: 0.6752\n",
      "Epoch: 69/100, Loss: 0.6172392, Train Acc: 0.6566, Test Acc: 0.6352, Train AUC: 0.7173, Train APUR: 0.7017, Test AUC: 0.6890, Test AUPR: 0.6738\n",
      "Epoch: 70/100, Loss: 0.6190628, Train Acc: 0.6561, Test Acc: 0.6365, Train AUC: 0.7143, Train APUR: 0.6987, Test AUC: 0.6872, Test AUPR: 0.6791\n",
      "Epoch: 71/100, Loss: 0.6143000, Train Acc: 0.6606, Test Acc: 0.6373, Train AUC: 0.7201, Train APUR: 0.7088, Test AUC: 0.6846, Test AUPR: 0.6765\n",
      "Epoch: 72/100, Loss: 0.6154481, Train Acc: 0.6579, Test Acc: 0.6390, Train AUC: 0.7194, Train APUR: 0.7092, Test AUC: 0.6918, Test AUPR: 0.6838\n",
      "Epoch: 73/100, Loss: 0.6138654, Train Acc: 0.6606, Test Acc: 0.6364, Train AUC: 0.7212, Train APUR: 0.7123, Test AUC: 0.6938, Test AUPR: 0.6812\n",
      "Epoch: 74/100, Loss: 0.6105958, Train Acc: 0.6627, Test Acc: 0.6407, Train AUC: 0.7257, Train APUR: 0.7120, Test AUC: 0.6909, Test AUPR: 0.6795\n",
      "Epoch: 75/100, Loss: 0.6140298, Train Acc: 0.6593, Test Acc: 0.6370, Train AUC: 0.7224, Train APUR: 0.7122, Test AUC: 0.6886, Test AUPR: 0.6782\n",
      "Epoch: 76/100, Loss: 0.6186568, Train Acc: 0.6505, Test Acc: 0.6280, Train AUC: 0.7116, Train APUR: 0.7047, Test AUC: 0.6851, Test AUPR: 0.6692\n",
      "Epoch: 77/100, Loss: 0.6143398, Train Acc: 0.6587, Test Acc: 0.6412, Train AUC: 0.7219, Train APUR: 0.7105, Test AUC: 0.6895, Test AUPR: 0.6783\n",
      "Epoch: 78/100, Loss: 0.6064975, Train Acc: 0.6667, Test Acc: 0.6397, Train AUC: 0.7294, Train APUR: 0.7189, Test AUC: 0.6869, Test AUPR: 0.6776\n",
      "Epoch: 79/100, Loss: 0.6098727, Train Acc: 0.6600, Test Acc: 0.6434, Train AUC: 0.7250, Train APUR: 0.7163, Test AUC: 0.6932, Test AUPR: 0.6827\n",
      "Epoch: 80/100, Loss: 0.6038810, Train Acc: 0.6690, Test Acc: 0.6319, Train AUC: 0.7332, Train APUR: 0.7259, Test AUC: 0.6893, Test AUPR: 0.6708\n",
      "Epoch: 81/100, Loss: 0.6055197, Train Acc: 0.6658, Test Acc: 0.6409, Train AUC: 0.7321, Train APUR: 0.7238, Test AUC: 0.6924, Test AUPR: 0.6691\n",
      "Epoch: 82/100, Loss: 0.6024593, Train Acc: 0.6686, Test Acc: 0.6447, Train AUC: 0.7339, Train APUR: 0.7235, Test AUC: 0.6959, Test AUPR: 0.6758\n",
      "Epoch: 83/100, Loss: 0.6042874, Train Acc: 0.6681, Test Acc: 0.6446, Train AUC: 0.7335, Train APUR: 0.7205, Test AUC: 0.6938, Test AUPR: 0.6836\n",
      "Epoch: 84/100, Loss: 0.6027499, Train Acc: 0.6689, Test Acc: 0.6406, Train AUC: 0.7337, Train APUR: 0.7264, Test AUC: 0.6914, Test AUPR: 0.6844\n",
      "Epoch: 85/100, Loss: 0.6021875, Train Acc: 0.6701, Test Acc: 0.6361, Train AUC: 0.7337, Train APUR: 0.7279, Test AUC: 0.6930, Test AUPR: 0.6833\n",
      "Epoch: 86/100, Loss: 0.6005062, Train Acc: 0.6711, Test Acc: 0.6357, Train AUC: 0.7371, Train APUR: 0.7295, Test AUC: 0.6891, Test AUPR: 0.6786\n",
      "Epoch: 87/100, Loss: 0.6043873, Train Acc: 0.6664, Test Acc: 0.6419, Train AUC: 0.7308, Train APUR: 0.7222, Test AUC: 0.6901, Test AUPR: 0.6819\n",
      "Epoch: 88/100, Loss: 0.6013717, Train Acc: 0.6711, Test Acc: 0.6454, Train AUC: 0.7356, Train APUR: 0.7294, Test AUC: 0.6981, Test AUPR: 0.6884\n",
      "Epoch: 89/100, Loss: 0.5967177, Train Acc: 0.6731, Test Acc: 0.6474, Train AUC: 0.7416, Train APUR: 0.7349, Test AUC: 0.7034, Test AUPR: 0.6912\n",
      "Epoch: 90/100, Loss: 0.5971205, Train Acc: 0.6714, Test Acc: 0.6383, Train AUC: 0.7382, Train APUR: 0.7329, Test AUC: 0.6963, Test AUPR: 0.6804\n",
      "Epoch: 91/100, Loss: 0.5989203, Train Acc: 0.6703, Test Acc: 0.6468, Train AUC: 0.7384, Train APUR: 0.7293, Test AUC: 0.7012, Test AUPR: 0.6875\n",
      "Epoch: 92/100, Loss: 0.5955437, Train Acc: 0.6741, Test Acc: 0.6447, Train AUC: 0.7401, Train APUR: 0.7343, Test AUC: 0.6967, Test AUPR: 0.6841\n",
      "Epoch: 93/100, Loss: 0.5955638, Train Acc: 0.6749, Test Acc: 0.6402, Train AUC: 0.7418, Train APUR: 0.7348, Test AUC: 0.6902, Test AUPR: 0.6796\n",
      "Epoch: 94/100, Loss: 0.5994982, Train Acc: 0.6716, Test Acc: 0.6409, Train AUC: 0.7379, Train APUR: 0.7313, Test AUC: 0.6966, Test AUPR: 0.6858\n",
      "Epoch: 95/100, Loss: 0.5940557, Train Acc: 0.6746, Test Acc: 0.6435, Train AUC: 0.7446, Train APUR: 0.7403, Test AUC: 0.7031, Test AUPR: 0.6933\n",
      "Epoch: 96/100, Loss: 0.5937213, Train Acc: 0.6742, Test Acc: 0.6409, Train AUC: 0.7452, Train APUR: 0.7417, Test AUC: 0.6907, Test AUPR: 0.6793\n",
      "Epoch: 97/100, Loss: 0.5996897, Train Acc: 0.6713, Test Acc: 0.6492, Train AUC: 0.7370, Train APUR: 0.7281, Test AUC: 0.7045, Test AUPR: 0.6943\n",
      "Epoch: 98/100, Loss: 0.5910427, Train Acc: 0.6763, Test Acc: 0.6468, Train AUC: 0.7472, Train APUR: 0.7419, Test AUC: 0.7020, Test AUPR: 0.6917\n",
      "Epoch: 99/100, Loss: 0.5986996, Train Acc: 0.6684, Test Acc: 0.6398, Train AUC: 0.7355, Train APUR: 0.7318, Test AUC: 0.6922, Test AUPR: 0.6796\n",
      "Epoch: 100/100, Loss: 0.5937400, Train Acc: 0.6766, Test Acc: 0.6404, Train AUC: 0.7436, Train APUR: 0.7368, Test AUC: 0.6947, Test AUPR: 0.6830\n",
      "/home/ubuntu/PA-Cancer-Immunotherapy/GNN/train_pa.py:246: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(configs['save_model']))\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 67.081 MB of 67.081 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 67.082 MB of 67.082 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 67.082 MB of 67.082 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 67.082 MB of 67.082 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▁▁▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      test_aupr ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   test_roc_auc ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▁▃▃▃▃▄▄▄▄▄▄▄▄▄▄▄▅▄▅▅▅▅▆▆▆▇▇▇▇▇▇▇███▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_aupr ▁▂▃▃▃▄▄▄▅▅▅▅▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss █▇▇▆▆▆▆▆▆▆▆▆▅▅▅▅▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▁▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_roc_auc ▁▁▁▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▆▇▇▇▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: valid_accuracy ▁▂▃▃▄▅▄▅▅▅▅▅▅▅▅▅▆▅▆▆▆▇▇▇▇█▇█▇██████▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     valid_aupr ▁▁▂▂▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▆▅▆▆▆▆▇▇▇▇▇▇▇▇█▇██▇▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  valid_roc_auc ▁▁▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▄▄▄▅▆▆▆▆▆▇▇▇▇▇▇█▇▇█▇█▇▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy 0.64922\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      test_aupr 0.69433\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   test_roc_auc 0.70448\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.67664\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_aupr 0.73677\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.59374\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_roc_auc 0.74361\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: valid_accuracy 0.64041\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     valid_aupr 0.68299\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  valid_roc_auc 0.69466\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mscarlet-dust-8\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-gene_GNN/runs/htr152ra\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-gene_GNN\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 120 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241203_234127-htr152ra/logs\u001b[0m\n",
      "Test Acc: 0.6492, Test AUC: 0.7045, Test AUPR: 0.6943\n"
     ]
    }
   ],
   "source": [
    "# embeddings with the trained tcrpeg model separately for cdr3 and for epitope. \n",
    "# This is the first try with wandb\n",
    "! python train_pa.py --gpu 0 --configs_path configs/PA_all_gene.yml --droup_out 0.1 --split StrictTCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0141ae63-b31f-426c-b616-4b5297c2d5e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c077021-0342-44c1-aa4b-4cab90ee4abc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(gpu=0, lr=0.001, epochs=100, w_celoss=1, w_aucloss=0, add_same_type_edges=False, dynamic_graph=False, dynamic_ratio=0.05, droup_out=0.1, positive_weights=1, dynamic_epochs=30, distance_threshold=10, configs_path='configs/PA_all_allele.yml', split='StrictTCR', dataset='pMTnet')\n",
      "PROJECT_NAME: dataset-allele_GNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfrohoari\u001b[0m (\u001b[33mpa_cancerimmunotherapy\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/ubuntu/PA-Cancer-Immunotherapy/GNN/wandb/run-20241203_235623-etp47d99\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mpeachy-yogurt-7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN/runs/etp47d99\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   10 of 10 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   10 of 10 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   10 of 10 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   10 of 10 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   10 of 10 files downloaded.  \n",
      "embeddings_path:   models/PA_all/gene_and_allele_embeddings.pkl\n",
      "train_file_list:   ['allele_fold_0.csv', 'allele_fold_1.csv', 'allele_fold_2.csv', 'allele_fold_3.csv']\n",
      "test_file_list:   ['allele_fold_4.csv']\n",
      "wandb logger initialisiert\n",
      "Epoch: 1/100, Loss: 0.6932291, Train Acc: 0.5062, Test Acc: 0.5140, Train AUC: 0.5029, Train APUR: 0.5013, Test AUC: 0.5891, Test AUPR: 0.5840\n",
      "Epoch: 2/100, Loss: 0.6899970, Train Acc: 0.5120, Test Acc: 0.5491, Train AUC: 0.5792, Train APUR: 0.5662, Test AUC: 0.5927, Test AUPR: 0.5868\n",
      "Epoch: 3/100, Loss: 0.6866980, Train Acc: 0.5478, Test Acc: 0.5649, Train AUC: 0.5871, Train APUR: 0.5748, Test AUC: 0.5977, Test AUPR: 0.5892\n",
      "Epoch: 4/100, Loss: 0.6827021, Train Acc: 0.5673, Test Acc: 0.5695, Train AUC: 0.5948, Train APUR: 0.5835, Test AUC: 0.6001, Test AUPR: 0.5905\n",
      "Epoch: 5/100, Loss: 0.6799321, Train Acc: 0.5744, Test Acc: 0.5741, Train AUC: 0.6012, Train APUR: 0.5881, Test AUC: 0.6014, Test AUPR: 0.5911\n",
      "Epoch: 6/100, Loss: 0.6784037, Train Acc: 0.5748, Test Acc: 0.5785, Train AUC: 0.6020, Train APUR: 0.5830, Test AUC: 0.6031, Test AUPR: 0.5923\n",
      "Epoch: 7/100, Loss: 0.6775478, Train Acc: 0.5807, Test Acc: 0.5784, Train AUC: 0.6056, Train APUR: 0.5859, Test AUC: 0.6076, Test AUPR: 0.5977\n",
      "Epoch: 8/100, Loss: 0.6742149, Train Acc: 0.5847, Test Acc: 0.5845, Train AUC: 0.6120, Train APUR: 0.5961, Test AUC: 0.6112, Test AUPR: 0.5994\n",
      "Epoch: 9/100, Loss: 0.6730417, Train Acc: 0.5872, Test Acc: 0.5856, Train AUC: 0.6168, Train APUR: 0.6006, Test AUC: 0.6135, Test AUPR: 0.5999\n",
      "Epoch: 10/100, Loss: 0.6714085, Train Acc: 0.5905, Test Acc: 0.5839, Train AUC: 0.6205, Train APUR: 0.6043, Test AUC: 0.6144, Test AUPR: 0.6001\n",
      "Epoch: 11/100, Loss: 0.6715982, Train Acc: 0.5856, Test Acc: 0.5797, Train AUC: 0.6216, Train APUR: 0.6034, Test AUC: 0.6113, Test AUPR: 0.5980\n",
      "Epoch: 12/100, Loss: 0.6701958, Train Acc: 0.5935, Test Acc: 0.5864, Train AUC: 0.6250, Train APUR: 0.6065, Test AUC: 0.6133, Test AUPR: 0.6008\n",
      "Epoch: 13/100, Loss: 0.6690095, Train Acc: 0.5938, Test Acc: 0.5898, Train AUC: 0.6272, Train APUR: 0.6072, Test AUC: 0.6190, Test AUPR: 0.6060\n",
      "Epoch: 14/100, Loss: 0.6673442, Train Acc: 0.5957, Test Acc: 0.5935, Train AUC: 0.6301, Train APUR: 0.6109, Test AUC: 0.6221, Test AUPR: 0.6096\n",
      "Epoch: 15/100, Loss: 0.6669343, Train Acc: 0.6013, Test Acc: 0.5926, Train AUC: 0.6315, Train APUR: 0.6117, Test AUC: 0.6247, Test AUPR: 0.6129\n",
      "Epoch: 16/100, Loss: 0.6668422, Train Acc: 0.5975, Test Acc: 0.6005, Train AUC: 0.6323, Train APUR: 0.6142, Test AUC: 0.6273, Test AUPR: 0.6149\n",
      "Epoch: 17/100, Loss: 0.6661530, Train Acc: 0.6011, Test Acc: 0.5973, Train AUC: 0.6335, Train APUR: 0.6155, Test AUC: 0.6287, Test AUPR: 0.6161\n",
      "Epoch: 18/100, Loss: 0.6646557, Train Acc: 0.6057, Test Acc: 0.5917, Train AUC: 0.6363, Train APUR: 0.6177, Test AUC: 0.6274, Test AUPR: 0.6161\n",
      "Epoch: 19/100, Loss: 0.6637720, Train Acc: 0.6043, Test Acc: 0.5880, Train AUC: 0.6390, Train APUR: 0.6194, Test AUC: 0.6267, Test AUPR: 0.6158\n",
      "Epoch: 20/100, Loss: 0.6639059, Train Acc: 0.6042, Test Acc: 0.5907, Train AUC: 0.6401, Train APUR: 0.6206, Test AUC: 0.6269, Test AUPR: 0.6156\n",
      "Epoch: 21/100, Loss: 0.6627429, Train Acc: 0.6061, Test Acc: 0.5979, Train AUC: 0.6422, Train APUR: 0.6235, Test AUC: 0.6300, Test AUPR: 0.6186\n",
      "Epoch: 22/100, Loss: 0.6617723, Train Acc: 0.6085, Test Acc: 0.5963, Train AUC: 0.6417, Train APUR: 0.6231, Test AUC: 0.6325, Test AUPR: 0.6217\n",
      "Epoch: 23/100, Loss: 0.6620511, Train Acc: 0.6016, Test Acc: 0.6064, Train AUC: 0.6421, Train APUR: 0.6249, Test AUC: 0.6334, Test AUPR: 0.6224\n",
      "Epoch: 24/100, Loss: 0.6611705, Train Acc: 0.6081, Test Acc: 0.6065, Train AUC: 0.6425, Train APUR: 0.6248, Test AUC: 0.6333, Test AUPR: 0.6224\n",
      "Epoch: 25/100, Loss: 0.6598582, Train Acc: 0.6123, Test Acc: 0.6007, Train AUC: 0.6456, Train APUR: 0.6258, Test AUC: 0.6325, Test AUPR: 0.6225\n",
      "Epoch: 26/100, Loss: 0.6603258, Train Acc: 0.6087, Test Acc: 0.5893, Train AUC: 0.6470, Train APUR: 0.6279, Test AUC: 0.6335, Test AUPR: 0.6240\n",
      "Epoch: 27/100, Loss: 0.6604123, Train Acc: 0.6039, Test Acc: 0.5991, Train AUC: 0.6463, Train APUR: 0.6271, Test AUC: 0.6343, Test AUPR: 0.6242\n",
      "Epoch: 28/100, Loss: 0.6575776, Train Acc: 0.6125, Test Acc: 0.6048, Train AUC: 0.6491, Train APUR: 0.6309, Test AUC: 0.6339, Test AUPR: 0.6232\n",
      "Epoch: 29/100, Loss: 0.6576699, Train Acc: 0.6115, Test Acc: 0.6028, Train AUC: 0.6494, Train APUR: 0.6305, Test AUC: 0.6348, Test AUPR: 0.6244\n",
      "Epoch: 30/100, Loss: 0.6566083, Train Acc: 0.6130, Test Acc: 0.6057, Train AUC: 0.6514, Train APUR: 0.6324, Test AUC: 0.6359, Test AUPR: 0.6261\n",
      "Epoch: 31/100, Loss: 0.6560158, Train Acc: 0.6142, Test Acc: 0.6043, Train AUC: 0.6523, Train APUR: 0.6333, Test AUC: 0.6362, Test AUPR: 0.6266\n",
      "Epoch: 32/100, Loss: 0.6553751, Train Acc: 0.6131, Test Acc: 0.6095, Train AUC: 0.6531, Train APUR: 0.6335, Test AUC: 0.6369, Test AUPR: 0.6280\n",
      "Epoch: 33/100, Loss: 0.6549853, Train Acc: 0.6156, Test Acc: 0.6021, Train AUC: 0.6549, Train APUR: 0.6355, Test AUC: 0.6373, Test AUPR: 0.6291\n",
      "Epoch: 34/100, Loss: 0.6541544, Train Acc: 0.6142, Test Acc: 0.6069, Train AUC: 0.6576, Train APUR: 0.6379, Test AUC: 0.6378, Test AUPR: 0.6285\n",
      "Epoch: 35/100, Loss: 0.6531096, Train Acc: 0.6120, Test Acc: 0.6072, Train AUC: 0.6570, Train APUR: 0.6379, Test AUC: 0.6377, Test AUPR: 0.6273\n",
      "Epoch: 36/100, Loss: 0.6532182, Train Acc: 0.6142, Test Acc: 0.6047, Train AUC: 0.6579, Train APUR: 0.6385, Test AUC: 0.6423, Test AUPR: 0.6325\n",
      "Epoch: 37/100, Loss: 0.6515258, Train Acc: 0.6109, Test Acc: 0.6063, Train AUC: 0.6611, Train APUR: 0.6435, Test AUC: 0.6430, Test AUPR: 0.6335\n",
      "Epoch: 38/100, Loss: 0.6505316, Train Acc: 0.6206, Test Acc: 0.6092, Train AUC: 0.6650, Train APUR: 0.6445, Test AUC: 0.6374, Test AUPR: 0.6294\n",
      "Epoch: 39/100, Loss: 0.6501292, Train Acc: 0.6168, Test Acc: 0.6070, Train AUC: 0.6646, Train APUR: 0.6425, Test AUC: 0.6405, Test AUPR: 0.6310\n",
      "Epoch: 40/100, Loss: 0.6477828, Train Acc: 0.6189, Test Acc: 0.6091, Train AUC: 0.6676, Train APUR: 0.6476, Test AUC: 0.6457, Test AUPR: 0.6344\n",
      "Epoch: 41/100, Loss: 0.6466691, Train Acc: 0.6221, Test Acc: 0.6109, Train AUC: 0.6699, Train APUR: 0.6509, Test AUC: 0.6485, Test AUPR: 0.6374\n",
      "Epoch: 42/100, Loss: 0.6453586, Train Acc: 0.6261, Test Acc: 0.5955, Train AUC: 0.6714, Train APUR: 0.6521, Test AUC: 0.6521, Test AUPR: 0.6419\n",
      "Epoch: 43/100, Loss: 0.6462863, Train Acc: 0.6236, Test Acc: 0.6131, Train AUC: 0.6743, Train APUR: 0.6544, Test AUC: 0.6505, Test AUPR: 0.6407\n",
      "Epoch: 44/100, Loss: 0.6430705, Train Acc: 0.6291, Test Acc: 0.6137, Train AUC: 0.6778, Train APUR: 0.6582, Test AUC: 0.6504, Test AUPR: 0.6384\n",
      "Epoch: 45/100, Loss: 0.6423957, Train Acc: 0.6270, Test Acc: 0.6101, Train AUC: 0.6775, Train APUR: 0.6574, Test AUC: 0.6553, Test AUPR: 0.6432\n",
      "Epoch: 46/100, Loss: 0.6414843, Train Acc: 0.6289, Test Acc: 0.6209, Train AUC: 0.6820, Train APUR: 0.6599, Test AUC: 0.6565, Test AUPR: 0.6453\n",
      "Epoch: 47/100, Loss: 0.6398768, Train Acc: 0.6366, Test Acc: 0.6133, Train AUC: 0.6867, Train APUR: 0.6615, Test AUC: 0.6491, Test AUPR: 0.6415\n",
      "Epoch: 48/100, Loss: 0.6391962, Train Acc: 0.6375, Test Acc: 0.5951, Train AUC: 0.6871, Train APUR: 0.6631, Test AUC: 0.6513, Test AUPR: 0.6424\n",
      "Epoch: 49/100, Loss: 0.6353984, Train Acc: 0.6364, Test Acc: 0.5945, Train AUC: 0.6902, Train APUR: 0.6696, Test AUC: 0.6551, Test AUPR: 0.6449\n",
      "Epoch: 50/100, Loss: 0.6374826, Train Acc: 0.6353, Test Acc: 0.6091, Train AUC: 0.6882, Train APUR: 0.6703, Test AUC: 0.6533, Test AUPR: 0.6480\n",
      "Epoch: 51/100, Loss: 0.6330466, Train Acc: 0.6433, Test Acc: 0.6217, Train AUC: 0.6977, Train APUR: 0.6750, Test AUC: 0.6589, Test AUPR: 0.6498\n",
      "Epoch: 52/100, Loss: 0.6328608, Train Acc: 0.6429, Test Acc: 0.6123, Train AUC: 0.6986, Train APUR: 0.6758, Test AUC: 0.6622, Test AUPR: 0.6483\n",
      "Epoch: 53/100, Loss: 0.6318561, Train Acc: 0.6445, Test Acc: 0.6141, Train AUC: 0.6977, Train APUR: 0.6745, Test AUC: 0.6638, Test AUPR: 0.6509\n",
      "Epoch: 54/100, Loss: 0.6302439, Train Acc: 0.6449, Test Acc: 0.6089, Train AUC: 0.6980, Train APUR: 0.6756, Test AUC: 0.6555, Test AUPR: 0.6495\n",
      "Epoch: 55/100, Loss: 0.6322275, Train Acc: 0.6386, Test Acc: 0.6168, Train AUC: 0.6958, Train APUR: 0.6767, Test AUC: 0.6556, Test AUPR: 0.6460\n",
      "Epoch: 56/100, Loss: 0.6301410, Train Acc: 0.6420, Test Acc: 0.6082, Train AUC: 0.6991, Train APUR: 0.6800, Test AUC: 0.6681, Test AUPR: 0.6538\n",
      "Epoch: 57/100, Loss: 0.6290272, Train Acc: 0.6458, Test Acc: 0.6122, Train AUC: 0.7018, Train APUR: 0.6813, Test AUC: 0.6731, Test AUPR: 0.6610\n",
      "Epoch: 58/100, Loss: 0.6253555, Train Acc: 0.6485, Test Acc: 0.6318, Train AUC: 0.7071, Train APUR: 0.6853, Test AUC: 0.6757, Test AUPR: 0.6636\n",
      "Epoch: 59/100, Loss: 0.6240948, Train Acc: 0.6510, Test Acc: 0.6257, Train AUC: 0.7127, Train APUR: 0.6923, Test AUC: 0.6689, Test AUPR: 0.6557\n",
      "Epoch: 60/100, Loss: 0.6256175, Train Acc: 0.6477, Test Acc: 0.6067, Train AUC: 0.7095, Train APUR: 0.6903, Test AUC: 0.6751, Test AUPR: 0.6590\n",
      "Epoch: 61/100, Loss: 0.6191974, Train Acc: 0.6515, Test Acc: 0.5983, Train AUC: 0.7151, Train APUR: 0.6986, Test AUC: 0.6759, Test AUPR: 0.6593\n",
      "Epoch: 62/100, Loss: 0.6203006, Train Acc: 0.6504, Test Acc: 0.6154, Train AUC: 0.7149, Train APUR: 0.6948, Test AUC: 0.6749, Test AUPR: 0.6631\n",
      "Epoch: 63/100, Loss: 0.6174383, Train Acc: 0.6534, Test Acc: 0.6224, Train AUC: 0.7152, Train APUR: 0.6965, Test AUC: 0.6721, Test AUPR: 0.6614\n",
      "Epoch: 64/100, Loss: 0.6183814, Train Acc: 0.6499, Test Acc: 0.6126, Train AUC: 0.7152, Train APUR: 0.7008, Test AUC: 0.6692, Test AUPR: 0.6562\n",
      "Epoch: 65/100, Loss: 0.6141295, Train Acc: 0.6551, Test Acc: 0.6075, Train AUC: 0.7190, Train APUR: 0.7035, Test AUC: 0.6786, Test AUPR: 0.6635\n",
      "Epoch: 66/100, Loss: 0.6159040, Train Acc: 0.6525, Test Acc: 0.6084, Train AUC: 0.7204, Train APUR: 0.7011, Test AUC: 0.6828, Test AUPR: 0.6698\n",
      "Epoch: 67/100, Loss: 0.6134688, Train Acc: 0.6558, Test Acc: 0.6222, Train AUC: 0.7240, Train APUR: 0.7095, Test AUC: 0.6728, Test AUPR: 0.6627\n",
      "Epoch: 68/100, Loss: 0.6134562, Train Acc: 0.6574, Test Acc: 0.6251, Train AUC: 0.7218, Train APUR: 0.7080, Test AUC: 0.6756, Test AUPR: 0.6715\n",
      "Epoch: 69/100, Loss: 0.6142191, Train Acc: 0.6548, Test Acc: 0.6293, Train AUC: 0.7172, Train APUR: 0.7052, Test AUC: 0.6792, Test AUPR: 0.6663\n",
      "Epoch: 70/100, Loss: 0.6065902, Train Acc: 0.6629, Test Acc: 0.6176, Train AUC: 0.7290, Train APUR: 0.7159, Test AUC: 0.6694, Test AUPR: 0.6553\n",
      "Epoch: 71/100, Loss: 0.6121846, Train Acc: 0.6548, Test Acc: 0.6148, Train AUC: 0.7201, Train APUR: 0.7076, Test AUC: 0.6837, Test AUPR: 0.6735\n",
      "Epoch: 72/100, Loss: 0.6082056, Train Acc: 0.6602, Test Acc: 0.6091, Train AUC: 0.7267, Train APUR: 0.7165, Test AUC: 0.6722, Test AUPR: 0.6647\n",
      "Epoch: 73/100, Loss: 0.6046594, Train Acc: 0.6622, Test Acc: 0.6044, Train AUC: 0.7321, Train APUR: 0.7202, Test AUC: 0.6618, Test AUPR: 0.6550\n",
      "Epoch: 74/100, Loss: 0.6047656, Train Acc: 0.6632, Test Acc: 0.6056, Train AUC: 0.7298, Train APUR: 0.7205, Test AUC: 0.6703, Test AUPR: 0.6630\n",
      "Epoch: 75/100, Loss: 0.6032307, Train Acc: 0.6644, Test Acc: 0.5963, Train AUC: 0.7325, Train APUR: 0.7208, Test AUC: 0.6786, Test AUPR: 0.6740\n",
      "Epoch: 76/100, Loss: 0.6089566, Train Acc: 0.6543, Test Acc: 0.6226, Train AUC: 0.7252, Train APUR: 0.7159, Test AUC: 0.6798, Test AUPR: 0.6662\n",
      "Epoch: 77/100, Loss: 0.6005260, Train Acc: 0.6660, Test Acc: 0.6206, Train AUC: 0.7354, Train APUR: 0.7244, Test AUC: 0.6714, Test AUPR: 0.6591\n",
      "Epoch: 78/100, Loss: 0.5999714, Train Acc: 0.6679, Test Acc: 0.6348, Train AUC: 0.7363, Train APUR: 0.7261, Test AUC: 0.6842, Test AUPR: 0.6734\n",
      "Epoch: 79/100, Loss: 0.5985790, Train Acc: 0.6699, Test Acc: 0.6196, Train AUC: 0.7404, Train APUR: 0.7297, Test AUC: 0.6819, Test AUPR: 0.6750\n",
      "Epoch: 80/100, Loss: 0.5991163, Train Acc: 0.6686, Test Acc: 0.6089, Train AUC: 0.7391, Train APUR: 0.7305, Test AUC: 0.6743, Test AUPR: 0.6677\n",
      "Epoch: 81/100, Loss: 0.5968730, Train Acc: 0.6675, Test Acc: 0.6156, Train AUC: 0.7398, Train APUR: 0.7317, Test AUC: 0.6696, Test AUPR: 0.6654\n",
      "Epoch: 82/100, Loss: 0.5983783, Train Acc: 0.6698, Test Acc: 0.6216, Train AUC: 0.7390, Train APUR: 0.7297, Test AUC: 0.6819, Test AUPR: 0.6782\n",
      "Epoch: 83/100, Loss: 0.5949515, Train Acc: 0.6730, Test Acc: 0.6152, Train AUC: 0.7439, Train APUR: 0.7386, Test AUC: 0.6773, Test AUPR: 0.6706\n",
      "Epoch: 84/100, Loss: 0.5939998, Train Acc: 0.6729, Test Acc: 0.6106, Train AUC: 0.7465, Train APUR: 0.7376, Test AUC: 0.6770, Test AUPR: 0.6683\n",
      "Epoch: 85/100, Loss: 0.5914236, Train Acc: 0.6724, Test Acc: 0.6212, Train AUC: 0.7465, Train APUR: 0.7378, Test AUC: 0.6894, Test AUPR: 0.6812\n",
      "Epoch: 86/100, Loss: 0.5936858, Train Acc: 0.6696, Test Acc: 0.6276, Train AUC: 0.7438, Train APUR: 0.7336, Test AUC: 0.6771, Test AUPR: 0.6692\n",
      "Epoch: 87/100, Loss: 0.5935369, Train Acc: 0.6763, Test Acc: 0.6238, Train AUC: 0.7474, Train APUR: 0.7394, Test AUC: 0.6909, Test AUPR: 0.6861\n",
      "Epoch: 88/100, Loss: 0.5877028, Train Acc: 0.6792, Test Acc: 0.6091, Train AUC: 0.7519, Train APUR: 0.7425, Test AUC: 0.6929, Test AUPR: 0.6868\n",
      "Epoch: 89/100, Loss: 0.5861448, Train Acc: 0.6781, Test Acc: 0.6074, Train AUC: 0.7534, Train APUR: 0.7439, Test AUC: 0.6829, Test AUPR: 0.6737\n",
      "Epoch: 90/100, Loss: 0.5862260, Train Acc: 0.6774, Test Acc: 0.6306, Train AUC: 0.7525, Train APUR: 0.7438, Test AUC: 0.6861, Test AUPR: 0.6766\n",
      "Epoch: 91/100, Loss: 0.5842778, Train Acc: 0.6806, Test Acc: 0.6328, Train AUC: 0.7542, Train APUR: 0.7470, Test AUC: 0.6879, Test AUPR: 0.6770\n",
      "Epoch: 92/100, Loss: 0.5841732, Train Acc: 0.6814, Test Acc: 0.6303, Train AUC: 0.7543, Train APUR: 0.7449, Test AUC: 0.6920, Test AUPR: 0.6856\n",
      "Epoch: 93/100, Loss: 0.5816194, Train Acc: 0.6850, Test Acc: 0.6247, Train AUC: 0.7578, Train APUR: 0.7481, Test AUC: 0.6893, Test AUPR: 0.6873\n",
      "Epoch: 94/100, Loss: 0.5867773, Train Acc: 0.6810, Test Acc: 0.6273, Train AUC: 0.7533, Train APUR: 0.7436, Test AUC: 0.6782, Test AUPR: 0.6722\n",
      "Epoch: 95/100, Loss: 0.5871803, Train Acc: 0.6806, Test Acc: 0.6352, Train AUC: 0.7519, Train APUR: 0.7434, Test AUC: 0.6897, Test AUPR: 0.6895\n",
      "Epoch: 96/100, Loss: 0.5804229, Train Acc: 0.6844, Test Acc: 0.6238, Train AUC: 0.7599, Train APUR: 0.7529, Test AUC: 0.6883, Test AUPR: 0.6853\n",
      "Epoch: 97/100, Loss: 0.5772929, Train Acc: 0.6848, Test Acc: 0.6135, Train AUC: 0.7620, Train APUR: 0.7568, Test AUC: 0.6745, Test AUPR: 0.6663\n",
      "Epoch: 98/100, Loss: 0.5816833, Train Acc: 0.6809, Test Acc: 0.6204, Train AUC: 0.7570, Train APUR: 0.7499, Test AUC: 0.6856, Test AUPR: 0.6820\n",
      "Epoch: 99/100, Loss: 0.5797138, Train Acc: 0.6837, Test Acc: 0.6282, Train AUC: 0.7604, Train APUR: 0.7573, Test AUC: 0.6903, Test AUPR: 0.6878\n",
      "Epoch: 100/100, Loss: 0.5730751, Train Acc: 0.6910, Test Acc: 0.6299, Train AUC: 0.7680, Train APUR: 0.7644, Test AUC: 0.6923, Test AUPR: 0.6891\n",
      "/home/ubuntu/PA-Cancer-Immunotherapy/GNN/train_pa.py:247: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(configs['save_model']))\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 53.522 MB of 53.522 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 53.522 MB of 53.522 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 53.528 MB of 53.528 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 53.528 MB of 53.528 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 53.528 MB of 53.528 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      test_aupr ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   test_roc_auc ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▁▃▃▄▄▄▄▅▅▅▅▅▅▅▅▅▅▆▅▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_aupr ▁▁▂▂▂▂▂▃▃▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▆▇▇▇▇▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss ███▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_roc_auc ▁▃▃▄▄▄▄▅▅▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇███████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: valid_accuracy ▁▁▂▂▃▃▃▄▄▅▅▄▅▅▅▅▃▃▅▅█▄▆▆▅▆▅▄▄▃█▆▆▆▆█▇█▆▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     valid_aupr ▁▁▁▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▆▆▆▆▆▇▇▇▇█▇█▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  valid_roc_auc ▁▂▂▂▃▄▄▄▄▄▄▄▄▅▅▅▅▅▅▅▅▅▆▆▅▇▇▇▇▆▆▇▇▇▇███▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy 0.60907\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      test_aupr 0.68679\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   test_roc_auc 0.69295\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.69101\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_aupr 0.76436\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.57308\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_roc_auc 0.768\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: valid_accuracy 0.62987\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     valid_aupr 0.68906\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  valid_roc_auc 0.69234\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mpeachy-yogurt-7\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN/runs/etp47d99\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 4 W&B file(s), 0 media file(s), 99 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241203_235623-etp47d99/logs\u001b[0m\n",
      "Test Acc: 0.6091, Test AUC: 0.6929, Test AUPR: 0.6868\n"
     ]
    }
   ],
   "source": [
    "# embeddings with the trained tcrpeg model separately for cdr3 and for epitope. \n",
    "# first time for allele in wandb\n",
    "! python train_pa.py --gpu 0 --configs_path configs/PA_all_allele.yml --droup_out 0.1 --split StrictTCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e404684f-a900-45e7-99b5-430bbcc6aa1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f17983c6-fce3-4353-b078-2b3caa479816",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(gpu=0, lr=0.001, epochs=100, w_celoss=1, w_aucloss=0, add_same_type_edges=False, dynamic_graph=False, dynamic_ratio=0.05, droup_out=0.1, positive_weights=1, dynamic_epochs=30, distance_threshold=10, configs_path='configs/PA_all_gene.yml', split='StrictTCR', dataset='pMTnet')\n",
      "PROJECT_NAME: dataset-gene_GNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfrohoari\u001b[0m (\u001b[33mpa_cancerimmunotherapy\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/ubuntu/PA-Cancer-Immunotherapy/GNN/wandb/run-20241205_095353-1xsrmsof\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mzany-donkey-9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-gene_GNN\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-gene_GNN/runs/1xsrmsof\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   10 of 10 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   10 of 10 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   10 of 10 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   10 of 10 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   10 of 10 files downloaded.  \n",
      "embeddings_path:   models/PA_all/gene_and_allele_embeddings.pkl\n",
      "train_file_list:   ['gene_fold_0.csv', 'gene_fold_1.csv', 'gene_fold_2.csv', 'gene_fold_3.csv']\n",
      "test_file_list:   ['gene_fold_4.csv']\n",
      "wandb logger initialisiert\n",
      "Epoch: 1/100, Loss: 0.6934743, Train Acc: 0.4947, Test Acc: 0.5056, Train AUC: 0.4920, Train APUR: 0.4947, Test AUC: 0.5806, Test AUPR: 0.5672\n",
      "Epoch: 2/100, Loss: 0.6910366, Train Acc: 0.5076, Test Acc: 0.5525, Train AUC: 0.5666, Train APUR: 0.5498, Test AUC: 0.5885, Test AUPR: 0.5857\n",
      "Epoch: 3/100, Loss: 0.6887306, Train Acc: 0.5465, Test Acc: 0.5687, Train AUC: 0.5776, Train APUR: 0.5649, Test AUC: 0.5921, Test AUPR: 0.5880\n",
      "Epoch: 4/100, Loss: 0.6840299, Train Acc: 0.5654, Test Acc: 0.5713, Train AUC: 0.5860, Train APUR: 0.5742, Test AUC: 0.5949, Test AUPR: 0.5893\n",
      "Epoch: 5/100, Loss: 0.6821817, Train Acc: 0.5674, Test Acc: 0.5741, Train AUC: 0.5876, Train APUR: 0.5767, Test AUC: 0.5983, Test AUPR: 0.5916\n",
      "Epoch: 6/100, Loss: 0.6804097, Train Acc: 0.5731, Test Acc: 0.5725, Train AUC: 0.5942, Train APUR: 0.5781, Test AUC: 0.6033, Test AUPR: 0.5948\n",
      "Epoch: 7/100, Loss: 0.6787059, Train Acc: 0.5746, Test Acc: 0.5826, Train AUC: 0.6018, Train APUR: 0.5887, Test AUC: 0.6088, Test AUPR: 0.5979\n",
      "Epoch: 8/100, Loss: 0.6760904, Train Acc: 0.5845, Test Acc: 0.5904, Train AUC: 0.6094, Train APUR: 0.5965, Test AUC: 0.6118, Test AUPR: 0.5996\n",
      "Epoch: 9/100, Loss: 0.6743938, Train Acc: 0.5879, Test Acc: 0.5833, Train AUC: 0.6136, Train APUR: 0.5992, Test AUC: 0.6138, Test AUPR: 0.6016\n",
      "Epoch: 10/100, Loss: 0.6737498, Train Acc: 0.5854, Test Acc: 0.5823, Train AUC: 0.6165, Train APUR: 0.6016, Test AUC: 0.6141, Test AUPR: 0.6023\n",
      "Epoch: 11/100, Loss: 0.6725912, Train Acc: 0.5901, Test Acc: 0.5929, Train AUC: 0.6194, Train APUR: 0.6042, Test AUC: 0.6157, Test AUPR: 0.6040\n",
      "Epoch: 12/100, Loss: 0.6713321, Train Acc: 0.5937, Test Acc: 0.5858, Train AUC: 0.6215, Train APUR: 0.6054, Test AUC: 0.6167, Test AUPR: 0.6059\n",
      "Epoch: 13/100, Loss: 0.6707268, Train Acc: 0.5922, Test Acc: 0.5864, Train AUC: 0.6218, Train APUR: 0.6067, Test AUC: 0.6185, Test AUPR: 0.6077\n",
      "Epoch: 14/100, Loss: 0.6701608, Train Acc: 0.5914, Test Acc: 0.5881, Train AUC: 0.6242, Train APUR: 0.6111, Test AUC: 0.6195, Test AUPR: 0.6091\n",
      "Epoch: 15/100, Loss: 0.6692224, Train Acc: 0.5935, Test Acc: 0.5896, Train AUC: 0.6264, Train APUR: 0.6133, Test AUC: 0.6204, Test AUPR: 0.6092\n",
      "Epoch: 16/100, Loss: 0.6676831, Train Acc: 0.5993, Test Acc: 0.5878, Train AUC: 0.6291, Train APUR: 0.6164, Test AUC: 0.6134, Test AUPR: 0.6058\n",
      "Epoch: 17/100, Loss: 0.6672701, Train Acc: 0.5975, Test Acc: 0.5883, Train AUC: 0.6304, Train APUR: 0.6170, Test AUC: 0.6106, Test AUPR: 0.6049\n",
      "Epoch: 18/100, Loss: 0.6682808, Train Acc: 0.5956, Test Acc: 0.5891, Train AUC: 0.6296, Train APUR: 0.6158, Test AUC: 0.6174, Test AUPR: 0.6093\n",
      "Epoch: 19/100, Loss: 0.6666229, Train Acc: 0.5998, Test Acc: 0.5936, Train AUC: 0.6333, Train APUR: 0.6190, Test AUC: 0.6249, Test AUPR: 0.6146\n",
      "Epoch: 20/100, Loss: 0.6656126, Train Acc: 0.6020, Test Acc: 0.5917, Train AUC: 0.6339, Train APUR: 0.6210, Test AUC: 0.6265, Test AUPR: 0.6165\n",
      "Epoch: 21/100, Loss: 0.6651662, Train Acc: 0.6001, Test Acc: 0.5912, Train AUC: 0.6350, Train APUR: 0.6227, Test AUC: 0.6282, Test AUPR: 0.6180\n",
      "Epoch: 22/100, Loss: 0.6656284, Train Acc: 0.5980, Test Acc: 0.5926, Train AUC: 0.6342, Train APUR: 0.6211, Test AUC: 0.6280, Test AUPR: 0.6179\n",
      "Epoch: 23/100, Loss: 0.6651269, Train Acc: 0.6000, Test Acc: 0.5934, Train AUC: 0.6372, Train APUR: 0.6240, Test AUC: 0.6292, Test AUPR: 0.6192\n",
      "Epoch: 24/100, Loss: 0.6632890, Train Acc: 0.6032, Test Acc: 0.6032, Train AUC: 0.6390, Train APUR: 0.6257, Test AUC: 0.6302, Test AUPR: 0.6207\n",
      "Epoch: 25/100, Loss: 0.6640995, Train Acc: 0.6050, Test Acc: 0.6056, Train AUC: 0.6383, Train APUR: 0.6243, Test AUC: 0.6310, Test AUPR: 0.6216\n",
      "Epoch: 26/100, Loss: 0.6630831, Train Acc: 0.6051, Test Acc: 0.5948, Train AUC: 0.6405, Train APUR: 0.6262, Test AUC: 0.6302, Test AUPR: 0.6210\n",
      "Epoch: 27/100, Loss: 0.6626669, Train Acc: 0.6035, Test Acc: 0.5973, Train AUC: 0.6426, Train APUR: 0.6280, Test AUC: 0.6312, Test AUPR: 0.6221\n",
      "Epoch: 28/100, Loss: 0.6618702, Train Acc: 0.6106, Test Acc: 0.5956, Train AUC: 0.6433, Train APUR: 0.6286, Test AUC: 0.6320, Test AUPR: 0.6237\n",
      "Epoch: 29/100, Loss: 0.6623258, Train Acc: 0.6034, Test Acc: 0.6018, Train AUC: 0.6428, Train APUR: 0.6288, Test AUC: 0.6327, Test AUPR: 0.6245\n",
      "Epoch: 30/100, Loss: 0.6609771, Train Acc: 0.6119, Test Acc: 0.6057, Train AUC: 0.6442, Train APUR: 0.6298, Test AUC: 0.6336, Test AUPR: 0.6250\n",
      "Epoch: 31/100, Loss: 0.6602697, Train Acc: 0.6119, Test Acc: 0.6007, Train AUC: 0.6458, Train APUR: 0.6311, Test AUC: 0.6345, Test AUPR: 0.6251\n",
      "Epoch: 32/100, Loss: 0.6597784, Train Acc: 0.6080, Test Acc: 0.6075, Train AUC: 0.6472, Train APUR: 0.6328, Test AUC: 0.6357, Test AUPR: 0.6274\n",
      "Epoch: 33/100, Loss: 0.6597103, Train Acc: 0.6121, Test Acc: 0.5967, Train AUC: 0.6456, Train APUR: 0.6322, Test AUC: 0.6366, Test AUPR: 0.6294\n",
      "Epoch: 34/100, Loss: 0.6593179, Train Acc: 0.6106, Test Acc: 0.5977, Train AUC: 0.6477, Train APUR: 0.6329, Test AUC: 0.6370, Test AUPR: 0.6301\n",
      "Epoch: 35/100, Loss: 0.6586978, Train Acc: 0.6069, Test Acc: 0.6075, Train AUC: 0.6485, Train APUR: 0.6347, Test AUC: 0.6375, Test AUPR: 0.6298\n",
      "Epoch: 36/100, Loss: 0.6577906, Train Acc: 0.6148, Test Acc: 0.6070, Train AUC: 0.6502, Train APUR: 0.6362, Test AUC: 0.6388, Test AUPR: 0.6304\n",
      "Epoch: 37/100, Loss: 0.6570019, Train Acc: 0.6117, Test Acc: 0.6120, Train AUC: 0.6524, Train APUR: 0.6377, Test AUC: 0.6412, Test AUPR: 0.6329\n",
      "Epoch: 38/100, Loss: 0.6564654, Train Acc: 0.6165, Test Acc: 0.6113, Train AUC: 0.6544, Train APUR: 0.6397, Test AUC: 0.6425, Test AUPR: 0.6339\n",
      "Epoch: 39/100, Loss: 0.6561438, Train Acc: 0.6152, Test Acc: 0.6120, Train AUC: 0.6542, Train APUR: 0.6404, Test AUC: 0.6429, Test AUPR: 0.6349\n",
      "Epoch: 40/100, Loss: 0.6548595, Train Acc: 0.6155, Test Acc: 0.6060, Train AUC: 0.6573, Train APUR: 0.6432, Test AUC: 0.6446, Test AUPR: 0.6382\n",
      "Epoch: 41/100, Loss: 0.6536291, Train Acc: 0.6189, Test Acc: 0.6057, Train AUC: 0.6599, Train APUR: 0.6453, Test AUC: 0.6468, Test AUPR: 0.6406\n",
      "Epoch: 42/100, Loss: 0.6530638, Train Acc: 0.6172, Test Acc: 0.6082, Train AUC: 0.6595, Train APUR: 0.6462, Test AUC: 0.6477, Test AUPR: 0.6415\n",
      "Epoch: 43/100, Loss: 0.6519675, Train Acc: 0.6180, Test Acc: 0.6179, Train AUC: 0.6610, Train APUR: 0.6478, Test AUC: 0.6486, Test AUPR: 0.6413\n",
      "Epoch: 44/100, Loss: 0.6505798, Train Acc: 0.6226, Test Acc: 0.6166, Train AUC: 0.6647, Train APUR: 0.6509, Test AUC: 0.6497, Test AUPR: 0.6427\n",
      "Epoch: 45/100, Loss: 0.6498328, Train Acc: 0.6242, Test Acc: 0.6218, Train AUC: 0.6674, Train APUR: 0.6530, Test AUC: 0.6533, Test AUPR: 0.6442\n",
      "Epoch: 46/100, Loss: 0.6483550, Train Acc: 0.6252, Test Acc: 0.6235, Train AUC: 0.6698, Train APUR: 0.6543, Test AUC: 0.6566, Test AUPR: 0.6465\n",
      "Epoch: 47/100, Loss: 0.6467853, Train Acc: 0.6229, Test Acc: 0.6170, Train AUC: 0.6706, Train APUR: 0.6571, Test AUC: 0.6602, Test AUPR: 0.6519\n",
      "Epoch: 48/100, Loss: 0.6456526, Train Acc: 0.6302, Test Acc: 0.6227, Train AUC: 0.6762, Train APUR: 0.6627, Test AUC: 0.6631, Test AUPR: 0.6540\n",
      "Epoch: 49/100, Loss: 0.6435327, Train Acc: 0.6388, Test Acc: 0.6273, Train AUC: 0.6792, Train APUR: 0.6649, Test AUC: 0.6688, Test AUPR: 0.6573\n",
      "Epoch: 50/100, Loss: 0.6418380, Train Acc: 0.6409, Test Acc: 0.6256, Train AUC: 0.6832, Train APUR: 0.6674, Test AUC: 0.6714, Test AUPR: 0.6591\n",
      "Epoch: 51/100, Loss: 0.6394350, Train Acc: 0.6409, Test Acc: 0.6268, Train AUC: 0.6869, Train APUR: 0.6697, Test AUC: 0.6726, Test AUPR: 0.6587\n",
      "Epoch: 52/100, Loss: 0.6376011, Train Acc: 0.6429, Test Acc: 0.6299, Train AUC: 0.6900, Train APUR: 0.6734, Test AUC: 0.6744, Test AUPR: 0.6638\n",
      "Epoch: 53/100, Loss: 0.6371481, Train Acc: 0.6421, Test Acc: 0.6244, Train AUC: 0.6915, Train APUR: 0.6775, Test AUC: 0.6777, Test AUPR: 0.6650\n",
      "Epoch: 54/100, Loss: 0.6349053, Train Acc: 0.6432, Test Acc: 0.6284, Train AUC: 0.6947, Train APUR: 0.6792, Test AUC: 0.6786, Test AUPR: 0.6634\n",
      "Epoch: 55/100, Loss: 0.6351950, Train Acc: 0.6444, Test Acc: 0.6174, Train AUC: 0.6932, Train APUR: 0.6770, Test AUC: 0.6652, Test AUPR: 0.6579\n",
      "Epoch: 56/100, Loss: 0.6453582, Train Acc: 0.6236, Test Acc: 0.6255, Train AUC: 0.6815, Train APUR: 0.6644, Test AUC: 0.6690, Test AUPR: 0.6555\n",
      "Epoch: 57/100, Loss: 0.6383255, Train Acc: 0.6430, Test Acc: 0.6179, Train AUC: 0.6917, Train APUR: 0.6781, Test AUC: 0.6762, Test AUPR: 0.6619\n",
      "Epoch: 58/100, Loss: 0.6335913, Train Acc: 0.6441, Test Acc: 0.6140, Train AUC: 0.6980, Train APUR: 0.6814, Test AUC: 0.6765, Test AUPR: 0.6686\n",
      "Epoch: 59/100, Loss: 0.6342227, Train Acc: 0.6454, Test Acc: 0.6186, Train AUC: 0.7043, Train APUR: 0.6875, Test AUC: 0.6633, Test AUPR: 0.6521\n",
      "Epoch: 60/100, Loss: 0.6382889, Train Acc: 0.6388, Test Acc: 0.6284, Train AUC: 0.6913, Train APUR: 0.6761, Test AUC: 0.6739, Test AUPR: 0.6641\n",
      "Epoch: 61/100, Loss: 0.6271555, Train Acc: 0.6505, Test Acc: 0.6210, Train AUC: 0.7063, Train APUR: 0.6930, Test AUC: 0.6657, Test AUPR: 0.6531\n",
      "Epoch: 62/100, Loss: 0.6358114, Train Acc: 0.6420, Test Acc: 0.6323, Train AUC: 0.6951, Train APUR: 0.6807, Test AUC: 0.6765, Test AUPR: 0.6619\n",
      "Epoch: 63/100, Loss: 0.6278309, Train Acc: 0.6503, Test Acc: 0.6306, Train AUC: 0.7030, Train APUR: 0.6867, Test AUC: 0.6812, Test AUPR: 0.6689\n",
      "Epoch: 64/100, Loss: 0.6267424, Train Acc: 0.6512, Test Acc: 0.6252, Train AUC: 0.7064, Train APUR: 0.6922, Test AUC: 0.6780, Test AUPR: 0.6671\n",
      "Epoch: 65/100, Loss: 0.6300198, Train Acc: 0.6463, Test Acc: 0.6306, Train AUC: 0.7012, Train APUR: 0.6871, Test AUC: 0.6858, Test AUPR: 0.6705\n",
      "Epoch: 66/100, Loss: 0.6232141, Train Acc: 0.6526, Test Acc: 0.6372, Train AUC: 0.7119, Train APUR: 0.6972, Test AUC: 0.6798, Test AUPR: 0.6646\n",
      "Epoch: 67/100, Loss: 0.6209966, Train Acc: 0.6553, Test Acc: 0.6346, Train AUC: 0.7117, Train APUR: 0.6974, Test AUC: 0.6793, Test AUPR: 0.6645\n",
      "Epoch: 68/100, Loss: 0.6220813, Train Acc: 0.6523, Test Acc: 0.6370, Train AUC: 0.7122, Train APUR: 0.6993, Test AUC: 0.6873, Test AUPR: 0.6756\n",
      "Epoch: 69/100, Loss: 0.6194068, Train Acc: 0.6563, Test Acc: 0.6372, Train AUC: 0.7177, Train APUR: 0.7034, Test AUC: 0.6861, Test AUPR: 0.6764\n",
      "Epoch: 70/100, Loss: 0.6185340, Train Acc: 0.6562, Test Acc: 0.6323, Train AUC: 0.7160, Train APUR: 0.7045, Test AUC: 0.6865, Test AUPR: 0.6767\n",
      "Epoch: 71/100, Loss: 0.6194869, Train Acc: 0.6562, Test Acc: 0.6338, Train AUC: 0.7152, Train APUR: 0.7041, Test AUC: 0.6906, Test AUPR: 0.6775\n",
      "Epoch: 72/100, Loss: 0.6174054, Train Acc: 0.6575, Test Acc: 0.6420, Train AUC: 0.7193, Train APUR: 0.7069, Test AUC: 0.6914, Test AUPR: 0.6786\n",
      "Epoch: 73/100, Loss: 0.6137459, Train Acc: 0.6613, Test Acc: 0.6412, Train AUC: 0.7203, Train APUR: 0.7097, Test AUC: 0.6921, Test AUPR: 0.6803\n",
      "Epoch: 74/100, Loss: 0.6155283, Train Acc: 0.6581, Test Acc: 0.6407, Train AUC: 0.7219, Train APUR: 0.7094, Test AUC: 0.6901, Test AUPR: 0.6781\n",
      "Epoch: 75/100, Loss: 0.6128296, Train Acc: 0.6611, Test Acc: 0.6378, Train AUC: 0.7240, Train APUR: 0.7138, Test AUC: 0.6879, Test AUPR: 0.6758\n",
      "Epoch: 76/100, Loss: 0.6127854, Train Acc: 0.6613, Test Acc: 0.6290, Train AUC: 0.7217, Train APUR: 0.7121, Test AUC: 0.6912, Test AUPR: 0.6800\n",
      "Epoch: 77/100, Loss: 0.6127079, Train Acc: 0.6596, Test Acc: 0.6342, Train AUC: 0.7239, Train APUR: 0.7136, Test AUC: 0.6938, Test AUPR: 0.6833\n",
      "Epoch: 78/100, Loss: 0.6093122, Train Acc: 0.6632, Test Acc: 0.6429, Train AUC: 0.7278, Train APUR: 0.7180, Test AUC: 0.6929, Test AUPR: 0.6824\n",
      "Epoch: 79/100, Loss: 0.6074803, Train Acc: 0.6669, Test Acc: 0.6420, Train AUC: 0.7281, Train APUR: 0.7184, Test AUC: 0.6934, Test AUPR: 0.6819\n",
      "Epoch: 80/100, Loss: 0.6079338, Train Acc: 0.6651, Test Acc: 0.6430, Train AUC: 0.7293, Train APUR: 0.7196, Test AUC: 0.6958, Test AUPR: 0.6827\n",
      "Epoch: 81/100, Loss: 0.6056473, Train Acc: 0.6673, Test Acc: 0.6449, Train AUC: 0.7319, Train APUR: 0.7219, Test AUC: 0.6956, Test AUPR: 0.6813\n",
      "Epoch: 82/100, Loss: 0.6051364, Train Acc: 0.6678, Test Acc: 0.6374, Train AUC: 0.7301, Train APUR: 0.7194, Test AUC: 0.6882, Test AUPR: 0.6730\n",
      "Epoch: 83/100, Loss: 0.6057027, Train Acc: 0.6659, Test Acc: 0.6428, Train AUC: 0.7307, Train APUR: 0.7200, Test AUC: 0.6923, Test AUPR: 0.6791\n",
      "Epoch: 84/100, Loss: 0.6042344, Train Acc: 0.6683, Test Acc: 0.6429, Train AUC: 0.7311, Train APUR: 0.7213, Test AUC: 0.6937, Test AUPR: 0.6821\n",
      "Epoch: 85/100, Loss: 0.6056818, Train Acc: 0.6659, Test Acc: 0.6430, Train AUC: 0.7292, Train APUR: 0.7199, Test AUC: 0.6932, Test AUPR: 0.6798\n",
      "Epoch: 86/100, Loss: 0.6011066, Train Acc: 0.6703, Test Acc: 0.6387, Train AUC: 0.7349, Train APUR: 0.7280, Test AUC: 0.6861, Test AUPR: 0.6696\n",
      "Epoch: 87/100, Loss: 0.6056350, Train Acc: 0.6677, Test Acc: 0.6452, Train AUC: 0.7302, Train APUR: 0.7216, Test AUC: 0.6960, Test AUPR: 0.6804\n",
      "Epoch: 88/100, Loss: 0.6006501, Train Acc: 0.6709, Test Acc: 0.6409, Train AUC: 0.7353, Train APUR: 0.7278, Test AUC: 0.6965, Test AUPR: 0.6802\n",
      "Epoch: 89/100, Loss: 0.6016465, Train Acc: 0.6704, Test Acc: 0.6383, Train AUC: 0.7357, Train APUR: 0.7270, Test AUC: 0.6935, Test AUPR: 0.6783\n",
      "Epoch: 90/100, Loss: 0.5986531, Train Acc: 0.6716, Test Acc: 0.6446, Train AUC: 0.7384, Train APUR: 0.7313, Test AUC: 0.6951, Test AUPR: 0.6819\n",
      "Epoch: 91/100, Loss: 0.5970249, Train Acc: 0.6750, Test Acc: 0.6452, Train AUC: 0.7391, Train APUR: 0.7322, Test AUC: 0.6989, Test AUPR: 0.6880\n",
      "Epoch: 92/100, Loss: 0.5998311, Train Acc: 0.6721, Test Acc: 0.6432, Train AUC: 0.7364, Train APUR: 0.7297, Test AUC: 0.6953, Test AUPR: 0.6831\n",
      "Epoch: 93/100, Loss: 0.6014517, Train Acc: 0.6696, Test Acc: 0.6475, Train AUC: 0.7366, Train APUR: 0.7280, Test AUC: 0.7001, Test AUPR: 0.6894\n",
      "Epoch: 94/100, Loss: 0.5956601, Train Acc: 0.6735, Test Acc: 0.6441, Train AUC: 0.7404, Train APUR: 0.7330, Test AUC: 0.7001, Test AUPR: 0.6888\n",
      "Epoch: 95/100, Loss: 0.5959885, Train Acc: 0.6748, Test Acc: 0.6433, Train AUC: 0.7413, Train APUR: 0.7349, Test AUC: 0.7003, Test AUPR: 0.6888\n",
      "Epoch: 96/100, Loss: 0.5939249, Train Acc: 0.6766, Test Acc: 0.6455, Train AUC: 0.7437, Train APUR: 0.7364, Test AUC: 0.6968, Test AUPR: 0.6837\n",
      "Epoch: 97/100, Loss: 0.5941889, Train Acc: 0.6766, Test Acc: 0.6474, Train AUC: 0.7427, Train APUR: 0.7347, Test AUC: 0.7020, Test AUPR: 0.6901\n",
      "Epoch: 98/100, Loss: 0.5935753, Train Acc: 0.6769, Test Acc: 0.6464, Train AUC: 0.7441, Train APUR: 0.7382, Test AUC: 0.7008, Test AUPR: 0.6894\n",
      "Epoch: 99/100, Loss: 0.5923323, Train Acc: 0.6764, Test Acc: 0.6436, Train AUC: 0.7456, Train APUR: 0.7395, Test AUC: 0.6935, Test AUPR: 0.6800\n",
      "Epoch: 100/100, Loss: 0.5932682, Train Acc: 0.6768, Test Acc: 0.6451, Train AUC: 0.7432, Train APUR: 0.7364, Test AUC: 0.7000, Test AUPR: 0.6891\n",
      "/home/ubuntu/PA-Cancer-Immunotherapy/GNN/train_pa.py:247: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(configs['save_model']))\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 71.610 MB of 71.610 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 71.611 MB of 71.611 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 71.611 MB of 71.611 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 71.611 MB of 71.611 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      test_aupr ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   test_roc_auc ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▁▃▄▄▄▅▅▅▅▅▅▅▅▅▅▅▅▆▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇███████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_aupr ▁▂▂▃▃▄▃▄▄▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇█▇█████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss ███▇▇▇▇▆▆▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▄▃▃▂▂▂▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_roc_auc ▁▃▄▄▅▅▅▅▅▅▅▅▅▅▅▆▆▆▆▇▆▇▇▇▇▇▇█████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: valid_accuracy ▁▃▃▄▄▄▄▄▄▄▄▄▅▅▄▄▅▅▅▆▇▇▆▆▆▇▆▇▇█▇█▇███▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     valid_aupr ▁▂▃▃▃▃▃▃▃▄▄▄▅▅▅▆▆▆▇▇▆▇▆▇▇▇▇▇▇██▇█▇▇█████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  valid_roc_auc ▁▁▂▂▃▃▃▂▃▃▄▄▄▄▅▅▅▅▆▆▆▇▆▆▆▆▇▇▇▇████▇█████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy 0.64739\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      test_aupr 0.69006\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   test_roc_auc 0.70199\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.67677\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_aupr 0.73638\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.59327\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_roc_auc 0.74315\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: valid_accuracy 0.64512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     valid_aupr 0.68905\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  valid_roc_auc 0.70004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mzany-donkey-9\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-gene_GNN/runs/1xsrmsof\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-gene_GNN\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 128 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241205_095353-1xsrmsof/logs\u001b[0m\n",
      "Test Acc: 0.6474, Test AUC: 0.7020, Test AUPR: 0.6901\n"
     ]
    }
   ],
   "source": [
    "# embeddings with the trained tcrpeg model separately for cdr3 and for epitope. \n",
    "\n",
    "# The embeddings were just generated again, since it was not sure if the tes.tsv file was used for the first embeddings file. \n",
    "# This is the second try with wandb for gene\n",
    "\n",
    "! python train_pa.py --gpu 0 --configs_path configs/PA_all_gene.yml --droup_out 0.1 --split StrictTCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95935bf-23e3-4dc5-9e83-d132d7c2eca0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e792381a-383e-479d-8efb-3b2aed54b949",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(gpu=0, lr=0.001, epochs=100, w_celoss=1, w_aucloss=0, add_same_type_edges=False, dynamic_graph=False, dynamic_ratio=0.05, droup_out=0.1, positive_weights=1, dynamic_epochs=30, distance_threshold=10, configs_path='configs/PA_all_allele.yml', split='StrictTCR', dataset='pMTnet')\n",
      "PROJECT_NAME: dataset-allele_GNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfrohoari\u001b[0m (\u001b[33mpa_cancerimmunotherapy\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/ubuntu/PA-Cancer-Immunotherapy/GNN/wandb/run-20241205_100337-2od3vm7l\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mgiddy-leaf-10\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN/runs/2od3vm7l\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   10 of 10 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   10 of 10 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   10 of 10 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   10 of 10 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   10 of 10 files downloaded.  \n",
      "embeddings_path:   models/PA_all/gene_and_allele_embeddings.pkl\n",
      "train_file_list:   ['allele_fold_0.csv', 'allele_fold_1.csv', 'allele_fold_2.csv', 'allele_fold_3.csv']\n",
      "test_file_list:   ['allele_fold_4.csv']\n",
      "wandb logger initialisiert\n",
      "Epoch: 1/100, Loss: 0.6932068, Train Acc: 0.5027, Test Acc: 0.5030, Train AUC: 0.5033, Train APUR: 0.5040, Test AUC: 0.5797, Test AUPR: 0.5654\n",
      "Epoch: 2/100, Loss: 0.6902107, Train Acc: 0.5106, Test Acc: 0.5491, Train AUC: 0.5778, Train APUR: 0.5629, Test AUC: 0.5913, Test AUPR: 0.5814\n",
      "Epoch: 3/100, Loss: 0.6868201, Train Acc: 0.5481, Test Acc: 0.5659, Train AUC: 0.5825, Train APUR: 0.5690, Test AUC: 0.5957, Test AUPR: 0.5850\n",
      "Epoch: 4/100, Loss: 0.6835045, Train Acc: 0.5602, Test Acc: 0.5677, Train AUC: 0.5897, Train APUR: 0.5738, Test AUC: 0.5986, Test AUPR: 0.5871\n",
      "Epoch: 5/100, Loss: 0.6807579, Train Acc: 0.5729, Test Acc: 0.5735, Train AUC: 0.5985, Train APUR: 0.5817, Test AUC: 0.6018, Test AUPR: 0.5897\n",
      "Epoch: 6/100, Loss: 0.6784322, Train Acc: 0.5773, Test Acc: 0.5796, Train AUC: 0.6031, Train APUR: 0.5855, Test AUC: 0.6049, Test AUPR: 0.5910\n",
      "Epoch: 7/100, Loss: 0.6769173, Train Acc: 0.5807, Test Acc: 0.5846, Train AUC: 0.6057, Train APUR: 0.5846, Test AUC: 0.6103, Test AUPR: 0.5948\n",
      "Epoch: 8/100, Loss: 0.6750937, Train Acc: 0.5858, Test Acc: 0.5852, Train AUC: 0.6129, Train APUR: 0.5916, Test AUC: 0.6143, Test AUPR: 0.5979\n",
      "Epoch: 9/100, Loss: 0.6725479, Train Acc: 0.5896, Test Acc: 0.5934, Train AUC: 0.6182, Train APUR: 0.5952, Test AUC: 0.6148, Test AUPR: 0.5990\n",
      "Epoch: 10/100, Loss: 0.6725231, Train Acc: 0.5892, Test Acc: 0.5807, Train AUC: 0.6209, Train APUR: 0.5978, Test AUC: 0.6100, Test AUPR: 0.5957\n",
      "Epoch: 11/100, Loss: 0.6721795, Train Acc: 0.5903, Test Acc: 0.5610, Train AUC: 0.6217, Train APUR: 0.6014, Test AUC: 0.6108, Test AUPR: 0.5964\n",
      "Epoch: 12/100, Loss: 0.6717090, Train Acc: 0.5860, Test Acc: 0.5941, Train AUC: 0.6232, Train APUR: 0.6018, Test AUC: 0.6193, Test AUPR: 0.6031\n",
      "Epoch: 13/100, Loss: 0.6688238, Train Acc: 0.5932, Test Acc: 0.5890, Train AUC: 0.6263, Train APUR: 0.6086, Test AUC: 0.6218, Test AUPR: 0.6067\n",
      "Epoch: 14/100, Loss: 0.6694049, Train Acc: 0.5982, Test Acc: 0.5921, Train AUC: 0.6283, Train APUR: 0.6091, Test AUC: 0.6223, Test AUPR: 0.6092\n",
      "Epoch: 15/100, Loss: 0.6697936, Train Acc: 0.5968, Test Acc: 0.5891, Train AUC: 0.6281, Train APUR: 0.6050, Test AUC: 0.6242, Test AUPR: 0.6119\n",
      "Epoch: 16/100, Loss: 0.6691867, Train Acc: 0.5944, Test Acc: 0.5939, Train AUC: 0.6304, Train APUR: 0.6119, Test AUC: 0.6266, Test AUPR: 0.6142\n",
      "Epoch: 17/100, Loss: 0.6661912, Train Acc: 0.5969, Test Acc: 0.5988, Train AUC: 0.6336, Train APUR: 0.6149, Test AUC: 0.6273, Test AUPR: 0.6143\n",
      "Epoch: 18/100, Loss: 0.6663543, Train Acc: 0.6046, Test Acc: 0.5938, Train AUC: 0.6350, Train APUR: 0.6161, Test AUC: 0.6274, Test AUPR: 0.6144\n",
      "Epoch: 19/100, Loss: 0.6679757, Train Acc: 0.5968, Test Acc: 0.6034, Train AUC: 0.6345, Train APUR: 0.6147, Test AUC: 0.6277, Test AUPR: 0.6153\n",
      "Epoch: 20/100, Loss: 0.6659764, Train Acc: 0.6058, Test Acc: 0.5962, Train AUC: 0.6375, Train APUR: 0.6168, Test AUC: 0.6292, Test AUPR: 0.6173\n",
      "Epoch: 21/100, Loss: 0.6655547, Train Acc: 0.6018, Test Acc: 0.5962, Train AUC: 0.6390, Train APUR: 0.6190, Test AUC: 0.6316, Test AUPR: 0.6196\n",
      "Epoch: 22/100, Loss: 0.6639396, Train Acc: 0.6039, Test Acc: 0.5975, Train AUC: 0.6389, Train APUR: 0.6195, Test AUC: 0.6326, Test AUPR: 0.6208\n",
      "Epoch: 23/100, Loss: 0.6633918, Train Acc: 0.6031, Test Acc: 0.5972, Train AUC: 0.6389, Train APUR: 0.6199, Test AUC: 0.6322, Test AUPR: 0.6210\n",
      "Epoch: 24/100, Loss: 0.6636038, Train Acc: 0.6074, Test Acc: 0.5975, Train AUC: 0.6387, Train APUR: 0.6218, Test AUC: 0.6329, Test AUPR: 0.6217\n",
      "Epoch: 25/100, Loss: 0.6636488, Train Acc: 0.6037, Test Acc: 0.6028, Train AUC: 0.6383, Train APUR: 0.6206, Test AUC: 0.6339, Test AUPR: 0.6219\n",
      "Epoch: 26/100, Loss: 0.6621316, Train Acc: 0.6103, Test Acc: 0.6038, Train AUC: 0.6412, Train APUR: 0.6225, Test AUC: 0.6345, Test AUPR: 0.6225\n",
      "Epoch: 27/100, Loss: 0.6611382, Train Acc: 0.6043, Test Acc: 0.6007, Train AUC: 0.6422, Train APUR: 0.6246, Test AUC: 0.6330, Test AUPR: 0.6215\n",
      "Epoch: 28/100, Loss: 0.6606393, Train Acc: 0.6117, Test Acc: 0.5893, Train AUC: 0.6440, Train APUR: 0.6248, Test AUC: 0.6295, Test AUPR: 0.6193\n",
      "Epoch: 29/100, Loss: 0.6605915, Train Acc: 0.6113, Test Acc: 0.5917, Train AUC: 0.6451, Train APUR: 0.6258, Test AUC: 0.6274, Test AUPR: 0.6180\n",
      "Epoch: 30/100, Loss: 0.6599361, Train Acc: 0.6112, Test Acc: 0.6000, Train AUC: 0.6462, Train APUR: 0.6262, Test AUC: 0.6316, Test AUPR: 0.6212\n",
      "Epoch: 31/100, Loss: 0.6594681, Train Acc: 0.6083, Test Acc: 0.6085, Train AUC: 0.6476, Train APUR: 0.6283, Test AUC: 0.6365, Test AUPR: 0.6258\n",
      "Epoch: 32/100, Loss: 0.6584557, Train Acc: 0.6113, Test Acc: 0.5993, Train AUC: 0.6478, Train APUR: 0.6294, Test AUC: 0.6386, Test AUPR: 0.6289\n",
      "Epoch: 33/100, Loss: 0.6586315, Train Acc: 0.6093, Test Acc: 0.5987, Train AUC: 0.6488, Train APUR: 0.6300, Test AUC: 0.6386, Test AUPR: 0.6292\n",
      "Epoch: 34/100, Loss: 0.6578864, Train Acc: 0.6083, Test Acc: 0.6050, Train AUC: 0.6505, Train APUR: 0.6321, Test AUC: 0.6380, Test AUPR: 0.6279\n",
      "Epoch: 35/100, Loss: 0.6574471, Train Acc: 0.6121, Test Acc: 0.6072, Train AUC: 0.6500, Train APUR: 0.6320, Test AUC: 0.6370, Test AUPR: 0.6274\n",
      "Epoch: 36/100, Loss: 0.6567225, Train Acc: 0.6122, Test Acc: 0.6025, Train AUC: 0.6516, Train APUR: 0.6328, Test AUC: 0.6348, Test AUPR: 0.6274\n",
      "Epoch: 37/100, Loss: 0.6556544, Train Acc: 0.6146, Test Acc: 0.5805, Train AUC: 0.6536, Train APUR: 0.6345, Test AUC: 0.6333, Test AUPR: 0.6272\n",
      "Epoch: 38/100, Loss: 0.6555712, Train Acc: 0.6082, Test Acc: 0.5904, Train AUC: 0.6557, Train APUR: 0.6368, Test AUC: 0.6276, Test AUPR: 0.6227\n",
      "Epoch: 39/100, Loss: 0.6544268, Train Acc: 0.6126, Test Acc: 0.5883, Train AUC: 0.6561, Train APUR: 0.6369, Test AUC: 0.6264, Test AUPR: 0.6211\n",
      "Epoch: 40/100, Loss: 0.6539388, Train Acc: 0.6119, Test Acc: 0.6022, Train AUC: 0.6559, Train APUR: 0.6370, Test AUC: 0.6366, Test AUPR: 0.6291\n",
      "Epoch: 41/100, Loss: 0.6526794, Train Acc: 0.6170, Test Acc: 0.5992, Train AUC: 0.6590, Train APUR: 0.6408, Test AUC: 0.6450, Test AUPR: 0.6364\n",
      "Epoch: 42/100, Loss: 0.6527225, Train Acc: 0.6060, Test Acc: 0.6083, Train AUC: 0.6599, Train APUR: 0.6432, Test AUC: 0.6460, Test AUPR: 0.6377\n",
      "Epoch: 43/100, Loss: 0.6510975, Train Acc: 0.6167, Test Acc: 0.6096, Train AUC: 0.6635, Train APUR: 0.6456, Test AUC: 0.6443, Test AUPR: 0.6358\n",
      "Epoch: 44/100, Loss: 0.6498497, Train Acc: 0.6189, Test Acc: 0.6104, Train AUC: 0.6647, Train APUR: 0.6470, Test AUC: 0.6450, Test AUPR: 0.6368\n",
      "Epoch: 45/100, Loss: 0.6488572, Train Acc: 0.6198, Test Acc: 0.6056, Train AUC: 0.6666, Train APUR: 0.6483, Test AUC: 0.6481, Test AUPR: 0.6399\n",
      "Epoch: 46/100, Loss: 0.6479008, Train Acc: 0.6178, Test Acc: 0.6099, Train AUC: 0.6693, Train APUR: 0.6519, Test AUC: 0.6502, Test AUPR: 0.6412\n",
      "Epoch: 47/100, Loss: 0.6459057, Train Acc: 0.6231, Test Acc: 0.6142, Train AUC: 0.6732, Train APUR: 0.6544, Test AUC: 0.6482, Test AUPR: 0.6390\n",
      "Epoch: 48/100, Loss: 0.6455358, Train Acc: 0.6229, Test Acc: 0.6236, Train AUC: 0.6722, Train APUR: 0.6540, Test AUC: 0.6563, Test AUPR: 0.6467\n",
      "Epoch: 49/100, Loss: 0.6435158, Train Acc: 0.6306, Test Acc: 0.6152, Train AUC: 0.6786, Train APUR: 0.6582, Test AUC: 0.6596, Test AUPR: 0.6492\n",
      "Epoch: 50/100, Loss: 0.6424866, Train Acc: 0.6330, Test Acc: 0.6153, Train AUC: 0.6830, Train APUR: 0.6618, Test AUC: 0.6530, Test AUPR: 0.6419\n",
      "Epoch: 51/100, Loss: 0.6442647, Train Acc: 0.6249, Test Acc: 0.6234, Train AUC: 0.6738, Train APUR: 0.6569, Test AUC: 0.6636, Test AUPR: 0.6512\n",
      "Epoch: 52/100, Loss: 0.6400650, Train Acc: 0.6396, Test Acc: 0.6259, Train AUC: 0.6867, Train APUR: 0.6654, Test AUC: 0.6648, Test AUPR: 0.6537\n",
      "Epoch: 53/100, Loss: 0.6387703, Train Acc: 0.6425, Test Acc: 0.6198, Train AUC: 0.6904, Train APUR: 0.6684, Test AUC: 0.6596, Test AUPR: 0.6467\n",
      "Epoch: 54/100, Loss: 0.6376272, Train Acc: 0.6364, Test Acc: 0.6092, Train AUC: 0.6861, Train APUR: 0.6670, Test AUC: 0.6618, Test AUPR: 0.6489\n",
      "Epoch: 55/100, Loss: 0.6351364, Train Acc: 0.6395, Test Acc: 0.6189, Train AUC: 0.6918, Train APUR: 0.6715, Test AUC: 0.6630, Test AUPR: 0.6527\n",
      "Epoch: 56/100, Loss: 0.6352599, Train Acc: 0.6440, Test Acc: 0.6204, Train AUC: 0.6950, Train APUR: 0.6722, Test AUC: 0.6640, Test AUPR: 0.6488\n",
      "Epoch: 57/100, Loss: 0.6346195, Train Acc: 0.6430, Test Acc: 0.6240, Train AUC: 0.6954, Train APUR: 0.6742, Test AUC: 0.6682, Test AUPR: 0.6536\n",
      "Epoch: 58/100, Loss: 0.6301826, Train Acc: 0.6461, Test Acc: 0.6209, Train AUC: 0.7001, Train APUR: 0.6777, Test AUC: 0.6683, Test AUPR: 0.6536\n",
      "Epoch: 59/100, Loss: 0.6297146, Train Acc: 0.6473, Test Acc: 0.6121, Train AUC: 0.7013, Train APUR: 0.6766, Test AUC: 0.6673, Test AUPR: 0.6535\n",
      "Epoch: 60/100, Loss: 0.6279219, Train Acc: 0.6490, Test Acc: 0.6122, Train AUC: 0.7039, Train APUR: 0.6805, Test AUC: 0.6642, Test AUPR: 0.6531\n",
      "Epoch: 61/100, Loss: 0.6268020, Train Acc: 0.6475, Test Acc: 0.6091, Train AUC: 0.7054, Train APUR: 0.6831, Test AUC: 0.6675, Test AUPR: 0.6539\n",
      "Epoch: 62/100, Loss: 0.6252015, Train Acc: 0.6499, Test Acc: 0.6129, Train AUC: 0.7071, Train APUR: 0.6845, Test AUC: 0.6739, Test AUPR: 0.6576\n",
      "Epoch: 63/100, Loss: 0.6251988, Train Acc: 0.6508, Test Acc: 0.6261, Train AUC: 0.7093, Train APUR: 0.6881, Test AUC: 0.6713, Test AUPR: 0.6541\n",
      "Epoch: 64/100, Loss: 0.6254447, Train Acc: 0.6506, Test Acc: 0.6201, Train AUC: 0.7083, Train APUR: 0.6876, Test AUC: 0.6689, Test AUPR: 0.6562\n",
      "Epoch: 65/100, Loss: 0.6305550, Train Acc: 0.6414, Test Acc: 0.6213, Train AUC: 0.6981, Train APUR: 0.6767, Test AUC: 0.6684, Test AUPR: 0.6505\n",
      "Epoch: 66/100, Loss: 0.6233521, Train Acc: 0.6527, Test Acc: 0.6213, Train AUC: 0.7081, Train APUR: 0.6854, Test AUC: 0.6678, Test AUPR: 0.6510\n",
      "Epoch: 67/100, Loss: 0.6191830, Train Acc: 0.6547, Test Acc: 0.6284, Train AUC: 0.7135, Train APUR: 0.6927, Test AUC: 0.6773, Test AUPR: 0.6644\n",
      "Epoch: 68/100, Loss: 0.6177336, Train Acc: 0.6566, Test Acc: 0.6327, Train AUC: 0.7183, Train APUR: 0.6980, Test AUC: 0.6830, Test AUPR: 0.6683\n",
      "Epoch: 69/100, Loss: 0.6158991, Train Acc: 0.6595, Test Acc: 0.6201, Train AUC: 0.7215, Train APUR: 0.7026, Test AUC: 0.6685, Test AUPR: 0.6547\n",
      "Epoch: 70/100, Loss: 0.6158709, Train Acc: 0.6574, Test Acc: 0.6229, Train AUC: 0.7178, Train APUR: 0.6980, Test AUC: 0.6729, Test AUPR: 0.6595\n",
      "Epoch: 71/100, Loss: 0.6128638, Train Acc: 0.6589, Test Acc: 0.6285, Train AUC: 0.7215, Train APUR: 0.7037, Test AUC: 0.6859, Test AUPR: 0.6748\n",
      "Epoch: 72/100, Loss: 0.6136280, Train Acc: 0.6598, Test Acc: 0.6153, Train AUC: 0.7226, Train APUR: 0.7051, Test AUC: 0.6779, Test AUPR: 0.6673\n",
      "Epoch: 73/100, Loss: 0.6095769, Train Acc: 0.6619, Test Acc: 0.6039, Train AUC: 0.7259, Train APUR: 0.7132, Test AUC: 0.6628, Test AUPR: 0.6491\n",
      "Epoch: 74/100, Loss: 0.6131526, Train Acc: 0.6562, Test Acc: 0.6265, Train AUC: 0.7209, Train APUR: 0.7056, Test AUC: 0.6798, Test AUPR: 0.6633\n",
      "Epoch: 75/100, Loss: 0.6073952, Train Acc: 0.6625, Test Acc: 0.6280, Train AUC: 0.7281, Train APUR: 0.7083, Test AUC: 0.6823, Test AUPR: 0.6708\n",
      "Epoch: 76/100, Loss: 0.6130188, Train Acc: 0.6566, Test Acc: 0.6110, Train AUC: 0.7195, Train APUR: 0.7057, Test AUC: 0.6741, Test AUPR: 0.6621\n",
      "Epoch: 77/100, Loss: 0.6045683, Train Acc: 0.6647, Test Acc: 0.6035, Train AUC: 0.7319, Train APUR: 0.7185, Test AUC: 0.6681, Test AUPR: 0.6586\n",
      "Epoch: 78/100, Loss: 0.6085110, Train Acc: 0.6619, Test Acc: 0.6176, Train AUC: 0.7267, Train APUR: 0.7127, Test AUC: 0.6874, Test AUPR: 0.6800\n",
      "Epoch: 79/100, Loss: 0.6065750, Train Acc: 0.6651, Test Acc: 0.6283, Train AUC: 0.7321, Train APUR: 0.7211, Test AUC: 0.6897, Test AUPR: 0.6798\n",
      "Epoch: 80/100, Loss: 0.6012751, Train Acc: 0.6698, Test Acc: 0.6289, Train AUC: 0.7385, Train APUR: 0.7266, Test AUC: 0.6767, Test AUPR: 0.6656\n",
      "Epoch: 81/100, Loss: 0.6043520, Train Acc: 0.6662, Test Acc: 0.6299, Train AUC: 0.7339, Train APUR: 0.7207, Test AUC: 0.6877, Test AUPR: 0.6762\n",
      "Epoch: 82/100, Loss: 0.5979440, Train Acc: 0.6703, Test Acc: 0.6194, Train AUC: 0.7390, Train APUR: 0.7272, Test AUC: 0.6881, Test AUPR: 0.6803\n",
      "Epoch: 83/100, Loss: 0.6022078, Train Acc: 0.6652, Test Acc: 0.6167, Train AUC: 0.7353, Train APUR: 0.7261, Test AUC: 0.6818, Test AUPR: 0.6755\n",
      "Epoch: 84/100, Loss: 0.5996265, Train Acc: 0.6693, Test Acc: 0.6120, Train AUC: 0.7368, Train APUR: 0.7265, Test AUC: 0.6717, Test AUPR: 0.6623\n",
      "Epoch: 85/100, Loss: 0.6021751, Train Acc: 0.6673, Test Acc: 0.6292, Train AUC: 0.7344, Train APUR: 0.7208, Test AUC: 0.6866, Test AUPR: 0.6757\n",
      "Epoch: 86/100, Loss: 0.5937220, Train Acc: 0.6735, Test Acc: 0.6340, Train AUC: 0.7448, Train APUR: 0.7341, Test AUC: 0.6937, Test AUPR: 0.6817\n",
      "Epoch: 87/100, Loss: 0.5958085, Train Acc: 0.6716, Test Acc: 0.6200, Train AUC: 0.7430, Train APUR: 0.7324, Test AUC: 0.6911, Test AUPR: 0.6788\n",
      "Epoch: 88/100, Loss: 0.5898126, Train Acc: 0.6758, Test Acc: 0.6171, Train AUC: 0.7487, Train APUR: 0.7393, Test AUC: 0.6835, Test AUPR: 0.6729\n",
      "Epoch: 89/100, Loss: 0.5929705, Train Acc: 0.6731, Test Acc: 0.6289, Train AUC: 0.7454, Train APUR: 0.7361, Test AUC: 0.6845, Test AUPR: 0.6773\n",
      "Epoch: 90/100, Loss: 0.5896552, Train Acc: 0.6782, Test Acc: 0.6336, Train AUC: 0.7503, Train APUR: 0.7410, Test AUC: 0.6942, Test AUPR: 0.6850\n",
      "Epoch: 91/100, Loss: 0.5906369, Train Acc: 0.6765, Test Acc: 0.6193, Train AUC: 0.7474, Train APUR: 0.7405, Test AUC: 0.6838, Test AUPR: 0.6741\n",
      "Epoch: 92/100, Loss: 0.5904759, Train Acc: 0.6750, Test Acc: 0.6199, Train AUC: 0.7491, Train APUR: 0.7383, Test AUC: 0.6813, Test AUPR: 0.6732\n",
      "Epoch: 93/100, Loss: 0.5859461, Train Acc: 0.6792, Test Acc: 0.6324, Train AUC: 0.7529, Train APUR: 0.7432, Test AUC: 0.6873, Test AUPR: 0.6810\n",
      "Epoch: 94/100, Loss: 0.5874705, Train Acc: 0.6782, Test Acc: 0.6167, Train AUC: 0.7536, Train APUR: 0.7452, Test AUC: 0.6872, Test AUPR: 0.6797\n",
      "Epoch: 95/100, Loss: 0.5853578, Train Acc: 0.6784, Test Acc: 0.6084, Train AUC: 0.7528, Train APUR: 0.7462, Test AUC: 0.6808, Test AUPR: 0.6690\n",
      "Epoch: 96/100, Loss: 0.5880302, Train Acc: 0.6749, Test Acc: 0.6248, Train AUC: 0.7517, Train APUR: 0.7418, Test AUC: 0.6847, Test AUPR: 0.6739\n",
      "Epoch: 97/100, Loss: 0.5804030, Train Acc: 0.6841, Test Acc: 0.6387, Train AUC: 0.7596, Train APUR: 0.7504, Test AUC: 0.6909, Test AUPR: 0.6831\n",
      "Epoch: 98/100, Loss: 0.5872220, Train Acc: 0.6808, Test Acc: 0.6315, Train AUC: 0.7555, Train APUR: 0.7469, Test AUC: 0.6816, Test AUPR: 0.6727\n",
      "Epoch: 99/100, Loss: 0.5843543, Train Acc: 0.6841, Test Acc: 0.6147, Train AUC: 0.7579, Train APUR: 0.7492, Test AUC: 0.6956, Test AUPR: 0.6863\n",
      "Epoch: 100/100, Loss: 0.5797986, Train Acc: 0.6852, Test Acc: 0.6070, Train AUC: 0.7609, Train APUR: 0.7508, Test AUC: 0.6962, Test AUPR: 0.6886\n",
      "/home/ubuntu/PA-Cancer-Immunotherapy/GNN/train_pa.py:247: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(configs['save_model']))\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 51.079 MB of 51.257 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 51.257 MB of 51.257 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 51.257 MB of 51.257 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 51.257 MB of 51.257 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▁▁▁▂▂▂▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▇▇▇▇▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      test_aupr ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   test_roc_auc ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▁▃▃▄▄▅▄▄▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇███████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_aupr ▁▃▃▃▃▄▄▄▄▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇█████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss ██▇▇▇▇▇▇▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▅▄▃▃▂▃▂▃▂▂▁▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_roc_auc ▁▁▂▃▃▃▃▃▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▆▆▆▆▇▆▇▇▇▇▇▇█████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: valid_accuracy ▁▄▅▅▅▆▄▆▆▆▇▆▆▆▇▅▆▆▇▇█▇▇█▇█▇█▇██▇████▇▇█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     valid_aupr ▁▁▁▂▂▂▃▃▃▃▃▃▃▃▃▄▄▃▄▄▅▆▆▆▆▆▆▅▇▅▇▆█▇██▇▇▇▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  valid_roc_auc ▁▂▃▃▃▄▄▄▄▄▄▄▅▅▅▄▄▅▅▅▆▆▆▆▆▆▆▇▇▆▇▇▇▇▆█▇█▇▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy 0.60705\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      test_aupr 0.68863\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   test_roc_auc 0.69624\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.68518\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_aupr 0.75078\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.5798\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_roc_auc 0.76095\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: valid_accuracy 0.60705\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     valid_aupr 0.68863\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  valid_roc_auc 0.69624\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mgiddy-leaf-10\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN/runs/2od3vm7l\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-allele_GNN\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 92 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241205_100337-2od3vm7l/logs\u001b[0m\n",
      "Test Acc: 0.6070, Test AUC: 0.6962, Test AUPR: 0.6886\n"
     ]
    }
   ],
   "source": [
    "# embeddings with the trained tcrpeg model separately for cdr3 and for epitope. \n",
    "# # The embeddings were just generated again, since it was not sure if the tes.tsv file was used for the first embeddings file. \n",
    "# second time for allele in wandb\n",
    "! python train_pa.py --gpu 0 --configs_path configs/PA_all_allele.yml --droup_out 0.1 --split StrictTCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6357e8-b1fe-4017-9900-2172cbc6657f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4268c3-64cd-4b79-bdd3-df99464a28ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROJECT: ONE_MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a878dbc5-d0d1-4a70-966a-0b83fdac2820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./processed_data/PA_all_one/allele_train.csv\n",
      "Saved: ./processed_data/PA_all_one/allele_test.csv\n",
      "Saved: ./processed_data/PA_all_one/gene_train.csv\n",
      "Saved: ./processed_data/PA_all_one/gene_test.csv\n"
     ]
    }
   ],
   "source": [
    "# first: data preparation for project 'one_model'\n",
    "\n",
    "#training a gnn with all 'BA-data', where train and validation are used for training und test for testing\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "ppl_path = \"./data_for_training/splitted_datasets/\"\n",
    "precisions = [\"allele\", \"gene\"]\n",
    "for precision in precisions:\n",
    "    train = f\"{ppl_path}{precision}/beta/train.tsv\"\n",
    "    valid = f\"{ppl_path}{precision}/beta/validation.tsv\"\n",
    "    test = f\"{ppl_path}{precision}/beta/test.tsv\"\n",
    "    train_dfs = [pd.read_csv(train, sep='\\t'), pd.read_csv(valid, sep='\\t')]\n",
    "    concat_train_df = pd.concat(train_dfs, ignore_index=True)\n",
    "    concat_train_df = concat_train_df[['TRB_CDR3', 'Epitope', 'Binding']]\n",
    "    test_df = pd.read_csv(test, sep='\\t')\n",
    "    test_df = test_df[['TRB_CDR3', 'Epitope', 'Binding']]\n",
    "\n",
    "    columns_to_rename = {'TRB_CDR3': 'CDR3.beta','Binding': 'Label'}\n",
    "    concat_train_df.rename(columns=columns_to_rename, inplace=True)\n",
    "    test_df.rename(columns=columns_to_rename, inplace=True)\n",
    "    concat_train_df = concat_train_df[concat_train_df['CDR3.beta'].apply(len) <= 30]\n",
    "    concat_train_df = concat_train_df[concat_train_df['Epitope'].apply(len) <= 30]\n",
    "    test_df = test_df[test_df['CDR3.beta'].apply(len) <= 30]\n",
    "    test_df = test_df[test_df['Epitope'].apply(len) <= 30]\n",
    "    save_path_train = f\"./processed_data/PA_all_one/{precision}_train.csv\"\n",
    "    save_path_test = f\"./processed_data/PA_all_one/{precision}_test.csv\"\n",
    "    concat_train_df.to_csv(save_path_train, index=False)\n",
    "    print(f\"Saved: {save_path_train}\")\n",
    "    test_df.to_csv(save_path_test, index=False)\n",
    "    print(f\"Saved: {save_path_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92a53f28-9f4b-48b4-81c3-5337446dc6ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploading dataset to dataset-all-one-allele_GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfrohoari\u001b[0m (\u001b[33mpa_cancerimmunotherapy\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/PA-Cancer-Immunotherapy/GNN/wandb/run-20241206_002645-gmn0r9p3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-one-allele_GNN/runs/gmn0r9p3' target=\"_blank\">hearty-hill-1</a></strong> to <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-one-allele_GNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-one-allele_GNN' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-one-allele_GNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-one-allele_GNN/runs/gmn0r9p3' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-one-allele_GNN/runs/gmn0r9p3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./processed_data/PA_all_one)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploading dataset to dataset-all-one-allele_GNN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:gmn0r9p3) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.114 MB of 21.909 MB uploaded\\r'), FloatProgress(value=0.050852023734566015, max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hearty-hill-1</strong> at: <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-one-allele_GNN/runs/gmn0r9p3' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-one-allele_GNN/runs/gmn0r9p3</a><br/> View project at: <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-one-allele_GNN' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-one-allele_GNN</a><br/>Synced 4 W&B file(s), 0 media file(s), 8 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241206_002645-gmn0r9p3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:gmn0r9p3). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/PA-Cancer-Immunotherapy/GNN/wandb/run-20241206_002645-o9sbiut5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-one-allele_GNN/runs/o9sbiut5' target=\"_blank\">silver-sun-2</a></strong> to <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-one-allele_GNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-one-allele_GNN' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-one-allele_GNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-one-allele_GNN/runs/o9sbiut5' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-one-allele_GNN/runs/o9sbiut5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./processed_data/PA_all_one)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploading dataset to dataset-all-one-gene_GNN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:o9sbiut5) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.161 MB of 21.909 MB uploaded\\r'), FloatProgress(value=0.05299147360257322, max=1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">silver-sun-2</strong> at: <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-one-allele_GNN/runs/o9sbiut5' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-one-allele_GNN/runs/o9sbiut5</a><br/> View project at: <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-one-allele_GNN' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-one-allele_GNN</a><br/>Synced 5 W&B file(s), 0 media file(s), 5 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241206_002645-o9sbiut5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:o9sbiut5). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/PA-Cancer-Immunotherapy/GNN/wandb/run-20241206_002653-ev88vsqm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-one-gene_GNN/runs/ev88vsqm' target=\"_blank\">ruby-valley-1</a></strong> to <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-one-gene_GNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-one-gene_GNN' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-one-gene_GNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-one-gene_GNN/runs/ev88vsqm' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-one-gene_GNN/runs/ev88vsqm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./processed_data/PA_all_one)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploading dataset to dataset-all-one-gene_GNN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:ev88vsqm) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.177 MB of 21.909 MB uploaded\\r'), FloatProgress(value=0.05370465110215393, max=1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ruby-valley-1</strong> at: <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-one-gene_GNN/runs/ev88vsqm' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-one-gene_GNN/runs/ev88vsqm</a><br/> View project at: <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-one-gene_GNN' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-one-gene_GNN</a><br/>Synced 4 W&B file(s), 0 media file(s), 8 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241206_002653-ev88vsqm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:ev88vsqm). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/PA-Cancer-Immunotherapy/GNN/wandb/run-20241206_002700-cuwbrv20</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-one-gene_GNN/runs/cuwbrv20' target=\"_blank\">polar-hill-2</a></strong> to <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-one-gene_GNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-one-gene_GNN' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-one-gene_GNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-one-gene_GNN/runs/cuwbrv20' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-one-gene_GNN/runs/cuwbrv20</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./processed_data/PA_all_one)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.161 MB of 21.909 MB uploaded\\r'), FloatProgress(value=0.05298957737575662, max=1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">polar-hill-2</strong> at: <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-one-gene_GNN/runs/cuwbrv20' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-one-gene_GNN/runs/cuwbrv20</a><br/> View project at: <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-one-gene_GNN' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-one-gene_GNN</a><br/>Synced 5 W&B file(s), 0 media file(s), 5 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241206_002700-cuwbrv20/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Datan hochladen auf wandb\n",
    "\n",
    "import wandb\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "#/home/ubuntu/PA-Cancer-Immunotherapy/GNN/processed_data/PA_all\n",
    "# upload paired data\n",
    "path_to_data = './processed_data/PA_all_one/' # path zu unseren Daten\n",
    "precisions = [\"allele\", \"gene\"]\n",
    "\n",
    "for precision in precisions:\n",
    "    \n",
    "    main_project_name = f\"dataset-all-one-{precision}_GNN\" # das erscheint auf wandb projects \n",
    "    \n",
    "\n",
    "    datasets_names = ['train.csv', 'test.csv']\n",
    "    for dataset_name in datasets_names:\n",
    "        #main_project_name = os.getenv(\"MAIN_PROJECT_NAME\")\n",
    "        print(f\"uploading dataset to {main_project_name}\")\n",
    "        run = wandb.init(project=main_project_name, job_type=\"Upload Dataset\", entity=\"pa_cancerimmunotherapy\")\n",
    "        artifact = wandb.Artifact(name=dataset_name, type=\"dataset\")\n",
    "        artifact.add_dir(path_to_data, name=f\"{precision}_\")\n",
    "        run.log_artifact(artifact)\n",
    "wandb.finish()\n",
    "\n",
    "# %run ./data_scripts/upload_datasets.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f012efc4-6e91-484e-a114-0fe330cbe6f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(gpu=0, lr=0.001, epochs=100, w_celoss=1, w_aucloss=0, add_same_type_edges=False, dynamic_graph=False, dynamic_ratio=0.05, droup_out=0.1, positive_weights=1, dynamic_epochs=30, distance_threshold=10, configs_path='configs/PA_all_one_allele.yml', split='StrictTCR', dataset='pMTnet')\n",
      "PROJECT_NAME: dataset-all-one-allele_GNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfrohoari\u001b[0m (\u001b[33mpa_cancerimmunotherapy\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/ubuntu/PA-Cancer-Immunotherapy/GNN/wandb/run-20241206_013248-3154au9d\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mjumping-planet-5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-one-allele_GNN\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-one-allele_GNN/runs/3154au9d\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   4 of 4 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   4 of 4 files downloaded.  \n",
      "embeddings_path:   models/PA_all/gene_and_allele_embeddings.pkl\n",
      "train_file_list:   ['allele_train.csv']\n",
      "test_file_list:   ['allele_test.csv']\n",
      "wandb logger initialisiert\n",
      "Epoch: 1/100, Loss: 0.6937548, Train Acc: 0.4844, Test Acc: 0.4994, Train AUC: 0.4799, Train APUR: 0.4918, Test AUC: 0.5944, Test AUPR: 0.5724\n",
      "Epoch: 2/100, Loss: 0.6914183, Train Acc: 0.5005, Test Acc: 0.5405, Train AUC: 0.5659, Train APUR: 0.5467, Test AUC: 0.5941, Test AUPR: 0.5735\n",
      "Epoch: 3/100, Loss: 0.6878773, Train Acc: 0.5497, Test Acc: 0.5562, Train AUC: 0.5874, Train APUR: 0.5679, Test AUC: 0.6012, Test AUPR: 0.5856\n",
      "Epoch: 4/100, Loss: 0.6844087, Train Acc: 0.5644, Test Acc: 0.5737, Train AUC: 0.5938, Train APUR: 0.5748, Test AUC: 0.6042, Test AUPR: 0.5902\n",
      "Epoch: 5/100, Loss: 0.6816819, Train Acc: 0.5752, Test Acc: 0.5708, Train AUC: 0.5971, Train APUR: 0.5762, Test AUC: 0.6047, Test AUPR: 0.5875\n",
      "Epoch: 6/100, Loss: 0.6789927, Train Acc: 0.5750, Test Acc: 0.5666, Train AUC: 0.5995, Train APUR: 0.5783, Test AUC: 0.6146, Test AUPR: 0.5967\n",
      "Epoch: 7/100, Loss: 0.6778042, Train Acc: 0.5751, Test Acc: 0.5910, Train AUC: 0.6070, Train APUR: 0.5872, Test AUC: 0.6235, Test AUPR: 0.6020\n",
      "Epoch: 8/100, Loss: 0.6750228, Train Acc: 0.5861, Test Acc: 0.5959, Train AUC: 0.6124, Train APUR: 0.5888, Test AUC: 0.6333, Test AUPR: 0.6079\n",
      "Epoch: 9/100, Loss: 0.6723680, Train Acc: 0.5922, Test Acc: 0.5879, Train AUC: 0.6189, Train APUR: 0.5927, Test AUC: 0.6372, Test AUPR: 0.6109\n",
      "Epoch: 10/100, Loss: 0.6723252, Train Acc: 0.5896, Test Acc: 0.6106, Train AUC: 0.6240, Train APUR: 0.5921, Test AUC: 0.6397, Test AUPR: 0.6120\n",
      "Epoch: 11/100, Loss: 0.6704141, Train Acc: 0.5932, Test Acc: 0.6032, Train AUC: 0.6280, Train APUR: 0.5977, Test AUC: 0.6401, Test AUPR: 0.6116\n",
      "Epoch: 12/100, Loss: 0.6687303, Train Acc: 0.6007, Test Acc: 0.6038, Train AUC: 0.6292, Train APUR: 0.5993, Test AUC: 0.6402, Test AUPR: 0.6118\n",
      "Epoch: 13/100, Loss: 0.6684390, Train Acc: 0.5977, Test Acc: 0.6056, Train AUC: 0.6285, Train APUR: 0.5970, Test AUC: 0.6422, Test AUPR: 0.6134\n",
      "Epoch: 14/100, Loss: 0.6675950, Train Acc: 0.5981, Test Acc: 0.6222, Train AUC: 0.6294, Train APUR: 0.6009, Test AUC: 0.6450, Test AUPR: 0.6159\n",
      "Epoch: 15/100, Loss: 0.6657421, Train Acc: 0.6023, Test Acc: 0.6223, Train AUC: 0.6351, Train APUR: 0.6024, Test AUC: 0.6473, Test AUPR: 0.6189\n",
      "Epoch: 16/100, Loss: 0.6652142, Train Acc: 0.6038, Test Acc: 0.6256, Train AUC: 0.6364, Train APUR: 0.6082, Test AUC: 0.6482, Test AUPR: 0.6210\n",
      "Epoch: 17/100, Loss: 0.6639065, Train Acc: 0.6073, Test Acc: 0.6232, Train AUC: 0.6371, Train APUR: 0.6079, Test AUC: 0.6485, Test AUPR: 0.6226\n",
      "Epoch: 18/100, Loss: 0.6639638, Train Acc: 0.6075, Test Acc: 0.6282, Train AUC: 0.6391, Train APUR: 0.6142, Test AUC: 0.6495, Test AUPR: 0.6238\n",
      "Epoch: 19/100, Loss: 0.6631768, Train Acc: 0.6062, Test Acc: 0.6293, Train AUC: 0.6377, Train APUR: 0.6117, Test AUC: 0.6515, Test AUPR: 0.6250\n",
      "Epoch: 20/100, Loss: 0.6613670, Train Acc: 0.6096, Test Acc: 0.6316, Train AUC: 0.6418, Train APUR: 0.6155, Test AUC: 0.6536, Test AUPR: 0.6261\n",
      "Epoch: 21/100, Loss: 0.6604723, Train Acc: 0.6096, Test Acc: 0.6326, Train AUC: 0.6438, Train APUR: 0.6174, Test AUC: 0.6555, Test AUPR: 0.6273\n",
      "Epoch: 22/100, Loss: 0.6604345, Train Acc: 0.6144, Test Acc: 0.6298, Train AUC: 0.6468, Train APUR: 0.6217, Test AUC: 0.6561, Test AUPR: 0.6275\n",
      "Epoch: 23/100, Loss: 0.6594772, Train Acc: 0.6106, Test Acc: 0.6330, Train AUC: 0.6456, Train APUR: 0.6195, Test AUC: 0.6570, Test AUPR: 0.6293\n",
      "Epoch: 24/100, Loss: 0.6593004, Train Acc: 0.6093, Test Acc: 0.6320, Train AUC: 0.6470, Train APUR: 0.6199, Test AUC: 0.6582, Test AUPR: 0.6312\n",
      "Epoch: 25/100, Loss: 0.6583246, Train Acc: 0.6123, Test Acc: 0.6309, Train AUC: 0.6470, Train APUR: 0.6214, Test AUC: 0.6597, Test AUPR: 0.6340\n",
      "Epoch: 26/100, Loss: 0.6572009, Train Acc: 0.6139, Test Acc: 0.6296, Train AUC: 0.6509, Train APUR: 0.6255, Test AUC: 0.6613, Test AUPR: 0.6361\n",
      "Epoch: 27/100, Loss: 0.6560339, Train Acc: 0.6130, Test Acc: 0.6298, Train AUC: 0.6506, Train APUR: 0.6280, Test AUC: 0.6644, Test AUPR: 0.6389\n",
      "Epoch: 28/100, Loss: 0.6556250, Train Acc: 0.6133, Test Acc: 0.6298, Train AUC: 0.6525, Train APUR: 0.6285, Test AUC: 0.6663, Test AUPR: 0.6405\n",
      "Epoch: 29/100, Loss: 0.6546937, Train Acc: 0.6141, Test Acc: 0.6290, Train AUC: 0.6544, Train APUR: 0.6296, Test AUC: 0.6670, Test AUPR: 0.6414\n",
      "Epoch: 30/100, Loss: 0.6544684, Train Acc: 0.6157, Test Acc: 0.6315, Train AUC: 0.6542, Train APUR: 0.6299, Test AUC: 0.6663, Test AUPR: 0.6429\n",
      "Epoch: 31/100, Loss: 0.6527857, Train Acc: 0.6159, Test Acc: 0.6333, Train AUC: 0.6568, Train APUR: 0.6340, Test AUC: 0.6681, Test AUPR: 0.6465\n",
      "Epoch: 32/100, Loss: 0.6522133, Train Acc: 0.6184, Test Acc: 0.6355, Train AUC: 0.6585, Train APUR: 0.6371, Test AUC: 0.6730, Test AUPR: 0.6501\n",
      "Epoch: 33/100, Loss: 0.6500576, Train Acc: 0.6173, Test Acc: 0.6364, Train AUC: 0.6623, Train APUR: 0.6406, Test AUC: 0.6766, Test AUPR: 0.6531\n",
      "Epoch: 34/100, Loss: 0.6495750, Train Acc: 0.6172, Test Acc: 0.6375, Train AUC: 0.6636, Train APUR: 0.6420, Test AUC: 0.6791, Test AUPR: 0.6561\n",
      "Epoch: 35/100, Loss: 0.6476084, Train Acc: 0.6204, Test Acc: 0.6362, Train AUC: 0.6676, Train APUR: 0.6463, Test AUC: 0.6800, Test AUPR: 0.6586\n",
      "Epoch: 36/100, Loss: 0.6471089, Train Acc: 0.6188, Test Acc: 0.6387, Train AUC: 0.6677, Train APUR: 0.6483, Test AUC: 0.6839, Test AUPR: 0.6615\n",
      "Epoch: 37/100, Loss: 0.6451888, Train Acc: 0.6198, Test Acc: 0.6489, Train AUC: 0.6690, Train APUR: 0.6490, Test AUC: 0.6897, Test AUPR: 0.6640\n",
      "Epoch: 38/100, Loss: 0.6454291, Train Acc: 0.6253, Test Acc: 0.6401, Train AUC: 0.6750, Train APUR: 0.6529, Test AUC: 0.6861, Test AUPR: 0.6634\n",
      "Epoch: 39/100, Loss: 0.6424600, Train Acc: 0.6224, Test Acc: 0.6488, Train AUC: 0.6750, Train APUR: 0.6554, Test AUC: 0.6916, Test AUPR: 0.6682\n",
      "Epoch: 40/100, Loss: 0.6404516, Train Acc: 0.6301, Test Acc: 0.6503, Train AUC: 0.6811, Train APUR: 0.6607, Test AUC: 0.6930, Test AUPR: 0.6701\n",
      "Epoch: 41/100, Loss: 0.6386497, Train Acc: 0.6294, Test Acc: 0.6589, Train AUC: 0.6834, Train APUR: 0.6648, Test AUC: 0.6971, Test AUPR: 0.6719\n",
      "Epoch: 42/100, Loss: 0.6358157, Train Acc: 0.6436, Test Acc: 0.6578, Train AUC: 0.6914, Train APUR: 0.6702, Test AUC: 0.6983, Test AUPR: 0.6742\n",
      "Epoch: 43/100, Loss: 0.6338243, Train Acc: 0.6436, Test Acc: 0.6606, Train AUC: 0.6932, Train APUR: 0.6734, Test AUC: 0.7016, Test AUPR: 0.6750\n",
      "Epoch: 44/100, Loss: 0.6329291, Train Acc: 0.6511, Test Acc: 0.6563, Train AUC: 0.6984, Train APUR: 0.6756, Test AUC: 0.6998, Test AUPR: 0.6772\n",
      "Epoch: 45/100, Loss: 0.6305543, Train Acc: 0.6483, Test Acc: 0.6580, Train AUC: 0.6978, Train APUR: 0.6773, Test AUC: 0.7038, Test AUPR: 0.6743\n",
      "Epoch: 46/100, Loss: 0.6294046, Train Acc: 0.6555, Test Acc: 0.6591, Train AUC: 0.7058, Train APUR: 0.6786, Test AUC: 0.7046, Test AUPR: 0.6799\n",
      "Epoch: 47/100, Loss: 0.6255406, Train Acc: 0.6551, Test Acc: 0.6613, Train AUC: 0.7056, Train APUR: 0.6826, Test AUC: 0.7071, Test AUPR: 0.6822\n",
      "Epoch: 48/100, Loss: 0.6230605, Train Acc: 0.6568, Test Acc: 0.6616, Train AUC: 0.7103, Train APUR: 0.6870, Test AUC: 0.7093, Test AUPR: 0.6830\n",
      "Epoch: 49/100, Loss: 0.6231546, Train Acc: 0.6535, Test Acc: 0.6590, Train AUC: 0.7104, Train APUR: 0.6890, Test AUC: 0.7094, Test AUPR: 0.6859\n",
      "Epoch: 50/100, Loss: 0.6220028, Train Acc: 0.6581, Test Acc: 0.6465, Train AUC: 0.7116, Train APUR: 0.6881, Test AUC: 0.6993, Test AUPR: 0.6749\n",
      "Epoch: 51/100, Loss: 0.6273068, Train Acc: 0.6475, Test Acc: 0.6533, Train AUC: 0.7033, Train APUR: 0.6770, Test AUC: 0.7028, Test AUPR: 0.6850\n",
      "Epoch: 52/100, Loss: 0.6283795, Train Acc: 0.6487, Test Acc: 0.6583, Train AUC: 0.7046, Train APUR: 0.6847, Test AUC: 0.7130, Test AUPR: 0.6898\n",
      "Epoch: 53/100, Loss: 0.6209080, Train Acc: 0.6547, Test Acc: 0.6294, Train AUC: 0.7157, Train APUR: 0.6937, Test AUC: 0.6790, Test AUPR: 0.6636\n",
      "Epoch: 54/100, Loss: 0.6328159, Train Acc: 0.6362, Test Acc: 0.6646, Train AUC: 0.6931, Train APUR: 0.6726, Test AUC: 0.7167, Test AUPR: 0.6950\n",
      "Epoch: 55/100, Loss: 0.6169506, Train Acc: 0.6617, Test Acc: 0.6537, Train AUC: 0.7208, Train APUR: 0.6975, Test AUC: 0.7002, Test AUPR: 0.6809\n",
      "Epoch: 56/100, Loss: 0.6285580, Train Acc: 0.6509, Test Acc: 0.6625, Train AUC: 0.7034, Train APUR: 0.6824, Test AUC: 0.7106, Test AUPR: 0.6926\n",
      "Epoch: 57/100, Loss: 0.6182749, Train Acc: 0.6556, Test Acc: 0.6623, Train AUC: 0.7145, Train APUR: 0.6931, Test AUC: 0.7155, Test AUPR: 0.6949\n",
      "Epoch: 58/100, Loss: 0.6143681, Train Acc: 0.6645, Test Acc: 0.6508, Train AUC: 0.7246, Train APUR: 0.7014, Test AUC: 0.7006, Test AUPR: 0.6824\n",
      "Epoch: 59/100, Loss: 0.6224095, Train Acc: 0.6508, Test Acc: 0.6656, Train AUC: 0.7163, Train APUR: 0.6913, Test AUC: 0.7193, Test AUPR: 0.7000\n",
      "Epoch: 60/100, Loss: 0.6128128, Train Acc: 0.6638, Test Acc: 0.6655, Train AUC: 0.7249, Train APUR: 0.7052, Test AUC: 0.7151, Test AUPR: 0.6986\n",
      "Epoch: 61/100, Loss: 0.6137269, Train Acc: 0.6643, Test Acc: 0.6640, Train AUC: 0.7215, Train APUR: 0.7011, Test AUC: 0.7135, Test AUPR: 0.6972\n",
      "Epoch: 62/100, Loss: 0.6169917, Train Acc: 0.6607, Test Acc: 0.6676, Train AUC: 0.7164, Train APUR: 0.6961, Test AUC: 0.7234, Test AUPR: 0.7059\n",
      "Epoch: 63/100, Loss: 0.6085542, Train Acc: 0.6677, Test Acc: 0.6616, Train AUC: 0.7305, Train APUR: 0.7096, Test AUC: 0.7168, Test AUPR: 0.6997\n",
      "Epoch: 64/100, Loss: 0.6105518, Train Acc: 0.6641, Test Acc: 0.6700, Train AUC: 0.7261, Train APUR: 0.7076, Test AUC: 0.7246, Test AUPR: 0.7079\n",
      "Epoch: 65/100, Loss: 0.6071275, Train Acc: 0.6689, Test Acc: 0.6694, Train AUC: 0.7313, Train APUR: 0.7123, Test AUC: 0.7240, Test AUPR: 0.7081\n",
      "Epoch: 66/100, Loss: 0.6050597, Train Acc: 0.6683, Test Acc: 0.6677, Train AUC: 0.7325, Train APUR: 0.7133, Test AUC: 0.7240, Test AUPR: 0.7090\n",
      "Epoch: 67/100, Loss: 0.6041533, Train Acc: 0.6686, Test Acc: 0.6690, Train AUC: 0.7328, Train APUR: 0.7146, Test AUC: 0.7256, Test AUPR: 0.7108\n",
      "Epoch: 68/100, Loss: 0.6041805, Train Acc: 0.6705, Test Acc: 0.6616, Train AUC: 0.7339, Train APUR: 0.7163, Test AUC: 0.7187, Test AUPR: 0.7046\n",
      "Epoch: 69/100, Loss: 0.6048917, Train Acc: 0.6651, Test Acc: 0.6699, Train AUC: 0.7318, Train APUR: 0.7153, Test AUC: 0.7258, Test AUPR: 0.7117\n",
      "Epoch: 70/100, Loss: 0.5995131, Train Acc: 0.6724, Test Acc: 0.6703, Train AUC: 0.7374, Train APUR: 0.7210, Test AUC: 0.7259, Test AUPR: 0.7130\n",
      "Epoch: 71/100, Loss: 0.6007156, Train Acc: 0.6720, Test Acc: 0.6703, Train AUC: 0.7366, Train APUR: 0.7198, Test AUC: 0.7285, Test AUPR: 0.7168\n",
      "Epoch: 72/100, Loss: 0.5976552, Train Acc: 0.6731, Test Acc: 0.6704, Train AUC: 0.7400, Train APUR: 0.7223, Test AUC: 0.7271, Test AUPR: 0.7165\n",
      "Epoch: 73/100, Loss: 0.5967621, Train Acc: 0.6734, Test Acc: 0.6725, Train AUC: 0.7417, Train APUR: 0.7271, Test AUC: 0.7302, Test AUPR: 0.7197\n",
      "Epoch: 74/100, Loss: 0.5969159, Train Acc: 0.6750, Test Acc: 0.6730, Train AUC: 0.7416, Train APUR: 0.7267, Test AUC: 0.7305, Test AUPR: 0.7200\n",
      "Epoch: 75/100, Loss: 0.5955990, Train Acc: 0.6749, Test Acc: 0.6722, Train AUC: 0.7428, Train APUR: 0.7288, Test AUC: 0.7334, Test AUPR: 0.7242\n",
      "Epoch: 76/100, Loss: 0.5946459, Train Acc: 0.6755, Test Acc: 0.6727, Train AUC: 0.7450, Train APUR: 0.7330, Test AUC: 0.7321, Test AUPR: 0.7224\n",
      "Epoch: 77/100, Loss: 0.5924603, Train Acc: 0.6760, Test Acc: 0.6751, Train AUC: 0.7460, Train APUR: 0.7335, Test AUC: 0.7363, Test AUPR: 0.7266\n",
      "Epoch: 78/100, Loss: 0.5925720, Train Acc: 0.6764, Test Acc: 0.6744, Train AUC: 0.7469, Train APUR: 0.7342, Test AUC: 0.7358, Test AUPR: 0.7276\n",
      "Epoch: 79/100, Loss: 0.5955079, Train Acc: 0.6755, Test Acc: 0.6657, Train AUC: 0.7435, Train APUR: 0.7286, Test AUC: 0.7329, Test AUPR: 0.7267\n",
      "Epoch: 80/100, Loss: 0.5910970, Train Acc: 0.6781, Test Acc: 0.6715, Train AUC: 0.7485, Train APUR: 0.7359, Test AUC: 0.7349, Test AUPR: 0.7289\n",
      "Epoch: 81/100, Loss: 0.5889302, Train Acc: 0.6788, Test Acc: 0.6698, Train AUC: 0.7503, Train APUR: 0.7407, Test AUC: 0.7348, Test AUPR: 0.7281\n",
      "Epoch: 82/100, Loss: 0.5925532, Train Acc: 0.6747, Test Acc: 0.6756, Train AUC: 0.7460, Train APUR: 0.7366, Test AUC: 0.7388, Test AUPR: 0.7324\n",
      "Epoch: 83/100, Loss: 0.5852872, Train Acc: 0.6836, Test Acc: 0.6769, Train AUC: 0.7540, Train APUR: 0.7444, Test AUC: 0.7415, Test AUPR: 0.7362\n",
      "Epoch: 84/100, Loss: 0.5853906, Train Acc: 0.6793, Test Acc: 0.6799, Train AUC: 0.7536, Train APUR: 0.7449, Test AUC: 0.7429, Test AUPR: 0.7370\n",
      "Epoch: 85/100, Loss: 0.5837293, Train Acc: 0.6832, Test Acc: 0.6763, Train AUC: 0.7554, Train APUR: 0.7443, Test AUC: 0.7375, Test AUPR: 0.7300\n",
      "Epoch: 86/100, Loss: 0.5876600, Train Acc: 0.6792, Test Acc: 0.6819, Train AUC: 0.7502, Train APUR: 0.7411, Test AUC: 0.7440, Test AUPR: 0.7364\n",
      "Epoch: 87/100, Loss: 0.5860840, Train Acc: 0.6857, Test Acc: 0.6813, Train AUC: 0.7546, Train APUR: 0.7398, Test AUC: 0.7459, Test AUPR: 0.7392\n",
      "Epoch: 88/100, Loss: 0.5824993, Train Acc: 0.6856, Test Acc: 0.6737, Train AUC: 0.7568, Train APUR: 0.7459, Test AUC: 0.7386, Test AUPR: 0.7357\n",
      "Epoch: 89/100, Loss: 0.5863143, Train Acc: 0.6775, Test Acc: 0.6818, Train AUC: 0.7519, Train APUR: 0.7460, Test AUC: 0.7460, Test AUPR: 0.7404\n",
      "Epoch: 90/100, Loss: 0.5799530, Train Acc: 0.6864, Test Acc: 0.6787, Train AUC: 0.7601, Train APUR: 0.7489, Test AUC: 0.7415, Test AUPR: 0.7355\n",
      "Epoch: 91/100, Loss: 0.5885979, Train Acc: 0.6801, Test Acc: 0.6684, Train AUC: 0.7511, Train APUR: 0.7385, Test AUC: 0.7333, Test AUPR: 0.7314\n",
      "Epoch: 92/100, Loss: 0.5872977, Train Acc: 0.6784, Test Acc: 0.6806, Train AUC: 0.7514, Train APUR: 0.7448, Test AUC: 0.7482, Test AUPR: 0.7459\n",
      "Epoch: 93/100, Loss: 0.5760618, Train Acc: 0.6874, Test Acc: 0.6819, Train AUC: 0.7641, Train APUR: 0.7563, Test AUC: 0.7476, Test AUPR: 0.7434\n",
      "Epoch: 94/100, Loss: 0.5812495, Train Acc: 0.6856, Test Acc: 0.6843, Train AUC: 0.7580, Train APUR: 0.7481, Test AUC: 0.7518, Test AUPR: 0.7475\n",
      "Epoch: 95/100, Loss: 0.5753586, Train Acc: 0.6888, Test Acc: 0.6799, Train AUC: 0.7644, Train APUR: 0.7577, Test AUC: 0.7464, Test AUPR: 0.7435\n",
      "Epoch: 96/100, Loss: 0.5760760, Train Acc: 0.6897, Test Acc: 0.6856, Train AUC: 0.7640, Train APUR: 0.7546, Test AUC: 0.7548, Test AUPR: 0.7522\n",
      "Epoch: 97/100, Loss: 0.5770438, Train Acc: 0.6890, Test Acc: 0.6880, Train AUC: 0.7635, Train APUR: 0.7538, Test AUC: 0.7550, Test AUPR: 0.7517\n",
      "Epoch: 98/100, Loss: 0.5698956, Train Acc: 0.6927, Test Acc: 0.6842, Train AUC: 0.7692, Train APUR: 0.7620, Test AUC: 0.7533, Test AUPR: 0.7507\n",
      "Epoch: 99/100, Loss: 0.5686924, Train Acc: 0.6942, Test Acc: 0.6845, Train AUC: 0.7712, Train APUR: 0.7653, Test AUC: 0.7540, Test AUPR: 0.7521\n",
      "Epoch: 100/100, Loss: 0.5697269, Train Acc: 0.6916, Test Acc: 0.6849, Train AUC: 0.7700, Train APUR: 0.7627, Test AUC: 0.7527, Test AUPR: 0.7507\n",
      "/home/ubuntu/PA-Cancer-Immunotherapy/GNN/train_pa_all.py:245: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(configs['save_model']))\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 77.267 MB of 77.267 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 77.267 MB of 77.267 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 77.267 MB of 77.267 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 77.274 MB of 77.274 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 77.274 MB of 77.274 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 77.274 MB of 77.274 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      test_aupr ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   test_roc_auc ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▁▂▄▄▄▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_aupr ▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss ███▇▇▇▆▆▆▆▆▆▆▆▆▅▅▅▄▄▄▄▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_roc_auc ▁▁▁▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▅▅▆▅▆▆▆▆▆▇▇▇▇▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: valid_accuracy ▁▃▃▄▄▅▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇███▇▇█████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     valid_aupr ▁▁▂▂▃▃▃▃▃▃▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇██▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  valid_roc_auc ▁▁▁▂▃▃▃▃▃▃▄▄▄▄▄▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇█▇▇█▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy 0.68797\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      test_aupr 0.7517\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   test_roc_auc 0.75496\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.69155\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_aupr 0.76269\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.56973\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_roc_auc 0.76995\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: valid_accuracy 0.68489\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     valid_aupr 0.75072\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  valid_roc_auc 0.75273\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mjumping-planet-5\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-one-allele_GNN/runs/3154au9d\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-one-allele_GNN\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 4 W&B file(s), 0 media file(s), 141 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241206_013248-3154au9d/logs\u001b[0m\n",
      "Test Acc: 0.6880, Test AUC: 0.7550, Test AUPR: 0.7517\n"
     ]
    }
   ],
   "source": [
    "# first for allele\n",
    "\n",
    "! python train_pa_all_one.py --gpu 0 --configs_path configs/PA_all_one_allele.yml --droup_out 0.1 --split StrictTCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c829b878-0c16-4027-93a4-5c26df997a3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(gpu=0, lr=0.001, epochs=100, w_celoss=1, w_aucloss=0, add_same_type_edges=False, dynamic_graph=False, dynamic_ratio=0.05, droup_out=0.1, positive_weights=1, dynamic_epochs=30, distance_threshold=10, configs_path='configs/PA_all_one_gene.yml', split='StrictTCR', dataset='pMTnet')\n",
      "PROJECT_NAME: dataset-all-one-allele_GNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfrohoari\u001b[0m (\u001b[33mpa_cancerimmunotherapy\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/ubuntu/PA-Cancer-Immunotherapy/GNN/wandb/run-20241206_014005-rl5m7xfr\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mexalted-wave-6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-one-allele_GNN\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-one-allele_GNN/runs/rl5m7xfr\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   4 of 4 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   4 of 4 files downloaded.  \n",
      "embeddings_path:   models/PA_all/gene_and_allele_embeddings.pkl\n",
      "train_file_list:   ['gene_train.csv']\n",
      "test_file_list:   ['gene_test.csv']\n",
      "wandb logger initialisiert\n",
      "Epoch: 1/100, Loss: 0.6935201, Train Acc: 0.4925, Test Acc: 0.4981, Train AUC: 0.4880, Train APUR: 0.4975, Test AUC: 0.5617, Test AUPR: 0.5394\n",
      "Epoch: 2/100, Loss: 0.6917302, Train Acc: 0.4988, Test Acc: 0.5399, Train AUC: 0.5684, Train APUR: 0.5501, Test AUC: 0.5841, Test AUPR: 0.5645\n",
      "Epoch: 3/100, Loss: 0.6876751, Train Acc: 0.5482, Test Acc: 0.5492, Train AUC: 0.5862, Train APUR: 0.5747, Test AUC: 0.5863, Test AUPR: 0.5704\n",
      "Epoch: 4/100, Loss: 0.6851264, Train Acc: 0.5587, Test Acc: 0.5574, Train AUC: 0.5957, Train APUR: 0.5809, Test AUC: 0.5870, Test AUPR: 0.5742\n",
      "Epoch: 5/100, Loss: 0.6816398, Train Acc: 0.5720, Test Acc: 0.5580, Train AUC: 0.5925, Train APUR: 0.5819, Test AUC: 0.5934, Test AUPR: 0.5774\n",
      "Epoch: 6/100, Loss: 0.6797784, Train Acc: 0.5698, Test Acc: 0.5632, Train AUC: 0.5944, Train APUR: 0.5823, Test AUC: 0.5991, Test AUPR: 0.5802\n",
      "Epoch: 7/100, Loss: 0.6794632, Train Acc: 0.5770, Test Acc: 0.5683, Train AUC: 0.6014, Train APUR: 0.5889, Test AUC: 0.6069, Test AUPR: 0.5844\n",
      "Epoch: 8/100, Loss: 0.6767046, Train Acc: 0.5803, Test Acc: 0.5884, Train AUC: 0.6108, Train APUR: 0.5919, Test AUC: 0.6159, Test AUPR: 0.5881\n",
      "Epoch: 9/100, Loss: 0.6732213, Train Acc: 0.5864, Test Acc: 0.5863, Train AUC: 0.6172, Train APUR: 0.6015, Test AUC: 0.6197, Test AUPR: 0.5890\n",
      "Epoch: 10/100, Loss: 0.6712392, Train Acc: 0.5961, Test Acc: 0.5797, Train AUC: 0.6243, Train APUR: 0.6040, Test AUC: 0.6217, Test AUPR: 0.5897\n",
      "Epoch: 11/100, Loss: 0.6728067, Train Acc: 0.5934, Test Acc: 0.5841, Train AUC: 0.6250, Train APUR: 0.6026, Test AUC: 0.6250, Test AUPR: 0.5923\n",
      "Epoch: 12/100, Loss: 0.6703109, Train Acc: 0.5897, Test Acc: 0.5890, Train AUC: 0.6266, Train APUR: 0.6068, Test AUC: 0.6265, Test AUPR: 0.5938\n",
      "Epoch: 13/100, Loss: 0.6703652, Train Acc: 0.5937, Test Acc: 0.6104, Train AUC: 0.6292, Train APUR: 0.6095, Test AUC: 0.6266, Test AUPR: 0.5948\n",
      "Epoch: 14/100, Loss: 0.6672552, Train Acc: 0.6028, Test Acc: 0.5946, Train AUC: 0.6321, Train APUR: 0.6101, Test AUC: 0.6262, Test AUPR: 0.5952\n",
      "Epoch: 15/100, Loss: 0.6702511, Train Acc: 0.5993, Test Acc: 0.5943, Train AUC: 0.6316, Train APUR: 0.6117, Test AUC: 0.6271, Test AUPR: 0.5965\n",
      "Epoch: 16/100, Loss: 0.6665028, Train Acc: 0.6039, Test Acc: 0.5857, Train AUC: 0.6332, Train APUR: 0.6132, Test AUC: 0.6287, Test AUPR: 0.5980\n",
      "Epoch: 17/100, Loss: 0.6691579, Train Acc: 0.5946, Test Acc: 0.6089, Train AUC: 0.6341, Train APUR: 0.6138, Test AUC: 0.6310, Test AUPR: 0.5994\n",
      "Epoch: 18/100, Loss: 0.6649501, Train Acc: 0.6017, Test Acc: 0.5907, Train AUC: 0.6365, Train APUR: 0.6159, Test AUC: 0.6334, Test AUPR: 0.6008\n",
      "Epoch: 19/100, Loss: 0.6646131, Train Acc: 0.6062, Test Acc: 0.5866, Train AUC: 0.6386, Train APUR: 0.6179, Test AUC: 0.6360, Test AUPR: 0.6021\n",
      "Epoch: 20/100, Loss: 0.6659443, Train Acc: 0.5946, Test Acc: 0.5883, Train AUC: 0.6401, Train APUR: 0.6194, Test AUC: 0.6386, Test AUPR: 0.6036\n",
      "Epoch: 21/100, Loss: 0.6643372, Train Acc: 0.6055, Test Acc: 0.6052, Train AUC: 0.6421, Train APUR: 0.6189, Test AUC: 0.6403, Test AUPR: 0.6045\n",
      "Epoch: 22/100, Loss: 0.6634827, Train Acc: 0.6102, Test Acc: 0.6185, Train AUC: 0.6438, Train APUR: 0.6218, Test AUC: 0.6408, Test AUPR: 0.6053\n",
      "Epoch: 23/100, Loss: 0.6636297, Train Acc: 0.6087, Test Acc: 0.6176, Train AUC: 0.6438, Train APUR: 0.6227, Test AUC: 0.6400, Test AUPR: 0.6057\n",
      "Epoch: 24/100, Loss: 0.6625232, Train Acc: 0.6107, Test Acc: 0.6102, Train AUC: 0.6442, Train APUR: 0.6228, Test AUC: 0.6384, Test AUPR: 0.6056\n",
      "Epoch: 25/100, Loss: 0.6615382, Train Acc: 0.6103, Test Acc: 0.6023, Train AUC: 0.6446, Train APUR: 0.6233, Test AUC: 0.6372, Test AUPR: 0.6055\n",
      "Epoch: 26/100, Loss: 0.6622727, Train Acc: 0.6006, Test Acc: 0.6094, Train AUC: 0.6438, Train APUR: 0.6234, Test AUC: 0.6368, Test AUPR: 0.6063\n",
      "Epoch: 27/100, Loss: 0.6616875, Train Acc: 0.6066, Test Acc: 0.6283, Train AUC: 0.6445, Train APUR: 0.6244, Test AUC: 0.6373, Test AUPR: 0.6080\n",
      "Epoch: 28/100, Loss: 0.6610032, Train Acc: 0.6103, Test Acc: 0.6294, Train AUC: 0.6444, Train APUR: 0.6256, Test AUC: 0.6385, Test AUPR: 0.6093\n",
      "Epoch: 29/100, Loss: 0.6597741, Train Acc: 0.6132, Test Acc: 0.6299, Train AUC: 0.6474, Train APUR: 0.6266, Test AUC: 0.6402, Test AUPR: 0.6110\n",
      "Epoch: 30/100, Loss: 0.6598275, Train Acc: 0.6117, Test Acc: 0.6281, Train AUC: 0.6470, Train APUR: 0.6270, Test AUC: 0.6434, Test AUPR: 0.6132\n",
      "Epoch: 31/100, Loss: 0.6593627, Train Acc: 0.6156, Test Acc: 0.6163, Train AUC: 0.6487, Train APUR: 0.6275, Test AUC: 0.6462, Test AUPR: 0.6148\n",
      "Epoch: 32/100, Loss: 0.6589682, Train Acc: 0.6124, Test Acc: 0.6043, Train AUC: 0.6492, Train APUR: 0.6292, Test AUC: 0.6502, Test AUPR: 0.6167\n",
      "Epoch: 33/100, Loss: 0.6588392, Train Acc: 0.6100, Test Acc: 0.6034, Train AUC: 0.6500, Train APUR: 0.6288, Test AUC: 0.6521, Test AUPR: 0.6177\n",
      "Epoch: 34/100, Loss: 0.6578016, Train Acc: 0.6094, Test Acc: 0.6070, Train AUC: 0.6518, Train APUR: 0.6300, Test AUC: 0.6524, Test AUPR: 0.6190\n",
      "Epoch: 35/100, Loss: 0.6572559, Train Acc: 0.6113, Test Acc: 0.6089, Train AUC: 0.6520, Train APUR: 0.6313, Test AUC: 0.6528, Test AUPR: 0.6209\n",
      "Epoch: 36/100, Loss: 0.6567954, Train Acc: 0.6136, Test Acc: 0.6109, Train AUC: 0.6532, Train APUR: 0.6325, Test AUC: 0.6533, Test AUPR: 0.6232\n",
      "Epoch: 37/100, Loss: 0.6563793, Train Acc: 0.6150, Test Acc: 0.6110, Train AUC: 0.6537, Train APUR: 0.6337, Test AUC: 0.6546, Test AUPR: 0.6254\n",
      "Epoch: 38/100, Loss: 0.6559712, Train Acc: 0.6109, Test Acc: 0.6186, Train AUC: 0.6543, Train APUR: 0.6342, Test AUC: 0.6563, Test AUPR: 0.6281\n",
      "Epoch: 39/100, Loss: 0.6554767, Train Acc: 0.6138, Test Acc: 0.6288, Train AUC: 0.6552, Train APUR: 0.6351, Test AUC: 0.6574, Test AUPR: 0.6304\n",
      "Epoch: 40/100, Loss: 0.6551917, Train Acc: 0.6160, Test Acc: 0.6301, Train AUC: 0.6563, Train APUR: 0.6368, Test AUC: 0.6601, Test AUPR: 0.6341\n",
      "Epoch: 41/100, Loss: 0.6550637, Train Acc: 0.6159, Test Acc: 0.6256, Train AUC: 0.6565, Train APUR: 0.6376, Test AUC: 0.6628, Test AUPR: 0.6377\n",
      "Epoch: 42/100, Loss: 0.6536664, Train Acc: 0.6166, Test Acc: 0.6190, Train AUC: 0.6585, Train APUR: 0.6402, Test AUC: 0.6641, Test AUPR: 0.6405\n",
      "Epoch: 43/100, Loss: 0.6532500, Train Acc: 0.6151, Test Acc: 0.6267, Train AUC: 0.6597, Train APUR: 0.6413, Test AUC: 0.6678, Test AUPR: 0.6446\n",
      "Epoch: 44/100, Loss: 0.6516932, Train Acc: 0.6192, Test Acc: 0.6274, Train AUC: 0.6627, Train APUR: 0.6438, Test AUC: 0.6713, Test AUPR: 0.6480\n",
      "Epoch: 45/100, Loss: 0.6510165, Train Acc: 0.6201, Test Acc: 0.6205, Train AUC: 0.6640, Train APUR: 0.6460, Test AUC: 0.6733, Test AUPR: 0.6506\n",
      "Epoch: 46/100, Loss: 0.6501539, Train Acc: 0.6162, Test Acc: 0.6239, Train AUC: 0.6653, Train APUR: 0.6465, Test AUC: 0.6768, Test AUPR: 0.6546\n",
      "Epoch: 47/100, Loss: 0.6490276, Train Acc: 0.6203, Test Acc: 0.6311, Train AUC: 0.6675, Train APUR: 0.6489, Test AUC: 0.6807, Test AUPR: 0.6589\n",
      "Epoch: 48/100, Loss: 0.6471443, Train Acc: 0.6205, Test Acc: 0.6323, Train AUC: 0.6706, Train APUR: 0.6519, Test AUC: 0.6825, Test AUPR: 0.6620\n",
      "Epoch: 49/100, Loss: 0.6461371, Train Acc: 0.6221, Test Acc: 0.6371, Train AUC: 0.6721, Train APUR: 0.6534, Test AUC: 0.6876, Test AUPR: 0.6662\n",
      "Epoch: 50/100, Loss: 0.6453476, Train Acc: 0.6268, Test Acc: 0.6365, Train AUC: 0.6747, Train APUR: 0.6554, Test AUC: 0.6900, Test AUPR: 0.6694\n",
      "Epoch: 51/100, Loss: 0.6443674, Train Acc: 0.6261, Test Acc: 0.6575, Train AUC: 0.6752, Train APUR: 0.6568, Test AUC: 0.6995, Test AUPR: 0.6755\n",
      "Epoch: 52/100, Loss: 0.6411628, Train Acc: 0.6354, Test Acc: 0.6628, Train AUC: 0.6835, Train APUR: 0.6629, Test AUC: 0.7029, Test AUPR: 0.6777\n",
      "Epoch: 53/100, Loss: 0.6388836, Train Acc: 0.6428, Test Acc: 0.6451, Train AUC: 0.6884, Train APUR: 0.6668, Test AUC: 0.6936, Test AUPR: 0.6745\n",
      "Epoch: 54/100, Loss: 0.6406732, Train Acc: 0.6371, Test Acc: 0.6674, Train AUC: 0.6824, Train APUR: 0.6636, Test AUC: 0.7116, Test AUPR: 0.6838\n",
      "Epoch: 55/100, Loss: 0.6374499, Train Acc: 0.6522, Test Acc: 0.6588, Train AUC: 0.6945, Train APUR: 0.6716, Test AUC: 0.7081, Test AUPR: 0.6866\n",
      "Epoch: 56/100, Loss: 0.6335926, Train Acc: 0.6501, Test Acc: 0.6602, Train AUC: 0.6956, Train APUR: 0.6760, Test AUC: 0.7107, Test AUPR: 0.6902\n",
      "Epoch: 57/100, Loss: 0.6326294, Train Acc: 0.6513, Test Acc: 0.6659, Train AUC: 0.6971, Train APUR: 0.6765, Test AUC: 0.7206, Test AUPR: 0.6967\n",
      "Epoch: 58/100, Loss: 0.6310799, Train Acc: 0.6526, Test Acc: 0.6624, Train AUC: 0.7024, Train APUR: 0.6796, Test AUC: 0.7194, Test AUPR: 0.7007\n",
      "Epoch: 59/100, Loss: 0.6274205, Train Acc: 0.6549, Test Acc: 0.6660, Train AUC: 0.7042, Train APUR: 0.6843, Test AUC: 0.7259, Test AUPR: 0.7058\n",
      "Epoch: 60/100, Loss: 0.6265937, Train Acc: 0.6533, Test Acc: 0.6669, Train AUC: 0.7070, Train APUR: 0.6868, Test AUC: 0.7258, Test AUPR: 0.7090\n",
      "Epoch: 61/100, Loss: 0.6254673, Train Acc: 0.6545, Test Acc: 0.6700, Train AUC: 0.7070, Train APUR: 0.6862, Test AUC: 0.7310, Test AUPR: 0.7129\n",
      "Epoch: 62/100, Loss: 0.6248129, Train Acc: 0.6529, Test Acc: 0.6589, Train AUC: 0.7112, Train APUR: 0.6910, Test AUC: 0.7160, Test AUPR: 0.7039\n",
      "Epoch: 63/100, Loss: 0.6243684, Train Acc: 0.6504, Test Acc: 0.6692, Train AUC: 0.7070, Train APUR: 0.6911, Test AUC: 0.7306, Test AUPR: 0.7118\n",
      "Epoch: 64/100, Loss: 0.6213139, Train Acc: 0.6526, Test Acc: 0.6718, Train AUC: 0.7134, Train APUR: 0.6943, Test AUC: 0.7335, Test AUPR: 0.7175\n",
      "Epoch: 65/100, Loss: 0.6196327, Train Acc: 0.6555, Test Acc: 0.6538, Train AUC: 0.7134, Train APUR: 0.6952, Test AUC: 0.7094, Test AUPR: 0.7034\n",
      "Epoch: 66/100, Loss: 0.6292031, Train Acc: 0.6486, Test Acc: 0.6734, Train AUC: 0.7024, Train APUR: 0.6889, Test AUC: 0.7389, Test AUPR: 0.7270\n",
      "Epoch: 67/100, Loss: 0.6149150, Train Acc: 0.6589, Test Acc: 0.6725, Train AUC: 0.7198, Train APUR: 0.7031, Test AUC: 0.7369, Test AUPR: 0.7222\n",
      "Epoch: 68/100, Loss: 0.6185274, Train Acc: 0.6555, Test Acc: 0.6775, Train AUC: 0.7166, Train APUR: 0.6996, Test AUC: 0.7429, Test AUPR: 0.7317\n",
      "Epoch: 69/100, Loss: 0.6135167, Train Acc: 0.6601, Test Acc: 0.6640, Train AUC: 0.7209, Train APUR: 0.7066, Test AUC: 0.7246, Test AUPR: 0.7189\n",
      "Epoch: 70/100, Loss: 0.6167293, Train Acc: 0.6570, Test Acc: 0.6716, Train AUC: 0.7164, Train APUR: 0.7051, Test AUC: 0.7374, Test AUPR: 0.7302\n",
      "Epoch: 71/100, Loss: 0.6155026, Train Acc: 0.6587, Test Acc: 0.6739, Train AUC: 0.7183, Train APUR: 0.7046, Test AUC: 0.7409, Test AUPR: 0.7296\n",
      "Epoch: 72/100, Loss: 0.6158562, Train Acc: 0.6583, Test Acc: 0.6774, Train AUC: 0.7179, Train APUR: 0.7032, Test AUC: 0.7458, Test AUPR: 0.7337\n",
      "Epoch: 73/100, Loss: 0.6099002, Train Acc: 0.6631, Test Acc: 0.6775, Train AUC: 0.7261, Train APUR: 0.7135, Test AUC: 0.7456, Test AUPR: 0.7370\n",
      "Epoch: 74/100, Loss: 0.6132331, Train Acc: 0.6616, Test Acc: 0.6795, Train AUC: 0.7218, Train APUR: 0.7067, Test AUC: 0.7494, Test AUPR: 0.7410\n",
      "Epoch: 75/100, Loss: 0.6084504, Train Acc: 0.6635, Test Acc: 0.6845, Train AUC: 0.7268, Train APUR: 0.7168, Test AUC: 0.7525, Test AUPR: 0.7391\n",
      "Epoch: 76/100, Loss: 0.6079613, Train Acc: 0.6654, Test Acc: 0.6866, Train AUC: 0.7261, Train APUR: 0.7146, Test AUC: 0.7565, Test AUPR: 0.7427\n",
      "Epoch: 77/100, Loss: 0.6052616, Train Acc: 0.6667, Test Acc: 0.6815, Train AUC: 0.7290, Train APUR: 0.7196, Test AUC: 0.7504, Test AUPR: 0.7421\n",
      "Epoch: 78/100, Loss: 0.6082351, Train Acc: 0.6640, Test Acc: 0.6892, Train AUC: 0.7267, Train APUR: 0.7175, Test AUC: 0.7595, Test AUPR: 0.7512\n",
      "Epoch: 79/100, Loss: 0.6025927, Train Acc: 0.6667, Test Acc: 0.6893, Train AUC: 0.7314, Train APUR: 0.7241, Test AUC: 0.7617, Test AUPR: 0.7535\n",
      "Epoch: 80/100, Loss: 0.6041301, Train Acc: 0.6670, Test Acc: 0.6945, Train AUC: 0.7316, Train APUR: 0.7228, Test AUC: 0.7659, Test AUPR: 0.7588\n",
      "Epoch: 81/100, Loss: 0.6003014, Train Acc: 0.6705, Test Acc: 0.6908, Train AUC: 0.7358, Train APUR: 0.7274, Test AUC: 0.7653, Test AUPR: 0.7584\n",
      "Epoch: 82/100, Loss: 0.6011134, Train Acc: 0.6683, Test Acc: 0.6998, Train AUC: 0.7348, Train APUR: 0.7270, Test AUC: 0.7720, Test AUPR: 0.7644\n",
      "Epoch: 83/100, Loss: 0.5993991, Train Acc: 0.6706, Test Acc: 0.7002, Train AUC: 0.7373, Train APUR: 0.7288, Test AUC: 0.7742, Test AUPR: 0.7653\n",
      "Epoch: 84/100, Loss: 0.5980625, Train Acc: 0.6724, Test Acc: 0.7027, Train AUC: 0.7383, Train APUR: 0.7308, Test AUC: 0.7758, Test AUPR: 0.7651\n",
      "Epoch: 85/100, Loss: 0.5963501, Train Acc: 0.6727, Test Acc: 0.7035, Train AUC: 0.7388, Train APUR: 0.7328, Test AUC: 0.7765, Test AUPR: 0.7658\n",
      "Epoch: 86/100, Loss: 0.5960727, Train Acc: 0.6740, Test Acc: 0.7083, Train AUC: 0.7397, Train APUR: 0.7315, Test AUC: 0.7830, Test AUPR: 0.7675\n",
      "Epoch: 87/100, Loss: 0.5941843, Train Acc: 0.6759, Test Acc: 0.7105, Train AUC: 0.7423, Train APUR: 0.7337, Test AUC: 0.7854, Test AUPR: 0.7696\n",
      "Epoch: 88/100, Loss: 0.5932657, Train Acc: 0.6757, Test Acc: 0.7120, Train AUC: 0.7434, Train APUR: 0.7351, Test AUC: 0.7879, Test AUPR: 0.7776\n",
      "Epoch: 89/100, Loss: 0.5917820, Train Acc: 0.6784, Test Acc: 0.7113, Train AUC: 0.7444, Train APUR: 0.7371, Test AUC: 0.7888, Test AUPR: 0.7789\n",
      "Epoch: 90/100, Loss: 0.5921174, Train Acc: 0.6772, Test Acc: 0.7070, Train AUC: 0.7442, Train APUR: 0.7386, Test AUC: 0.7837, Test AUPR: 0.7793\n",
      "Epoch: 91/100, Loss: 0.5950493, Train Acc: 0.6731, Test Acc: 0.7122, Train AUC: 0.7409, Train APUR: 0.7343, Test AUC: 0.7857, Test AUPR: 0.7738\n",
      "Epoch: 92/100, Loss: 0.5957519, Train Acc: 0.6727, Test Acc: 0.7109, Train AUC: 0.7388, Train APUR: 0.7328, Test AUC: 0.7861, Test AUPR: 0.7827\n",
      "Epoch: 93/100, Loss: 0.5926545, Train Acc: 0.6766, Test Acc: 0.7214, Train AUC: 0.7429, Train APUR: 0.7378, Test AUC: 0.7999, Test AUPR: 0.7924\n",
      "Epoch: 94/100, Loss: 0.5867137, Train Acc: 0.6809, Test Acc: 0.7181, Train AUC: 0.7506, Train APUR: 0.7456, Test AUC: 0.7947, Test AUPR: 0.7815\n",
      "Epoch: 95/100, Loss: 0.5880609, Train Acc: 0.6804, Test Acc: 0.7234, Train AUC: 0.7486, Train APUR: 0.7430, Test AUC: 0.8026, Test AUPR: 0.7934\n",
      "Epoch: 96/100, Loss: 0.5862232, Train Acc: 0.6818, Test Acc: 0.7228, Train AUC: 0.7511, Train APUR: 0.7455, Test AUC: 0.8021, Test AUPR: 0.7941\n",
      "Epoch: 97/100, Loss: 0.5861679, Train Acc: 0.6812, Test Acc: 0.7188, Train AUC: 0.7509, Train APUR: 0.7458, Test AUC: 0.7948, Test AUPR: 0.7826\n",
      "Epoch: 98/100, Loss: 0.5869408, Train Acc: 0.6800, Test Acc: 0.7218, Train AUC: 0.7489, Train APUR: 0.7434, Test AUC: 0.8020, Test AUPR: 0.7944\n",
      "Epoch: 99/100, Loss: 0.5849124, Train Acc: 0.6823, Test Acc: 0.7204, Train AUC: 0.7518, Train APUR: 0.7471, Test AUC: 0.7988, Test AUPR: 0.7939\n",
      "Epoch: 100/100, Loss: 0.5862859, Train Acc: 0.6807, Test Acc: 0.7264, Train AUC: 0.7507, Train APUR: 0.7458, Test AUC: 0.8056, Test AUPR: 0.7959\n",
      "/home/ubuntu/PA-Cancer-Immunotherapy/GNN/train_pa_all.py:245: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(configs['save_model']))\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 78.279 MB of 78.374 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 78.375 MB of 78.375 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 78.375 MB of 78.375 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 78.375 MB of 78.375 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▇▇▇▇▇▇▇▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      test_aupr ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   test_roc_auc ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▁▃▃▄▄▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇██████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_aupr ▁▁▁▂▂▂▃▃▃▃▃▃▃▄▄▄▅▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇███████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss ██▇▇▇▆▇▆▆▆▆▆▆▆▆▆▆▆▆▆▅▅▅▅▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_roc_auc ▁▂▂▃▃▃▄▄▄▄▄▄▄▄▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇███████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: valid_accuracy ▁▃▃▃▄▄▄▄▄▄▅▄▅▄▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇███████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     valid_aupr ▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▅▅▆▅▆▆▆▆▆▇▇▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  valid_roc_auc ▁▂▂▂▃▃▃▃▃▃▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇█████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy 0.72644\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      test_aupr 0.79588\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   test_roc_auc 0.8056\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.68074\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_aupr 0.74584\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.58629\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_roc_auc 0.75067\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: valid_accuracy 0.72644\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     valid_aupr 0.79588\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  valid_roc_auc 0.8056\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mexalted-wave-6\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-one-allele_GNN/runs/rl5m7xfr\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-one-allele_GNN\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 140 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241206_014005-rl5m7xfr/logs\u001b[0m\n",
      "Test Acc: 0.7264, Test AUC: 0.8056, Test AUPR: 0.7959\n"
     ]
    }
   ],
   "source": [
    "# and for gene:\n",
    "\n",
    "! python train_pa_all_one.py --gpu 0 --configs_path configs/PA_all_one_gene.yml --droup_out 0.1 --split StrictTCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb713128-a2dd-46f8-8b6b-468113a266f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7919e2-26ee-441d-92ef-bb5a36fc2422",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc7ffc6-2a84-40fc-a6a7-33d4e9d30df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================================================================================\n",
    "# PROJECT: TVT TRAIN-VALIDATION-TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee77992-8236-4984-8f77-d18dd1657340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This might be the project I should have done from the begining...\n",
    "# The train, validation and test data from BA will be used as train validation test data for the gnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d294aae8-672a-4718-8b0f-e39f1f9e5a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./processed_data/PA_all_tvt/allele_train.csv\n",
      "Saved: ./processed_data/PA_all_tvt/allele_validation.csv\n",
      "Saved: ./processed_data/PA_all_tvt/allele_test.csv\n",
      "Saved: ./processed_data/PA_all_tvt/gene_train.csv\n",
      "Saved: ./processed_data/PA_all_tvt/gene_validation.csv\n",
      "Saved: ./processed_data/PA_all_tvt/gene_test.csv\n"
     ]
    }
   ],
   "source": [
    "# just added 'task' for TTP (17.12.)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "ppl_path = \"./data_for_training/splitted_datasets/\"\n",
    "precisions = [\"allele\", \"gene\"]\n",
    "for precision in precisions:\n",
    "    train = f\"{ppl_path}{precision}/beta/train.tsv\"\n",
    "    valid = f\"{ppl_path}{precision}/beta/validation.tsv\"\n",
    "    test = f\"{ppl_path}{precision}/beta/test.tsv\"\n",
    "    train_df = pd.read_csv(train, sep='\\t')\n",
    "    train_df = train_df[['TRB_CDR3', 'Epitope', 'Binding']]\n",
    "    valid_df = pd.read_csv(valid, sep='\\t')\n",
    "    valid_df = valid_df[['TRB_CDR3', 'Epitope', 'Binding']]\n",
    "    test_df = pd.read_csv(test, sep='\\t')\n",
    "    test_df = test_df[['TRB_CDR3', 'Epitope', 'Binding','task']]\n",
    "\n",
    "    columns_to_rename = {'TRB_CDR3': 'CDR3.beta','Binding': 'Label'}\n",
    "    train_df.rename(columns=columns_to_rename, inplace=True)\n",
    "    valid_df.rename(columns=columns_to_rename, inplace=True)\n",
    "    test_df.rename(columns=columns_to_rename, inplace=True)\n",
    "    train_df = train_df[train_df['CDR3.beta'].apply(len) <= 30]\n",
    "    train_df = train_df[train_df['Epitope'].apply(len) <= 30]\n",
    "    valid_df = valid_df[valid_df['CDR3.beta'].apply(len) <= 30]\n",
    "    valid_df = valid_df[valid_df['Epitope'].apply(len) <= 30]\n",
    "    test_df = test_df[test_df['CDR3.beta'].apply(len) <= 30]\n",
    "    test_df = test_df[test_df['Epitope'].apply(len) <= 30]\n",
    "    save_path_train = f\"./processed_data/PA_all_tvt/{precision}_train.csv\"\n",
    "    save_path_valid = f\"./processed_data/PA_all_tvt/{precision}_validation.csv\"\n",
    "    save_path_test = f\"./processed_data/PA_all_tvt/{precision}_test.csv\"\n",
    "    train_df.to_csv(save_path_train, index=False)\n",
    "    print(f\"Saved: {save_path_train}\")\n",
    "    valid_df.to_csv(save_path_valid, index=False)\n",
    "    print(f\"Saved: {save_path_valid}\")\n",
    "    test_df.to_csv(save_path_test, index=False)\n",
    "    print(f\"Saved: {save_path_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60a2c092-d0fb-4f80-ace1-8b72501feda7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploading dataset to dataset-all-tvt-allele_GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfrohoari\u001b[0m (\u001b[33mpa_cancerimmunotherapy\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/PA-Cancer-Immunotherapy/GNN/wandb/run-20241206_205028-ydhw7ibt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-allele_GNN/runs/ydhw7ibt' target=\"_blank\">silver-aardvark-1</a></strong> to <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-allele_GNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-allele_GNN' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-allele_GNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-allele_GNN/runs/ydhw7ibt' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-allele_GNN/runs/ydhw7ibt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./processed_data/PA_all_tvt)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploading dataset to dataset-all-tvt-allele_GNN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:ydhw7ibt) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.223 MB of 21.909 MB uploaded\\r'), FloatProgress(value=0.055844149116976834, max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">silver-aardvark-1</strong> at: <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-allele_GNN/runs/ydhw7ibt' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-allele_GNN/runs/ydhw7ibt</a><br/> View project at: <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-allele_GNN' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-allele_GNN</a><br/>Synced 4 W&B file(s), 0 media file(s), 10 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241206_205028-ydhw7ibt/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:ydhw7ibt). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/PA-Cancer-Immunotherapy/GNN/wandb/run-20241206_205028-4eeg6dvr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-allele_GNN/runs/4eeg6dvr' target=\"_blank\">kind-wildflower-2</a></strong> to <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-allele_GNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-allele_GNN' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-allele_GNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-allele_GNN/runs/4eeg6dvr' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-allele_GNN/runs/4eeg6dvr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./processed_data/PA_all_tvt)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploading dataset to dataset-all-tvt-allele_GNN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:4eeg6dvr) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.223 MB of 21.909 MB uploaded\\r'), FloatProgress(value=0.055844149116976834, max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">kind-wildflower-2</strong> at: <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-allele_GNN/runs/4eeg6dvr' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-allele_GNN/runs/4eeg6dvr</a><br/> View project at: <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-allele_GNN' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-allele_GNN</a><br/>Synced 5 W&B file(s), 0 media file(s), 7 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241206_205028-4eeg6dvr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:4eeg6dvr). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/PA-Cancer-Immunotherapy/GNN/wandb/run-20241206_205036-5eac98hz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-allele_GNN/runs/5eac98hz' target=\"_blank\">legendary-planet-3</a></strong> to <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-allele_GNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-allele_GNN' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-allele_GNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-allele_GNN/runs/5eac98hz' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-allele_GNN/runs/5eac98hz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./processed_data/PA_all_tvt)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploading dataset to dataset-all-tvt-gene_GNN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:5eac98hz) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.239 MB of 21.909 MB uploaded\\r'), FloatProgress(value=0.056557242930496986, max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">legendary-planet-3</strong> at: <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-allele_GNN/runs/5eac98hz' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-allele_GNN/runs/5eac98hz</a><br/> View project at: <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-allele_GNN' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-allele_GNN</a><br/>Synced 5 W&B file(s), 0 media file(s), 7 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241206_205036-5eac98hz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:5eac98hz). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/PA-Cancer-Immunotherapy/GNN/wandb/run-20241206_205043-7aoadetw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-gene_GNN/runs/7aoadetw' target=\"_blank\">faithful-leaf-1</a></strong> to <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-gene_GNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-gene_GNN' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-gene_GNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-gene_GNN/runs/7aoadetw' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-gene_GNN/runs/7aoadetw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./processed_data/PA_all_tvt)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploading dataset to dataset-all-tvt-gene_GNN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:7aoadetw) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.223 MB of 21.909 MB uploaded\\r'), FloatProgress(value=0.05584406692101711, max=1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">faithful-leaf-1</strong> at: <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-gene_GNN/runs/7aoadetw' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-gene_GNN/runs/7aoadetw</a><br/> View project at: <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-gene_GNN' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-gene_GNN</a><br/>Synced 4 W&B file(s), 0 media file(s), 10 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241206_205043-7aoadetw/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:7aoadetw). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/PA-Cancer-Immunotherapy/GNN/wandb/run-20241206_205049-38e9pkga</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-gene_GNN/runs/38e9pkga' target=\"_blank\">stellar-serenity-2</a></strong> to <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-gene_GNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-gene_GNN' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-gene_GNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-gene_GNN/runs/38e9pkga' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-gene_GNN/runs/38e9pkga</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./processed_data/PA_all_tvt)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploading dataset to dataset-all-tvt-gene_GNN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:38e9pkga) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bea483155bd7451e96c87becd89d270d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.223 MB of 21.909 MB uploaded\\r'), FloatProgress(value=0.05584406692101711, max=1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">stellar-serenity-2</strong> at: <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-gene_GNN/runs/38e9pkga' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-gene_GNN/runs/38e9pkga</a><br/> View project at: <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-gene_GNN' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-gene_GNN</a><br/>Synced 5 W&B file(s), 0 media file(s), 7 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241206_205049-38e9pkga/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:38e9pkga). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/PA-Cancer-Immunotherapy/GNN/wandb/run-20241206_205057-5azjgxln</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-gene_GNN/runs/5azjgxln' target=\"_blank\">sleek-elevator-3</a></strong> to <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-gene_GNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-gene_GNN' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-gene_GNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-gene_GNN/runs/5azjgxln' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-gene_GNN/runs/5azjgxln</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./processed_data/PA_all_tvt)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f91035dbda564000ab1acca44732b018",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.239 MB of 21.909 MB uploaded\\r'), FloatProgress(value=0.0565553538474865, max=1.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sleek-elevator-3</strong> at: <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-gene_GNN/runs/5azjgxln' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-gene_GNN/runs/5azjgxln</a><br/> View project at: <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-gene_GNN' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-gene_GNN</a><br/>Synced 5 W&B file(s), 0 media file(s), 7 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241206_205057-5azjgxln/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Datan hochladen auf wandb\n",
    "\n",
    "import wandb\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "#/home/ubuntu/PA-Cancer-Immunotherapy/GNN/processed_data/PA_all\n",
    "# upload paired data\n",
    "path_to_data = './processed_data/PA_all_tvt/' # path zu unseren Daten\n",
    "precisions = [\"allele\", \"gene\"]\n",
    "\n",
    "for precision in precisions:\n",
    "    \n",
    "    main_project_name = f\"dataset-all-tvt-{precision}_GNN\" # das erscheint auf wandb projects \n",
    "    \n",
    "\n",
    "    datasets_names = ['train.csv', 'validation.csv', 'test.csv']\n",
    "    for dataset_name in datasets_names:\n",
    "        #main_project_name = os.getenv(\"MAIN_PROJECT_NAME\")\n",
    "        print(f\"uploading dataset to {main_project_name}\")\n",
    "        run = wandb.init(project=main_project_name, job_type=\"Upload Dataset\", entity=\"pa_cancerimmunotherapy\")\n",
    "        artifact = wandb.Artifact(name=dataset_name, type=\"dataset\")\n",
    "        artifact.add_dir(path_to_data, name=f\"{precision}_\")\n",
    "        run.log_artifact(artifact)\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10471bf3-5f65-400c-803d-b30f44dca20f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(gpu=0, lr=0.001, epochs=100, w_celoss=1, w_aucloss=0, add_same_type_edges=False, dynamic_graph=False, dynamic_ratio=0.05, droup_out=0.1, positive_weights=1, dynamic_epochs=30, distance_threshold=10, configs_path='configs/PA_all_tvt_allele.yml', split='StrictTCR', dataset='pMTnet')\n",
      "PROJECT_NAME: dataset-all-tvt-allele_GNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfrohoari\u001b[0m (\u001b[33mpa_cancerimmunotherapy\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/ubuntu/PA-Cancer-Immunotherapy/GNN/wandb/run-20241206_210112-1vgj835w\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mcrisp-sound-5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-allele_GNN\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-allele_GNN/runs/1vgj835w\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   6 of 6 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   6 of 6 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   6 of 6 files downloaded.  \n",
      "embeddings_path:   models/PA_all/gene_and_allele_embeddings.pkl\n",
      "train_file_list:   ['allele_train.csv']\n",
      "validation_file_list:   ['allele_validation.csv']\n",
      "test_file_list:   ['allele_test.csv']\n",
      "wandb logger initialisiert\n",
      "Epoch: 1/100, Loss: 0.6935461, Train Acc: 0.4871, Test Acc: 0.5031, Train AUC: 0.4853, Train APUR: 0.4985, Test AUC: 0.5574, Test AUPR: 0.5489\n",
      "Epoch: 2/100, Loss: 0.6912209, Train Acc: 0.5072, Test Acc: 0.5374, Train AUC: 0.5700, Train APUR: 0.5563, Test AUC: 0.5625, Test AUPR: 0.5545\n",
      "Epoch: 3/100, Loss: 0.6868216, Train Acc: 0.5492, Test Acc: 0.5559, Train AUC: 0.5897, Train APUR: 0.5732, Test AUC: 0.5627, Test AUPR: 0.5554\n",
      "Epoch: 4/100, Loss: 0.6830894, Train Acc: 0.5681, Test Acc: 0.5254, Train AUC: 0.5979, Train APUR: 0.5825, Test AUC: 0.5638, Test AUPR: 0.5561\n",
      "Epoch: 5/100, Loss: 0.6811143, Train Acc: 0.5708, Test Acc: 0.5635, Train AUC: 0.5971, Train APUR: 0.5814, Test AUC: 0.5717, Test AUPR: 0.5601\n",
      "Epoch: 6/100, Loss: 0.6785971, Train Acc: 0.5794, Test Acc: 0.5686, Train AUC: 0.6035, Train APUR: 0.5817, Test AUC: 0.5820, Test AUPR: 0.5668\n",
      "Epoch: 7/100, Loss: 0.6762490, Train Acc: 0.5827, Test Acc: 0.5646, Train AUC: 0.6095, Train APUR: 0.5865, Test AUC: 0.5916, Test AUPR: 0.5750\n",
      "Epoch: 8/100, Loss: 0.6739103, Train Acc: 0.5884, Test Acc: 0.5709, Train AUC: 0.6144, Train APUR: 0.5888, Test AUC: 0.6053, Test AUPR: 0.5892\n",
      "Epoch: 9/100, Loss: 0.6727347, Train Acc: 0.5906, Test Acc: 0.5719, Train AUC: 0.6205, Train APUR: 0.5967, Test AUC: 0.6136, Test AUPR: 0.5963\n",
      "Epoch: 10/100, Loss: 0.6755972, Train Acc: 0.5845, Test Acc: 0.5816, Train AUC: 0.6251, Train APUR: 0.6019, Test AUC: 0.6210, Test AUPR: 0.6037\n",
      "Epoch: 11/100, Loss: 0.6703852, Train Acc: 0.5963, Test Acc: 0.5930, Train AUC: 0.6258, Train APUR: 0.5979, Test AUC: 0.6240, Test AUPR: 0.6067\n",
      "Epoch: 12/100, Loss: 0.6712688, Train Acc: 0.5934, Test Acc: 0.5879, Train AUC: 0.6284, Train APUR: 0.6031, Test AUC: 0.6255, Test AUPR: 0.6085\n",
      "Epoch: 13/100, Loss: 0.6690725, Train Acc: 0.5990, Test Acc: 0.5790, Train AUC: 0.6267, Train APUR: 0.6020, Test AUC: 0.6263, Test AUPR: 0.6095\n",
      "Epoch: 14/100, Loss: 0.6691639, Train Acc: 0.5916, Test Acc: 0.5831, Train AUC: 0.6315, Train APUR: 0.6073, Test AUC: 0.6278, Test AUPR: 0.6113\n",
      "Epoch: 15/100, Loss: 0.6671296, Train Acc: 0.5957, Test Acc: 0.5961, Train AUC: 0.6327, Train APUR: 0.6113, Test AUC: 0.6292, Test AUPR: 0.6127\n",
      "Epoch: 16/100, Loss: 0.6659300, Train Acc: 0.6015, Test Acc: 0.5872, Train AUC: 0.6343, Train APUR: 0.6097, Test AUC: 0.6288, Test AUPR: 0.6126\n",
      "Epoch: 17/100, Loss: 0.6663696, Train Acc: 0.6022, Test Acc: 0.5865, Train AUC: 0.6361, Train APUR: 0.6136, Test AUC: 0.6281, Test AUPR: 0.6121\n",
      "Epoch: 18/100, Loss: 0.6651689, Train Acc: 0.6025, Test Acc: 0.5945, Train AUC: 0.6376, Train APUR: 0.6140, Test AUC: 0.6275, Test AUPR: 0.6116\n",
      "Epoch: 19/100, Loss: 0.6639980, Train Acc: 0.6025, Test Acc: 0.5927, Train AUC: 0.6390, Train APUR: 0.6169, Test AUC: 0.6262, Test AUPR: 0.6105\n",
      "Epoch: 20/100, Loss: 0.6641960, Train Acc: 0.6008, Test Acc: 0.5947, Train AUC: 0.6384, Train APUR: 0.6165, Test AUC: 0.6258, Test AUPR: 0.6104\n",
      "Epoch: 21/100, Loss: 0.6624004, Train Acc: 0.6027, Test Acc: 0.5811, Train AUC: 0.6412, Train APUR: 0.6192, Test AUC: 0.6260, Test AUPR: 0.6110\n",
      "Epoch: 22/100, Loss: 0.6621095, Train Acc: 0.6050, Test Acc: 0.5806, Train AUC: 0.6420, Train APUR: 0.6198, Test AUC: 0.6279, Test AUPR: 0.6128\n",
      "Epoch: 23/100, Loss: 0.6618519, Train Acc: 0.6069, Test Acc: 0.5826, Train AUC: 0.6421, Train APUR: 0.6192, Test AUC: 0.6277, Test AUPR: 0.6128\n",
      "Epoch: 24/100, Loss: 0.6605166, Train Acc: 0.6057, Test Acc: 0.5860, Train AUC: 0.6455, Train APUR: 0.6227, Test AUC: 0.6281, Test AUPR: 0.6131\n",
      "Epoch: 25/100, Loss: 0.6601804, Train Acc: 0.6091, Test Acc: 0.5834, Train AUC: 0.6475, Train APUR: 0.6241, Test AUC: 0.6293, Test AUPR: 0.6138\n",
      "Epoch: 26/100, Loss: 0.6592426, Train Acc: 0.6074, Test Acc: 0.5824, Train AUC: 0.6475, Train APUR: 0.6251, Test AUC: 0.6317, Test AUPR: 0.6156\n",
      "Epoch: 27/100, Loss: 0.6592296, Train Acc: 0.6086, Test Acc: 0.5958, Train AUC: 0.6474, Train APUR: 0.6254, Test AUC: 0.6344, Test AUPR: 0.6176\n",
      "Epoch: 28/100, Loss: 0.6580057, Train Acc: 0.6065, Test Acc: 0.6010, Train AUC: 0.6497, Train APUR: 0.6277, Test AUC: 0.6400, Test AUPR: 0.6218\n",
      "Epoch: 29/100, Loss: 0.6574144, Train Acc: 0.6078, Test Acc: 0.6027, Train AUC: 0.6504, Train APUR: 0.6295, Test AUC: 0.6435, Test AUPR: 0.6243\n",
      "Epoch: 30/100, Loss: 0.6565055, Train Acc: 0.6099, Test Acc: 0.6106, Train AUC: 0.6522, Train APUR: 0.6310, Test AUC: 0.6478, Test AUPR: 0.6270\n",
      "Epoch: 31/100, Loss: 0.6562824, Train Acc: 0.6096, Test Acc: 0.6267, Train AUC: 0.6534, Train APUR: 0.6316, Test AUC: 0.6495, Test AUPR: 0.6279\n",
      "Epoch: 32/100, Loss: 0.6555820, Train Acc: 0.6109, Test Acc: 0.6275, Train AUC: 0.6545, Train APUR: 0.6325, Test AUC: 0.6512, Test AUPR: 0.6292\n",
      "Epoch: 33/100, Loss: 0.6538488, Train Acc: 0.6140, Test Acc: 0.6194, Train AUC: 0.6569, Train APUR: 0.6345, Test AUC: 0.6526, Test AUPR: 0.6304\n",
      "Epoch: 34/100, Loss: 0.6533172, Train Acc: 0.6124, Test Acc: 0.6296, Train AUC: 0.6580, Train APUR: 0.6369, Test AUC: 0.6537, Test AUPR: 0.6316\n",
      "Epoch: 35/100, Loss: 0.6529697, Train Acc: 0.6145, Test Acc: 0.6300, Train AUC: 0.6579, Train APUR: 0.6372, Test AUC: 0.6541, Test AUPR: 0.6325\n",
      "Epoch: 36/100, Loss: 0.6512406, Train Acc: 0.6144, Test Acc: 0.6202, Train AUC: 0.6607, Train APUR: 0.6404, Test AUC: 0.6543, Test AUPR: 0.6327\n",
      "Epoch: 37/100, Loss: 0.6516874, Train Acc: 0.6143, Test Acc: 0.6235, Train AUC: 0.6617, Train APUR: 0.6421, Test AUC: 0.6538, Test AUPR: 0.6337\n",
      "Epoch: 38/100, Loss: 0.6493883, Train Acc: 0.6157, Test Acc: 0.6168, Train AUC: 0.6645, Train APUR: 0.6444, Test AUC: 0.6538, Test AUPR: 0.6348\n",
      "Epoch: 39/100, Loss: 0.6488023, Train Acc: 0.6165, Test Acc: 0.6161, Train AUC: 0.6664, Train APUR: 0.6470, Test AUC: 0.6547, Test AUPR: 0.6372\n",
      "Epoch: 40/100, Loss: 0.6469296, Train Acc: 0.6157, Test Acc: 0.6148, Train AUC: 0.6686, Train APUR: 0.6505, Test AUC: 0.6559, Test AUPR: 0.6383\n",
      "Epoch: 41/100, Loss: 0.6458932, Train Acc: 0.6198, Test Acc: 0.6187, Train AUC: 0.6705, Train APUR: 0.6511, Test AUC: 0.6527, Test AUPR: 0.6357\n",
      "Epoch: 42/100, Loss: 0.6466708, Train Acc: 0.6215, Test Acc: 0.6232, Train AUC: 0.6740, Train APUR: 0.6537, Test AUC: 0.6608, Test AUPR: 0.6438\n",
      "Epoch: 43/100, Loss: 0.6427497, Train Acc: 0.6238, Test Acc: 0.6318, Train AUC: 0.6754, Train APUR: 0.6581, Test AUC: 0.6654, Test AUPR: 0.6469\n",
      "Epoch: 44/100, Loss: 0.6409882, Train Acc: 0.6286, Test Acc: 0.6342, Train AUC: 0.6791, Train APUR: 0.6614, Test AUC: 0.6685, Test AUPR: 0.6475\n",
      "Epoch: 45/100, Loss: 0.6395972, Train Acc: 0.6386, Test Acc: 0.6348, Train AUC: 0.6872, Train APUR: 0.6652, Test AUC: 0.6734, Test AUPR: 0.6528\n",
      "Epoch: 46/100, Loss: 0.6369903, Train Acc: 0.6363, Test Acc: 0.6392, Train AUC: 0.6862, Train APUR: 0.6676, Test AUC: 0.6764, Test AUPR: 0.6558\n",
      "Epoch: 47/100, Loss: 0.6358582, Train Acc: 0.6391, Test Acc: 0.6136, Train AUC: 0.6874, Train APUR: 0.6694, Test AUC: 0.6615, Test AUPR: 0.6428\n",
      "Epoch: 48/100, Loss: 0.6384894, Train Acc: 0.6427, Test Acc: 0.6433, Train AUC: 0.6923, Train APUR: 0.6670, Test AUC: 0.6824, Test AUPR: 0.6617\n",
      "Epoch: 49/100, Loss: 0.6314682, Train Acc: 0.6470, Test Acc: 0.6366, Train AUC: 0.6963, Train APUR: 0.6783, Test AUC: 0.6842, Test AUPR: 0.6633\n",
      "Epoch: 50/100, Loss: 0.6325893, Train Acc: 0.6432, Test Acc: 0.6432, Train AUC: 0.6950, Train APUR: 0.6779, Test AUC: 0.6858, Test AUPR: 0.6636\n",
      "Epoch: 51/100, Loss: 0.6286933, Train Acc: 0.6501, Test Acc: 0.6341, Train AUC: 0.7012, Train APUR: 0.6784, Test AUC: 0.6811, Test AUPR: 0.6611\n",
      "Epoch: 52/100, Loss: 0.6293068, Train Acc: 0.6495, Test Acc: 0.6429, Train AUC: 0.7032, Train APUR: 0.6812, Test AUC: 0.6911, Test AUPR: 0.6698\n",
      "Epoch: 53/100, Loss: 0.6265091, Train Acc: 0.6490, Test Acc: 0.6425, Train AUC: 0.7049, Train APUR: 0.6850, Test AUC: 0.6912, Test AUPR: 0.6703\n",
      "Epoch: 54/100, Loss: 0.6268542, Train Acc: 0.6482, Test Acc: 0.6197, Train AUC: 0.7037, Train APUR: 0.6854, Test AUC: 0.6693, Test AUPR: 0.6555\n",
      "Epoch: 55/100, Loss: 0.6332558, Train Acc: 0.6399, Test Acc: 0.6408, Train AUC: 0.6946, Train APUR: 0.6733, Test AUC: 0.6914, Test AUPR: 0.6724\n",
      "Epoch: 56/100, Loss: 0.6214474, Train Acc: 0.6542, Test Acc: 0.6376, Train AUC: 0.7118, Train APUR: 0.6907, Test AUC: 0.6907, Test AUPR: 0.6698\n",
      "Epoch: 57/100, Loss: 0.6265215, Train Acc: 0.6516, Test Acc: 0.6303, Train AUC: 0.7050, Train APUR: 0.6847, Test AUC: 0.6934, Test AUPR: 0.6744\n",
      "Epoch: 58/100, Loss: 0.6203770, Train Acc: 0.6528, Test Acc: 0.6381, Train AUC: 0.7152, Train APUR: 0.6936, Test AUC: 0.6867, Test AUPR: 0.6707\n",
      "Epoch: 59/100, Loss: 0.6190625, Train Acc: 0.6558, Test Acc: 0.6400, Train AUC: 0.7158, Train APUR: 0.6943, Test AUC: 0.6944, Test AUPR: 0.6753\n",
      "Epoch: 60/100, Loss: 0.6192613, Train Acc: 0.6568, Test Acc: 0.6459, Train AUC: 0.7177, Train APUR: 0.6940, Test AUC: 0.6984, Test AUPR: 0.6788\n",
      "Epoch: 61/100, Loss: 0.6169099, Train Acc: 0.6576, Test Acc: 0.6470, Train AUC: 0.7165, Train APUR: 0.6954, Test AUC: 0.6996, Test AUPR: 0.6815\n",
      "Epoch: 62/100, Loss: 0.6148779, Train Acc: 0.6593, Test Acc: 0.6330, Train AUC: 0.7208, Train APUR: 0.7012, Test AUC: 0.6931, Test AUPR: 0.6781\n",
      "Epoch: 63/100, Loss: 0.6164694, Train Acc: 0.6546, Test Acc: 0.6387, Train AUC: 0.7220, Train APUR: 0.7014, Test AUC: 0.6884, Test AUPR: 0.6752\n",
      "Epoch: 64/100, Loss: 0.6133618, Train Acc: 0.6586, Test Acc: 0.6449, Train AUC: 0.7203, Train APUR: 0.7034, Test AUC: 0.6972, Test AUPR: 0.6815\n",
      "Epoch: 65/100, Loss: 0.6153533, Train Acc: 0.6598, Test Acc: 0.6432, Train AUC: 0.7209, Train APUR: 0.7031, Test AUC: 0.6989, Test AUPR: 0.6848\n",
      "Epoch: 66/100, Loss: 0.6109364, Train Acc: 0.6625, Test Acc: 0.6305, Train AUC: 0.7247, Train APUR: 0.7067, Test AUC: 0.6839, Test AUPR: 0.6720\n",
      "Epoch: 67/100, Loss: 0.6147851, Train Acc: 0.6544, Test Acc: 0.6438, Train AUC: 0.7182, Train APUR: 0.7009, Test AUC: 0.7000, Test AUPR: 0.6867\n",
      "Epoch: 68/100, Loss: 0.6111076, Train Acc: 0.6593, Test Acc: 0.6477, Train AUC: 0.7261, Train APUR: 0.7092, Test AUC: 0.7009, Test AUPR: 0.6860\n",
      "Epoch: 69/100, Loss: 0.6091349, Train Acc: 0.6622, Test Acc: 0.6515, Train AUC: 0.7261, Train APUR: 0.7099, Test AUC: 0.7051, Test AUPR: 0.6902\n",
      "Epoch: 70/100, Loss: 0.6055030, Train Acc: 0.6683, Test Acc: 0.6432, Train AUC: 0.7313, Train APUR: 0.7142, Test AUC: 0.6985, Test AUPR: 0.6837\n",
      "Epoch: 71/100, Loss: 0.6059543, Train Acc: 0.6640, Test Acc: 0.6505, Train AUC: 0.7299, Train APUR: 0.7136, Test AUC: 0.7029, Test AUPR: 0.6872\n",
      "Epoch: 72/100, Loss: 0.6040306, Train Acc: 0.6662, Test Acc: 0.6523, Train AUC: 0.7313, Train APUR: 0.7154, Test AUC: 0.7058, Test AUPR: 0.6907\n",
      "Epoch: 73/100, Loss: 0.6062605, Train Acc: 0.6659, Test Acc: 0.6507, Train AUC: 0.7303, Train APUR: 0.7140, Test AUC: 0.7040, Test AUPR: 0.6897\n",
      "Epoch: 74/100, Loss: 0.6017511, Train Acc: 0.6671, Test Acc: 0.6418, Train AUC: 0.7341, Train APUR: 0.7187, Test AUC: 0.6976, Test AUPR: 0.6856\n",
      "Epoch: 75/100, Loss: 0.6022359, Train Acc: 0.6676, Test Acc: 0.6452, Train AUC: 0.7339, Train APUR: 0.7180, Test AUC: 0.6992, Test AUPR: 0.6874\n",
      "Epoch: 76/100, Loss: 0.6005591, Train Acc: 0.6693, Test Acc: 0.6488, Train AUC: 0.7364, Train APUR: 0.7229, Test AUC: 0.7011, Test AUPR: 0.6886\n",
      "Epoch: 77/100, Loss: 0.6029079, Train Acc: 0.6691, Test Acc: 0.6431, Train AUC: 0.7329, Train APUR: 0.7179, Test AUC: 0.6990, Test AUPR: 0.6879\n",
      "Epoch: 78/100, Loss: 0.5982144, Train Acc: 0.6689, Test Acc: 0.6386, Train AUC: 0.7395, Train APUR: 0.7265, Test AUC: 0.6915, Test AUPR: 0.6808\n",
      "Epoch: 79/100, Loss: 0.5997026, Train Acc: 0.6655, Test Acc: 0.6480, Train AUC: 0.7355, Train APUR: 0.7238, Test AUC: 0.7040, Test AUPR: 0.6933\n",
      "Epoch: 80/100, Loss: 0.6009908, Train Acc: 0.6685, Test Acc: 0.6509, Train AUC: 0.7352, Train APUR: 0.7208, Test AUC: 0.7070, Test AUPR: 0.6967\n",
      "Epoch: 81/100, Loss: 0.5967221, Train Acc: 0.6722, Test Acc: 0.6441, Train AUC: 0.7400, Train APUR: 0.7278, Test AUC: 0.7005, Test AUPR: 0.6905\n",
      "Epoch: 82/100, Loss: 0.5943716, Train Acc: 0.6728, Test Acc: 0.6471, Train AUC: 0.7429, Train APUR: 0.7324, Test AUC: 0.7030, Test AUPR: 0.6929\n",
      "Epoch: 83/100, Loss: 0.5936167, Train Acc: 0.6734, Test Acc: 0.6577, Train AUC: 0.7428, Train APUR: 0.7344, Test AUC: 0.7115, Test AUPR: 0.7007\n",
      "Epoch: 84/100, Loss: 0.5941641, Train Acc: 0.6762, Test Acc: 0.6536, Train AUC: 0.7434, Train APUR: 0.7311, Test AUC: 0.7114, Test AUPR: 0.7025\n",
      "Epoch: 85/100, Loss: 0.5909495, Train Acc: 0.6770, Test Acc: 0.6427, Train AUC: 0.7479, Train APUR: 0.7374, Test AUC: 0.6997, Test AUPR: 0.6928\n",
      "Epoch: 86/100, Loss: 0.5951577, Train Acc: 0.6702, Test Acc: 0.6533, Train AUC: 0.7396, Train APUR: 0.7320, Test AUC: 0.7065, Test AUPR: 0.6955\n",
      "Epoch: 87/100, Loss: 0.6013742, Train Acc: 0.6683, Test Acc: 0.6545, Train AUC: 0.7370, Train APUR: 0.7235, Test AUC: 0.7119, Test AUPR: 0.7039\n",
      "Epoch: 88/100, Loss: 0.5873578, Train Acc: 0.6792, Test Acc: 0.6209, Train AUC: 0.7506, Train APUR: 0.7411, Test AUC: 0.6747, Test AUPR: 0.6712\n",
      "Epoch: 89/100, Loss: 0.6060207, Train Acc: 0.6593, Test Acc: 0.6515, Train AUC: 0.7252, Train APUR: 0.7180, Test AUC: 0.7063, Test AUPR: 0.6968\n",
      "Epoch: 90/100, Loss: 0.5968524, Train Acc: 0.6725, Test Acc: 0.6547, Train AUC: 0.7409, Train APUR: 0.7297, Test AUC: 0.7104, Test AUPR: 0.7014\n",
      "Epoch: 91/100, Loss: 0.5909978, Train Acc: 0.6781, Test Acc: 0.6272, Train AUC: 0.7468, Train APUR: 0.7371, Test AUC: 0.6839, Test AUPR: 0.6809\n",
      "Epoch: 92/100, Loss: 0.5958884, Train Acc: 0.6684, Test Acc: 0.6398, Train AUC: 0.7399, Train APUR: 0.7338, Test AUC: 0.6992, Test AUPR: 0.6950\n",
      "Epoch: 93/100, Loss: 0.5912622, Train Acc: 0.6742, Test Acc: 0.6563, Train AUC: 0.7484, Train APUR: 0.7441, Test AUC: 0.7125, Test AUPR: 0.7041\n",
      "Epoch: 94/100, Loss: 0.5920612, Train Acc: 0.6791, Test Acc: 0.6576, Train AUC: 0.7469, Train APUR: 0.7380, Test AUC: 0.7152, Test AUPR: 0.7075\n",
      "Epoch: 95/100, Loss: 0.5874668, Train Acc: 0.6798, Test Acc: 0.6404, Train AUC: 0.7509, Train APUR: 0.7430, Test AUC: 0.6976, Test AUPR: 0.6918\n",
      "Epoch: 96/100, Loss: 0.5879701, Train Acc: 0.6772, Test Acc: 0.6471, Train AUC: 0.7496, Train APUR: 0.7452, Test AUC: 0.7062, Test AUPR: 0.7000\n",
      "Epoch: 97/100, Loss: 0.5858648, Train Acc: 0.6773, Test Acc: 0.6589, Train AUC: 0.7519, Train APUR: 0.7488, Test AUC: 0.7171, Test AUPR: 0.7084\n",
      "Epoch: 98/100, Loss: 0.5859954, Train Acc: 0.6808, Test Acc: 0.6583, Train AUC: 0.7527, Train APUR: 0.7446, Test AUC: 0.7180, Test AUPR: 0.7104\n",
      "Epoch: 99/100, Loss: 0.5837861, Train Acc: 0.6821, Test Acc: 0.6397, Train AUC: 0.7552, Train APUR: 0.7472, Test AUC: 0.6995, Test AUPR: 0.6964\n",
      "Epoch: 100/100, Loss: 0.5853266, Train Acc: 0.6787, Test Acc: 0.6416, Train AUC: 0.7516, Train APUR: 0.7464, Test AUC: 0.7016, Test AUPR: 0.6979\n",
      "/home/ubuntu/PA-Cancer-Immunotherapy/GNN/train_pa_all_tvt.py:246: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(configs['save_model']))\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 55.755 MB of 55.755 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 55.755 MB of 55.755 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 55.755 MB of 55.755 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 55.755 MB of 55.755 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 55.755 MB of 55.755 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 55.755 MB of 55.755 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 55.755 MB of 55.755 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 55.755 MB of 55.755 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 55.755 MB of 55.755 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 55.755 MB of 55.755 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 55.755 MB of 55.755 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 55.755 MB of 55.755 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 56.887 MB of 56.887 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 56.887 MB of 56.887 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 56.887 MB of 56.887 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 58.019 MB of 58.019 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 58.020 MB of 58.020 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 58.020 MB of 58.020 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 58.707 MB of 59.152 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 58.707 MB of 59.152 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 58.707 MB of 59.152 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 58.707 MB of 59.152 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 58.707 MB of 59.152 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 58.707 MB of 59.152 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 58.707 MB of 59.152 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 58.707 MB of 59.152 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 58.707 MB of 59.152 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 58.707 MB of 59.152 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 58.707 MB of 59.152 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 58.707 MB of 59.152 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 58.707 MB of 59.152 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 58.707 MB of 59.152 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 58.957 MB of 59.152 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 59.152 MB of 59.152 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 59.152 MB of 59.152 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 59.152 MB of 59.152 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 60.284 MB of 60.284 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 60.284 MB of 60.284 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 61.362 MB of 61.416 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 61.416 MB of 61.416 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 61.416 MB of 61.416 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 62.291 MB of 62.548 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 62.548 MB of 62.548 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 62.548 MB of 62.548 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 62.555 MB of 62.555 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 62.555 MB of 62.555 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 62.555 MB of 62.555 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      test_aupr ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   test_roc_auc ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▁▅▄▅▅▅▅▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇██▇███████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_aupr ▁▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇█▇▇█████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss █▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▆▆▅▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▁▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_roc_auc ▁▂▂▂▂▂▃▃▃▃▄▄▄▅▅▅▅▆▅▆▆▆▆▆▆▇▇▇▇▇███▇▇█████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: valid_accuracy ▁▁▂▃▂▃▂▂▂▃▄▆▆▅▅▆▇▇▇▇▇▇▇▆▇▇▆█▇▇▇▇▇▇▇█▅██▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     valid_aupr ▁▁▁▁▂▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▇▆▇▇▇▇▇▇▇▇██▇██▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  valid_roc_auc ▁▁▂▃▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇█████▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy 0.66154\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      test_aupr 0.7114\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   test_roc_auc 0.72091\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.67871\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_aupr 0.74638\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.58533\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_roc_auc 0.75158\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: valid_accuracy 0.64165\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     valid_aupr 0.69788\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  valid_roc_auc 0.7016\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mcrisp-sound-5\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-allele_GNN/runs/1vgj835w\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-allele_GNN\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 4 W&B file(s), 0 media file(s), 115 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241206_210112-1vgj835w/logs\u001b[0m\n",
      "Test Acc: 0.6615, Test AUC: 0.7209, Test AUPR: 0.7114\n"
     ]
    }
   ],
   "source": [
    "# first for allele (using only the adam optimizer)(pos_weight=1 = not used, since balanced datasets)\n",
    "\n",
    "! python train_pa_all_tvt.py --gpu 0 --configs_path configs/PA_all_tvt_allele.yml --droup_out 0.1 --split StrictTCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75cdb1ab-3970-4f38-b605-e161da809761",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(gpu=0, lr=0.001, epochs=100, w_celoss=1, w_aucloss=0, add_same_type_edges=False, dynamic_graph=False, dynamic_ratio=0.05, droup_out=0.1, positive_weights=1, dynamic_epochs=30, distance_threshold=10, configs_path='configs/PA_all_tvt_gene.yml', split='StrictTCR', dataset='pMTnet')\n",
      "PROJECT_NAME: dataset-all-tvt-gene_GNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfrohoari\u001b[0m (\u001b[33mpa_cancerimmunotherapy\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/ubuntu/PA-Cancer-Immunotherapy/GNN/wandb/run-20241206_213812-k5nznux9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mgrateful-lion-4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-gene_GNN\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-gene_GNN/runs/k5nznux9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   6 of 6 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   6 of 6 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   6 of 6 files downloaded.  \n",
      "embeddings_path:   models/PA_all/gene_and_allele_embeddings.pkl\n",
      "train_file_list:   ['gene_train.csv']\n",
      "validation_file_list:   ['gene_validation.csv']\n",
      "test_file_list:   ['gene_test.csv']\n",
      "wandb logger initialisiert\n",
      "Epoch: 1/100, Loss: 0.6933187, Train Acc: 0.5015, Test Acc: 0.4996, Train AUC: 0.4987, Train APUR: 0.4993, Test AUC: 0.5409, Test AUPR: 0.5310\n",
      "Epoch: 2/100, Loss: 0.6909529, Train Acc: 0.5056, Test Acc: 0.5382, Train AUC: 0.5701, Train APUR: 0.5528, Test AUC: 0.5544, Test AUPR: 0.5475\n",
      "Epoch: 3/100, Loss: 0.6864630, Train Acc: 0.5495, Test Acc: 0.5545, Train AUC: 0.5937, Train APUR: 0.5843, Test AUC: 0.5515, Test AUPR: 0.5441\n",
      "Epoch: 4/100, Loss: 0.6836001, Train Acc: 0.5693, Test Acc: 0.5189, Train AUC: 0.5953, Train APUR: 0.5846, Test AUC: 0.5519, Test AUPR: 0.5429\n",
      "Epoch: 5/100, Loss: 0.6805422, Train Acc: 0.5728, Test Acc: 0.5522, Train AUC: 0.5991, Train APUR: 0.5860, Test AUC: 0.5579, Test AUPR: 0.5487\n",
      "Epoch: 6/100, Loss: 0.6789079, Train Acc: 0.5763, Test Acc: 0.5602, Train AUC: 0.6028, Train APUR: 0.5912, Test AUC: 0.5656, Test AUPR: 0.5572\n",
      "Epoch: 7/100, Loss: 0.6759975, Train Acc: 0.5801, Test Acc: 0.5618, Train AUC: 0.6116, Train APUR: 0.5962, Test AUC: 0.5744, Test AUPR: 0.5631\n",
      "Epoch: 8/100, Loss: 0.6750875, Train Acc: 0.5835, Test Acc: 0.5449, Train AUC: 0.6149, Train APUR: 0.6014, Test AUC: 0.5810, Test AUPR: 0.5668\n",
      "Epoch: 9/100, Loss: 0.6722893, Train Acc: 0.5908, Test Acc: 0.5520, Train AUC: 0.6201, Train APUR: 0.6062, Test AUC: 0.5911, Test AUPR: 0.5745\n",
      "Epoch: 10/100, Loss: 0.6707441, Train Acc: 0.5944, Test Acc: 0.5741, Train AUC: 0.6242, Train APUR: 0.6074, Test AUC: 0.6009, Test AUPR: 0.5817\n",
      "Epoch: 11/100, Loss: 0.6695098, Train Acc: 0.5961, Test Acc: 0.5788, Train AUC: 0.6293, Train APUR: 0.6129, Test AUC: 0.6068, Test AUPR: 0.5868\n",
      "Epoch: 12/100, Loss: 0.6692325, Train Acc: 0.5975, Test Acc: 0.5761, Train AUC: 0.6289, Train APUR: 0.6158, Test AUC: 0.6105, Test AUPR: 0.5896\n",
      "Epoch: 13/100, Loss: 0.6674324, Train Acc: 0.5985, Test Acc: 0.5842, Train AUC: 0.6332, Train APUR: 0.6186, Test AUC: 0.6141, Test AUPR: 0.5922\n",
      "Epoch: 14/100, Loss: 0.6663365, Train Acc: 0.6010, Test Acc: 0.5754, Train AUC: 0.6344, Train APUR: 0.6176, Test AUC: 0.6159, Test AUPR: 0.5930\n",
      "Epoch: 15/100, Loss: 0.6668053, Train Acc: 0.5994, Test Acc: 0.5820, Train AUC: 0.6351, Train APUR: 0.6192, Test AUC: 0.6178, Test AUPR: 0.5944\n",
      "Epoch: 16/100, Loss: 0.6648215, Train Acc: 0.6020, Test Acc: 0.5906, Train AUC: 0.6369, Train APUR: 0.6204, Test AUC: 0.6219, Test AUPR: 0.5965\n",
      "Epoch: 17/100, Loss: 0.6640831, Train Acc: 0.6042, Test Acc: 0.6085, Train AUC: 0.6390, Train APUR: 0.6231, Test AUC: 0.6232, Test AUPR: 0.5972\n",
      "Epoch: 18/100, Loss: 0.6633779, Train Acc: 0.6034, Test Acc: 0.5872, Train AUC: 0.6413, Train APUR: 0.6255, Test AUC: 0.6249, Test AUPR: 0.5985\n",
      "Epoch: 19/100, Loss: 0.6626759, Train Acc: 0.6066, Test Acc: 0.5857, Train AUC: 0.6429, Train APUR: 0.6274, Test AUC: 0.6263, Test AUPR: 0.5996\n",
      "Epoch: 20/100, Loss: 0.6637576, Train Acc: 0.6063, Test Acc: 0.5877, Train AUC: 0.6440, Train APUR: 0.6278, Test AUC: 0.6266, Test AUPR: 0.6002\n",
      "Epoch: 21/100, Loss: 0.6616418, Train Acc: 0.6068, Test Acc: 0.6028, Train AUC: 0.6440, Train APUR: 0.6282, Test AUC: 0.6258, Test AUPR: 0.5998\n",
      "Epoch: 22/100, Loss: 0.6614261, Train Acc: 0.6055, Test Acc: 0.5975, Train AUC: 0.6451, Train APUR: 0.6293, Test AUC: 0.6250, Test AUPR: 0.5997\n",
      "Epoch: 23/100, Loss: 0.6606070, Train Acc: 0.6085, Test Acc: 0.5905, Train AUC: 0.6460, Train APUR: 0.6298, Test AUC: 0.6257, Test AUPR: 0.6008\n",
      "Epoch: 24/100, Loss: 0.6605352, Train Acc: 0.6083, Test Acc: 0.5894, Train AUC: 0.6458, Train APUR: 0.6305, Test AUC: 0.6290, Test AUPR: 0.6036\n",
      "Epoch: 25/100, Loss: 0.6606740, Train Acc: 0.6094, Test Acc: 0.5993, Train AUC: 0.6478, Train APUR: 0.6319, Test AUC: 0.6295, Test AUPR: 0.6043\n",
      "Epoch: 26/100, Loss: 0.6595277, Train Acc: 0.6095, Test Acc: 0.5989, Train AUC: 0.6482, Train APUR: 0.6320, Test AUC: 0.6316, Test AUPR: 0.6059\n",
      "Epoch: 27/100, Loss: 0.6592865, Train Acc: 0.6091, Test Acc: 0.6207, Train AUC: 0.6494, Train APUR: 0.6337, Test AUC: 0.6333, Test AUPR: 0.6071\n",
      "Epoch: 28/100, Loss: 0.6598850, Train Acc: 0.6081, Test Acc: 0.6232, Train AUC: 0.6467, Train APUR: 0.6318, Test AUC: 0.6354, Test AUPR: 0.6084\n",
      "Epoch: 29/100, Loss: 0.6580555, Train Acc: 0.6115, Test Acc: 0.6252, Train AUC: 0.6510, Train APUR: 0.6348, Test AUC: 0.6362, Test AUPR: 0.6091\n",
      "Epoch: 30/100, Loss: 0.6577852, Train Acc: 0.6116, Test Acc: 0.6266, Train AUC: 0.6513, Train APUR: 0.6353, Test AUC: 0.6358, Test AUPR: 0.6093\n",
      "Epoch: 31/100, Loss: 0.6571670, Train Acc: 0.6116, Test Acc: 0.6262, Train AUC: 0.6526, Train APUR: 0.6368, Test AUC: 0.6360, Test AUPR: 0.6096\n",
      "Epoch: 32/100, Loss: 0.6569431, Train Acc: 0.6120, Test Acc: 0.6242, Train AUC: 0.6531, Train APUR: 0.6367, Test AUC: 0.6362, Test AUPR: 0.6097\n",
      "Epoch: 33/100, Loss: 0.6566541, Train Acc: 0.6126, Test Acc: 0.6219, Train AUC: 0.6535, Train APUR: 0.6379, Test AUC: 0.6368, Test AUPR: 0.6103\n",
      "Epoch: 34/100, Loss: 0.6568348, Train Acc: 0.6127, Test Acc: 0.6239, Train AUC: 0.6534, Train APUR: 0.6367, Test AUC: 0.6367, Test AUPR: 0.6111\n",
      "Epoch: 35/100, Loss: 0.6562832, Train Acc: 0.6124, Test Acc: 0.6185, Train AUC: 0.6542, Train APUR: 0.6385, Test AUC: 0.6373, Test AUPR: 0.6124\n",
      "Epoch: 36/100, Loss: 0.6562046, Train Acc: 0.6125, Test Acc: 0.6241, Train AUC: 0.6551, Train APUR: 0.6384, Test AUC: 0.6378, Test AUPR: 0.6131\n",
      "Epoch: 37/100, Loss: 0.6551340, Train Acc: 0.6139, Test Acc: 0.6231, Train AUC: 0.6566, Train APUR: 0.6409, Test AUC: 0.6382, Test AUPR: 0.6138\n",
      "Epoch: 38/100, Loss: 0.6549864, Train Acc: 0.6131, Test Acc: 0.6196, Train AUC: 0.6570, Train APUR: 0.6416, Test AUC: 0.6388, Test AUPR: 0.6149\n",
      "Epoch: 39/100, Loss: 0.6541831, Train Acc: 0.6139, Test Acc: 0.6261, Train AUC: 0.6583, Train APUR: 0.6425, Test AUC: 0.6408, Test AUPR: 0.6174\n",
      "Epoch: 40/100, Loss: 0.6538407, Train Acc: 0.6144, Test Acc: 0.6253, Train AUC: 0.6588, Train APUR: 0.6444, Test AUC: 0.6421, Test AUPR: 0.6192\n",
      "Epoch: 41/100, Loss: 0.6533638, Train Acc: 0.6162, Test Acc: 0.6237, Train AUC: 0.6600, Train APUR: 0.6453, Test AUC: 0.6432, Test AUPR: 0.6202\n",
      "Epoch: 42/100, Loss: 0.6527296, Train Acc: 0.6155, Test Acc: 0.6163, Train AUC: 0.6609, Train APUR: 0.6460, Test AUC: 0.6441, Test AUPR: 0.6209\n",
      "Epoch: 43/100, Loss: 0.6529158, Train Acc: 0.6161, Test Acc: 0.6128, Train AUC: 0.6622, Train APUR: 0.6468, Test AUC: 0.6429, Test AUPR: 0.6204\n",
      "Epoch: 44/100, Loss: 0.6515153, Train Acc: 0.6167, Test Acc: 0.6191, Train AUC: 0.6632, Train APUR: 0.6481, Test AUC: 0.6421, Test AUPR: 0.6207\n",
      "Epoch: 45/100, Loss: 0.6510922, Train Acc: 0.6180, Test Acc: 0.6175, Train AUC: 0.6635, Train APUR: 0.6496, Test AUC: 0.6458, Test AUPR: 0.6250\n",
      "Epoch: 46/100, Loss: 0.6501938, Train Acc: 0.6184, Test Acc: 0.6160, Train AUC: 0.6660, Train APUR: 0.6515, Test AUC: 0.6476, Test AUPR: 0.6268\n",
      "Epoch: 47/100, Loss: 0.6498582, Train Acc: 0.6256, Test Acc: 0.6150, Train AUC: 0.6704, Train APUR: 0.6570, Test AUC: 0.6462, Test AUPR: 0.6249\n",
      "Epoch: 48/100, Loss: 0.6472249, Train Acc: 0.6227, Test Acc: 0.6069, Train AUC: 0.6706, Train APUR: 0.6573, Test AUC: 0.6450, Test AUPR: 0.6231\n",
      "Epoch: 49/100, Loss: 0.6474198, Train Acc: 0.6209, Test Acc: 0.6234, Train AUC: 0.6702, Train APUR: 0.6577, Test AUC: 0.6539, Test AUPR: 0.6318\n",
      "Epoch: 50/100, Loss: 0.6446726, Train Acc: 0.6310, Test Acc: 0.6277, Train AUC: 0.6766, Train APUR: 0.6626, Test AUC: 0.6595, Test AUPR: 0.6365\n",
      "Epoch: 51/100, Loss: 0.6466390, Train Acc: 0.6323, Test Acc: 0.6160, Train AUC: 0.6813, Train APUR: 0.6658, Test AUC: 0.6541, Test AUPR: 0.6314\n",
      "Epoch: 52/100, Loss: 0.6411110, Train Acc: 0.6350, Test Acc: 0.6069, Train AUC: 0.6820, Train APUR: 0.6688, Test AUC: 0.6537, Test AUPR: 0.6303\n",
      "Epoch: 53/100, Loss: 0.6403417, Train Acc: 0.6374, Test Acc: 0.6275, Train AUC: 0.6832, Train APUR: 0.6694, Test AUC: 0.6665, Test AUPR: 0.6438\n",
      "Epoch: 54/100, Loss: 0.6393396, Train Acc: 0.6491, Test Acc: 0.6300, Train AUC: 0.6916, Train APUR: 0.6746, Test AUC: 0.6676, Test AUPR: 0.6447\n",
      "Epoch: 55/100, Loss: 0.6347078, Train Acc: 0.6515, Test Acc: 0.6232, Train AUC: 0.6964, Train APUR: 0.6800, Test AUC: 0.6637, Test AUPR: 0.6402\n",
      "Epoch: 56/100, Loss: 0.6341131, Train Acc: 0.6504, Test Acc: 0.6324, Train AUC: 0.6961, Train APUR: 0.6798, Test AUC: 0.6717, Test AUPR: 0.6484\n",
      "Epoch: 57/100, Loss: 0.6326156, Train Acc: 0.6543, Test Acc: 0.6318, Train AUC: 0.7006, Train APUR: 0.6846, Test AUC: 0.6733, Test AUPR: 0.6508\n",
      "Epoch: 58/100, Loss: 0.6298586, Train Acc: 0.6542, Test Acc: 0.6252, Train AUC: 0.7034, Train APUR: 0.6920, Test AUC: 0.6644, Test AUPR: 0.6403\n",
      "Epoch: 59/100, Loss: 0.6278850, Train Acc: 0.6543, Test Acc: 0.6326, Train AUC: 0.7052, Train APUR: 0.6916, Test AUC: 0.6721, Test AUPR: 0.6491\n",
      "Epoch: 60/100, Loss: 0.6233045, Train Acc: 0.6570, Test Acc: 0.6341, Train AUC: 0.7111, Train APUR: 0.6995, Test AUC: 0.6759, Test AUPR: 0.6543\n",
      "Epoch: 61/100, Loss: 0.6242708, Train Acc: 0.6533, Test Acc: 0.6197, Train AUC: 0.7119, Train APUR: 0.7037, Test AUC: 0.6581, Test AUPR: 0.6355\n",
      "Epoch: 62/100, Loss: 0.6252958, Train Acc: 0.6532, Test Acc: 0.6284, Train AUC: 0.7085, Train APUR: 0.6959, Test AUC: 0.6748, Test AUPR: 0.6568\n",
      "Epoch: 63/100, Loss: 0.6235491, Train Acc: 0.6540, Test Acc: 0.6333, Train AUC: 0.7124, Train APUR: 0.7030, Test AUC: 0.6765, Test AUPR: 0.6578\n",
      "Epoch: 64/100, Loss: 0.6208343, Train Acc: 0.6542, Test Acc: 0.6214, Train AUC: 0.7124, Train APUR: 0.7033, Test AUC: 0.6659, Test AUPR: 0.6434\n",
      "Epoch: 65/100, Loss: 0.6196277, Train Acc: 0.6585, Test Acc: 0.6283, Train AUC: 0.7166, Train APUR: 0.7081, Test AUC: 0.6712, Test AUPR: 0.6495\n",
      "Epoch: 66/100, Loss: 0.6173288, Train Acc: 0.6598, Test Acc: 0.6333, Train AUC: 0.7177, Train APUR: 0.7099, Test AUC: 0.6791, Test AUPR: 0.6595\n",
      "Epoch: 67/100, Loss: 0.6265487, Train Acc: 0.6486, Test Acc: 0.6307, Train AUC: 0.7070, Train APUR: 0.6998, Test AUC: 0.6731, Test AUPR: 0.6525\n",
      "Epoch: 68/100, Loss: 0.6143909, Train Acc: 0.6609, Test Acc: 0.6221, Train AUC: 0.7200, Train APUR: 0.7116, Test AUC: 0.6675, Test AUPR: 0.6465\n",
      "Epoch: 69/100, Loss: 0.6183140, Train Acc: 0.6579, Test Acc: 0.6373, Train AUC: 0.7193, Train APUR: 0.7077, Test AUC: 0.6821, Test AUPR: 0.6619\n",
      "Epoch: 70/100, Loss: 0.6145980, Train Acc: 0.6599, Test Acc: 0.6412, Train AUC: 0.7221, Train APUR: 0.7090, Test AUC: 0.6880, Test AUPR: 0.6693\n",
      "Epoch: 71/100, Loss: 0.6132479, Train Acc: 0.6582, Test Acc: 0.6401, Train AUC: 0.7202, Train APUR: 0.7146, Test AUC: 0.6890, Test AUPR: 0.6699\n",
      "Epoch: 72/100, Loss: 0.6127245, Train Acc: 0.6601, Test Acc: 0.6370, Train AUC: 0.7238, Train APUR: 0.7166, Test AUC: 0.6833, Test AUPR: 0.6626\n",
      "Epoch: 73/100, Loss: 0.6116689, Train Acc: 0.6624, Test Acc: 0.6428, Train AUC: 0.7231, Train APUR: 0.7155, Test AUC: 0.6875, Test AUPR: 0.6658\n",
      "Epoch: 74/100, Loss: 0.6091469, Train Acc: 0.6622, Test Acc: 0.6442, Train AUC: 0.7256, Train APUR: 0.7214, Test AUC: 0.6903, Test AUPR: 0.6680\n",
      "Epoch: 75/100, Loss: 0.6102098, Train Acc: 0.6599, Test Acc: 0.6413, Train AUC: 0.7245, Train APUR: 0.7204, Test AUC: 0.6869, Test AUPR: 0.6657\n",
      "Epoch: 76/100, Loss: 0.6079025, Train Acc: 0.6647, Test Acc: 0.6353, Train AUC: 0.7275, Train APUR: 0.7203, Test AUC: 0.6809, Test AUPR: 0.6608\n",
      "Epoch: 77/100, Loss: 0.6087435, Train Acc: 0.6640, Test Acc: 0.6395, Train AUC: 0.7257, Train APUR: 0.7203, Test AUC: 0.6859, Test AUPR: 0.6677\n",
      "Epoch: 78/100, Loss: 0.6062567, Train Acc: 0.6651, Test Acc: 0.6432, Train AUC: 0.7291, Train APUR: 0.7253, Test AUC: 0.6883, Test AUPR: 0.6721\n",
      "Epoch: 79/100, Loss: 0.6058385, Train Acc: 0.6653, Test Acc: 0.6389, Train AUC: 0.7287, Train APUR: 0.7237, Test AUC: 0.6843, Test AUPR: 0.6697\n",
      "Epoch: 80/100, Loss: 0.6059736, Train Acc: 0.6646, Test Acc: 0.6421, Train AUC: 0.7291, Train APUR: 0.7257, Test AUC: 0.6894, Test AUPR: 0.6742\n",
      "Epoch: 81/100, Loss: 0.6042528, Train Acc: 0.6648, Test Acc: 0.6418, Train AUC: 0.7297, Train APUR: 0.7271, Test AUC: 0.6889, Test AUPR: 0.6733\n",
      "Epoch: 82/100, Loss: 0.6031327, Train Acc: 0.6663, Test Acc: 0.6369, Train AUC: 0.7306, Train APUR: 0.7275, Test AUC: 0.6856, Test AUPR: 0.6687\n",
      "Epoch: 83/100, Loss: 0.6063755, Train Acc: 0.6655, Test Acc: 0.6403, Train AUC: 0.7288, Train APUR: 0.7224, Test AUC: 0.6893, Test AUPR: 0.6722\n",
      "Epoch: 84/100, Loss: 0.6034595, Train Acc: 0.6647, Test Acc: 0.6396, Train AUC: 0.7306, Train APUR: 0.7289, Test AUC: 0.6877, Test AUPR: 0.6716\n",
      "Epoch: 85/100, Loss: 0.6034429, Train Acc: 0.6673, Test Acc: 0.6423, Train AUC: 0.7314, Train APUR: 0.7282, Test AUC: 0.6911, Test AUPR: 0.6757\n",
      "Epoch: 86/100, Loss: 0.6021392, Train Acc: 0.6669, Test Acc: 0.6455, Train AUC: 0.7323, Train APUR: 0.7304, Test AUC: 0.6948, Test AUPR: 0.6794\n",
      "Epoch: 87/100, Loss: 0.6019089, Train Acc: 0.6674, Test Acc: 0.6411, Train AUC: 0.7320, Train APUR: 0.7291, Test AUC: 0.6878, Test AUPR: 0.6733\n",
      "Epoch: 88/100, Loss: 0.6026609, Train Acc: 0.6675, Test Acc: 0.6444, Train AUC: 0.7318, Train APUR: 0.7293, Test AUC: 0.6950, Test AUPR: 0.6808\n",
      "Epoch: 89/100, Loss: 0.5998923, Train Acc: 0.6697, Test Acc: 0.6469, Train AUC: 0.7348, Train APUR: 0.7328, Test AUC: 0.6965, Test AUPR: 0.6817\n",
      "Epoch: 90/100, Loss: 0.6013277, Train Acc: 0.6691, Test Acc: 0.6383, Train AUC: 0.7332, Train APUR: 0.7313, Test AUC: 0.6861, Test AUPR: 0.6705\n",
      "Epoch: 91/100, Loss: 0.6006732, Train Acc: 0.6684, Test Acc: 0.6430, Train AUC: 0.7341, Train APUR: 0.7316, Test AUC: 0.6923, Test AUPR: 0.6772\n",
      "Epoch: 92/100, Loss: 0.5982257, Train Acc: 0.6705, Test Acc: 0.6467, Train AUC: 0.7362, Train APUR: 0.7346, Test AUC: 0.6971, Test AUPR: 0.6817\n",
      "Epoch: 93/100, Loss: 0.6007143, Train Acc: 0.6687, Test Acc: 0.6433, Train AUC: 0.7334, Train APUR: 0.7319, Test AUC: 0.6927, Test AUPR: 0.6775\n",
      "Epoch: 94/100, Loss: 0.5988087, Train Acc: 0.6704, Test Acc: 0.6434, Train AUC: 0.7358, Train APUR: 0.7338, Test AUC: 0.6929, Test AUPR: 0.6778\n",
      "Epoch: 95/100, Loss: 0.6004514, Train Acc: 0.6685, Test Acc: 0.6455, Train AUC: 0.7344, Train APUR: 0.7323, Test AUC: 0.6964, Test AUPR: 0.6812\n",
      "Epoch: 96/100, Loss: 0.6027008, Train Acc: 0.6663, Test Acc: 0.6472, Train AUC: 0.7304, Train APUR: 0.7293, Test AUC: 0.6980, Test AUPR: 0.6835\n",
      "Epoch: 97/100, Loss: 0.5977389, Train Acc: 0.6715, Test Acc: 0.6411, Train AUC: 0.7370, Train APUR: 0.7356, Test AUC: 0.6885, Test AUPR: 0.6737\n",
      "Epoch: 98/100, Loss: 0.5987846, Train Acc: 0.6709, Test Acc: 0.6471, Train AUC: 0.7361, Train APUR: 0.7345, Test AUC: 0.6968, Test AUPR: 0.6822\n",
      "Epoch: 99/100, Loss: 0.5988984, Train Acc: 0.6698, Test Acc: 0.6439, Train AUC: 0.7352, Train APUR: 0.7335, Test AUC: 0.6938, Test AUPR: 0.6803\n",
      "Epoch: 100/100, Loss: 0.5963945, Train Acc: 0.6714, Test Acc: 0.6444, Train AUC: 0.7386, Train APUR: 0.7381, Test AUC: 0.6938, Test AUPR: 0.6798\n",
      "/home/ubuntu/PA-Cancer-Immunotherapy/GNN/train_pa_all_tvt.py:244: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(configs['save_model']))\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.260 MB of 1.385 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.386 MB of 1.386 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.386 MB of 1.386 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.392 MB of 1.392 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.392 MB of 1.392 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.392 MB of 1.392 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▁▁▁▂▂▂▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      test_aupr ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   test_roc_auc ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▁▁▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇██████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_aupr ▁▄▄▄▅▅▅▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇███████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss █▇▇▇▆▆▆▆▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▃▃▃▃▂▃▂▂▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_roc_auc ▁▂▂▃▃▄▄▄▄▄▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▇▇▇▇▇▇█████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: valid_accuracy ▂▃▁▃▄▅▄▄▆▅▅▅▅▅▇▇▇▇▆▆▆▇▇▇▇▇▇█▇█▇█████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     valid_aupr ▁▂▂▂▃▄▄▄▄▄▄▄▄▅▅▅▅▅▅▅▅▅▅▅▆▆▆▇▆▇▇▇▇▇██████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  valid_roc_auc ▁▁▂▂▃▄▄▄▄▄▄▄▄▄▅▅▅▅▅▅▅▅▅▅▅▆▇▇▇██▇███▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy 0.64887\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      test_aupr 0.68939\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   test_roc_auc 0.70333\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.6714\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_aupr 0.73806\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.59639\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_roc_auc 0.73861\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: valid_accuracy 0.64443\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     valid_aupr 0.67978\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  valid_roc_auc 0.69381\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mgrateful-lion-4\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-gene_GNN/runs/k5nznux9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-gene_GNN\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 4 W&B file(s), 0 media file(s), 7 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241206_213812-k5nznux9/logs\u001b[0m\n",
      "Test Acc: 0.6489, Test AUC: 0.7033, Test AUPR: 0.6894\n"
     ]
    }
   ],
   "source": [
    "# for gene  (using only the adam optimizer)(pos_weight=1 = not used, since balanced datasets)\n",
    "\n",
    "! python train_pa_all_tvt.py --gpu 0 --configs_path configs/PA_all_tvt_gene.yml --droup_out 0.1 --split StrictTCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8038cb30-849a-4684-b8a0-44d0b1d52e0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bc2e018-a2bc-41e5-945e-e6a5c2f29b1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(gpu=0, lr=0.001, epochs=100, w_celoss=1, w_aucloss=0, add_same_type_edges=False, dynamic_graph=False, dynamic_ratio=0.05, droup_out=0.1, positive_weights=1, dynamic_epochs=30, distance_threshold=10, configs_path='configs/PA_all_tvt_allele.yml', split='StrictTCR', dataset='pMTnet')\n",
      "PROJECT_NAME: dataset-all-tvt-allele_GNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfrohoari\u001b[0m (\u001b[33mpa_cancerimmunotherapy\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/ubuntu/PA-Cancer-Immunotherapy/GNN/wandb/run-20241217_120820-j92tngw2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdauntless-sponge-14\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-allele_GNN\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-allele_GNN/runs/j92tngw2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   6 of 6 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   6 of 6 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   6 of 6 files downloaded.  \n",
      "embeddings_path:   models/PA_all/gene_and_allele_embeddings.pkl\n",
      "train_file_list:   ['allele_train.csv']\n",
      "validation_file_list:   ['allele_validation.csv']\n",
      "test_file_list:   ['allele_test.csv']\n",
      "wandb logger initialisiert\n",
      "Epoch: 1/100, Loss: 0.6935461, Train Acc: 0.4871, Valid. Acc: 0.5031, Train AUC: 0.4853, Train AP: 0.4985, Valid. AUC: 0.5574, Valid. AP: 0.5489\n",
      "Epoch: 2/100, Loss: 0.6912209, Train Acc: 0.5072, Valid. Acc: 0.5374, Train AUC: 0.5700, Train AP: 0.5563, Valid. AUC: 0.5625, Valid. AP: 0.5545\n",
      "Epoch: 3/100, Loss: 0.6868216, Train Acc: 0.5492, Valid. Acc: 0.5559, Train AUC: 0.5897, Train AP: 0.5732, Valid. AUC: 0.5627, Valid. AP: 0.5554\n",
      "Epoch: 4/100, Loss: 0.6830894, Train Acc: 0.5681, Valid. Acc: 0.5254, Train AUC: 0.5979, Train AP: 0.5825, Valid. AUC: 0.5638, Valid. AP: 0.5561\n",
      "Epoch: 5/100, Loss: 0.6811141, Train Acc: 0.5708, Valid. Acc: 0.5635, Train AUC: 0.5971, Train AP: 0.5814, Valid. AUC: 0.5717, Valid. AP: 0.5601\n",
      "Epoch: 6/100, Loss: 0.6785973, Train Acc: 0.5794, Valid. Acc: 0.5685, Train AUC: 0.6035, Train AP: 0.5817, Valid. AUC: 0.5820, Valid. AP: 0.5668\n",
      "Epoch: 7/100, Loss: 0.6762485, Train Acc: 0.5827, Valid. Acc: 0.5646, Train AUC: 0.6095, Train AP: 0.5865, Valid. AUC: 0.5916, Valid. AP: 0.5750\n",
      "Epoch: 8/100, Loss: 0.6739098, Train Acc: 0.5884, Valid. Acc: 0.5709, Train AUC: 0.6144, Train AP: 0.5888, Valid. AUC: 0.6053, Valid. AP: 0.5892\n",
      "Epoch: 9/100, Loss: 0.6727383, Train Acc: 0.5906, Valid. Acc: 0.5719, Train AUC: 0.6205, Train AP: 0.5967, Valid. AUC: 0.6136, Valid. AP: 0.5963\n",
      "Epoch: 10/100, Loss: 0.6756079, Train Acc: 0.5845, Valid. Acc: 0.5816, Train AUC: 0.6251, Train AP: 0.6019, Valid. AUC: 0.6209, Valid. AP: 0.6037\n",
      "Epoch: 11/100, Loss: 0.6703794, Train Acc: 0.5963, Valid. Acc: 0.5929, Train AUC: 0.6258, Train AP: 0.5979, Valid. AUC: 0.6239, Valid. AP: 0.6067\n",
      "Epoch: 12/100, Loss: 0.6712795, Train Acc: 0.5935, Valid. Acc: 0.5879, Train AUC: 0.6284, Train AP: 0.6031, Valid. AUC: 0.6254, Valid. AP: 0.6084\n",
      "Epoch: 13/100, Loss: 0.6690730, Train Acc: 0.5990, Valid. Acc: 0.5790, Train AUC: 0.6267, Train AP: 0.6020, Valid. AUC: 0.6262, Valid. AP: 0.6095\n",
      "Epoch: 14/100, Loss: 0.6691584, Train Acc: 0.5916, Valid. Acc: 0.5830, Train AUC: 0.6315, Train AP: 0.6072, Valid. AUC: 0.6278, Valid. AP: 0.6113\n",
      "Epoch: 15/100, Loss: 0.6671425, Train Acc: 0.5956, Valid. Acc: 0.5960, Train AUC: 0.6327, Train AP: 0.6113, Valid. AUC: 0.6291, Valid. AP: 0.6127\n",
      "Epoch: 16/100, Loss: 0.6659281, Train Acc: 0.6016, Valid. Acc: 0.5872, Train AUC: 0.6343, Train AP: 0.6097, Valid. AUC: 0.6288, Valid. AP: 0.6126\n",
      "Epoch: 17/100, Loss: 0.6663672, Train Acc: 0.6022, Valid. Acc: 0.5864, Train AUC: 0.6361, Train AP: 0.6135, Valid. AUC: 0.6281, Valid. AP: 0.6120\n",
      "Epoch: 18/100, Loss: 0.6651834, Train Acc: 0.6026, Valid. Acc: 0.5948, Train AUC: 0.6375, Train AP: 0.6139, Valid. AUC: 0.6275, Valid. AP: 0.6116\n",
      "Epoch: 19/100, Loss: 0.6640031, Train Acc: 0.6025, Valid. Acc: 0.5927, Train AUC: 0.6390, Train AP: 0.6169, Valid. AUC: 0.6262, Valid. AP: 0.6105\n",
      "Epoch: 20/100, Loss: 0.6641955, Train Acc: 0.6008, Valid. Acc: 0.5949, Train AUC: 0.6384, Train AP: 0.6165, Valid. AUC: 0.6257, Valid. AP: 0.6104\n",
      "Epoch: 21/100, Loss: 0.6624089, Train Acc: 0.6027, Valid. Acc: 0.5810, Train AUC: 0.6412, Train AP: 0.6191, Valid. AUC: 0.6260, Valid. AP: 0.6109\n",
      "Epoch: 22/100, Loss: 0.6621076, Train Acc: 0.6050, Valid. Acc: 0.5807, Train AUC: 0.6420, Train AP: 0.6198, Valid. AUC: 0.6277, Valid. AP: 0.6127\n",
      "Epoch: 23/100, Loss: 0.6618505, Train Acc: 0.6068, Valid. Acc: 0.5817, Train AUC: 0.6421, Train AP: 0.6192, Valid. AUC: 0.6276, Valid. AP: 0.6127\n",
      "Epoch: 24/100, Loss: 0.6605157, Train Acc: 0.6057, Valid. Acc: 0.5844, Train AUC: 0.6455, Train AP: 0.6227, Valid. AUC: 0.6280, Valid. AP: 0.6130\n",
      "Epoch: 25/100, Loss: 0.6601701, Train Acc: 0.6089, Valid. Acc: 0.5834, Train AUC: 0.6474, Train AP: 0.6241, Valid. AUC: 0.6291, Valid. AP: 0.6136\n",
      "Epoch: 26/100, Loss: 0.6592460, Train Acc: 0.6075, Valid. Acc: 0.5827, Train AUC: 0.6475, Train AP: 0.6251, Valid. AUC: 0.6314, Valid. AP: 0.6153\n",
      "Epoch: 27/100, Loss: 0.6592195, Train Acc: 0.6085, Valid. Acc: 0.5932, Train AUC: 0.6474, Train AP: 0.6253, Valid. AUC: 0.6340, Valid. AP: 0.6174\n",
      "Epoch: 28/100, Loss: 0.6580051, Train Acc: 0.6066, Valid. Acc: 0.6013, Train AUC: 0.6496, Train AP: 0.6277, Valid. AUC: 0.6397, Valid. AP: 0.6215\n",
      "Epoch: 29/100, Loss: 0.6573762, Train Acc: 0.6079, Valid. Acc: 0.6029, Train AUC: 0.6504, Train AP: 0.6295, Valid. AUC: 0.6433, Valid. AP: 0.6241\n",
      "Epoch: 30/100, Loss: 0.6565138, Train Acc: 0.6098, Valid. Acc: 0.6105, Train AUC: 0.6521, Train AP: 0.6310, Valid. AUC: 0.6478, Valid. AP: 0.6270\n",
      "Epoch: 31/100, Loss: 0.6562007, Train Acc: 0.6096, Valid. Acc: 0.6269, Train AUC: 0.6535, Train AP: 0.6316, Valid. AUC: 0.6496, Valid. AP: 0.6280\n",
      "Epoch: 32/100, Loss: 0.6555163, Train Acc: 0.6109, Valid. Acc: 0.6273, Train AUC: 0.6545, Train AP: 0.6325, Valid. AUC: 0.6513, Valid. AP: 0.6293\n",
      "Epoch: 33/100, Loss: 0.6538236, Train Acc: 0.6140, Valid. Acc: 0.6197, Train AUC: 0.6569, Train AP: 0.6345, Valid. AUC: 0.6527, Valid. AP: 0.6304\n",
      "Epoch: 34/100, Loss: 0.6532729, Train Acc: 0.6126, Valid. Acc: 0.6302, Train AUC: 0.6581, Train AP: 0.6369, Valid. AUC: 0.6537, Valid. AP: 0.6315\n",
      "Epoch: 35/100, Loss: 0.6529352, Train Acc: 0.6142, Valid. Acc: 0.6298, Train AUC: 0.6579, Train AP: 0.6373, Valid. AUC: 0.6541, Valid. AP: 0.6324\n",
      "Epoch: 36/100, Loss: 0.6512091, Train Acc: 0.6143, Valid. Acc: 0.6192, Train AUC: 0.6607, Train AP: 0.6404, Valid. AUC: 0.6542, Valid. AP: 0.6326\n",
      "Epoch: 37/100, Loss: 0.6518016, Train Acc: 0.6143, Valid. Acc: 0.6237, Train AUC: 0.6617, Train AP: 0.6422, Valid. AUC: 0.6538, Valid. AP: 0.6336\n",
      "Epoch: 38/100, Loss: 0.6493986, Train Acc: 0.6158, Valid. Acc: 0.6161, Train AUC: 0.6646, Train AP: 0.6444, Valid. AUC: 0.6537, Valid. AP: 0.6347\n",
      "Epoch: 39/100, Loss: 0.6487797, Train Acc: 0.6168, Valid. Acc: 0.6147, Train AUC: 0.6665, Train AP: 0.6470, Valid. AUC: 0.6544, Valid. AP: 0.6369\n",
      "Epoch: 40/100, Loss: 0.6469814, Train Acc: 0.6150, Valid. Acc: 0.6152, Train AUC: 0.6686, Train AP: 0.6504, Valid. AUC: 0.6558, Valid. AP: 0.6381\n",
      "Epoch: 41/100, Loss: 0.6459673, Train Acc: 0.6194, Valid. Acc: 0.6192, Train AUC: 0.6703, Train AP: 0.6510, Valid. AUC: 0.6526, Valid. AP: 0.6357\n",
      "Epoch: 42/100, Loss: 0.6466458, Train Acc: 0.6217, Valid. Acc: 0.6237, Train AUC: 0.6741, Train AP: 0.6539, Valid. AUC: 0.6606, Valid. AP: 0.6437\n",
      "Epoch: 43/100, Loss: 0.6427230, Train Acc: 0.6233, Valid. Acc: 0.6322, Train AUC: 0.6754, Train AP: 0.6582, Valid. AUC: 0.6653, Valid. AP: 0.6468\n",
      "Epoch: 44/100, Loss: 0.6408905, Train Acc: 0.6289, Valid. Acc: 0.6339, Train AUC: 0.6793, Train AP: 0.6614, Valid. AUC: 0.6683, Valid. AP: 0.6474\n",
      "Epoch: 45/100, Loss: 0.6395313, Train Acc: 0.6387, Valid. Acc: 0.6342, Train AUC: 0.6873, Train AP: 0.6651, Valid. AUC: 0.6732, Valid. AP: 0.6526\n",
      "Epoch: 46/100, Loss: 0.6369756, Train Acc: 0.6358, Valid. Acc: 0.6396, Train AUC: 0.6861, Train AP: 0.6674, Valid. AUC: 0.6765, Valid. AP: 0.6557\n",
      "Epoch: 47/100, Loss: 0.6356410, Train Acc: 0.6394, Valid. Acc: 0.6156, Train AUC: 0.6877, Train AP: 0.6693, Valid. AUC: 0.6632, Valid. AP: 0.6439\n",
      "Epoch: 48/100, Loss: 0.6379789, Train Acc: 0.6438, Valid. Acc: 0.6434, Train AUC: 0.6931, Train AP: 0.6675, Valid. AUC: 0.6826, Valid. AP: 0.6619\n",
      "Epoch: 49/100, Loss: 0.6315776, Train Acc: 0.6469, Valid. Acc: 0.6378, Train AUC: 0.6961, Train AP: 0.6782, Valid. AUC: 0.6844, Valid. AP: 0.6635\n",
      "Epoch: 50/100, Loss: 0.6318666, Train Acc: 0.6439, Valid. Acc: 0.6414, Train AUC: 0.6957, Train AP: 0.6785, Valid. AUC: 0.6853, Valid. AP: 0.6632\n",
      "Epoch: 51/100, Loss: 0.6290219, Train Acc: 0.6496, Valid. Acc: 0.6383, Train AUC: 0.7012, Train AP: 0.6783, Valid. AUC: 0.6837, Valid. AP: 0.6632\n",
      "Epoch: 52/100, Loss: 0.6281747, Train Acc: 0.6511, Valid. Acc: 0.6412, Train AUC: 0.7042, Train AP: 0.6826, Valid. AUC: 0.6907, Valid. AP: 0.6692\n",
      "Epoch: 53/100, Loss: 0.6272560, Train Acc: 0.6481, Valid. Acc: 0.6430, Train AUC: 0.7046, Train AP: 0.6848, Valid. AUC: 0.6919, Valid. AP: 0.6708\n",
      "Epoch: 54/100, Loss: 0.6242323, Train Acc: 0.6509, Valid. Acc: 0.6189, Train AUC: 0.7064, Train AP: 0.6876, Valid. AUC: 0.6693, Valid. AP: 0.6552\n",
      "Epoch: 55/100, Loss: 0.6331717, Train Acc: 0.6399, Valid. Acc: 0.6439, Train AUC: 0.6951, Train AP: 0.6736, Valid. AUC: 0.6925, Valid. AP: 0.6727\n",
      "Epoch: 56/100, Loss: 0.6208996, Train Acc: 0.6555, Valid. Acc: 0.6341, Train AUC: 0.7113, Train AP: 0.6910, Valid. AUC: 0.6907, Valid. AP: 0.6702\n",
      "Epoch: 57/100, Loss: 0.6257567, Train Acc: 0.6517, Valid. Acc: 0.6290, Train AUC: 0.7063, Train AP: 0.6860, Valid. AUC: 0.6890, Valid. AP: 0.6723\n",
      "Epoch: 58/100, Loss: 0.6202258, Train Acc: 0.6521, Valid. Acc: 0.6425, Train AUC: 0.7147, Train AP: 0.6938, Valid. AUC: 0.6927, Valid. AP: 0.6749\n",
      "Epoch: 59/100, Loss: 0.6173255, Train Acc: 0.6572, Valid. Acc: 0.6443, Train AUC: 0.7171, Train AP: 0.6954, Valid. AUC: 0.6981, Valid. AP: 0.6779\n",
      "Epoch: 60/100, Loss: 0.6179705, Train Acc: 0.6582, Valid. Acc: 0.6489, Train AUC: 0.7179, Train AP: 0.6948, Valid. AUC: 0.6996, Valid. AP: 0.6802\n",
      "Epoch: 61/100, Loss: 0.6140473, Train Acc: 0.6596, Valid. Acc: 0.6424, Train AUC: 0.7198, Train AP: 0.6988, Valid. AUC: 0.6965, Valid. AP: 0.6797\n",
      "Epoch: 62/100, Loss: 0.6151810, Train Acc: 0.6575, Valid. Acc: 0.6443, Train AUC: 0.7210, Train AP: 0.7020, Valid. AUC: 0.6986, Valid. AP: 0.6820\n",
      "Epoch: 63/100, Loss: 0.6151695, Train Acc: 0.6590, Valid. Acc: 0.6411, Train AUC: 0.7217, Train AP: 0.7011, Valid. AUC: 0.6921, Valid. AP: 0.6783\n",
      "Epoch: 64/100, Loss: 0.6120823, Train Acc: 0.6607, Valid. Acc: 0.6442, Train AUC: 0.7222, Train AP: 0.7050, Valid. AUC: 0.6984, Valid. AP: 0.6833\n",
      "Epoch: 65/100, Loss: 0.6116033, Train Acc: 0.6615, Valid. Acc: 0.6459, Train AUC: 0.7245, Train AP: 0.7068, Valid. AUC: 0.6982, Valid. AP: 0.6845\n",
      "Epoch: 66/100, Loss: 0.6087167, Train Acc: 0.6627, Valid. Acc: 0.6370, Train AUC: 0.7265, Train AP: 0.7089, Valid. AUC: 0.6915, Valid. AP: 0.6788\n",
      "Epoch: 67/100, Loss: 0.6114676, Train Acc: 0.6572, Valid. Acc: 0.6456, Train AUC: 0.7235, Train AP: 0.7062, Valid. AUC: 0.7013, Valid. AP: 0.6871\n",
      "Epoch: 68/100, Loss: 0.6099407, Train Acc: 0.6611, Valid. Acc: 0.6514, Train AUC: 0.7262, Train AP: 0.7086, Valid. AUC: 0.7048, Valid. AP: 0.6899\n",
      "Epoch: 69/100, Loss: 0.6052092, Train Acc: 0.6655, Valid. Acc: 0.6473, Train AUC: 0.7310, Train AP: 0.7149, Valid. AUC: 0.7026, Valid. AP: 0.6877\n",
      "Epoch: 70/100, Loss: 0.6059283, Train Acc: 0.6666, Valid. Acc: 0.6544, Train AUC: 0.7309, Train AP: 0.7133, Valid. AUC: 0.7064, Valid. AP: 0.6907\n",
      "Epoch: 71/100, Loss: 0.6041256, Train Acc: 0.6677, Valid. Acc: 0.6464, Train AUC: 0.7317, Train AP: 0.7153, Valid. AUC: 0.6990, Valid. AP: 0.6837\n",
      "Epoch: 72/100, Loss: 0.6052843, Train Acc: 0.6634, Valid. Acc: 0.6539, Train AUC: 0.7305, Train AP: 0.7149, Valid. AUC: 0.7064, Valid. AP: 0.6921\n",
      "Epoch: 73/100, Loss: 0.6021159, Train Acc: 0.6687, Valid. Acc: 0.6517, Train AUC: 0.7337, Train AP: 0.7180, Valid. AUC: 0.7054, Valid. AP: 0.6921\n",
      "Epoch: 74/100, Loss: 0.5999977, Train Acc: 0.6703, Valid. Acc: 0.6354, Train AUC: 0.7361, Train AP: 0.7210, Valid. AUC: 0.6907, Valid. AP: 0.6813\n",
      "Epoch: 75/100, Loss: 0.6024966, Train Acc: 0.6665, Valid. Acc: 0.6446, Train AUC: 0.7336, Train AP: 0.7179, Valid. AUC: 0.6989, Valid. AP: 0.6881\n",
      "Epoch: 76/100, Loss: 0.5980247, Train Acc: 0.6709, Valid. Acc: 0.6451, Train AUC: 0.7379, Train AP: 0.7254, Valid. AUC: 0.7017, Valid. AP: 0.6903\n",
      "Epoch: 77/100, Loss: 0.6007788, Train Acc: 0.6702, Valid. Acc: 0.6437, Train AUC: 0.7355, Train AP: 0.7217, Valid. AUC: 0.6993, Valid. AP: 0.6888\n",
      "Epoch: 78/100, Loss: 0.5949411, Train Acc: 0.6712, Valid. Acc: 0.6430, Train AUC: 0.7424, Train AP: 0.7308, Valid. AUC: 0.6989, Valid. AP: 0.6884\n",
      "Epoch: 79/100, Loss: 0.5968510, Train Acc: 0.6700, Valid. Acc: 0.6495, Train AUC: 0.7392, Train AP: 0.7279, Valid. AUC: 0.7070, Valid. AP: 0.6967\n",
      "Epoch: 80/100, Loss: 0.5984450, Train Acc: 0.6706, Valid. Acc: 0.6493, Train AUC: 0.7384, Train AP: 0.7246, Valid. AUC: 0.7053, Valid. AP: 0.6960\n",
      "Epoch: 81/100, Loss: 0.5946098, Train Acc: 0.6726, Valid. Acc: 0.6516, Train AUC: 0.7421, Train AP: 0.7304, Valid. AUC: 0.7089, Valid. AP: 0.6998\n",
      "Epoch: 82/100, Loss: 0.5928665, Train Acc: 0.6759, Valid. Acc: 0.6526, Train AUC: 0.7459, Train AP: 0.7353, Valid. AUC: 0.7075, Valid. AP: 0.6989\n",
      "Epoch: 83/100, Loss: 0.5910758, Train Acc: 0.6764, Valid. Acc: 0.6576, Train AUC: 0.7460, Train AP: 0.7376, Valid. AUC: 0.7130, Valid. AP: 0.7037\n",
      "Epoch: 84/100, Loss: 0.5906198, Train Acc: 0.6775, Valid. Acc: 0.6598, Train AUC: 0.7477, Train AP: 0.7372, Valid. AUC: 0.7156, Valid. AP: 0.7057\n",
      "Epoch: 85/100, Loss: 0.5899737, Train Acc: 0.6776, Valid. Acc: 0.6328, Train AUC: 0.7475, Train AP: 0.7363, Valid. AUC: 0.6861, Valid. AP: 0.6805\n",
      "Epoch: 86/100, Loss: 0.6004120, Train Acc: 0.6653, Valid. Acc: 0.6496, Train AUC: 0.7328, Train AP: 0.7259, Valid. AUC: 0.7029, Valid. AP: 0.6921\n",
      "Epoch: 87/100, Loss: 0.6063285, Train Acc: 0.6658, Valid. Acc: 0.6505, Train AUC: 0.7335, Train AP: 0.7203, Valid. AUC: 0.7098, Valid. AP: 0.7036\n",
      "Epoch: 88/100, Loss: 0.5863287, Train Acc: 0.6802, Valid. Acc: 0.6136, Train AUC: 0.7521, Train AP: 0.7439, Valid. AUC: 0.6668, Valid. AP: 0.6661\n",
      "Epoch: 89/100, Loss: 0.6053855, Train Acc: 0.6582, Valid. Acc: 0.6522, Train AUC: 0.7260, Train AP: 0.7206, Valid. AUC: 0.7089, Valid. AP: 0.7008\n",
      "Epoch: 90/100, Loss: 0.5909459, Train Acc: 0.6761, Valid. Acc: 0.6528, Train AUC: 0.7471, Train AP: 0.7374, Valid. AUC: 0.7094, Valid. AP: 0.6998\n",
      "Epoch: 91/100, Loss: 0.5940167, Train Acc: 0.6751, Valid. Acc: 0.6406, Train AUC: 0.7443, Train AP: 0.7342, Valid. AUC: 0.6991, Valid. AP: 0.6944\n",
      "Epoch: 92/100, Loss: 0.5897904, Train Acc: 0.6762, Valid. Acc: 0.6344, Train AUC: 0.7489, Train AP: 0.7417, Valid. AUC: 0.6916, Valid. AP: 0.6879\n",
      "Epoch: 93/100, Loss: 0.5930558, Train Acc: 0.6726, Valid. Acc: 0.6564, Train AUC: 0.7458, Train AP: 0.7420, Valid. AUC: 0.7161, Valid. AP: 0.7087\n",
      "Epoch: 94/100, Loss: 0.5873957, Train Acc: 0.6812, Valid. Acc: 0.6589, Train AUC: 0.7522, Train AP: 0.7440, Valid. AUC: 0.7163, Valid. AP: 0.7081\n",
      "Epoch: 95/100, Loss: 0.5872586, Train Acc: 0.6804, Valid. Acc: 0.6499, Train AUC: 0.7511, Train AP: 0.7429, Valid. AUC: 0.7094, Valid. AP: 0.7041\n",
      "Epoch: 96/100, Loss: 0.5832050, Train Acc: 0.6829, Valid. Acc: 0.6466, Train AUC: 0.7558, Train AP: 0.7515, Valid. AUC: 0.7059, Valid. AP: 0.7010\n",
      "Epoch: 97/100, Loss: 0.5855558, Train Acc: 0.6777, Valid. Acc: 0.6594, Train AUC: 0.7527, Train AP: 0.7500, Valid. AUC: 0.7195, Valid. AP: 0.7118\n",
      "Epoch: 98/100, Loss: 0.5814133, Train Acc: 0.6846, Valid. Acc: 0.6590, Train AUC: 0.7576, Train AP: 0.7502, Valid. AUC: 0.7196, Valid. AP: 0.7125\n",
      "Epoch: 99/100, Loss: 0.5811061, Train Acc: 0.6846, Valid. Acc: 0.6478, Train AUC: 0.7579, Train AP: 0.7499, Valid. AUC: 0.7082, Valid. AP: 0.7047\n",
      "Epoch: 100/100, Loss: 0.5819615, Train Acc: 0.6825, Valid. Acc: 0.6490, Train AUC: 0.7557, Train AP: 0.7502, Valid. AUC: 0.7089, Valid. AP: 0.7048\n",
      "/home/ubuntu/PA-Cancer-Immunotherapy/GNN/train_pa_all_tvt.py:212: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(configs['save_model']))\n",
      "Task-wise AP and ROC AUC:\n",
      "Task: TPP1, AP: 0.6848, ROC AUC: 0.6973\n",
      "Task: TPP2, AP: 0.7511, ROC AUC: 0.7509\n",
      "Task: TPP3, AP: 0.8148, ROC AUC: 0.5691\n",
      "Task: TPP4, AP and ROC AUC cannot be calculated (only one class present).\n",
      "\n",
      "Overall AP and ROC AUC:\n",
      "Overall AP: 0.7133, Overall ROC AUC: 0.7224\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.695 MB of 1.695 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.696 MB of 1.696 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.696 MB of 1.696 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.696 MB of 1.696 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▁▁▂▂▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇█████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        test_ap ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   test_roc_auc ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▁▂▄▄▅▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇██████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train_ap ▁▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss ██▇▇▇▇▇▆▆▆▆▆▆▆▆▅▅▅▅▅▄▄▃▃▃▃▃▃▃▃▂▂▂▂▁▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_roc_auc ▁▃▄▄▄▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇██▇█████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: valid_accuracy ▂▃▁▃▃▃▄▄▄▅▄▄▄▄▄▆▆▆▆▇▇▇▆▇▆▇▇▇▇█▇▇▇█▇▆██▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       valid_ap ▁▁▂▃▃▄▄▄▄▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇█▇▇▆▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  valid_roc_auc ▁▁▂▂▄▄▄▄▄▅▅▅▅▅▅▆▆▇▇▇▇▇▇▇▇▇▇▇█████▇██████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy 0.66169\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        test_ap 0.71326\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   test_roc_auc 0.72242\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.68246\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train_ap 0.75023\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.58196\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_roc_auc 0.75567\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: valid_accuracy 0.64899\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       valid_ap 0.70482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  valid_roc_auc 0.70894\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mdauntless-sponge-14\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-allele_GNN/runs/j92tngw2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-allele_GNN\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 6 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241217_120820-j92tngw2/logs\u001b[0m\n",
      "Test Acc: 0.6617, Test AUC: 0.7224, Test AP: 0.7133\n"
     ]
    }
   ],
   "source": [
    "# new calculation AP and AUC for TTP and compare global metrics to check correct code.\n",
    "# allele\n",
    "\n",
    "! python train_pa_all_tvt.py --gpu 0 --configs_path configs/PA_all_tvt_allele.yml --droup_out 0.1 --split StrictTCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbd5bf8d-3157-4397-ad91-558f2664aa38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(gpu=0, lr=0.001, epochs=100, w_celoss=1, w_aucloss=0, add_same_type_edges=False, dynamic_graph=False, dynamic_ratio=0.05, droup_out=0.1, positive_weights=1, dynamic_epochs=30, distance_threshold=10, configs_path='configs/PA_all_tvt_gene.yml', split='StrictTCR', dataset='pMTnet')\n",
      "PROJECT_NAME: dataset-all-tvt-gene_GNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfrohoari\u001b[0m (\u001b[33mpa_cancerimmunotherapy\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/ubuntu/PA-Cancer-Immunotherapy/GNN/wandb/run-20241217_122309-erlsy45d\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mvisionary-frog-10\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-gene_GNN\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-gene_GNN/runs/erlsy45d\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   6 of 6 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   6 of 6 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   6 of 6 files downloaded.  \n",
      "embeddings_path:   models/PA_all/gene_and_allele_embeddings.pkl\n",
      "train_file_list:   ['gene_train.csv']\n",
      "validation_file_list:   ['gene_validation.csv']\n",
      "test_file_list:   ['gene_test.csv']\n",
      "wandb logger initialisiert\n",
      "Epoch: 1/100, Loss: 0.6933187, Train Acc: 0.5015, Valid. Acc: 0.4996, Train AUC: 0.4987, Train AP: 0.4993, Valid. AUC: 0.5409, Valid. AP: 0.5310\n",
      "Epoch: 2/100, Loss: 0.6909529, Train Acc: 0.5056, Valid. Acc: 0.5382, Train AUC: 0.5701, Train AP: 0.5528, Valid. AUC: 0.5544, Valid. AP: 0.5475\n",
      "Epoch: 3/100, Loss: 0.6864629, Train Acc: 0.5495, Valid. Acc: 0.5545, Train AUC: 0.5937, Train AP: 0.5843, Valid. AUC: 0.5515, Valid. AP: 0.5441\n",
      "Epoch: 4/100, Loss: 0.6836001, Train Acc: 0.5693, Valid. Acc: 0.5189, Train AUC: 0.5953, Train AP: 0.5846, Valid. AUC: 0.5519, Valid. AP: 0.5429\n",
      "Epoch: 5/100, Loss: 0.6805421, Train Acc: 0.5728, Valid. Acc: 0.5522, Train AUC: 0.5991, Train AP: 0.5860, Valid. AUC: 0.5579, Valid. AP: 0.5487\n",
      "Epoch: 6/100, Loss: 0.6789077, Train Acc: 0.5763, Valid. Acc: 0.5602, Train AUC: 0.6028, Train AP: 0.5912, Valid. AUC: 0.5656, Valid. AP: 0.5572\n",
      "Epoch: 7/100, Loss: 0.6759972, Train Acc: 0.5801, Valid. Acc: 0.5618, Train AUC: 0.6116, Train AP: 0.5962, Valid. AUC: 0.5744, Valid. AP: 0.5631\n",
      "Epoch: 8/100, Loss: 0.6750869, Train Acc: 0.5835, Valid. Acc: 0.5449, Train AUC: 0.6149, Train AP: 0.6014, Valid. AUC: 0.5810, Valid. AP: 0.5668\n",
      "Epoch: 9/100, Loss: 0.6722889, Train Acc: 0.5908, Valid. Acc: 0.5521, Train AUC: 0.6201, Train AP: 0.6062, Valid. AUC: 0.5911, Valid. AP: 0.5745\n",
      "Epoch: 10/100, Loss: 0.6707431, Train Acc: 0.5943, Valid. Acc: 0.5741, Train AUC: 0.6242, Train AP: 0.6074, Valid. AUC: 0.6009, Valid. AP: 0.5817\n",
      "Epoch: 11/100, Loss: 0.6695085, Train Acc: 0.5961, Valid. Acc: 0.5788, Train AUC: 0.6293, Train AP: 0.6129, Valid. AUC: 0.6068, Valid. AP: 0.5869\n",
      "Epoch: 12/100, Loss: 0.6692298, Train Acc: 0.5975, Valid. Acc: 0.5755, Train AUC: 0.6289, Train AP: 0.6158, Valid. AUC: 0.6105, Valid. AP: 0.5897\n",
      "Epoch: 13/100, Loss: 0.6674303, Train Acc: 0.5985, Valid. Acc: 0.5843, Train AUC: 0.6332, Train AP: 0.6186, Valid. AUC: 0.6141, Valid. AP: 0.5922\n",
      "Epoch: 14/100, Loss: 0.6663337, Train Acc: 0.6010, Valid. Acc: 0.5753, Train AUC: 0.6344, Train AP: 0.6176, Valid. AUC: 0.6159, Valid. AP: 0.5930\n",
      "Epoch: 15/100, Loss: 0.6667811, Train Acc: 0.5994, Valid. Acc: 0.5821, Train AUC: 0.6351, Train AP: 0.6193, Valid. AUC: 0.6176, Valid. AP: 0.5943\n",
      "Epoch: 16/100, Loss: 0.6648242, Train Acc: 0.6021, Valid. Acc: 0.5902, Train AUC: 0.6369, Train AP: 0.6204, Valid. AUC: 0.6218, Valid. AP: 0.5965\n",
      "Epoch: 17/100, Loss: 0.6640779, Train Acc: 0.6042, Valid. Acc: 0.6055, Train AUC: 0.6390, Train AP: 0.6231, Valid. AUC: 0.6233, Valid. AP: 0.5973\n",
      "Epoch: 18/100, Loss: 0.6633551, Train Acc: 0.6035, Valid. Acc: 0.5877, Train AUC: 0.6414, Train AP: 0.6256, Valid. AUC: 0.6249, Valid. AP: 0.5985\n",
      "Epoch: 19/100, Loss: 0.6626718, Train Acc: 0.6066, Valid. Acc: 0.5857, Train AUC: 0.6429, Train AP: 0.6274, Valid. AUC: 0.6262, Valid. AP: 0.5996\n",
      "Epoch: 20/100, Loss: 0.6637596, Train Acc: 0.6062, Valid. Acc: 0.5877, Train AUC: 0.6440, Train AP: 0.6278, Valid. AUC: 0.6264, Valid. AP: 0.6002\n",
      "Epoch: 21/100, Loss: 0.6616318, Train Acc: 0.6067, Valid. Acc: 0.5999, Train AUC: 0.6440, Train AP: 0.6282, Valid. AUC: 0.6256, Valid. AP: 0.5998\n",
      "Epoch: 22/100, Loss: 0.6614210, Train Acc: 0.6054, Valid. Acc: 0.5957, Train AUC: 0.6451, Train AP: 0.6293, Valid. AUC: 0.6244, Valid. AP: 0.5995\n",
      "Epoch: 23/100, Loss: 0.6606087, Train Acc: 0.6084, Valid. Acc: 0.5901, Train AUC: 0.6460, Train AP: 0.6298, Valid. AUC: 0.6245, Valid. AP: 0.6002\n",
      "Epoch: 24/100, Loss: 0.6605316, Train Acc: 0.6082, Valid. Acc: 0.5893, Train AUC: 0.6458, Train AP: 0.6305, Valid. AUC: 0.6284, Valid. AP: 0.6034\n",
      "Epoch: 25/100, Loss: 0.6606395, Train Acc: 0.6093, Valid. Acc: 0.5988, Train AUC: 0.6479, Train AP: 0.6319, Valid. AUC: 0.6290, Valid. AP: 0.6042\n",
      "Epoch: 26/100, Loss: 0.6595280, Train Acc: 0.6094, Valid. Acc: 0.5965, Train AUC: 0.6482, Train AP: 0.6320, Valid. AUC: 0.6314, Valid. AP: 0.6059\n",
      "Epoch: 27/100, Loss: 0.6593182, Train Acc: 0.6090, Valid. Acc: 0.6210, Train AUC: 0.6494, Train AP: 0.6337, Valid. AUC: 0.6333, Valid. AP: 0.6073\n",
      "Epoch: 28/100, Loss: 0.6598665, Train Acc: 0.6082, Valid. Acc: 0.6220, Train AUC: 0.6468, Train AP: 0.6318, Valid. AUC: 0.6353, Valid. AP: 0.6086\n",
      "Epoch: 29/100, Loss: 0.6580538, Train Acc: 0.6114, Valid. Acc: 0.6239, Train AUC: 0.6510, Train AP: 0.6349, Valid. AUC: 0.6362, Valid. AP: 0.6093\n",
      "Epoch: 30/100, Loss: 0.6577575, Train Acc: 0.6117, Valid. Acc: 0.6256, Train AUC: 0.6513, Train AP: 0.6353, Valid. AUC: 0.6358, Valid. AP: 0.6094\n",
      "Epoch: 31/100, Loss: 0.6571519, Train Acc: 0.6118, Valid. Acc: 0.6259, Train AUC: 0.6526, Train AP: 0.6368, Valid. AUC: 0.6360, Valid. AP: 0.6097\n",
      "Epoch: 32/100, Loss: 0.6569284, Train Acc: 0.6121, Valid. Acc: 0.6248, Train AUC: 0.6531, Train AP: 0.6367, Valid. AUC: 0.6361, Valid. AP: 0.6098\n",
      "Epoch: 33/100, Loss: 0.6566291, Train Acc: 0.6126, Valid. Acc: 0.6223, Train AUC: 0.6535, Train AP: 0.6379, Valid. AUC: 0.6367, Valid. AP: 0.6103\n",
      "Epoch: 34/100, Loss: 0.6567823, Train Acc: 0.6128, Valid. Acc: 0.6236, Train AUC: 0.6535, Train AP: 0.6367, Valid. AUC: 0.6367, Valid. AP: 0.6111\n",
      "Epoch: 35/100, Loss: 0.6562457, Train Acc: 0.6123, Valid. Acc: 0.6194, Train AUC: 0.6543, Train AP: 0.6386, Valid. AUC: 0.6373, Valid. AP: 0.6122\n",
      "Epoch: 36/100, Loss: 0.6561733, Train Acc: 0.6124, Valid. Acc: 0.6235, Train AUC: 0.6551, Train AP: 0.6384, Valid. AUC: 0.6377, Valid. AP: 0.6130\n",
      "Epoch: 37/100, Loss: 0.6551155, Train Acc: 0.6140, Valid. Acc: 0.6217, Train AUC: 0.6567, Train AP: 0.6410, Valid. AUC: 0.6381, Valid. AP: 0.6138\n",
      "Epoch: 38/100, Loss: 0.6549547, Train Acc: 0.6130, Valid. Acc: 0.6196, Train AUC: 0.6571, Train AP: 0.6417, Valid. AUC: 0.6386, Valid. AP: 0.6149\n",
      "Epoch: 39/100, Loss: 0.6541387, Train Acc: 0.6143, Valid. Acc: 0.6258, Train AUC: 0.6584, Train AP: 0.6426, Valid. AUC: 0.6405, Valid. AP: 0.6174\n",
      "Epoch: 40/100, Loss: 0.6537728, Train Acc: 0.6148, Valid. Acc: 0.6250, Train AUC: 0.6589, Train AP: 0.6446, Valid. AUC: 0.6419, Valid. AP: 0.6193\n",
      "Epoch: 41/100, Loss: 0.6533148, Train Acc: 0.6164, Valid. Acc: 0.6233, Train AUC: 0.6601, Train AP: 0.6455, Valid. AUC: 0.6430, Valid. AP: 0.6203\n",
      "Epoch: 42/100, Loss: 0.6527172, Train Acc: 0.6158, Valid. Acc: 0.6159, Train AUC: 0.6609, Train AP: 0.6461, Valid. AUC: 0.6442, Valid. AP: 0.6212\n",
      "Epoch: 43/100, Loss: 0.6528263, Train Acc: 0.6161, Valid. Acc: 0.6126, Train AUC: 0.6624, Train AP: 0.6471, Valid. AUC: 0.6427, Valid. AP: 0.6205\n",
      "Epoch: 44/100, Loss: 0.6514575, Train Acc: 0.6165, Valid. Acc: 0.6200, Train AUC: 0.6633, Train AP: 0.6483, Valid. AUC: 0.6424, Valid. AP: 0.6211\n",
      "Epoch: 45/100, Loss: 0.6509945, Train Acc: 0.6182, Valid. Acc: 0.6177, Train AUC: 0.6637, Train AP: 0.6500, Valid. AUC: 0.6462, Valid. AP: 0.6254\n",
      "Epoch: 46/100, Loss: 0.6500645, Train Acc: 0.6187, Valid. Acc: 0.6162, Train AUC: 0.6665, Train AP: 0.6519, Valid. AUC: 0.6480, Valid. AP: 0.6272\n",
      "Epoch: 47/100, Loss: 0.6495217, Train Acc: 0.6256, Valid. Acc: 0.6153, Train AUC: 0.6706, Train AP: 0.6574, Valid. AUC: 0.6464, Valid. AP: 0.6248\n",
      "Epoch: 48/100, Loss: 0.6471900, Train Acc: 0.6221, Valid. Acc: 0.6100, Train AUC: 0.6705, Train AP: 0.6573, Valid. AUC: 0.6464, Valid. AP: 0.6242\n",
      "Epoch: 49/100, Loss: 0.6470814, Train Acc: 0.6212, Valid. Acc: 0.6263, Train AUC: 0.6706, Train AP: 0.6581, Valid. AUC: 0.6558, Valid. AP: 0.6332\n",
      "Epoch: 50/100, Loss: 0.6445941, Train Acc: 0.6313, Valid. Acc: 0.6289, Train AUC: 0.6775, Train AP: 0.6632, Valid. AUC: 0.6600, Valid. AP: 0.6367\n",
      "Epoch: 51/100, Loss: 0.6460763, Train Acc: 0.6324, Valid. Acc: 0.6130, Train AUC: 0.6816, Train AP: 0.6662, Valid. AUC: 0.6535, Valid. AP: 0.6303\n",
      "Epoch: 52/100, Loss: 0.6412714, Train Acc: 0.6344, Valid. Acc: 0.6084, Train AUC: 0.6814, Train AP: 0.6683, Valid. AUC: 0.6547, Valid. AP: 0.6310\n",
      "Epoch: 53/100, Loss: 0.6400561, Train Acc: 0.6386, Valid. Acc: 0.6295, Train AUC: 0.6839, Train AP: 0.6699, Valid. AUC: 0.6672, Valid. AP: 0.6449\n",
      "Epoch: 54/100, Loss: 0.6397169, Train Acc: 0.6496, Valid. Acc: 0.6282, Train AUC: 0.6919, Train AP: 0.6743, Valid. AUC: 0.6671, Valid. AP: 0.6443\n",
      "Epoch: 55/100, Loss: 0.6346830, Train Acc: 0.6510, Valid. Acc: 0.6229, Train AUC: 0.6964, Train AP: 0.6801, Valid. AUC: 0.6628, Valid. AP: 0.6392\n",
      "Epoch: 56/100, Loss: 0.6337485, Train Acc: 0.6507, Valid. Acc: 0.6307, Train AUC: 0.6958, Train AP: 0.6800, Valid. AUC: 0.6709, Valid. AP: 0.6479\n",
      "Epoch: 57/100, Loss: 0.6325554, Train Acc: 0.6537, Valid. Acc: 0.6330, Train AUC: 0.7007, Train AP: 0.6854, Valid. AUC: 0.6737, Valid. AP: 0.6524\n",
      "Epoch: 58/100, Loss: 0.6296391, Train Acc: 0.6539, Valid. Acc: 0.6227, Train AUC: 0.7034, Train AP: 0.6922, Valid. AUC: 0.6622, Valid. AP: 0.6391\n",
      "Epoch: 59/100, Loss: 0.6285743, Train Acc: 0.6538, Valid. Acc: 0.6316, Train AUC: 0.7048, Train AP: 0.6905, Valid. AUC: 0.6702, Valid. AP: 0.6472\n",
      "Epoch: 60/100, Loss: 0.6233042, Train Acc: 0.6563, Valid. Acc: 0.6314, Train AUC: 0.7105, Train AP: 0.6988, Valid. AUC: 0.6747, Valid. AP: 0.6538\n",
      "Epoch: 61/100, Loss: 0.6259409, Train Acc: 0.6510, Valid. Acc: 0.6222, Train AUC: 0.7097, Train AP: 0.7013, Valid. AUC: 0.6597, Valid. AP: 0.6371\n",
      "Epoch: 62/100, Loss: 0.6240962, Train Acc: 0.6544, Valid. Acc: 0.6250, Train AUC: 0.7097, Train AP: 0.6968, Valid. AUC: 0.6695, Valid. AP: 0.6499\n",
      "Epoch: 63/100, Loss: 0.6243451, Train Acc: 0.6540, Valid. Acc: 0.6327, Train AUC: 0.7129, Train AP: 0.7025, Valid. AUC: 0.6766, Valid. AP: 0.6564\n",
      "Epoch: 64/100, Loss: 0.6207426, Train Acc: 0.6542, Valid. Acc: 0.6309, Train AUC: 0.7133, Train AP: 0.7037, Valid. AUC: 0.6758, Valid. AP: 0.6527\n",
      "Epoch: 65/100, Loss: 0.6180912, Train Acc: 0.6583, Valid. Acc: 0.6256, Train AUC: 0.7184, Train AP: 0.7110, Valid. AUC: 0.6684, Valid. AP: 0.6463\n",
      "Epoch: 66/100, Loss: 0.6187843, Train Acc: 0.6590, Valid. Acc: 0.6324, Train AUC: 0.7162, Train AP: 0.7086, Valid. AUC: 0.6808, Valid. AP: 0.6613\n",
      "Epoch: 67/100, Loss: 0.6222064, Train Acc: 0.6526, Valid. Acc: 0.6354, Train AUC: 0.7154, Train AP: 0.7090, Valid. AUC: 0.6774, Valid. AP: 0.6577\n",
      "Epoch: 68/100, Loss: 0.6133219, Train Acc: 0.6618, Valid. Acc: 0.6291, Train AUC: 0.7212, Train AP: 0.7139, Valid. AUC: 0.6752, Valid. AP: 0.6558\n",
      "Epoch: 69/100, Loss: 0.6170978, Train Acc: 0.6591, Valid. Acc: 0.6381, Train AUC: 0.7223, Train AP: 0.7112, Valid. AUC: 0.6831, Valid. AP: 0.6641\n",
      "Epoch: 70/100, Loss: 0.6148390, Train Acc: 0.6598, Valid. Acc: 0.6415, Train AUC: 0.7228, Train AP: 0.7109, Valid. AUC: 0.6872, Valid. AP: 0.6686\n",
      "Epoch: 71/100, Loss: 0.6113935, Train Acc: 0.6608, Valid. Acc: 0.6386, Train AUC: 0.7230, Train AP: 0.7174, Valid. AUC: 0.6866, Valid. AP: 0.6671\n",
      "Epoch: 72/100, Loss: 0.6124291, Train Acc: 0.6614, Valid. Acc: 0.6389, Train AUC: 0.7248, Train AP: 0.7177, Valid. AUC: 0.6839, Valid. AP: 0.6632\n",
      "Epoch: 73/100, Loss: 0.6111993, Train Acc: 0.6629, Valid. Acc: 0.6443, Train AUC: 0.7238, Train AP: 0.7169, Valid. AUC: 0.6904, Valid. AP: 0.6690\n",
      "Epoch: 74/100, Loss: 0.6096309, Train Acc: 0.6619, Valid. Acc: 0.6428, Train AUC: 0.7241, Train AP: 0.7198, Valid. AUC: 0.6891, Valid. AP: 0.6677\n",
      "Epoch: 75/100, Loss: 0.6090367, Train Acc: 0.6608, Valid. Acc: 0.6358, Train AUC: 0.7257, Train AP: 0.7220, Valid. AUC: 0.6791, Valid. AP: 0.6584\n",
      "Epoch: 76/100, Loss: 0.6090275, Train Acc: 0.6640, Valid. Acc: 0.6376, Train AUC: 0.7267, Train AP: 0.7178, Valid. AUC: 0.6824, Valid. AP: 0.6634\n",
      "Epoch: 77/100, Loss: 0.6068557, Train Acc: 0.6648, Valid. Acc: 0.6433, Train AUC: 0.7270, Train AP: 0.7222, Valid. AUC: 0.6910, Valid. AP: 0.6737\n",
      "Epoch: 78/100, Loss: 0.6083627, Train Acc: 0.6614, Valid. Acc: 0.6352, Train AUC: 0.7253, Train AP: 0.7220, Valid. AUC: 0.6823, Valid. AP: 0.6667\n",
      "Epoch: 79/100, Loss: 0.6062557, Train Acc: 0.6653, Valid. Acc: 0.6343, Train AUC: 0.7287, Train AP: 0.7220, Valid. AUC: 0.6781, Valid. AP: 0.6640\n",
      "Epoch: 80/100, Loss: 0.6080498, Train Acc: 0.6643, Valid. Acc: 0.6411, Train AUC: 0.7271, Train AP: 0.7227, Valid. AUC: 0.6909, Valid. AP: 0.6747\n",
      "Epoch: 81/100, Loss: 0.6082672, Train Acc: 0.6604, Valid. Acc: 0.6411, Train AUC: 0.7245, Train AP: 0.7214, Valid. AUC: 0.6894, Valid. AP: 0.6739\n",
      "Epoch: 82/100, Loss: 0.6032993, Train Acc: 0.6658, Valid. Acc: 0.6301, Train AUC: 0.7308, Train AP: 0.7280, Valid. AUC: 0.6753, Valid. AP: 0.6579\n",
      "Epoch: 83/100, Loss: 0.6079459, Train Acc: 0.6646, Valid. Acc: 0.6368, Train AUC: 0.7268, Train AP: 0.7205, Valid. AUC: 0.6854, Valid. AP: 0.6671\n",
      "Epoch: 84/100, Loss: 0.6036656, Train Acc: 0.6650, Valid. Acc: 0.6418, Train AUC: 0.7305, Train AP: 0.7287, Valid. AUC: 0.6928, Valid. AP: 0.6744\n",
      "Epoch: 85/100, Loss: 0.6049963, Train Acc: 0.6667, Valid. Acc: 0.6423, Train AUC: 0.7299, Train AP: 0.7274, Valid. AUC: 0.6908, Valid. AP: 0.6740\n",
      "Epoch: 86/100, Loss: 0.6015903, Train Acc: 0.6668, Valid. Acc: 0.6407, Train AUC: 0.7321, Train AP: 0.7302, Valid. AUC: 0.6870, Valid. AP: 0.6717\n",
      "Epoch: 87/100, Loss: 0.6017112, Train Acc: 0.6672, Valid. Acc: 0.6437, Train AUC: 0.7325, Train AP: 0.7307, Valid. AUC: 0.6922, Valid. AP: 0.6778\n",
      "Epoch: 88/100, Loss: 0.6018358, Train Acc: 0.6677, Valid. Acc: 0.6461, Train AUC: 0.7323, Train AP: 0.7307, Valid. AUC: 0.6966, Valid. AP: 0.6816\n",
      "Epoch: 89/100, Loss: 0.6009750, Train Acc: 0.6688, Valid. Acc: 0.6437, Train AUC: 0.7333, Train AP: 0.7316, Valid. AUC: 0.6945, Valid. AP: 0.6797\n",
      "Epoch: 90/100, Loss: 0.6007121, Train Acc: 0.6697, Valid. Acc: 0.6404, Train AUC: 0.7345, Train AP: 0.7321, Valid. AUC: 0.6884, Valid. AP: 0.6727\n",
      "Epoch: 91/100, Loss: 0.6003309, Train Acc: 0.6691, Valid. Acc: 0.6453, Train AUC: 0.7346, Train AP: 0.7325, Valid. AUC: 0.6928, Valid. AP: 0.6776\n",
      "Epoch: 92/100, Loss: 0.5985876, Train Acc: 0.6705, Valid. Acc: 0.6463, Train AUC: 0.7357, Train AP: 0.7342, Valid. AUC: 0.6947, Valid. AP: 0.6799\n",
      "Epoch: 93/100, Loss: 0.5997810, Train Acc: 0.6692, Valid. Acc: 0.6449, Train AUC: 0.7348, Train AP: 0.7334, Valid. AUC: 0.6944, Valid. AP: 0.6797\n",
      "Epoch: 94/100, Loss: 0.5984551, Train Acc: 0.6703, Valid. Acc: 0.6457, Train AUC: 0.7363, Train AP: 0.7345, Valid. AUC: 0.6957, Valid. AP: 0.6809\n",
      "Epoch: 95/100, Loss: 0.5988425, Train Acc: 0.6697, Valid. Acc: 0.6486, Train AUC: 0.7357, Train AP: 0.7342, Valid. AUC: 0.7000, Valid. AP: 0.6850\n",
      "Epoch: 96/100, Loss: 0.6003191, Train Acc: 0.6683, Valid. Acc: 0.6475, Train AUC: 0.7333, Train AP: 0.7321, Valid. AUC: 0.6985, Valid. AP: 0.6837\n",
      "Epoch: 97/100, Loss: 0.5985730, Train Acc: 0.6709, Valid. Acc: 0.6437, Train AUC: 0.7360, Train AP: 0.7349, Valid. AUC: 0.6935, Valid. AP: 0.6786\n",
      "Epoch: 98/100, Loss: 0.5976745, Train Acc: 0.6714, Valid. Acc: 0.6458, Train AUC: 0.7374, Train AP: 0.7361, Valid. AUC: 0.6970, Valid. AP: 0.6814\n",
      "Epoch: 99/100, Loss: 0.6017609, Train Acc: 0.6673, Valid. Acc: 0.6368, Train AUC: 0.7314, Train AP: 0.7292, Valid. AUC: 0.6811, Valid. AP: 0.6663\n",
      "Epoch: 100/100, Loss: 0.6012840, Train Acc: 0.6687, Valid. Acc: 0.6443, Train AUC: 0.7338, Train AP: 0.7323, Valid. AUC: 0.6924, Valid. AP: 0.6774\n",
      "/home/ubuntu/PA-Cancer-Immunotherapy/GNN/train_pa_all_tvt.py:212: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(configs['save_model']))\n",
      "Task-wise AP and ROC AUC:\n",
      "Task: TPP1, AP: 0.6691, ROC AUC: 0.6675\n",
      "Task: TPP2, AP: 0.7257, ROC AUC: 0.7501\n",
      "Task: TPP3, AP: 0.8265, ROC AUC: 0.6594\n",
      "Task: TPP4, AP and ROC AUC cannot be calculated (only one class present).\n",
      "\n",
      "Overall AP and ROC AUC:\n",
      "Overall AP: 0.6907, Overall ROC AUC: 0.7054\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.644 MB of 1.644 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.644 MB of 1.644 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.644 MB of 1.644 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.644 MB of 1.644 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.644 MB of 1.644 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▁▁▁▁▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇█████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        test_ap ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   test_roc_auc ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▁▁▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇█████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train_ap ▁▂▂▃▃▄▄▄▄▄▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇█████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss █▇▇▆▆▆▆▆▆▆▆▅▅▅▅▅▅▅▅▅▄▄▄▃▃▂▃▂▂▂▂▂▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_roc_auc ▁▁▂▂▃▃▃▃▃▃▄▄▄▄▄▄▄▄▄▄▅▅▆▆▇▇▇▇▇▇▇█████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: valid_accuracy ▁▁▂▃▃▃▄▅▄▄▄▆▆▆▆▆▅▆▆▆▇▆▇▆▇▇███▇█▇▇██▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       valid_ap ▁▂▂▂▂▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▅▅▆▅▆▆▆▇▇▇▇▇▇██▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  valid_roc_auc ▁▂▂▄▄▄▄▅▄▅▅▅▅▅▅▅▅▅▅▆▆▇▇▆▇▆▇▇▇▇▇▇▇▇██▇▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy 0.65212\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        test_ap 0.69075\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   test_roc_auc 0.70541\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.66866\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train_ap 0.73228\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.60128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_roc_auc 0.73383\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: valid_accuracy 0.6443\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       valid_ap 0.67738\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  valid_roc_auc 0.69237\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mvisionary-frog-10\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-gene_GNN/runs/erlsy45d\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-gene_GNN\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 4 W&B file(s), 0 media file(s), 8 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241217_122309-erlsy45d/logs\u001b[0m\n",
      "Test Acc: 0.6521, Test AUC: 0.7054, Test AP: 0.6907\n"
     ]
    }
   ],
   "source": [
    "# new calculation AP and AUC for TTP and compare global metrics to check correct code.\n",
    "# gene\n",
    "\n",
    "! python train_pa_all_tvt.py --gpu 0 --configs_path configs/PA_all_tvt_gene.yml --droup_out 0.1 --split StrictTCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74bf9f4-cbf5-4fc3-8c6b-92b75a75b015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1eb976-f477-4402-88fe-93239283e79c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8471f982-b504-4078-80c8-7d618c1b3d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e6d6403-d36b-410f-b4ae-a07db6c172a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(gpu=0, lr=0.001, epochs=100, w_celoss=1, w_aucloss=0, add_same_type_edges=False, dynamic_graph=False, dynamic_ratio=0.05, droup_out=0.1, positive_weights=1, dynamic_epochs=30, distance_threshold=10, configs_path='configs/PA_all_tvt_allele.yml', split='StrictTCR', dataset='pMTnet')\n",
      "PROJECT_NAME: dataset-all-tvt-allele_GNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfrohoari\u001b[0m (\u001b[33mpa_cancerimmunotherapy\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/ubuntu/PA-Cancer-Immunotherapy/GNN/wandb/run-20241213_160714-ut01k0ej\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mswept-rain-10\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-allele_GNN\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-allele_GNN/runs/ut01k0ej\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   6 of 6 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   6 of 6 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   6 of 6 files downloaded.  \n",
      "embeddings_path:   models/PA_all/gene_and_allele_embeddings.pkl\n",
      "train_file_list:   ['allele_train.csv']\n",
      "validation_file_list:   ['allele_validation.csv']\n",
      "test_file_list:   ['allele_test.csv']\n",
      "wandb logger initialisiert\n",
      "Epoch: 1/100, Loss: 0.6935461, Train Acc: 0.4871, Test Acc: 0.5031, Train AUC: 0.4853, Train AP: 0.4985, Valid. AUC: 0.5574, Valid AP: 0.5489\n",
      "Epoch: 2/100, Loss: 0.6912209, Train Acc: 0.5072, Test Acc: 0.5374, Train AUC: 0.5700, Train AP: 0.5563, Valid. AUC: 0.5625, Valid AP: 0.5545\n",
      "Epoch: 3/100, Loss: 0.6868216, Train Acc: 0.5492, Test Acc: 0.5559, Train AUC: 0.5897, Train AP: 0.5732, Valid. AUC: 0.5627, Valid AP: 0.5554\n",
      "Epoch: 4/100, Loss: 0.6830894, Train Acc: 0.5681, Test Acc: 0.5253, Train AUC: 0.5979, Train AP: 0.5825, Valid. AUC: 0.5638, Valid AP: 0.5560\n",
      "Epoch: 5/100, Loss: 0.6811174, Train Acc: 0.5708, Test Acc: 0.5634, Train AUC: 0.5971, Train AP: 0.5814, Valid. AUC: 0.5716, Valid AP: 0.5600\n",
      "Epoch: 6/100, Loss: 0.6786046, Train Acc: 0.5794, Test Acc: 0.5685, Train AUC: 0.6035, Train AP: 0.5817, Valid. AUC: 0.5818, Valid AP: 0.5667\n",
      "Epoch: 7/100, Loss: 0.6762573, Train Acc: 0.5828, Test Acc: 0.5643, Train AUC: 0.6094, Train AP: 0.5865, Valid. AUC: 0.5915, Valid AP: 0.5749\n",
      "Epoch: 8/100, Loss: 0.6739233, Train Acc: 0.5883, Test Acc: 0.5709, Train AUC: 0.6144, Train AP: 0.5887, Valid. AUC: 0.6052, Valid AP: 0.5891\n",
      "Epoch: 9/100, Loss: 0.6727633, Train Acc: 0.5906, Test Acc: 0.5720, Train AUC: 0.6205, Train AP: 0.5967, Valid. AUC: 0.6134, Valid AP: 0.5961\n",
      "Epoch: 10/100, Loss: 0.6756302, Train Acc: 0.5844, Test Acc: 0.5816, Train AUC: 0.6251, Train AP: 0.6019, Valid. AUC: 0.6209, Valid AP: 0.6036\n",
      "Epoch: 11/100, Loss: 0.6703709, Train Acc: 0.5963, Test Acc: 0.5919, Train AUC: 0.6259, Train AP: 0.5979, Valid. AUC: 0.6239, Valid AP: 0.6066\n",
      "Epoch: 12/100, Loss: 0.6712454, Train Acc: 0.5933, Test Acc: 0.5879, Train AUC: 0.6284, Train AP: 0.6032, Valid. AUC: 0.6256, Valid AP: 0.6085\n",
      "Epoch: 13/100, Loss: 0.6690708, Train Acc: 0.5990, Test Acc: 0.5789, Train AUC: 0.6267, Train AP: 0.6020, Valid. AUC: 0.6264, Valid AP: 0.6096\n",
      "Epoch: 14/100, Loss: 0.6691018, Train Acc: 0.5917, Test Acc: 0.5834, Train AUC: 0.6315, Train AP: 0.6072, Valid. AUC: 0.6280, Valid AP: 0.6114\n",
      "Epoch: 15/100, Loss: 0.6671123, Train Acc: 0.5956, Test Acc: 0.5960, Train AUC: 0.6328, Train AP: 0.6114, Valid. AUC: 0.6294, Valid AP: 0.6129\n",
      "Epoch: 16/100, Loss: 0.6659065, Train Acc: 0.6018, Test Acc: 0.5869, Train AUC: 0.6344, Train AP: 0.6097, Valid. AUC: 0.6290, Valid AP: 0.6127\n",
      "Epoch: 17/100, Loss: 0.6663166, Train Acc: 0.6024, Test Acc: 0.5866, Train AUC: 0.6362, Train AP: 0.6136, Valid. AUC: 0.6283, Valid AP: 0.6123\n",
      "Epoch: 18/100, Loss: 0.6651844, Train Acc: 0.6027, Test Acc: 0.5949, Train AUC: 0.6376, Train AP: 0.6140, Valid. AUC: 0.6280, Valid AP: 0.6120\n",
      "Epoch: 19/100, Loss: 0.6639847, Train Acc: 0.6027, Test Acc: 0.5931, Train AUC: 0.6391, Train AP: 0.6169, Valid. AUC: 0.6268, Valid AP: 0.6110\n",
      "Epoch: 20/100, Loss: 0.6641515, Train Acc: 0.6010, Test Acc: 0.5950, Train AUC: 0.6384, Train AP: 0.6166, Valid. AUC: 0.6264, Valid AP: 0.6108\n",
      "Epoch: 21/100, Loss: 0.6623968, Train Acc: 0.6028, Test Acc: 0.5824, Train AUC: 0.6412, Train AP: 0.6192, Valid. AUC: 0.6266, Valid AP: 0.6114\n",
      "Epoch: 22/100, Loss: 0.6620680, Train Acc: 0.6052, Test Acc: 0.5810, Train AUC: 0.6421, Train AP: 0.6199, Valid. AUC: 0.6283, Valid AP: 0.6131\n",
      "Epoch: 23/100, Loss: 0.6617399, Train Acc: 0.6067, Test Acc: 0.5831, Train AUC: 0.6423, Train AP: 0.6194, Valid. AUC: 0.6283, Valid AP: 0.6132\n",
      "Epoch: 24/100, Loss: 0.6604580, Train Acc: 0.6058, Test Acc: 0.5851, Train AUC: 0.6456, Train AP: 0.6228, Valid. AUC: 0.6287, Valid AP: 0.6136\n",
      "Epoch: 25/100, Loss: 0.6601006, Train Acc: 0.6091, Test Acc: 0.5835, Train AUC: 0.6475, Train AP: 0.6242, Valid. AUC: 0.6298, Valid AP: 0.6142\n",
      "Epoch: 26/100, Loss: 0.6592042, Train Acc: 0.6075, Test Acc: 0.5827, Train AUC: 0.6476, Train AP: 0.6253, Valid. AUC: 0.6320, Valid AP: 0.6158\n",
      "Epoch: 27/100, Loss: 0.6591350, Train Acc: 0.6086, Test Acc: 0.5997, Train AUC: 0.6475, Train AP: 0.6256, Valid. AUC: 0.6348, Valid AP: 0.6179\n",
      "Epoch: 28/100, Loss: 0.6579846, Train Acc: 0.6062, Test Acc: 0.6013, Train AUC: 0.6497, Train AP: 0.6278, Valid. AUC: 0.6404, Valid AP: 0.6220\n",
      "Epoch: 29/100, Loss: 0.6572686, Train Acc: 0.6081, Test Acc: 0.6037, Train AUC: 0.6506, Train AP: 0.6297, Valid. AUC: 0.6443, Valid AP: 0.6247\n",
      "Epoch: 30/100, Loss: 0.6563449, Train Acc: 0.6105, Test Acc: 0.6109, Train AUC: 0.6523, Train AP: 0.6310, Valid. AUC: 0.6477, Valid AP: 0.6268\n",
      "Epoch: 31/100, Loss: 0.6561406, Train Acc: 0.6095, Test Acc: 0.6281, Train AUC: 0.6537, Train AP: 0.6317, Valid. AUC: 0.6495, Valid AP: 0.6279\n",
      "Epoch: 32/100, Loss: 0.6552496, Train Acc: 0.6117, Test Acc: 0.6260, Train AUC: 0.6548, Train AP: 0.6327, Valid. AUC: 0.6512, Valid AP: 0.6292\n",
      "Epoch: 33/100, Loss: 0.6536583, Train Acc: 0.6141, Test Acc: 0.6212, Train AUC: 0.6572, Train AP: 0.6348, Valid. AUC: 0.6528, Valid AP: 0.6303\n",
      "Epoch: 34/100, Loss: 0.6530835, Train Acc: 0.6126, Test Acc: 0.6302, Train AUC: 0.6582, Train AP: 0.6371, Valid. AUC: 0.6540, Valid AP: 0.6316\n",
      "Epoch: 35/100, Loss: 0.6527843, Train Acc: 0.6145, Test Acc: 0.6273, Train AUC: 0.6582, Train AP: 0.6374, Valid. AUC: 0.6546, Valid AP: 0.6326\n",
      "Epoch: 36/100, Loss: 0.6508727, Train Acc: 0.6145, Test Acc: 0.6181, Train AUC: 0.6615, Train AP: 0.6410, Valid. AUC: 0.6548, Valid AP: 0.6330\n",
      "Epoch: 37/100, Loss: 0.6515045, Train Acc: 0.6144, Test Acc: 0.6247, Train AUC: 0.6624, Train AP: 0.6427, Valid. AUC: 0.6545, Valid AP: 0.6341\n",
      "Epoch: 38/100, Loss: 0.6493139, Train Acc: 0.6159, Test Acc: 0.6160, Train AUC: 0.6647, Train AP: 0.6446, Valid. AUC: 0.6544, Valid AP: 0.6351\n",
      "Epoch: 39/100, Loss: 0.6485248, Train Acc: 0.6174, Test Acc: 0.6152, Train AUC: 0.6672, Train AP: 0.6477, Valid. AUC: 0.6547, Valid AP: 0.6370\n",
      "Epoch: 40/100, Loss: 0.6465607, Train Acc: 0.6157, Test Acc: 0.6046, Train AUC: 0.6695, Train AP: 0.6513, Valid. AUC: 0.6560, Valid AP: 0.6383\n",
      "Epoch: 41/100, Loss: 0.6459281, Train Acc: 0.6193, Test Acc: 0.6170, Train AUC: 0.6708, Train AP: 0.6516, Valid. AUC: 0.6521, Valid AP: 0.6352\n",
      "Epoch: 42/100, Loss: 0.6462444, Train Acc: 0.6224, Test Acc: 0.6247, Train AUC: 0.6748, Train AP: 0.6543, Valid. AUC: 0.6609, Valid AP: 0.6440\n",
      "Epoch: 43/100, Loss: 0.6421133, Train Acc: 0.6253, Test Acc: 0.6318, Train AUC: 0.6766, Train AP: 0.6593, Valid. AUC: 0.6656, Valid AP: 0.6473\n",
      "Epoch: 44/100, Loss: 0.6409568, Train Acc: 0.6294, Test Acc: 0.6346, Train AUC: 0.6791, Train AP: 0.6616, Valid. AUC: 0.6694, Valid AP: 0.6482\n",
      "Epoch: 45/100, Loss: 0.6392431, Train Acc: 0.6394, Test Acc: 0.6358, Train AUC: 0.6882, Train AP: 0.6661, Valid. AUC: 0.6747, Valid AP: 0.6533\n",
      "Epoch: 46/100, Loss: 0.6365694, Train Acc: 0.6379, Test Acc: 0.6388, Train AUC: 0.6875, Train AP: 0.6683, Valid. AUC: 0.6776, Valid AP: 0.6565\n",
      "Epoch: 47/100, Loss: 0.6356624, Train Acc: 0.6390, Test Acc: 0.6208, Train AUC: 0.6877, Train AP: 0.6696, Valid. AUC: 0.6662, Valid AP: 0.6459\n",
      "Epoch: 48/100, Loss: 0.6373277, Train Acc: 0.6451, Test Acc: 0.6438, Train AUC: 0.6944, Train AP: 0.6688, Valid. AUC: 0.6838, Valid AP: 0.6625\n",
      "Epoch: 49/100, Loss: 0.6309342, Train Acc: 0.6478, Test Acc: 0.6369, Train AUC: 0.6973, Train AP: 0.6788, Valid. AUC: 0.6853, Valid AP: 0.6645\n",
      "Epoch: 50/100, Loss: 0.6318048, Train Acc: 0.6441, Test Acc: 0.6397, Train AUC: 0.6964, Train AP: 0.6790, Valid. AUC: 0.6841, Valid AP: 0.6627\n",
      "Epoch: 51/100, Loss: 0.6285861, Train Acc: 0.6502, Test Acc: 0.6350, Train AUC: 0.7019, Train AP: 0.6786, Valid. AUC: 0.6820, Valid AP: 0.6627\n",
      "Epoch: 52/100, Loss: 0.6281194, Train Acc: 0.6508, Test Acc: 0.6418, Train AUC: 0.7045, Train AP: 0.6828, Valid. AUC: 0.6909, Valid AP: 0.6699\n",
      "Epoch: 53/100, Loss: 0.6267962, Train Acc: 0.6484, Test Acc: 0.6429, Train AUC: 0.7047, Train AP: 0.6851, Valid. AUC: 0.6916, Valid AP: 0.6710\n",
      "Epoch: 54/100, Loss: 0.6251026, Train Acc: 0.6503, Test Acc: 0.6170, Train AUC: 0.7058, Train AP: 0.6872, Valid. AUC: 0.6669, Valid AP: 0.6538\n",
      "Epoch: 55/100, Loss: 0.6349723, Train Acc: 0.6373, Test Acc: 0.6397, Train AUC: 0.6911, Train AP: 0.6706, Valid. AUC: 0.6918, Valid AP: 0.6724\n",
      "Epoch: 56/100, Loss: 0.6213493, Train Acc: 0.6540, Test Acc: 0.6351, Train AUC: 0.7115, Train AP: 0.6908, Valid. AUC: 0.6898, Valid AP: 0.6690\n",
      "Epoch: 57/100, Loss: 0.6268964, Train Acc: 0.6513, Test Acc: 0.6286, Train AUC: 0.7050, Train AP: 0.6845, Valid. AUC: 0.6909, Valid AP: 0.6732\n",
      "Epoch: 58/100, Loss: 0.6203465, Train Acc: 0.6521, Test Acc: 0.6387, Train AUC: 0.7153, Train AP: 0.6938, Valid. AUC: 0.6880, Valid AP: 0.6716\n",
      "Epoch: 59/100, Loss: 0.6183722, Train Acc: 0.6567, Test Acc: 0.6443, Train AUC: 0.7168, Train AP: 0.6951, Valid. AUC: 0.6968, Valid AP: 0.6768\n",
      "Epoch: 60/100, Loss: 0.6181288, Train Acc: 0.6583, Test Acc: 0.6464, Train AUC: 0.7186, Train AP: 0.6948, Valid. AUC: 0.6989, Valid AP: 0.6787\n",
      "Epoch: 61/100, Loss: 0.6164240, Train Acc: 0.6573, Test Acc: 0.6486, Train AUC: 0.7170, Train AP: 0.6957, Valid. AUC: 0.6997, Valid AP: 0.6811\n",
      "Epoch: 62/100, Loss: 0.6140465, Train Acc: 0.6592, Test Acc: 0.6376, Train AUC: 0.7216, Train AP: 0.7014, Valid. AUC: 0.6955, Valid AP: 0.6793\n",
      "Epoch: 63/100, Loss: 0.6155273, Train Acc: 0.6560, Test Acc: 0.6417, Train AUC: 0.7227, Train AP: 0.7017, Valid. AUC: 0.6917, Valid AP: 0.6775\n",
      "Epoch: 64/100, Loss: 0.6124598, Train Acc: 0.6599, Test Acc: 0.6465, Train AUC: 0.7216, Train AP: 0.7039, Valid. AUC: 0.6983, Valid AP: 0.6821\n",
      "Epoch: 65/100, Loss: 0.6135854, Train Acc: 0.6618, Test Acc: 0.6431, Train AUC: 0.7225, Train AP: 0.7044, Valid. AUC: 0.6987, Valid AP: 0.6845\n",
      "Epoch: 66/100, Loss: 0.6107537, Train Acc: 0.6627, Test Acc: 0.6315, Train AUC: 0.7251, Train AP: 0.7069, Valid. AUC: 0.6848, Valid AP: 0.6729\n",
      "Epoch: 67/100, Loss: 0.6130810, Train Acc: 0.6562, Test Acc: 0.6440, Train AUC: 0.7202, Train AP: 0.7029, Valid. AUC: 0.7001, Valid AP: 0.6865\n",
      "Epoch: 68/100, Loss: 0.6104443, Train Acc: 0.6604, Test Acc: 0.6478, Train AUC: 0.7269, Train AP: 0.7094, Valid. AUC: 0.7010, Valid AP: 0.6861\n",
      "Epoch: 69/100, Loss: 0.6081028, Train Acc: 0.6634, Test Acc: 0.6494, Train AUC: 0.7273, Train AP: 0.7105, Valid. AUC: 0.7038, Valid AP: 0.6889\n",
      "Epoch: 70/100, Loss: 0.6052526, Train Acc: 0.6674, Test Acc: 0.6461, Train AUC: 0.7312, Train AP: 0.7140, Valid. AUC: 0.7008, Valid AP: 0.6855\n",
      "Epoch: 71/100, Loss: 0.6048349, Train Acc: 0.6657, Test Acc: 0.6520, Train AUC: 0.7311, Train AP: 0.7146, Valid. AUC: 0.7044, Valid AP: 0.6885\n",
      "Epoch: 72/100, Loss: 0.6034564, Train Acc: 0.6670, Test Acc: 0.6520, Train AUC: 0.7321, Train AP: 0.7156, Valid. AUC: 0.7065, Valid AP: 0.6915\n",
      "Epoch: 73/100, Loss: 0.6050582, Train Acc: 0.6668, Test Acc: 0.6472, Train AUC: 0.7314, Train AP: 0.7150, Valid. AUC: 0.7009, Valid AP: 0.6871\n",
      "Epoch: 74/100, Loss: 0.6019741, Train Acc: 0.6667, Test Acc: 0.6473, Train AUC: 0.7331, Train AP: 0.7182, Valid. AUC: 0.7024, Valid AP: 0.6898\n",
      "Epoch: 75/100, Loss: 0.6015296, Train Acc: 0.6685, Test Acc: 0.6457, Train AUC: 0.7347, Train AP: 0.7177, Valid. AUC: 0.7003, Valid AP: 0.6887\n",
      "Epoch: 76/100, Loss: 0.5989691, Train Acc: 0.6702, Test Acc: 0.6418, Train AUC: 0.7373, Train AP: 0.7238, Valid. AUC: 0.6967, Valid AP: 0.6859\n",
      "Epoch: 77/100, Loss: 0.6006820, Train Acc: 0.6694, Test Acc: 0.6443, Train AUC: 0.7350, Train AP: 0.7213, Valid. AUC: 0.7015, Valid AP: 0.6908\n",
      "Epoch: 78/100, Loss: 0.5977808, Train Acc: 0.6699, Test Acc: 0.6430, Train AUC: 0.7397, Train AP: 0.7273, Valid. AUC: 0.6977, Valid AP: 0.6874\n",
      "Epoch: 79/100, Loss: 0.5972279, Train Acc: 0.6692, Test Acc: 0.6468, Train AUC: 0.7385, Train AP: 0.7274, Valid. AUC: 0.7032, Valid AP: 0.6932\n",
      "Epoch: 80/100, Loss: 0.5989059, Train Acc: 0.6693, Test Acc: 0.6510, Train AUC: 0.7376, Train AP: 0.7239, Valid. AUC: 0.7063, Valid AP: 0.6966\n",
      "Epoch: 81/100, Loss: 0.5953938, Train Acc: 0.6721, Test Acc: 0.6528, Train AUC: 0.7408, Train AP: 0.7297, Valid. AUC: 0.7089, Valid AP: 0.6995\n",
      "Epoch: 82/100, Loss: 0.5938128, Train Acc: 0.6753, Test Acc: 0.6372, Train AUC: 0.7446, Train AP: 0.7337, Valid. AUC: 0.6903, Valid AP: 0.6825\n",
      "Epoch: 83/100, Loss: 0.5969778, Train Acc: 0.6691, Test Acc: 0.6560, Train AUC: 0.7372, Train AP: 0.7293, Valid. AUC: 0.7083, Valid AP: 0.6966\n",
      "Epoch: 84/100, Loss: 0.5976676, Train Acc: 0.6743, Test Acc: 0.6529, Train AUC: 0.7396, Train AP: 0.7253, Valid. AUC: 0.7116, Valid AP: 0.7032\n",
      "Epoch: 85/100, Loss: 0.5908307, Train Acc: 0.6774, Test Acc: 0.6380, Train AUC: 0.7474, Train AP: 0.7376, Valid. AUC: 0.6954, Valid AP: 0.6900\n",
      "Epoch: 86/100, Loss: 0.5971704, Train Acc: 0.6679, Test Acc: 0.6507, Train AUC: 0.7367, Train AP: 0.7303, Valid. AUC: 0.7038, Valid AP: 0.6932\n",
      "Epoch: 87/100, Loss: 0.6025009, Train Acc: 0.6668, Test Acc: 0.6549, Train AUC: 0.7356, Train AP: 0.7225, Valid. AUC: 0.7123, Valid AP: 0.7043\n",
      "Epoch: 88/100, Loss: 0.5894212, Train Acc: 0.6789, Test Acc: 0.6099, Train AUC: 0.7485, Train AP: 0.7395, Valid. AUC: 0.6601, Valid AP: 0.6569\n",
      "Epoch: 89/100, Loss: 0.6126195, Train Acc: 0.6518, Test Acc: 0.6549, Train AUC: 0.7160, Train AP: 0.7089, Valid. AUC: 0.7119, Valid AP: 0.7042\n",
      "Epoch: 90/100, Loss: 0.5882075, Train Acc: 0.6779, Test Acc: 0.6508, Train AUC: 0.7496, Train AP: 0.7407, Valid. AUC: 0.7036, Valid AP: 0.6941\n",
      "Epoch: 91/100, Loss: 0.6015890, Train Acc: 0.6700, Test Acc: 0.6483, Train AUC: 0.7362, Train AP: 0.7252, Valid. AUC: 0.7079, Valid AP: 0.7022\n",
      "Epoch: 92/100, Loss: 0.5876006, Train Acc: 0.6791, Test Acc: 0.6226, Train AUC: 0.7523, Train AP: 0.7447, Valid. AUC: 0.6801, Valid AP: 0.6779\n",
      "Epoch: 93/100, Loss: 0.5980273, Train Acc: 0.6684, Test Acc: 0.6492, Train AUC: 0.7396, Train AP: 0.7351, Valid. AUC: 0.7099, Valid AP: 0.7048\n",
      "Epoch: 94/100, Loss: 0.5853121, Train Acc: 0.6837, Test Acc: 0.6568, Train AUC: 0.7544, Train AP: 0.7465, Valid. AUC: 0.7133, Valid AP: 0.7050\n",
      "Epoch: 95/100, Loss: 0.5916819, Train Acc: 0.6781, Test Acc: 0.6571, Train AUC: 0.7467, Train AP: 0.7369, Valid. AUC: 0.7157, Valid AP: 0.7092\n",
      "Epoch: 96/100, Loss: 0.5830477, Train Acc: 0.6837, Test Acc: 0.6427, Train AUC: 0.7557, Train AP: 0.7494, Valid. AUC: 0.6997, Valid AP: 0.6938\n",
      "Epoch: 97/100, Loss: 0.5876518, Train Acc: 0.6760, Test Acc: 0.6555, Train AUC: 0.7495, Train AP: 0.7459, Valid. AUC: 0.7151, Valid AP: 0.7089\n",
      "Epoch: 98/100, Loss: 0.5808343, Train Acc: 0.6834, Test Acc: 0.6605, Train AUC: 0.7577, Train AP: 0.7525, Valid. AUC: 0.7189, Valid AP: 0.7112\n",
      "Epoch: 99/100, Loss: 0.5825617, Train Acc: 0.6828, Test Acc: 0.6560, Train AUC: 0.7560, Train AP: 0.7479, Valid. AUC: 0.7178, Valid AP: 0.7117\n",
      "Epoch: 100/100, Loss: 0.5832586, Train Acc: 0.6821, Test Acc: 0.6406, Train AUC: 0.7556, Train AP: 0.7482, Valid. AUC: 0.7012, Valid AP: 0.6976\n",
      "/home/ubuntu/PA-Cancer-Immunotherapy/GNN/train_pa_all_tvt.py:212: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(configs['save_model']))\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.411 MB of 1.411 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.411 MB of 1.411 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.411 MB of 1.411 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▁▁▁▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        test_ap ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   test_roc_auc ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▁▂▂▃▃▃▃▃▃▃▃▃▃▄▄▄▄▄▄▄▆▆▆▆▅▆▆▆▇▆▆▇▇▇▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train_ap ▁▁▂▂▂▃▃▃▃▃▃▃▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▆█▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss ██▇▇▇▆▆▆▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▂▂▂▂▂▂▁▂▁▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_roc_auc ▁▃▄▄▄▄▅▅▅▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇██▇█▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: valid_accuracy ▁▃▄▄▄▅▄▅▅▅▅▇▇▆▇▇▆▆▇▇▇▇▆▇▇▇▇█▇▇██▇██▆█▆█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       valid_ap ▁▁▁▂▂▃▄▄▄▄▄▄▄▅▅▆▅▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  valid_roc_auc ▁▁▁▂▃▄▄▄▄▄▄▄▄▄▅▅▅▅▆▆▇▆▇▇▇▇▇▇▇▇▇▇█▇█▇▆███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy 0.66575\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        test_ap 0.71227\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   test_roc_auc 0.72234\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.68213\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train_ap 0.74825\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.58326\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_roc_auc 0.75555\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: valid_accuracy 0.64063\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       valid_ap 0.69762\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  valid_roc_auc 0.7012\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mswept-rain-10\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-allele_GNN/runs/ut01k0ej\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-allele_GNN\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 6 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241213_160714-ut01k0ej/logs\u001b[0m\n",
      "Test Acc: 0.6657, Test AUC: 0.7223, Test AP: 0.7123\n"
     ]
    }
   ],
   "source": [
    "# Training using both optimizers (pos_weight=1 = not used, since balanced datasets)\n",
    "# first for allele\n",
    "\n",
    "! python train_pa_all_tvt.py --gpu 0 --configs_path configs/PA_all_tvt_allele.yml --droup_out 0.1 --split StrictTCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1bdf042-322c-45e3-9795-438da39ace8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(gpu=0, lr=0.001, epochs=100, w_celoss=1, w_aucloss=0, add_same_type_edges=False, dynamic_graph=False, dynamic_ratio=0.05, droup_out=0.1, positive_weights=1, dynamic_epochs=30, distance_threshold=10, configs_path='configs/PA_all_tvt_gene.yml', split='StrictTCR', dataset='pMTnet')\n",
      "PROJECT_NAME: dataset-all-tvt-gene_GNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfrohoari\u001b[0m (\u001b[33mpa_cancerimmunotherapy\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/ubuntu/PA-Cancer-Immunotherapy/GNN/wandb/run-20241213_165119-dkl081o4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mcopper-planet-9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-gene_GNN\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-gene_GNN/runs/dkl081o4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   6 of 6 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   6 of 6 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   6 of 6 files downloaded.  \n",
      "embeddings_path:   models/PA_all/gene_and_allele_embeddings.pkl\n",
      "train_file_list:   ['gene_train.csv']\n",
      "validation_file_list:   ['gene_validation.csv']\n",
      "test_file_list:   ['gene_test.csv']\n",
      "wandb logger initialisiert\n",
      "Epoch: 1/100, Loss: 0.6933187, Train Acc: 0.5015, Valid. Acc: 0.4996, Train AUC: 0.4987, Train AP: 0.4993, Valid. AUC: 0.5409, Valid. AP: 0.5310\n",
      "Epoch: 2/100, Loss: 0.6909529, Train Acc: 0.5056, Valid. Acc: 0.5382, Train AUC: 0.5701, Train AP: 0.5528, Valid. AUC: 0.5544, Valid. AP: 0.5475\n",
      "Epoch: 3/100, Loss: 0.6864630, Train Acc: 0.5495, Valid. Acc: 0.5545, Train AUC: 0.5937, Train AP: 0.5843, Valid. AUC: 0.5515, Valid. AP: 0.5441\n",
      "Epoch: 4/100, Loss: 0.6836001, Train Acc: 0.5694, Valid. Acc: 0.5189, Train AUC: 0.5953, Train AP: 0.5846, Valid. AUC: 0.5519, Valid. AP: 0.5429\n",
      "Epoch: 5/100, Loss: 0.6805422, Train Acc: 0.5728, Valid. Acc: 0.5523, Train AUC: 0.5991, Train AP: 0.5860, Valid. AUC: 0.5579, Valid. AP: 0.5487\n",
      "Epoch: 6/100, Loss: 0.6789078, Train Acc: 0.5763, Valid. Acc: 0.5602, Train AUC: 0.6028, Train AP: 0.5912, Valid. AUC: 0.5656, Valid. AP: 0.5572\n",
      "Epoch: 7/100, Loss: 0.6759974, Train Acc: 0.5801, Valid. Acc: 0.5618, Train AUC: 0.6116, Train AP: 0.5962, Valid. AUC: 0.5744, Valid. AP: 0.5631\n",
      "Epoch: 8/100, Loss: 0.6750874, Train Acc: 0.5835, Valid. Acc: 0.5449, Train AUC: 0.6149, Train AP: 0.6014, Valid. AUC: 0.5810, Valid. AP: 0.5668\n",
      "Epoch: 9/100, Loss: 0.6722894, Train Acc: 0.5908, Valid. Acc: 0.5521, Train AUC: 0.6201, Train AP: 0.6062, Valid. AUC: 0.5911, Valid. AP: 0.5745\n",
      "Epoch: 10/100, Loss: 0.6707444, Train Acc: 0.5943, Valid. Acc: 0.5741, Train AUC: 0.6242, Train AP: 0.6074, Valid. AUC: 0.6009, Valid. AP: 0.5817\n",
      "Epoch: 11/100, Loss: 0.6695105, Train Acc: 0.5961, Valid. Acc: 0.5789, Train AUC: 0.6293, Train AP: 0.6129, Valid. AUC: 0.6068, Valid. AP: 0.5869\n",
      "Epoch: 12/100, Loss: 0.6692327, Train Acc: 0.5975, Valid. Acc: 0.5761, Train AUC: 0.6289, Train AP: 0.6158, Valid. AUC: 0.6105, Valid. AP: 0.5896\n",
      "Epoch: 13/100, Loss: 0.6674330, Train Acc: 0.5985, Valid. Acc: 0.5842, Train AUC: 0.6332, Train AP: 0.6186, Valid. AUC: 0.6141, Valid. AP: 0.5922\n",
      "Epoch: 14/100, Loss: 0.6663371, Train Acc: 0.6010, Valid. Acc: 0.5754, Train AUC: 0.6344, Train AP: 0.6176, Valid. AUC: 0.6159, Valid. AP: 0.5930\n",
      "Epoch: 15/100, Loss: 0.6668058, Train Acc: 0.5994, Valid. Acc: 0.5820, Train AUC: 0.6351, Train AP: 0.6192, Valid. AUC: 0.6178, Valid. AP: 0.5944\n",
      "Epoch: 16/100, Loss: 0.6648228, Train Acc: 0.6020, Valid. Acc: 0.5905, Train AUC: 0.6369, Train AP: 0.6204, Valid. AUC: 0.6219, Valid. AP: 0.5965\n",
      "Epoch: 17/100, Loss: 0.6640836, Train Acc: 0.6042, Valid. Acc: 0.6085, Train AUC: 0.6390, Train AP: 0.6231, Valid. AUC: 0.6232, Valid. AP: 0.5972\n",
      "Epoch: 18/100, Loss: 0.6633776, Train Acc: 0.6034, Valid. Acc: 0.5872, Train AUC: 0.6413, Train AP: 0.6256, Valid. AUC: 0.6249, Valid. AP: 0.5985\n",
      "Epoch: 19/100, Loss: 0.6626746, Train Acc: 0.6066, Valid. Acc: 0.5856, Train AUC: 0.6429, Train AP: 0.6274, Valid. AUC: 0.6263, Valid. AP: 0.5996\n",
      "Epoch: 20/100, Loss: 0.6637579, Train Acc: 0.6063, Valid. Acc: 0.5876, Train AUC: 0.6440, Train AP: 0.6278, Valid. AUC: 0.6266, Valid. AP: 0.6002\n",
      "Epoch: 21/100, Loss: 0.6616412, Train Acc: 0.6068, Valid. Acc: 0.6028, Train AUC: 0.6440, Train AP: 0.6282, Valid. AUC: 0.6258, Valid. AP: 0.5997\n",
      "Epoch: 22/100, Loss: 0.6614264, Train Acc: 0.6055, Valid. Acc: 0.5974, Train AUC: 0.6451, Train AP: 0.6293, Valid. AUC: 0.6250, Valid. AP: 0.5997\n",
      "Epoch: 23/100, Loss: 0.6606088, Train Acc: 0.6085, Valid. Acc: 0.5906, Train AUC: 0.6460, Train AP: 0.6298, Valid. AUC: 0.6257, Valid. AP: 0.6008\n",
      "Epoch: 24/100, Loss: 0.6605361, Train Acc: 0.6083, Valid. Acc: 0.5894, Train AUC: 0.6458, Train AP: 0.6305, Valid. AUC: 0.6290, Valid. AP: 0.6036\n",
      "Epoch: 25/100, Loss: 0.6606751, Train Acc: 0.6094, Valid. Acc: 0.5991, Train AUC: 0.6478, Train AP: 0.6319, Valid. AUC: 0.6295, Valid. AP: 0.6043\n",
      "Epoch: 26/100, Loss: 0.6595295, Train Acc: 0.6095, Valid. Acc: 0.5991, Train AUC: 0.6481, Train AP: 0.6320, Valid. AUC: 0.6316, Valid. AP: 0.6059\n",
      "Epoch: 27/100, Loss: 0.6592873, Train Acc: 0.6091, Valid. Acc: 0.6209, Train AUC: 0.6494, Train AP: 0.6337, Valid. AUC: 0.6333, Valid. AP: 0.6071\n",
      "Epoch: 28/100, Loss: 0.6598791, Train Acc: 0.6081, Valid. Acc: 0.6233, Train AUC: 0.6468, Train AP: 0.6318, Valid. AUC: 0.6353, Valid. AP: 0.6084\n",
      "Epoch: 29/100, Loss: 0.6580535, Train Acc: 0.6115, Valid. Acc: 0.6254, Train AUC: 0.6510, Train AP: 0.6348, Valid. AUC: 0.6361, Valid. AP: 0.6091\n",
      "Epoch: 30/100, Loss: 0.6577806, Train Acc: 0.6117, Valid. Acc: 0.6266, Train AUC: 0.6513, Train AP: 0.6353, Valid. AUC: 0.6358, Valid. AP: 0.6092\n",
      "Epoch: 31/100, Loss: 0.6571639, Train Acc: 0.6116, Valid. Acc: 0.6261, Train AUC: 0.6526, Train AP: 0.6368, Valid. AUC: 0.6360, Valid. AP: 0.6095\n",
      "Epoch: 32/100, Loss: 0.6569401, Train Acc: 0.6120, Valid. Acc: 0.6241, Train AUC: 0.6531, Train AP: 0.6367, Valid. AUC: 0.6362, Valid. AP: 0.6097\n",
      "Epoch: 33/100, Loss: 0.6566515, Train Acc: 0.6126, Valid. Acc: 0.6221, Train AUC: 0.6535, Train AP: 0.6379, Valid. AUC: 0.6367, Valid. AP: 0.6103\n",
      "Epoch: 34/100, Loss: 0.6568226, Train Acc: 0.6126, Valid. Acc: 0.6240, Train AUC: 0.6535, Train AP: 0.6366, Valid. AUC: 0.6366, Valid. AP: 0.6111\n",
      "Epoch: 35/100, Loss: 0.6562921, Train Acc: 0.6124, Valid. Acc: 0.6188, Train AUC: 0.6542, Train AP: 0.6385, Valid. AUC: 0.6373, Valid. AP: 0.6123\n",
      "Epoch: 36/100, Loss: 0.6562069, Train Acc: 0.6124, Valid. Acc: 0.6240, Train AUC: 0.6551, Train AP: 0.6384, Valid. AUC: 0.6378, Valid. AP: 0.6131\n",
      "Epoch: 37/100, Loss: 0.6551303, Train Acc: 0.6138, Valid. Acc: 0.6231, Train AUC: 0.6566, Train AP: 0.6409, Valid. AUC: 0.6382, Valid. AP: 0.6138\n",
      "Epoch: 38/100, Loss: 0.6549480, Train Acc: 0.6133, Valid. Acc: 0.6197, Train AUC: 0.6571, Train AP: 0.6416, Valid. AUC: 0.6388, Valid. AP: 0.6148\n",
      "Epoch: 39/100, Loss: 0.6542056, Train Acc: 0.6139, Valid. Acc: 0.6257, Train AUC: 0.6583, Train AP: 0.6425, Valid. AUC: 0.6408, Valid. AP: 0.6173\n",
      "Epoch: 40/100, Loss: 0.6538233, Train Acc: 0.6142, Valid. Acc: 0.6254, Train AUC: 0.6588, Train AP: 0.6444, Valid. AUC: 0.6422, Valid. AP: 0.6193\n",
      "Epoch: 41/100, Loss: 0.6533868, Train Acc: 0.6161, Valid. Acc: 0.6246, Train AUC: 0.6600, Train AP: 0.6453, Valid. AUC: 0.6432, Valid. AP: 0.6202\n",
      "Epoch: 42/100, Loss: 0.6527231, Train Acc: 0.6157, Valid. Acc: 0.6163, Train AUC: 0.6609, Train AP: 0.6461, Valid. AUC: 0.6441, Valid. AP: 0.6209\n",
      "Epoch: 43/100, Loss: 0.6528723, Train Acc: 0.6161, Valid. Acc: 0.6127, Train AUC: 0.6623, Train AP: 0.6469, Valid. AUC: 0.6427, Valid. AP: 0.6203\n",
      "Epoch: 44/100, Loss: 0.6515493, Train Acc: 0.6166, Valid. Acc: 0.6197, Train AUC: 0.6632, Train AP: 0.6480, Valid. AUC: 0.6420, Valid. AP: 0.6207\n",
      "Epoch: 45/100, Loss: 0.6511009, Train Acc: 0.6177, Valid. Acc: 0.6171, Train AUC: 0.6635, Train AP: 0.6497, Valid. AUC: 0.6458, Valid. AP: 0.6250\n",
      "Epoch: 46/100, Loss: 0.6502185, Train Acc: 0.6184, Valid. Acc: 0.6156, Train AUC: 0.6661, Train AP: 0.6516, Valid. AUC: 0.6476, Valid. AP: 0.6269\n",
      "Epoch: 47/100, Loss: 0.6498582, Train Acc: 0.6254, Valid. Acc: 0.6150, Train AUC: 0.6704, Train AP: 0.6570, Valid. AUC: 0.6461, Valid. AP: 0.6249\n",
      "Epoch: 48/100, Loss: 0.6472185, Train Acc: 0.6227, Valid. Acc: 0.6070, Train AUC: 0.6706, Train AP: 0.6573, Valid. AUC: 0.6450, Valid. AP: 0.6231\n",
      "Epoch: 49/100, Loss: 0.6474429, Train Acc: 0.6209, Valid. Acc: 0.6225, Train AUC: 0.6702, Train AP: 0.6577, Valid. AUC: 0.6538, Valid. AP: 0.6318\n",
      "Epoch: 50/100, Loss: 0.6446825, Train Acc: 0.6311, Valid. Acc: 0.6270, Train AUC: 0.6765, Train AP: 0.6626, Valid. AUC: 0.6593, Valid. AP: 0.6364\n",
      "Epoch: 51/100, Loss: 0.6465610, Train Acc: 0.6324, Valid. Acc: 0.6175, Train AUC: 0.6814, Train AP: 0.6659, Valid. AUC: 0.6542, Valid. AP: 0.6318\n",
      "Epoch: 52/100, Loss: 0.6412415, Train Acc: 0.6346, Valid. Acc: 0.6066, Train AUC: 0.6820, Train AP: 0.6687, Valid. AUC: 0.6537, Valid. AP: 0.6305\n",
      "Epoch: 53/100, Loss: 0.6403762, Train Acc: 0.6372, Valid. Acc: 0.6243, Train AUC: 0.6831, Train AP: 0.6694, Valid. AUC: 0.6658, Valid. AP: 0.6434\n",
      "Epoch: 54/100, Loss: 0.6396163, Train Acc: 0.6487, Valid. Acc: 0.6298, Train AUC: 0.6913, Train AP: 0.6745, Valid. AUC: 0.6672, Valid. AP: 0.6444\n",
      "Epoch: 55/100, Loss: 0.6347492, Train Acc: 0.6513, Valid. Acc: 0.6226, Train AUC: 0.6961, Train AP: 0.6799, Valid. AUC: 0.6632, Valid. AP: 0.6401\n",
      "Epoch: 56/100, Loss: 0.6346534, Train Acc: 0.6496, Valid. Acc: 0.6325, Train AUC: 0.6956, Train AP: 0.6793, Valid. AUC: 0.6716, Valid. AP: 0.6487\n",
      "Epoch: 57/100, Loss: 0.6324803, Train Acc: 0.6536, Valid. Acc: 0.6323, Train AUC: 0.7005, Train AP: 0.6843, Valid. AUC: 0.6733, Valid. AP: 0.6516\n",
      "Epoch: 58/100, Loss: 0.6305537, Train Acc: 0.6533, Valid. Acc: 0.6248, Train AUC: 0.7029, Train AP: 0.6918, Valid. AUC: 0.6638, Valid. AP: 0.6397\n",
      "Epoch: 59/100, Loss: 0.6274734, Train Acc: 0.6543, Valid. Acc: 0.6300, Train AUC: 0.7047, Train AP: 0.6913, Valid. AUC: 0.6704, Valid. AP: 0.6477\n",
      "Epoch: 60/100, Loss: 0.6239828, Train Acc: 0.6564, Valid. Acc: 0.6320, Train AUC: 0.7106, Train AP: 0.6982, Valid. AUC: 0.6751, Valid. AP: 0.6553\n",
      "Epoch: 61/100, Loss: 0.6257749, Train Acc: 0.6518, Valid. Acc: 0.6196, Train AUC: 0.7093, Train AP: 0.7006, Valid. AUC: 0.6579, Valid. AP: 0.6347\n",
      "Epoch: 62/100, Loss: 0.6267740, Train Acc: 0.6524, Valid. Acc: 0.6258, Train AUC: 0.7077, Train AP: 0.6950, Valid. AUC: 0.6703, Valid. AP: 0.6513\n",
      "Epoch: 63/100, Loss: 0.6236851, Train Acc: 0.6546, Valid. Acc: 0.6311, Train AUC: 0.7130, Train AP: 0.7023, Valid. AUC: 0.6733, Valid. AP: 0.6561\n",
      "Epoch: 64/100, Loss: 0.6230177, Train Acc: 0.6525, Valid. Acc: 0.6276, Train AUC: 0.7089, Train AP: 0.7000, Valid. AUC: 0.6726, Valid. AP: 0.6509\n",
      "Epoch: 65/100, Loss: 0.6173770, Train Acc: 0.6593, Valid. Acc: 0.6200, Train AUC: 0.7184, Train AP: 0.7098, Valid. AUC: 0.6632, Valid. AP: 0.6411\n",
      "Epoch: 66/100, Loss: 0.6207625, Train Acc: 0.6578, Valid. Acc: 0.6370, Train AUC: 0.7144, Train AP: 0.7062, Valid. AUC: 0.6811, Valid. AP: 0.6609\n",
      "Epoch: 67/100, Loss: 0.6194701, Train Acc: 0.6553, Valid. Acc: 0.6375, Train AUC: 0.7162, Train AP: 0.7093, Valid. AUC: 0.6819, Valid. AP: 0.6615\n",
      "Epoch: 68/100, Loss: 0.6138155, Train Acc: 0.6612, Valid. Acc: 0.6317, Train AUC: 0.7204, Train AP: 0.7128, Valid. AUC: 0.6776, Valid. AP: 0.6569\n",
      "Epoch: 69/100, Loss: 0.6146597, Train Acc: 0.6607, Valid. Acc: 0.6360, Train AUC: 0.7222, Train AP: 0.7116, Valid. AUC: 0.6801, Valid. AP: 0.6600\n",
      "Epoch: 70/100, Loss: 0.6131330, Train Acc: 0.6617, Valid. Acc: 0.6427, Train AUC: 0.7226, Train AP: 0.7104, Valid. AUC: 0.6878, Valid. AP: 0.6684\n",
      "Epoch: 71/100, Loss: 0.6111112, Train Acc: 0.6609, Valid. Acc: 0.6431, Train AUC: 0.7229, Train AP: 0.7168, Valid. AUC: 0.6892, Valid. AP: 0.6695\n",
      "Epoch: 72/100, Loss: 0.6110122, Train Acc: 0.6616, Valid. Acc: 0.6409, Train AUC: 0.7236, Train AP: 0.7171, Valid. AUC: 0.6850, Valid. AP: 0.6643\n",
      "Epoch: 73/100, Loss: 0.6100256, Train Acc: 0.6628, Valid. Acc: 0.6430, Train AUC: 0.7245, Train AP: 0.7186, Valid. AUC: 0.6880, Valid. AP: 0.6668\n",
      "Epoch: 74/100, Loss: 0.6082649, Train Acc: 0.6628, Valid. Acc: 0.6438, Train AUC: 0.7258, Train AP: 0.7220, Valid. AUC: 0.6906, Valid. AP: 0.6695\n",
      "Epoch: 75/100, Loss: 0.6079236, Train Acc: 0.6618, Valid. Acc: 0.6391, Train AUC: 0.7255, Train AP: 0.7219, Valid. AUC: 0.6844, Valid. AP: 0.6641\n",
      "Epoch: 76/100, Loss: 0.6079621, Train Acc: 0.6648, Valid. Acc: 0.6383, Train AUC: 0.7273, Train AP: 0.7189, Valid. AUC: 0.6840, Valid. AP: 0.6647\n",
      "Epoch: 77/100, Loss: 0.6070617, Train Acc: 0.6648, Valid. Acc: 0.6464, Train AUC: 0.7266, Train AP: 0.7219, Valid. AUC: 0.6915, Valid. AP: 0.6734\n",
      "Epoch: 78/100, Loss: 0.6051478, Train Acc: 0.6647, Valid. Acc: 0.6411, Train AUC: 0.7280, Train AP: 0.7250, Valid. AUC: 0.6863, Valid. AP: 0.6706\n",
      "Epoch: 79/100, Loss: 0.6055384, Train Acc: 0.6643, Valid. Acc: 0.6385, Train AUC: 0.7292, Train AP: 0.7252, Valid. AUC: 0.6844, Valid. AP: 0.6697\n",
      "Epoch: 80/100, Loss: 0.6048353, Train Acc: 0.6655, Valid. Acc: 0.6446, Train AUC: 0.7293, Train AP: 0.7263, Valid. AUC: 0.6930, Valid. AP: 0.6760\n",
      "Epoch: 81/100, Loss: 0.6068666, Train Acc: 0.6629, Valid. Acc: 0.6345, Train AUC: 0.7257, Train AP: 0.7228, Valid. AUC: 0.6810, Valid. AP: 0.6662\n",
      "Epoch: 82/100, Loss: 0.6035222, Train Acc: 0.6664, Valid. Acc: 0.6311, Train AUC: 0.7304, Train AP: 0.7273, Valid. AUC: 0.6790, Valid. AP: 0.6642\n",
      "Epoch: 83/100, Loss: 0.6077132, Train Acc: 0.6650, Valid. Acc: 0.6421, Train AUC: 0.7271, Train AP: 0.7209, Valid. AUC: 0.6920, Valid. AP: 0.6753\n",
      "Epoch: 84/100, Loss: 0.6031677, Train Acc: 0.6652, Valid. Acc: 0.6420, Train AUC: 0.7300, Train AP: 0.7288, Valid. AUC: 0.6932, Valid. AP: 0.6756\n",
      "Epoch: 85/100, Loss: 0.6033931, Train Acc: 0.6677, Valid. Acc: 0.6403, Train AUC: 0.7313, Train AP: 0.7292, Valid. AUC: 0.6893, Valid. AP: 0.6714\n",
      "Epoch: 86/100, Loss: 0.6020590, Train Acc: 0.6668, Valid. Acc: 0.6445, Train AUC: 0.7319, Train AP: 0.7296, Valid. AUC: 0.6944, Valid. AP: 0.6770\n",
      "Epoch: 87/100, Loss: 0.6022716, Train Acc: 0.6684, Valid. Acc: 0.6455, Train AUC: 0.7322, Train AP: 0.7283, Valid. AUC: 0.6931, Valid. AP: 0.6782\n",
      "Epoch: 88/100, Loss: 0.6012254, Train Acc: 0.6679, Valid. Acc: 0.6449, Train AUC: 0.7329, Train AP: 0.7309, Valid. AUC: 0.6951, Valid. AP: 0.6814\n",
      "Epoch: 89/100, Loss: 0.6005971, Train Acc: 0.6686, Valid. Acc: 0.6453, Train AUC: 0.7341, Train AP: 0.7326, Valid. AUC: 0.6953, Valid. AP: 0.6811\n",
      "Epoch: 90/100, Loss: 0.6007977, Train Acc: 0.6697, Valid. Acc: 0.6414, Train AUC: 0.7339, Train AP: 0.7316, Valid. AUC: 0.6925, Valid. AP: 0.6761\n",
      "Epoch: 91/100, Loss: 0.6001079, Train Acc: 0.6689, Valid. Acc: 0.6458, Train AUC: 0.7353, Train AP: 0.7333, Valid. AUC: 0.6953, Valid. AP: 0.6780\n",
      "Epoch: 92/100, Loss: 0.5987334, Train Acc: 0.6704, Valid. Acc: 0.6452, Train AUC: 0.7357, Train AP: 0.7339, Valid. AUC: 0.6961, Valid. AP: 0.6798\n",
      "Epoch: 93/100, Loss: 0.5985740, Train Acc: 0.6694, Valid. Acc: 0.6471, Train AUC: 0.7365, Train AP: 0.7352, Valid. AUC: 0.6996, Valid. AP: 0.6841\n",
      "Epoch: 94/100, Loss: 0.5989615, Train Acc: 0.6692, Valid. Acc: 0.6467, Train AUC: 0.7362, Train AP: 0.7344, Valid. AUC: 0.6979, Valid. AP: 0.6827\n",
      "Epoch: 95/100, Loss: 0.5983550, Train Acc: 0.6695, Valid. Acc: 0.6494, Train AUC: 0.7363, Train AP: 0.7347, Valid. AUC: 0.7013, Valid. AP: 0.6868\n",
      "Epoch: 96/100, Loss: 0.5999531, Train Acc: 0.6692, Valid. Acc: 0.6466, Train AUC: 0.7342, Train AP: 0.7330, Valid. AUC: 0.6978, Valid. AP: 0.6830\n",
      "Epoch: 97/100, Loss: 0.5979038, Train Acc: 0.6713, Valid. Acc: 0.6467, Train AUC: 0.7376, Train AP: 0.7364, Valid. AUC: 0.6972, Valid. AP: 0.6825\n",
      "Epoch: 98/100, Loss: 0.5958140, Train Acc: 0.6732, Valid. Acc: 0.6462, Train AUC: 0.7395, Train AP: 0.7386, Valid. AUC: 0.6973, Valid. AP: 0.6825\n",
      "Epoch: 99/100, Loss: 0.5986370, Train Acc: 0.6698, Valid. Acc: 0.6353, Train AUC: 0.7355, Train AP: 0.7339, Valid. AUC: 0.6776, Valid. AP: 0.6620\n",
      "Epoch: 100/100, Loss: 0.6033250, Train Acc: 0.6676, Valid. Acc: 0.6493, Train AUC: 0.7327, Train AP: 0.7311, Valid. AUC: 0.6999, Valid. AP: 0.6852\n",
      "/home/ubuntu/PA-Cancer-Immunotherapy/GNN/train_pa_all_tvt.py:212: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(configs['save_model']))\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.388 MB of 1.388 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.389 MB of 1.389 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.389 MB of 1.389 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.389 MB of 1.389 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        test_ap ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   test_roc_auc ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▁▄▄▄▄▅▅▅▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇█████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train_ap ▁▃▄▄▄▄▄▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss ██▇▇▇▇▇▆▆▆▆▆▆▆▆▆▆▆▆▅▅▅▅▅▄▃▃▂▂▂▂▂▂▂▂▁▁▁▁▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_roc_auc ▁▃▄▄▄▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: valid_accuracy ▁▃▃▅▅▆▅▅▆▆▇▇▇▇▇▆▆▆▆▇▇▇▇▇▇▇████▇▇████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       valid_ap ▁▂▂▂▂▄▄▄▄▄▄▄▅▅▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇█▇█████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  valid_roc_auc ▁▁▂▂▄▅▅▄▅▅▅▅▅▅▅▆▆▆▆▇▇▆▇▇▇▇▇▇█▇██████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy 0.65296\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        test_ap 0.69252\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   test_roc_auc 0.70675\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.66756\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train_ap 0.73109\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.60333\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_roc_auc 0.73273\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: valid_accuracy 0.64927\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       valid_ap 0.6852\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  valid_roc_auc 0.69989\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mcopper-planet-9\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-gene_GNN/runs/dkl081o4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-gene_GNN\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 6 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241213_165119-dkl081o4/logs\u001b[0m\n",
      "Test Acc: 0.6530, Test AUC: 0.7068, Test AP: 0.6925\n"
     ]
    }
   ],
   "source": [
    "# for gene  (using both optimizers)\n",
    "\n",
    "! python train_pa_all_tvt.py --gpu 0 --configs_path configs/PA_all_tvt_gene.yml --droup_out 0.1 --split StrictTCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e553fa4-e99e-4ce1-8ee2-e5b2264b593c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "091a3b1b-1213-440c-862e-d44cd6f5b696",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(gpu=0, lr=0.001, epochs=100, w_celoss=1, w_aucloss=0, add_same_type_edges=False, dynamic_graph=False, dynamic_ratio=0.05, droup_out=0.1, positive_weights=1, dynamic_epochs=30, distance_threshold=10, configs_path='configs/PA_all_tvt_allele.yml', split='StrictTCR', dataset='pMTnet')\n",
      "PROJECT_NAME: dataset-all-tvt-allele_GNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfrohoari\u001b[0m (\u001b[33mpa_cancerimmunotherapy\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/ubuntu/PA-Cancer-Immunotherapy/GNN/wandb/run-20241206_234252-1o6tyk92\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mgolden-meadow-6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-allele_GNN\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-allele_GNN/runs/1o6tyk92\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   6 of 6 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   6 of 6 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   6 of 6 files downloaded.  \n",
      "embeddings_path:   models/PA_all/gene_and_allele_embeddings.pkl\n",
      "train_file_list:   ['allele_train.csv']\n",
      "validation_file_list:   ['allele_validation.csv']\n",
      "test_file_list:   ['allele_test.csv']\n",
      "wandb logger initialisiert\n",
      "Epoch: 1/100, Loss: 0.6935461, Train Acc: 0.4871, Test Acc: 0.5031, Train AUC: 0.4853, Train APUR: 0.4985, Test AUC: 0.5574, Test AUPR: 0.5489\n",
      "Epoch: 2/100, Loss: 0.6912209, Train Acc: 0.5072, Test Acc: 0.5374, Train AUC: 0.5700, Train APUR: 0.5563, Test AUC: 0.5625, Test AUPR: 0.5545\n",
      "Epoch: 3/100, Loss: 0.6868216, Train Acc: 0.5492, Test Acc: 0.5559, Train AUC: 0.5897, Train APUR: 0.5732, Test AUC: 0.5627, Test AUPR: 0.5554\n",
      "Epoch: 4/100, Loss: 0.6830894, Train Acc: 0.5681, Test Acc: 0.5254, Train AUC: 0.5979, Train APUR: 0.5825, Test AUC: 0.5638, Test AUPR: 0.5561\n",
      "Epoch: 5/100, Loss: 0.6811142, Train Acc: 0.5708, Test Acc: 0.5635, Train AUC: 0.5971, Train APUR: 0.5814, Test AUC: 0.5717, Test AUPR: 0.5601\n",
      "Epoch: 6/100, Loss: 0.6785972, Train Acc: 0.5794, Test Acc: 0.5686, Train AUC: 0.6035, Train APUR: 0.5817, Test AUC: 0.5820, Test AUPR: 0.5668\n",
      "Epoch: 7/100, Loss: 0.6762490, Train Acc: 0.5827, Test Acc: 0.5646, Train AUC: 0.6095, Train APUR: 0.5865, Test AUC: 0.5916, Test AUPR: 0.5750\n",
      "Epoch: 8/100, Loss: 0.6739101, Train Acc: 0.5884, Test Acc: 0.5709, Train AUC: 0.6144, Train APUR: 0.5888, Test AUC: 0.6053, Test AUPR: 0.5892\n",
      "Epoch: 9/100, Loss: 0.6727343, Train Acc: 0.5906, Test Acc: 0.5719, Train AUC: 0.6205, Train APUR: 0.5967, Test AUC: 0.6136, Test AUPR: 0.5963\n",
      "Epoch: 10/100, Loss: 0.6755987, Train Acc: 0.5845, Test Acc: 0.5816, Train AUC: 0.6251, Train APUR: 0.6019, Test AUC: 0.6210, Test AUPR: 0.6037\n",
      "Epoch: 11/100, Loss: 0.6703843, Train Acc: 0.5963, Test Acc: 0.5930, Train AUC: 0.6258, Train APUR: 0.5979, Test AUC: 0.6239, Test AUPR: 0.6067\n",
      "Epoch: 12/100, Loss: 0.6712692, Train Acc: 0.5934, Test Acc: 0.5880, Train AUC: 0.6284, Train APUR: 0.6031, Test AUC: 0.6255, Test AUPR: 0.6084\n",
      "Epoch: 13/100, Loss: 0.6690730, Train Acc: 0.5990, Test Acc: 0.5790, Train AUC: 0.6267, Train APUR: 0.6020, Test AUC: 0.6262, Test AUPR: 0.6095\n",
      "Epoch: 14/100, Loss: 0.6691637, Train Acc: 0.5915, Test Acc: 0.5830, Train AUC: 0.6315, Train APUR: 0.6073, Test AUC: 0.6278, Test AUPR: 0.6113\n",
      "Epoch: 15/100, Loss: 0.6671317, Train Acc: 0.5957, Test Acc: 0.5961, Train AUC: 0.6327, Train APUR: 0.6113, Test AUC: 0.6292, Test AUPR: 0.6127\n",
      "Epoch: 16/100, Loss: 0.6659296, Train Acc: 0.6016, Test Acc: 0.5871, Train AUC: 0.6343, Train APUR: 0.6097, Test AUC: 0.6288, Test AUPR: 0.6126\n",
      "Epoch: 17/100, Loss: 0.6663686, Train Acc: 0.6022, Test Acc: 0.5867, Train AUC: 0.6361, Train APUR: 0.6136, Test AUC: 0.6281, Test AUPR: 0.6121\n",
      "Epoch: 18/100, Loss: 0.6651752, Train Acc: 0.6025, Test Acc: 0.5946, Train AUC: 0.6376, Train APUR: 0.6139, Test AUC: 0.6275, Test AUPR: 0.6116\n",
      "Epoch: 19/100, Loss: 0.6639968, Train Acc: 0.6025, Test Acc: 0.5928, Train AUC: 0.6390, Train APUR: 0.6169, Test AUC: 0.6261, Test AUPR: 0.6105\n",
      "Epoch: 20/100, Loss: 0.6641932, Train Acc: 0.6008, Test Acc: 0.5947, Train AUC: 0.6384, Train APUR: 0.6165, Test AUC: 0.6258, Test AUPR: 0.6104\n",
      "Epoch: 21/100, Loss: 0.6624036, Train Acc: 0.6027, Test Acc: 0.5810, Train AUC: 0.6412, Train APUR: 0.6192, Test AUC: 0.6260, Test AUPR: 0.6110\n",
      "Epoch: 22/100, Loss: 0.6621052, Train Acc: 0.6050, Test Acc: 0.5809, Train AUC: 0.6420, Train APUR: 0.6198, Test AUC: 0.6278, Test AUPR: 0.6128\n",
      "Epoch: 23/100, Loss: 0.6618458, Train Acc: 0.6069, Test Acc: 0.5823, Train AUC: 0.6421, Train APUR: 0.6192, Test AUC: 0.6277, Test AUPR: 0.6128\n",
      "Epoch: 24/100, Loss: 0.6605177, Train Acc: 0.6058, Test Acc: 0.5862, Train AUC: 0.6455, Train APUR: 0.6227, Test AUC: 0.6282, Test AUPR: 0.6132\n",
      "Epoch: 25/100, Loss: 0.6601762, Train Acc: 0.6091, Test Acc: 0.5834, Train AUC: 0.6475, Train APUR: 0.6241, Test AUC: 0.6294, Test AUPR: 0.6139\n",
      "Epoch: 26/100, Loss: 0.6592344, Train Acc: 0.6073, Test Acc: 0.5825, Train AUC: 0.6475, Train APUR: 0.6252, Test AUC: 0.6318, Test AUPR: 0.6156\n",
      "Epoch: 27/100, Loss: 0.6592245, Train Acc: 0.6086, Test Acc: 0.5966, Train AUC: 0.6474, Train APUR: 0.6254, Test AUC: 0.6346, Test AUPR: 0.6177\n",
      "Epoch: 28/100, Loss: 0.6579987, Train Acc: 0.6067, Test Acc: 0.6009, Train AUC: 0.6497, Train APUR: 0.6277, Test AUC: 0.6400, Test AUPR: 0.6218\n",
      "Epoch: 29/100, Loss: 0.6574175, Train Acc: 0.6077, Test Acc: 0.6029, Train AUC: 0.6504, Train APUR: 0.6295, Test AUC: 0.6436, Test AUPR: 0.6243\n",
      "Epoch: 30/100, Loss: 0.6564965, Train Acc: 0.6099, Test Acc: 0.6108, Train AUC: 0.6522, Train APUR: 0.6310, Test AUC: 0.6479, Test AUPR: 0.6270\n",
      "Epoch: 31/100, Loss: 0.6562525, Train Acc: 0.6097, Test Acc: 0.6269, Train AUC: 0.6534, Train APUR: 0.6316, Test AUC: 0.6495, Test AUPR: 0.6279\n",
      "Epoch: 32/100, Loss: 0.6555253, Train Acc: 0.6109, Test Acc: 0.6277, Train AUC: 0.6546, Train APUR: 0.6326, Test AUC: 0.6512, Test AUPR: 0.6292\n",
      "Epoch: 33/100, Loss: 0.6538423, Train Acc: 0.6140, Test Acc: 0.6206, Train AUC: 0.6569, Train APUR: 0.6345, Test AUC: 0.6526, Test AUPR: 0.6304\n",
      "Epoch: 34/100, Loss: 0.6532855, Train Acc: 0.6125, Test Acc: 0.6302, Train AUC: 0.6581, Train APUR: 0.6369, Test AUC: 0.6536, Test AUPR: 0.6315\n",
      "Epoch: 35/100, Loss: 0.6529422, Train Acc: 0.6143, Test Acc: 0.6292, Train AUC: 0.6579, Train APUR: 0.6373, Test AUC: 0.6541, Test AUPR: 0.6324\n",
      "Epoch: 36/100, Loss: 0.6511979, Train Acc: 0.6143, Test Acc: 0.6205, Train AUC: 0.6608, Train APUR: 0.6405, Test AUC: 0.6542, Test AUPR: 0.6326\n",
      "Epoch: 37/100, Loss: 0.6516984, Train Acc: 0.6142, Test Acc: 0.6244, Train AUC: 0.6617, Train APUR: 0.6421, Test AUC: 0.6539, Test AUPR: 0.6337\n",
      "Epoch: 38/100, Loss: 0.6494229, Train Acc: 0.6159, Test Acc: 0.6165, Train AUC: 0.6645, Train APUR: 0.6444, Test AUC: 0.6540, Test AUPR: 0.6349\n",
      "Epoch: 39/100, Loss: 0.6487944, Train Acc: 0.6165, Test Acc: 0.6157, Train AUC: 0.6664, Train APUR: 0.6469, Test AUC: 0.6550, Test AUPR: 0.6373\n",
      "Epoch: 40/100, Loss: 0.6468792, Train Acc: 0.6154, Test Acc: 0.6153, Train AUC: 0.6688, Train APUR: 0.6506, Test AUC: 0.6560, Test AUPR: 0.6385\n",
      "Epoch: 41/100, Loss: 0.6459289, Train Acc: 0.6196, Test Acc: 0.6186, Train AUC: 0.6704, Train APUR: 0.6511, Test AUC: 0.6529, Test AUPR: 0.6360\n",
      "Epoch: 42/100, Loss: 0.6465461, Train Acc: 0.6214, Test Acc: 0.6235, Train AUC: 0.6741, Train APUR: 0.6538, Test AUC: 0.6608, Test AUPR: 0.6438\n",
      "Epoch: 43/100, Loss: 0.6426073, Train Acc: 0.6238, Test Acc: 0.6308, Train AUC: 0.6756, Train APUR: 0.6583, Test AUC: 0.6653, Test AUPR: 0.6469\n",
      "Epoch: 44/100, Loss: 0.6409063, Train Acc: 0.6286, Test Acc: 0.6332, Train AUC: 0.6793, Train APUR: 0.6615, Test AUC: 0.6682, Test AUPR: 0.6474\n",
      "Epoch: 45/100, Loss: 0.6394761, Train Acc: 0.6390, Test Acc: 0.6329, Train AUC: 0.6875, Train APUR: 0.6654, Test AUC: 0.6731, Test AUPR: 0.6528\n",
      "Epoch: 46/100, Loss: 0.6370594, Train Acc: 0.6360, Test Acc: 0.6394, Train AUC: 0.6859, Train APUR: 0.6674, Test AUC: 0.6765, Test AUPR: 0.6558\n",
      "Epoch: 47/100, Loss: 0.6353444, Train Acc: 0.6402, Test Acc: 0.6135, Train AUC: 0.6884, Train APUR: 0.6699, Test AUC: 0.6613, Test AUPR: 0.6427\n",
      "Epoch: 48/100, Loss: 0.6383094, Train Acc: 0.6430, Test Acc: 0.6442, Train AUC: 0.6924, Train APUR: 0.6671, Test AUC: 0.6823, Test AUPR: 0.6620\n",
      "Epoch: 49/100, Loss: 0.6315815, Train Acc: 0.6468, Test Acc: 0.6378, Train AUC: 0.6958, Train APUR: 0.6780, Test AUC: 0.6848, Test AUPR: 0.6641\n",
      "Epoch: 50/100, Loss: 0.6315229, Train Acc: 0.6449, Test Acc: 0.6420, Train AUC: 0.6963, Train APUR: 0.6791, Test AUC: 0.6855, Test AUPR: 0.6633\n",
      "Epoch: 51/100, Loss: 0.6287380, Train Acc: 0.6497, Test Acc: 0.6393, Train AUC: 0.7013, Train APUR: 0.6783, Test AUC: 0.6849, Test AUPR: 0.6642\n",
      "Epoch: 52/100, Loss: 0.6275368, Train Acc: 0.6521, Test Acc: 0.6417, Train AUC: 0.7050, Train APUR: 0.6834, Test AUC: 0.6910, Test AUPR: 0.6696\n",
      "Epoch: 53/100, Loss: 0.6270136, Train Acc: 0.6480, Test Acc: 0.6456, Train AUC: 0.7046, Train APUR: 0.6848, Test AUC: 0.6923, Test AUPR: 0.6714\n",
      "Epoch: 54/100, Loss: 0.6237199, Train Acc: 0.6516, Test Acc: 0.6197, Train AUC: 0.7066, Train APUR: 0.6877, Test AUC: 0.6704, Test AUPR: 0.6561\n",
      "Epoch: 55/100, Loss: 0.6329811, Train Acc: 0.6399, Test Acc: 0.6450, Train AUC: 0.6951, Train APUR: 0.6742, Test AUC: 0.6928, Test AUPR: 0.6729\n",
      "Epoch: 56/100, Loss: 0.6209260, Train Acc: 0.6550, Test Acc: 0.6346, Train AUC: 0.7106, Train APUR: 0.6906, Test AUC: 0.6917, Test AUPR: 0.6719\n",
      "Epoch: 57/100, Loss: 0.6250452, Train Acc: 0.6514, Test Acc: 0.6288, Train AUC: 0.7072, Train APUR: 0.6873, Test AUC: 0.6861, Test AUPR: 0.6706\n",
      "Epoch: 58/100, Loss: 0.6204500, Train Acc: 0.6521, Test Acc: 0.6436, Train AUC: 0.7136, Train APUR: 0.6932, Test AUC: 0.6947, Test AUPR: 0.6760\n",
      "Epoch: 59/100, Loss: 0.6171550, Train Acc: 0.6581, Test Acc: 0.6441, Train AUC: 0.7170, Train APUR: 0.6951, Test AUC: 0.6980, Test AUPR: 0.6779\n",
      "Epoch: 60/100, Loss: 0.6174706, Train Acc: 0.6584, Test Acc: 0.6479, Train AUC: 0.7172, Train APUR: 0.6944, Test AUC: 0.6984, Test AUPR: 0.6797\n",
      "Epoch: 61/100, Loss: 0.6135675, Train Acc: 0.6589, Test Acc: 0.6415, Train AUC: 0.7207, Train APUR: 0.6997, Test AUC: 0.6961, Test AUPR: 0.6796\n",
      "Epoch: 62/100, Loss: 0.6148323, Train Acc: 0.6576, Test Acc: 0.6485, Train AUC: 0.7214, Train APUR: 0.7024, Test AUC: 0.6988, Test AUPR: 0.6823\n",
      "Epoch: 63/100, Loss: 0.6141235, Train Acc: 0.6619, Test Acc: 0.6368, Train AUC: 0.7213, Train APUR: 0.7010, Test AUC: 0.6904, Test AUPR: 0.6770\n",
      "Epoch: 64/100, Loss: 0.6132518, Train Acc: 0.6602, Test Acc: 0.6452, Train AUC: 0.7219, Train APUR: 0.7050, Test AUC: 0.6989, Test AUPR: 0.6840\n",
      "Epoch: 65/100, Loss: 0.6100566, Train Acc: 0.6624, Test Acc: 0.6460, Train AUC: 0.7253, Train APUR: 0.7079, Test AUC: 0.6995, Test AUPR: 0.6855\n",
      "Epoch: 66/100, Loss: 0.6095353, Train Acc: 0.6617, Test Acc: 0.6390, Train AUC: 0.7262, Train APUR: 0.7085, Test AUC: 0.6932, Test AUPR: 0.6803\n",
      "Epoch: 67/100, Loss: 0.6117673, Train Acc: 0.6566, Test Acc: 0.6477, Train AUC: 0.7237, Train APUR: 0.7057, Test AUC: 0.7023, Test AUPR: 0.6881\n",
      "Epoch: 68/100, Loss: 0.6081505, Train Acc: 0.6628, Test Acc: 0.6491, Train AUC: 0.7275, Train APUR: 0.7096, Test AUC: 0.7047, Test AUPR: 0.6897\n",
      "Epoch: 69/100, Loss: 0.6064550, Train Acc: 0.6644, Test Acc: 0.6501, Train AUC: 0.7303, Train APUR: 0.7138, Test AUC: 0.7034, Test AUPR: 0.6885\n",
      "Epoch: 70/100, Loss: 0.6044878, Train Acc: 0.6680, Test Acc: 0.6520, Train AUC: 0.7316, Train APUR: 0.7141, Test AUC: 0.7055, Test AUPR: 0.6901\n",
      "Epoch: 71/100, Loss: 0.6044473, Train Acc: 0.6673, Test Acc: 0.6475, Train AUC: 0.7323, Train APUR: 0.7159, Test AUC: 0.6996, Test AUPR: 0.6850\n",
      "Epoch: 72/100, Loss: 0.6040296, Train Acc: 0.6654, Test Acc: 0.6509, Train AUC: 0.7315, Train APUR: 0.7156, Test AUC: 0.7058, Test AUPR: 0.6921\n",
      "Epoch: 73/100, Loss: 0.6019141, Train Acc: 0.6688, Test Acc: 0.6458, Train AUC: 0.7336, Train APUR: 0.7176, Test AUC: 0.7030, Test AUPR: 0.6906\n",
      "Epoch: 74/100, Loss: 0.6001900, Train Acc: 0.6683, Test Acc: 0.6439, Train AUC: 0.7359, Train APUR: 0.7207, Test AUC: 0.6992, Test AUPR: 0.6886\n",
      "Epoch: 75/100, Loss: 0.6001255, Train Acc: 0.6690, Test Acc: 0.6388, Train AUC: 0.7366, Train APUR: 0.7205, Test AUC: 0.6953, Test AUPR: 0.6853\n",
      "Epoch: 76/100, Loss: 0.5983430, Train Acc: 0.6692, Test Acc: 0.6425, Train AUC: 0.7371, Train APUR: 0.7253, Test AUC: 0.6990, Test AUPR: 0.6885\n",
      "Epoch: 77/100, Loss: 0.5998175, Train Acc: 0.6703, Test Acc: 0.6492, Train AUC: 0.7358, Train APUR: 0.7229, Test AUC: 0.7050, Test AUPR: 0.6943\n",
      "Epoch: 78/100, Loss: 0.5943359, Train Acc: 0.6731, Test Acc: 0.6373, Train AUC: 0.7428, Train APUR: 0.7303, Test AUC: 0.6907, Test AUPR: 0.6813\n",
      "Epoch: 79/100, Loss: 0.5994658, Train Acc: 0.6674, Test Acc: 0.6502, Train AUC: 0.7353, Train APUR: 0.7243, Test AUC: 0.7052, Test AUPR: 0.6947\n",
      "Epoch: 80/100, Loss: 0.6007764, Train Acc: 0.6698, Test Acc: 0.6449, Train AUC: 0.7354, Train APUR: 0.7208, Test AUC: 0.7025, Test AUPR: 0.6937\n",
      "Epoch: 81/100, Loss: 0.5956789, Train Acc: 0.6727, Test Acc: 0.6497, Train AUC: 0.7416, Train APUR: 0.7286, Test AUC: 0.7076, Test AUPR: 0.6989\n",
      "Epoch: 82/100, Loss: 0.5914852, Train Acc: 0.6766, Test Acc: 0.6562, Train AUC: 0.7464, Train APUR: 0.7362, Test AUC: 0.7119, Test AUPR: 0.7022\n",
      "Epoch: 83/100, Loss: 0.5917399, Train Acc: 0.6766, Test Acc: 0.6540, Train AUC: 0.7465, Train APUR: 0.7373, Test AUC: 0.7095, Test AUPR: 0.7009\n",
      "Epoch: 84/100, Loss: 0.5911595, Train Acc: 0.6763, Test Acc: 0.6593, Train AUC: 0.7467, Train APUR: 0.7380, Test AUC: 0.7153, Test AUPR: 0.7049\n",
      "Epoch: 85/100, Loss: 0.5917017, Train Acc: 0.6767, Test Acc: 0.6401, Train AUC: 0.7460, Train APUR: 0.7344, Test AUC: 0.6962, Test AUPR: 0.6897\n",
      "Epoch: 86/100, Loss: 0.5975755, Train Acc: 0.6681, Test Acc: 0.6540, Train AUC: 0.7366, Train APUR: 0.7299, Test AUC: 0.7100, Test AUPR: 0.7000\n",
      "Epoch: 87/100, Loss: 0.5951344, Train Acc: 0.6719, Test Acc: 0.6539, Train AUC: 0.7426, Train APUR: 0.7309, Test AUC: 0.7132, Test AUPR: 0.7057\n",
      "Epoch: 88/100, Loss: 0.5871829, Train Acc: 0.6808, Test Acc: 0.6190, Train AUC: 0.7512, Train APUR: 0.7422, Test AUC: 0.6738, Test AUPR: 0.6712\n",
      "Epoch: 89/100, Loss: 0.6036543, Train Acc: 0.6612, Test Acc: 0.6532, Train AUC: 0.7279, Train APUR: 0.7212, Test AUC: 0.7109, Test AUPR: 0.7020\n",
      "Epoch: 90/100, Loss: 0.5925422, Train Acc: 0.6754, Test Acc: 0.6563, Train AUC: 0.7466, Train APUR: 0.7368, Test AUC: 0.7138, Test AUPR: 0.7052\n",
      "Epoch: 91/100, Loss: 0.5888811, Train Acc: 0.6794, Test Acc: 0.6247, Train AUC: 0.7492, Train APUR: 0.7401, Test AUC: 0.6826, Test AUPR: 0.6813\n",
      "Epoch: 92/100, Loss: 0.5954129, Train Acc: 0.6685, Test Acc: 0.6456, Train AUC: 0.7397, Train APUR: 0.7335, Test AUC: 0.7072, Test AUPR: 0.7029\n",
      "Epoch: 93/100, Loss: 0.5877632, Train Acc: 0.6776, Test Acc: 0.6559, Train AUC: 0.7525, Train APUR: 0.7472, Test AUC: 0.7136, Test AUPR: 0.7051\n",
      "Epoch: 94/100, Loss: 0.5926079, Train Acc: 0.6792, Test Acc: 0.6554, Train AUC: 0.7466, Train APUR: 0.7378, Test AUC: 0.7162, Test AUPR: 0.7104\n",
      "Epoch: 95/100, Loss: 0.5838809, Train Acc: 0.6811, Test Acc: 0.6288, Train AUC: 0.7545, Train APUR: 0.7484, Test AUC: 0.6867, Test AUPR: 0.6830\n",
      "Epoch: 96/100, Loss: 0.5908924, Train Acc: 0.6722, Test Acc: 0.6529, Train AUC: 0.7445, Train APUR: 0.7414, Test AUC: 0.7143, Test AUPR: 0.7090\n",
      "Epoch: 97/100, Loss: 0.5813977, Train Acc: 0.6817, Test Acc: 0.6583, Train AUC: 0.7577, Train APUR: 0.7539, Test AUC: 0.7167, Test AUPR: 0.7080\n",
      "Epoch: 98/100, Loss: 0.5890477, Train Acc: 0.6797, Test Acc: 0.6593, Train AUC: 0.7499, Train APUR: 0.7404, Test AUC: 0.7205, Test AUPR: 0.7145\n",
      "Epoch: 99/100, Loss: 0.5811995, Train Acc: 0.6841, Test Acc: 0.6343, Train AUC: 0.7586, Train APUR: 0.7524, Test AUC: 0.6921, Test AUPR: 0.6895\n",
      "Epoch: 100/100, Loss: 0.5866944, Train Acc: 0.6766, Test Acc: 0.6505, Train AUC: 0.7496, Train APUR: 0.7454, Test AUC: 0.7125, Test AUPR: 0.7085\n",
      "/home/ubuntu/PA-Cancer-Immunotherapy/GNN/train_pa_all_tvt.py:202: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(configs['save_model']))\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.372 MB of 1.411 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.412 MB of 1.412 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.412 MB of 1.412 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.412 MB of 1.412 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.412 MB of 1.412 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      test_aupr ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   test_roc_auc ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▁▂▄▅▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇█▇███████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_aupr ▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇█▇█████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss █▇▇▇▇▆▆▆▆▆▆▆▆▆▅▅▅▅▅▄▃▄▃▃▃▃▃▃▂▂▂▂▂▂▁▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_roc_auc ▁▂▂▃▃▄▄▄▄▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇██▇▇█▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: valid_accuracy ▃▁▃▄▄▄▅▅▅▄▄▅▆▇▆▆▆▇▇▆▇▇▇▆▇▇▇███▇▇▇███▇██▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     valid_aupr ▁▁▂▂▃▄▄▄▄▄▄▅▅▅▅▅▆▅▆▆▆▇▆▇▇▇▇▇▇▇▇█▇███▇██▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  valid_roc_auc ▁▁▂▃▃▄▄▄▄▄▅▅▅▅▅▅▆▅▇▇▇▆▇▇▇▇▇▇█▇▇▇█████▇█▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy 0.66215\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      test_aupr 0.71474\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   test_roc_auc 0.72193\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.67665\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_aupr 0.74543\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.58669\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_roc_auc 0.74956\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: valid_accuracy 0.65049\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     valid_aupr 0.70851\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  valid_roc_auc 0.71248\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mgolden-meadow-6\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-allele_GNN/runs/1o6tyk92\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-allele_GNN\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 8 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241206_234252-1o6tyk92/logs\u001b[0m\n",
      "Test Acc: 0.6621, Test AUC: 0.7219, Test AUPR: 0.7147\n"
     ]
    }
   ],
   "source": [
    "# allele. Mit confusion Matrix\n",
    "\n",
    "! python train_pa_all_tvt.py --gpu 0 --configs_path configs/PA_all_tvt_allele.yml --droup_out 0.1 --split StrictTCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6e458c9-931e-459b-b149-20554b33ae24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(gpu=0, lr=0.001, epochs=100, w_celoss=1, w_aucloss=0, add_same_type_edges=False, dynamic_graph=False, dynamic_ratio=0.05, droup_out=0.1, positive_weights=1, dynamic_epochs=30, distance_threshold=10, configs_path='configs/PA_all_tvt_gene.yml', split='StrictTCR', dataset='pMTnet')\n",
      "PROJECT_NAME: dataset-all-tvt-gene_GNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfrohoari\u001b[0m (\u001b[33mpa_cancerimmunotherapy\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/ubuntu/PA-Cancer-Immunotherapy/GNN/wandb/run-20241206_231404-sq6ngple\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdry-sponge-6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-gene_GNN\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-gene_GNN/runs/sq6ngple\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   6 of 6 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   6 of 6 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   6 of 6 files downloaded.  \n",
      "embeddings_path:   models/PA_all/gene_and_allele_embeddings.pkl\n",
      "train_file_list:   ['gene_train.csv']\n",
      "validation_file_list:   ['gene_validation.csv']\n",
      "test_file_list:   ['gene_test.csv']\n",
      "wandb logger initialisiert\n",
      "Epoch: 1/100, Loss: 0.6933187, Train Acc: 0.5015, Test Acc: 0.4996, Train AUC: 0.4987, Train APUR: 0.4993, Test AUC: 0.5409, Test AUPR: 0.5310\n",
      "Epoch: 2/100, Loss: 0.6909529, Train Acc: 0.5056, Test Acc: 0.5382, Train AUC: 0.5701, Train APUR: 0.5528, Test AUC: 0.5544, Test AUPR: 0.5475\n",
      "Epoch: 3/100, Loss: 0.6864629, Train Acc: 0.5495, Test Acc: 0.5545, Train AUC: 0.5937, Train APUR: 0.5843, Test AUC: 0.5515, Test AUPR: 0.5441\n",
      "Epoch: 4/100, Loss: 0.6836001, Train Acc: 0.5694, Test Acc: 0.5189, Train AUC: 0.5953, Train APUR: 0.5846, Test AUC: 0.5519, Test AUPR: 0.5429\n",
      "Epoch: 5/100, Loss: 0.6805421, Train Acc: 0.5729, Test Acc: 0.5522, Train AUC: 0.5991, Train APUR: 0.5860, Test AUC: 0.5579, Test AUPR: 0.5487\n",
      "Epoch: 6/100, Loss: 0.6789077, Train Acc: 0.5763, Test Acc: 0.5602, Train AUC: 0.6028, Train APUR: 0.5912, Test AUC: 0.5656, Test AUPR: 0.5572\n",
      "Epoch: 7/100, Loss: 0.6759972, Train Acc: 0.5801, Test Acc: 0.5618, Train AUC: 0.6116, Train APUR: 0.5962, Test AUC: 0.5744, Test AUPR: 0.5631\n",
      "Epoch: 8/100, Loss: 0.6750871, Train Acc: 0.5835, Test Acc: 0.5449, Train AUC: 0.6149, Train APUR: 0.6014, Test AUC: 0.5810, Test AUPR: 0.5668\n",
      "Epoch: 9/100, Loss: 0.6722891, Train Acc: 0.5908, Test Acc: 0.5521, Train AUC: 0.6201, Train APUR: 0.6062, Test AUC: 0.5911, Test AUPR: 0.5745\n",
      "Epoch: 10/100, Loss: 0.6707435, Train Acc: 0.5943, Test Acc: 0.5741, Train AUC: 0.6242, Train APUR: 0.6074, Test AUC: 0.6009, Test AUPR: 0.5817\n",
      "Epoch: 11/100, Loss: 0.6695089, Train Acc: 0.5961, Test Acc: 0.5788, Train AUC: 0.6293, Train APUR: 0.6129, Test AUC: 0.6068, Test AUPR: 0.5869\n",
      "Epoch: 12/100, Loss: 0.6692299, Train Acc: 0.5976, Test Acc: 0.5754, Train AUC: 0.6289, Train APUR: 0.6158, Test AUC: 0.6105, Test AUPR: 0.5896\n",
      "Epoch: 13/100, Loss: 0.6674276, Train Acc: 0.5985, Test Acc: 0.5842, Train AUC: 0.6332, Train APUR: 0.6186, Test AUC: 0.6141, Test AUPR: 0.5922\n",
      "Epoch: 14/100, Loss: 0.6663354, Train Acc: 0.6010, Test Acc: 0.5752, Train AUC: 0.6344, Train APUR: 0.6176, Test AUC: 0.6159, Test AUPR: 0.5929\n",
      "Epoch: 15/100, Loss: 0.6667919, Train Acc: 0.5994, Test Acc: 0.5822, Train AUC: 0.6351, Train APUR: 0.6192, Test AUC: 0.6177, Test AUPR: 0.5943\n",
      "Epoch: 16/100, Loss: 0.6648233, Train Acc: 0.6021, Test Acc: 0.5903, Train AUC: 0.6369, Train APUR: 0.6204, Test AUC: 0.6219, Test AUPR: 0.5965\n",
      "Epoch: 17/100, Loss: 0.6640841, Train Acc: 0.6041, Test Acc: 0.6073, Train AUC: 0.6390, Train APUR: 0.6231, Test AUC: 0.6233, Test AUPR: 0.5973\n",
      "Epoch: 18/100, Loss: 0.6633551, Train Acc: 0.6035, Test Acc: 0.5874, Train AUC: 0.6413, Train APUR: 0.6256, Test AUC: 0.6249, Test AUPR: 0.5985\n",
      "Epoch: 19/100, Loss: 0.6626631, Train Acc: 0.6065, Test Acc: 0.5856, Train AUC: 0.6430, Train APUR: 0.6274, Test AUC: 0.6263, Test AUPR: 0.5996\n",
      "Epoch: 20/100, Loss: 0.6637696, Train Acc: 0.6062, Test Acc: 0.5879, Train AUC: 0.6440, Train APUR: 0.6278, Test AUC: 0.6265, Test AUPR: 0.6001\n",
      "Epoch: 21/100, Loss: 0.6616318, Train Acc: 0.6069, Test Acc: 0.6013, Train AUC: 0.6440, Train APUR: 0.6282, Test AUC: 0.6255, Test AUPR: 0.5996\n",
      "Epoch: 22/100, Loss: 0.6614066, Train Acc: 0.6056, Test Acc: 0.5937, Train AUC: 0.6451, Train APUR: 0.6293, Test AUC: 0.6242, Test AUPR: 0.5991\n",
      "Epoch: 23/100, Loss: 0.6606228, Train Acc: 0.6085, Test Acc: 0.5904, Train AUC: 0.6460, Train APUR: 0.6298, Test AUC: 0.6247, Test AUPR: 0.6002\n",
      "Epoch: 24/100, Loss: 0.6605307, Train Acc: 0.6081, Test Acc: 0.5893, Train AUC: 0.6458, Train APUR: 0.6305, Test AUC: 0.6286, Test AUPR: 0.6034\n",
      "Epoch: 25/100, Loss: 0.6606950, Train Acc: 0.6092, Test Acc: 0.5985, Train AUC: 0.6478, Train APUR: 0.6319, Test AUC: 0.6293, Test AUPR: 0.6042\n",
      "Epoch: 26/100, Loss: 0.6595262, Train Acc: 0.6096, Test Acc: 0.5989, Train AUC: 0.6482, Train APUR: 0.6320, Test AUC: 0.6317, Test AUPR: 0.6059\n",
      "Epoch: 27/100, Loss: 0.6593072, Train Acc: 0.6090, Test Acc: 0.6214, Train AUC: 0.6494, Train APUR: 0.6337, Test AUC: 0.6334, Test AUPR: 0.6071\n",
      "Epoch: 28/100, Loss: 0.6598341, Train Acc: 0.6081, Test Acc: 0.6229, Train AUC: 0.6469, Train APUR: 0.6319, Test AUC: 0.6354, Test AUPR: 0.6084\n",
      "Epoch: 29/100, Loss: 0.6580723, Train Acc: 0.6114, Test Acc: 0.6246, Train AUC: 0.6509, Train APUR: 0.6348, Test AUC: 0.6362, Test AUPR: 0.6091\n",
      "Epoch: 30/100, Loss: 0.6577902, Train Acc: 0.6116, Test Acc: 0.6260, Train AUC: 0.6512, Train APUR: 0.6353, Test AUC: 0.6359, Test AUPR: 0.6092\n",
      "Epoch: 31/100, Loss: 0.6571773, Train Acc: 0.6118, Test Acc: 0.6260, Train AUC: 0.6526, Train APUR: 0.6368, Test AUC: 0.6361, Test AUPR: 0.6096\n",
      "Epoch: 32/100, Loss: 0.6569622, Train Acc: 0.6121, Test Acc: 0.6256, Train AUC: 0.6530, Train APUR: 0.6367, Test AUC: 0.6363, Test AUPR: 0.6098\n",
      "Epoch: 33/100, Loss: 0.6566586, Train Acc: 0.6125, Test Acc: 0.6225, Train AUC: 0.6535, Train APUR: 0.6379, Test AUC: 0.6368, Test AUPR: 0.6103\n",
      "Epoch: 34/100, Loss: 0.6568392, Train Acc: 0.6126, Test Acc: 0.6241, Train AUC: 0.6534, Train APUR: 0.6367, Test AUC: 0.6367, Test AUPR: 0.6112\n",
      "Epoch: 35/100, Loss: 0.6562686, Train Acc: 0.6124, Test Acc: 0.6159, Train AUC: 0.6542, Train APUR: 0.6385, Test AUC: 0.6373, Test AUPR: 0.6124\n",
      "Epoch: 36/100, Loss: 0.6562128, Train Acc: 0.6126, Test Acc: 0.6237, Train AUC: 0.6551, Train APUR: 0.6384, Test AUC: 0.6377, Test AUPR: 0.6131\n",
      "Epoch: 37/100, Loss: 0.6551522, Train Acc: 0.6137, Test Acc: 0.6221, Train AUC: 0.6566, Train APUR: 0.6409, Test AUC: 0.6382, Test AUPR: 0.6138\n",
      "Epoch: 38/100, Loss: 0.6549670, Train Acc: 0.6132, Test Acc: 0.6195, Train AUC: 0.6571, Train APUR: 0.6416, Test AUC: 0.6388, Test AUPR: 0.6149\n",
      "Epoch: 39/100, Loss: 0.6541967, Train Acc: 0.6139, Test Acc: 0.6259, Train AUC: 0.6583, Train APUR: 0.6425, Test AUC: 0.6407, Test AUPR: 0.6174\n",
      "Epoch: 40/100, Loss: 0.6538315, Train Acc: 0.6146, Test Acc: 0.6248, Train AUC: 0.6588, Train APUR: 0.6445, Test AUC: 0.6421, Test AUPR: 0.6194\n",
      "Epoch: 41/100, Loss: 0.6533788, Train Acc: 0.6162, Test Acc: 0.6243, Train AUC: 0.6600, Train APUR: 0.6454, Test AUC: 0.6432, Test AUPR: 0.6203\n",
      "Epoch: 42/100, Loss: 0.6527465, Train Acc: 0.6157, Test Acc: 0.6161, Train AUC: 0.6609, Train APUR: 0.6460, Test AUC: 0.6442, Test AUPR: 0.6211\n",
      "Epoch: 43/100, Loss: 0.6528416, Train Acc: 0.6160, Test Acc: 0.6144, Train AUC: 0.6623, Train APUR: 0.6470, Test AUC: 0.6429, Test AUPR: 0.6206\n",
      "Epoch: 44/100, Loss: 0.6514971, Train Acc: 0.6164, Test Acc: 0.6204, Train AUC: 0.6633, Train APUR: 0.6482, Test AUC: 0.6426, Test AUPR: 0.6212\n",
      "Epoch: 45/100, Loss: 0.6509216, Train Acc: 0.6184, Test Acc: 0.6183, Train AUC: 0.6638, Train APUR: 0.6499, Test AUC: 0.6464, Test AUPR: 0.6254\n",
      "Epoch: 46/100, Loss: 0.6501348, Train Acc: 0.6184, Test Acc: 0.6178, Train AUC: 0.6663, Train APUR: 0.6517, Test AUC: 0.6483, Test AUPR: 0.6273\n",
      "Epoch: 47/100, Loss: 0.6496365, Train Acc: 0.6256, Test Acc: 0.6142, Train AUC: 0.6704, Train APUR: 0.6572, Test AUC: 0.6460, Test AUPR: 0.6245\n",
      "Epoch: 48/100, Loss: 0.6473917, Train Acc: 0.6217, Test Acc: 0.6087, Train AUC: 0.6700, Train APUR: 0.6570, Test AUC: 0.6461, Test AUPR: 0.6239\n",
      "Epoch: 49/100, Loss: 0.6470761, Train Acc: 0.6212, Test Acc: 0.6254, Train AUC: 0.6706, Train APUR: 0.6581, Test AUC: 0.6557, Test AUPR: 0.6331\n",
      "Epoch: 50/100, Loss: 0.6448486, Train Acc: 0.6315, Test Acc: 0.6292, Train AUC: 0.6772, Train APUR: 0.6629, Test AUC: 0.6600, Test AUPR: 0.6367\n",
      "Epoch: 51/100, Loss: 0.6460808, Train Acc: 0.6319, Test Acc: 0.6138, Train AUC: 0.6817, Train APUR: 0.6664, Test AUC: 0.6533, Test AUPR: 0.6302\n",
      "Epoch: 52/100, Loss: 0.6412737, Train Acc: 0.6337, Test Acc: 0.6095, Train AUC: 0.6814, Train APUR: 0.6683, Test AUC: 0.6552, Test AUPR: 0.6314\n",
      "Epoch: 53/100, Loss: 0.6399094, Train Acc: 0.6390, Test Acc: 0.6279, Train AUC: 0.6842, Train APUR: 0.6702, Test AUC: 0.6676, Test AUPR: 0.6454\n",
      "Epoch: 54/100, Loss: 0.6399691, Train Acc: 0.6494, Test Acc: 0.6273, Train AUC: 0.6917, Train APUR: 0.6745, Test AUC: 0.6667, Test AUPR: 0.6437\n",
      "Epoch: 55/100, Loss: 0.6345089, Train Acc: 0.6514, Test Acc: 0.6225, Train AUC: 0.6962, Train APUR: 0.6799, Test AUC: 0.6625, Test AUPR: 0.6389\n",
      "Epoch: 56/100, Loss: 0.6341457, Train Acc: 0.6510, Test Acc: 0.6316, Train AUC: 0.6954, Train APUR: 0.6793, Test AUC: 0.6721, Test AUPR: 0.6492\n",
      "Epoch: 57/100, Loss: 0.6325572, Train Acc: 0.6548, Test Acc: 0.6326, Train AUC: 0.7009, Train APUR: 0.6851, Test AUC: 0.6740, Test AUPR: 0.6526\n",
      "Epoch: 58/100, Loss: 0.6302024, Train Acc: 0.6536, Test Acc: 0.6250, Train AUC: 0.7029, Train APUR: 0.6916, Test AUC: 0.6640, Test AUPR: 0.6402\n",
      "Epoch: 59/100, Loss: 0.6279351, Train Acc: 0.6543, Test Acc: 0.6291, Train AUC: 0.7052, Train APUR: 0.6914, Test AUC: 0.6688, Test AUPR: 0.6453\n",
      "Epoch: 60/100, Loss: 0.6237742, Train Acc: 0.6561, Test Acc: 0.6328, Train AUC: 0.7101, Train APUR: 0.6978, Test AUC: 0.6754, Test AUPR: 0.6545\n",
      "Epoch: 61/100, Loss: 0.6262124, Train Acc: 0.6511, Test Acc: 0.6234, Train AUC: 0.7093, Train APUR: 0.7006, Test AUC: 0.6622, Test AUPR: 0.6394\n",
      "Epoch: 62/100, Loss: 0.6239561, Train Acc: 0.6539, Test Acc: 0.6243, Train AUC: 0.7108, Train APUR: 0.6986, Test AUC: 0.6690, Test AUPR: 0.6500\n",
      "Epoch: 63/100, Loss: 0.6238388, Train Acc: 0.6547, Test Acc: 0.6342, Train AUC: 0.7135, Train APUR: 0.7022, Test AUC: 0.6775, Test AUPR: 0.6586\n",
      "Epoch: 64/100, Loss: 0.6200570, Train Acc: 0.6550, Test Acc: 0.6313, Train AUC: 0.7139, Train APUR: 0.7044, Test AUC: 0.6771, Test AUPR: 0.6550\n",
      "Epoch: 65/100, Loss: 0.6176515, Train Acc: 0.6585, Test Acc: 0.6266, Train AUC: 0.7188, Train APUR: 0.7110, Test AUC: 0.6699, Test AUPR: 0.6482\n",
      "Epoch: 66/100, Loss: 0.6181863, Train Acc: 0.6596, Test Acc: 0.6339, Train AUC: 0.7170, Train APUR: 0.7090, Test AUC: 0.6816, Test AUPR: 0.6619\n",
      "Epoch: 67/100, Loss: 0.6214105, Train Acc: 0.6533, Test Acc: 0.6333, Train AUC: 0.7159, Train APUR: 0.7091, Test AUC: 0.6759, Test AUPR: 0.6561\n",
      "Epoch: 68/100, Loss: 0.6135420, Train Acc: 0.6620, Test Acc: 0.6301, Train AUC: 0.7210, Train APUR: 0.7131, Test AUC: 0.6778, Test AUPR: 0.6581\n",
      "Epoch: 69/100, Loss: 0.6153049, Train Acc: 0.6595, Test Acc: 0.6400, Train AUC: 0.7230, Train APUR: 0.7145, Test AUC: 0.6854, Test AUPR: 0.6662\n",
      "Epoch: 70/100, Loss: 0.6135028, Train Acc: 0.6607, Test Acc: 0.6426, Train AUC: 0.7231, Train APUR: 0.7129, Test AUC: 0.6885, Test AUPR: 0.6697\n",
      "Epoch: 71/100, Loss: 0.6111418, Train Acc: 0.6609, Test Acc: 0.6377, Train AUC: 0.7232, Train APUR: 0.7176, Test AUC: 0.6864, Test AUPR: 0.6669\n",
      "Epoch: 72/100, Loss: 0.6116026, Train Acc: 0.6621, Test Acc: 0.6427, Train AUC: 0.7249, Train APUR: 0.7175, Test AUC: 0.6872, Test AUPR: 0.6671\n",
      "Epoch: 73/100, Loss: 0.6098670, Train Acc: 0.6631, Test Acc: 0.6452, Train AUC: 0.7247, Train APUR: 0.7182, Test AUC: 0.6925, Test AUPR: 0.6709\n",
      "Epoch: 74/100, Loss: 0.6102516, Train Acc: 0.6605, Test Acc: 0.6427, Train AUC: 0.7232, Train APUR: 0.7186, Test AUC: 0.6887, Test AUPR: 0.6679\n",
      "Epoch: 75/100, Loss: 0.6080649, Train Acc: 0.6617, Test Acc: 0.6350, Train AUC: 0.7265, Train APUR: 0.7230, Test AUC: 0.6768, Test AUPR: 0.6566\n",
      "Epoch: 76/100, Loss: 0.6092827, Train Acc: 0.6641, Test Acc: 0.6408, Train AUC: 0.7255, Train APUR: 0.7161, Test AUC: 0.6871, Test AUPR: 0.6684\n",
      "Epoch: 77/100, Loss: 0.6069215, Train Acc: 0.6645, Test Acc: 0.6462, Train AUC: 0.7271, Train APUR: 0.7225, Test AUC: 0.6929, Test AUPR: 0.6752\n",
      "Epoch: 78/100, Loss: 0.6085511, Train Acc: 0.6613, Test Acc: 0.6345, Train AUC: 0.7249, Train APUR: 0.7217, Test AUC: 0.6795, Test AUPR: 0.6651\n",
      "Epoch: 79/100, Loss: 0.6063710, Train Acc: 0.6654, Test Acc: 0.6354, Train AUC: 0.7280, Train APUR: 0.7219, Test AUC: 0.6795, Test AUPR: 0.6660\n",
      "Epoch: 80/100, Loss: 0.6077318, Train Acc: 0.6643, Test Acc: 0.6413, Train AUC: 0.7276, Train APUR: 0.7239, Test AUC: 0.6906, Test AUPR: 0.6736\n",
      "Epoch: 81/100, Loss: 0.6085764, Train Acc: 0.6607, Test Acc: 0.6434, Train AUC: 0.7236, Train APUR: 0.7203, Test AUC: 0.6901, Test AUPR: 0.6742\n",
      "Epoch: 82/100, Loss: 0.6026699, Train Acc: 0.6665, Test Acc: 0.6279, Train AUC: 0.7308, Train APUR: 0.7281, Test AUC: 0.6739, Test AUPR: 0.6566\n",
      "Epoch: 83/100, Loss: 0.6091613, Train Acc: 0.6642, Test Acc: 0.6342, Train AUC: 0.7256, Train APUR: 0.7183, Test AUC: 0.6826, Test AUPR: 0.6654\n",
      "Epoch: 84/100, Loss: 0.6029935, Train Acc: 0.6650, Test Acc: 0.6416, Train AUC: 0.7304, Train APUR: 0.7285, Test AUC: 0.6928, Test AUPR: 0.6749\n",
      "Epoch: 85/100, Loss: 0.6056097, Train Acc: 0.6664, Test Acc: 0.6431, Train AUC: 0.7291, Train APUR: 0.7265, Test AUC: 0.6927, Test AUPR: 0.6760\n",
      "Epoch: 86/100, Loss: 0.6020119, Train Acc: 0.6669, Test Acc: 0.6386, Train AUC: 0.7318, Train APUR: 0.7297, Test AUC: 0.6853, Test AUPR: 0.6701\n",
      "Epoch: 87/100, Loss: 0.6024162, Train Acc: 0.6669, Test Acc: 0.6416, Train AUC: 0.7315, Train APUR: 0.7292, Test AUC: 0.6909, Test AUPR: 0.6764\n",
      "Epoch: 88/100, Loss: 0.6021211, Train Acc: 0.6675, Test Acc: 0.6460, Train AUC: 0.7317, Train APUR: 0.7295, Test AUC: 0.6970, Test AUPR: 0.6820\n",
      "Epoch: 89/100, Loss: 0.6020820, Train Acc: 0.6684, Test Acc: 0.6466, Train AUC: 0.7322, Train APUR: 0.7303, Test AUC: 0.6972, Test AUPR: 0.6830\n",
      "Epoch: 90/100, Loss: 0.6017429, Train Acc: 0.6694, Test Acc: 0.6424, Train AUC: 0.7332, Train APUR: 0.7302, Test AUC: 0.6909, Test AUPR: 0.6766\n",
      "Epoch: 91/100, Loss: 0.5997127, Train Acc: 0.6691, Test Acc: 0.6423, Train AUC: 0.7346, Train APUR: 0.7326, Test AUC: 0.6913, Test AUPR: 0.6759\n",
      "Epoch: 92/100, Loss: 0.5989361, Train Acc: 0.6696, Test Acc: 0.6457, Train AUC: 0.7352, Train APUR: 0.7337, Test AUC: 0.6938, Test AUPR: 0.6776\n",
      "Epoch: 93/100, Loss: 0.5999448, Train Acc: 0.6688, Test Acc: 0.6456, Train AUC: 0.7342, Train APUR: 0.7326, Test AUC: 0.6951, Test AUPR: 0.6785\n",
      "Epoch: 94/100, Loss: 0.5985039, Train Acc: 0.6702, Test Acc: 0.6452, Train AUC: 0.7359, Train APUR: 0.7342, Test AUC: 0.6949, Test AUPR: 0.6787\n",
      "Epoch: 95/100, Loss: 0.5993137, Train Acc: 0.6692, Test Acc: 0.6477, Train AUC: 0.7351, Train APUR: 0.7334, Test AUC: 0.7002, Test AUPR: 0.6853\n",
      "Epoch: 96/100, Loss: 0.5996354, Train Acc: 0.6696, Test Acc: 0.6481, Train AUC: 0.7351, Train APUR: 0.7334, Test AUC: 0.6994, Test AUPR: 0.6841\n",
      "Epoch: 97/100, Loss: 0.5995703, Train Acc: 0.6699, Test Acc: 0.6440, Train AUC: 0.7339, Train APUR: 0.7323, Test AUC: 0.6929, Test AUPR: 0.6777\n",
      "Epoch: 98/100, Loss: 0.5986539, Train Acc: 0.6712, Test Acc: 0.6471, Train AUC: 0.7365, Train APUR: 0.7349, Test AUC: 0.6971, Test AUPR: 0.6818\n",
      "Epoch: 99/100, Loss: 0.5978724, Train Acc: 0.6708, Test Acc: 0.6438, Train AUC: 0.7365, Train APUR: 0.7343, Test AUC: 0.6926, Test AUPR: 0.6782\n",
      "Epoch: 100/100, Loss: 0.5963926, Train Acc: 0.6719, Test Acc: 0.6446, Train AUC: 0.7383, Train APUR: 0.7375, Test AUC: 0.6936, Test AUPR: 0.6792\n",
      "/home/ubuntu/PA-Cancer-Immunotherapy/GNN/train_pa_all_tvt.py:202: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(configs['save_model']))\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.389 MB of 1.389 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.389 MB of 1.389 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.389 MB of 1.389 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.389 MB of 1.389 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.389 MB of 1.389 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▁▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▅▅▅▅▅▅▅▅▅▆▆▆▆▆▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      test_aupr ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   test_roc_auc ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▁▄▄▄▅▅▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇██████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_aupr ▁▄▄▄▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇█▇█████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss ██▇▇▇▆▆▆▆▆▆▆▆▅▅▅▅▅▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_roc_auc ▁▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: valid_accuracy ▁▃▃▅▅▅▅▆▅▅▅▅▆▇▇▇▇▇▇▇▇▆▇▆▆▇▇▇▇▇████▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     valid_aupr ▁▂▂▂▃▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▇▆▆▆▇▆▇▇▇▇▇▇▇█▇█████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  valid_roc_auc ▁▂▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▇▇▆▇▇▇▇▇██▇█▇▇███████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy 0.65081\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      test_aupr 0.69104\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   test_roc_auc 0.70529\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.67188\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_aupr 0.73753\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.59639\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_roc_auc 0.73835\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: valid_accuracy 0.64463\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     valid_aupr 0.67924\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  valid_roc_auc 0.69358\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mdry-sponge-6\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-gene_GNN/runs/sq6ngple\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-gene_GNN\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 8 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241206_231404-sq6ngple/logs\u001b[0m\n",
      "Test Acc: 0.6508, Test AUC: 0.7053, Test AUPR: 0.6910\n"
     ]
    }
   ],
   "source": [
    "# for gene. Mit confusion Matrix \n",
    "\n",
    "! python train_pa_all_tvt.py --gpu 0 --configs_path configs/PA_all_tvt_gene.yml --droup_out 0.1 --split StrictTCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ac20e5-e6f7-436c-b6cd-f4530d2fc958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcc24bec-9684-4e97-9333-4391be1cac4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(gpu=0, lr=0.01, epochs=100, w_celoss=1, w_aucloss=0, add_same_type_edges=False, dynamic_graph=False, dynamic_ratio=0.05, droup_out=0.1, positive_weights=1, dynamic_epochs=30, distance_threshold=10, configs_path='configs/PA_all_tvt_allele.yml', split='StrictTCR', dataset='pMTnet')\n",
      "PROJECT_NAME: dataset-all-tvt-allele_GNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfrohoari\u001b[0m (\u001b[33mpa_cancerimmunotherapy\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/ubuntu/PA-Cancer-Immunotherapy/GNN/wandb/run-20241209_120454-k8vnt1db\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mblooming-glitter-9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-allele_GNN\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-allele_GNN/runs/k8vnt1db\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   6 of 6 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   6 of 6 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   6 of 6 files downloaded.  \n",
      "embeddings_path:   models/PA_all/gene_and_allele_embeddings.pkl\n",
      "train_file_list:   ['allele_train.csv']\n",
      "validation_file_list:   ['allele_validation.csv']\n",
      "test_file_list:   ['allele_test.csv']\n",
      "wandb logger initialisiert\n",
      "Epoch: 1/100, Loss: 0.6935461, Train Acc: 0.4871, Test Acc: 0.4982, Train AUC: 0.4853, Train AP: 0.4985, Valid. AUC: 0.5240, Valid AP: 0.5156\n",
      "Epoch: 2/100, Loss: 0.9900393, Train Acc: 0.4978, Test Acc: 0.5018, Train AUC: 0.5542, Train AP: 0.5360, Valid. AUC: 0.4832, Valid AP: 0.4756\n",
      "Epoch: 3/100, Loss: 3.9024136, Train Acc: 0.5022, Test Acc: 0.5018, Train AUC: 0.4800, Train AP: 0.4786, Valid. AUC: 0.4867, Valid AP: 0.4810\n",
      "Epoch: 4/100, Loss: 0.7926100, Train Acc: 0.5022, Test Acc: 0.4982, Train AUC: 0.4898, Train AP: 0.4800, Valid. AUC: 0.5121, Valid AP: 0.5063\n",
      "Epoch: 5/100, Loss: 0.6942956, Train Acc: 0.4979, Test Acc: 0.4982, Train AUC: 0.5202, Train AP: 0.5167, Valid. AUC: 0.5138, Valid AP: 0.5067\n",
      "Epoch: 6/100, Loss: 0.6955533, Train Acc: 0.4978, Test Acc: 0.4982, Train AUC: 0.5100, Train AP: 0.5092, Valid. AUC: 0.5071, Valid AP: 0.5001\n",
      "Epoch: 7/100, Loss: 0.6935793, Train Acc: 0.4983, Test Acc: 0.5018, Train AUC: 0.5097, Train AP: 0.5094, Valid. AUC: 0.5033, Valid AP: 0.5059\n",
      "Epoch: 8/100, Loss: 0.6949272, Train Acc: 0.5023, Test Acc: 0.5064, Train AUC: 0.5099, Train AP: 0.5105, Valid. AUC: 0.5085, Valid AP: 0.5061\n",
      "Epoch: 9/100, Loss: 0.6926823, Train Acc: 0.5155, Test Acc: 0.4982, Train AUC: 0.5235, Train AP: 0.5210, Valid. AUC: 0.5212, Valid AP: 0.5041\n",
      "Epoch: 10/100, Loss: 0.6933517, Train Acc: 0.4978, Test Acc: 0.5149, Train AUC: 0.5473, Train AP: 0.5315, Valid. AUC: 0.5166, Valid AP: 0.5061\n",
      "Epoch: 11/100, Loss: 0.6920531, Train Acc: 0.5232, Test Acc: 0.5025, Train AUC: 0.5336, Train AP: 0.5267, Valid. AUC: 0.5283, Valid AP: 0.5139\n",
      "Epoch: 12/100, Loss: 0.6922868, Train Acc: 0.5136, Test Acc: 0.4947, Train AUC: 0.5381, Train AP: 0.5334, Valid. AUC: 0.5323, Valid AP: 0.5152\n",
      "Epoch: 13/100, Loss: 0.6903465, Train Acc: 0.5103, Test Acc: 0.5149, Train AUC: 0.5732, Train AP: 0.5489, Valid. AUC: 0.5389, Valid AP: 0.5360\n",
      "Epoch: 14/100, Loss: 0.6907003, Train Acc: 0.5243, Test Acc: 0.5230, Train AUC: 0.5450, Train AP: 0.5313, Valid. AUC: 0.5415, Valid AP: 0.5404\n",
      "Epoch: 15/100, Loss: 0.6827533, Train Acc: 0.5617, Test Acc: 0.5187, Train AUC: 0.5843, Train AP: 0.5672, Valid. AUC: 0.5453, Valid AP: 0.5433\n",
      "Epoch: 16/100, Loss: 0.6824953, Train Acc: 0.5603, Test Acc: 0.5279, Train AUC: 0.5849, Train AP: 0.5710, Valid. AUC: 0.5521, Valid AP: 0.5505\n",
      "Epoch: 17/100, Loss: 0.6817670, Train Acc: 0.5708, Test Acc: 0.5459, Train AUC: 0.5961, Train AP: 0.5757, Valid. AUC: 0.5630, Valid AP: 0.5560\n",
      "Epoch: 18/100, Loss: 0.6854450, Train Acc: 0.5595, Test Acc: 0.5309, Train AUC: 0.5991, Train AP: 0.5794, Valid. AUC: 0.5654, Valid AP: 0.5607\n",
      "Epoch: 19/100, Loss: 0.6814711, Train Acc: 0.5691, Test Acc: 0.5328, Train AUC: 0.6015, Train AP: 0.5851, Valid. AUC: 0.5721, Valid AP: 0.5650\n",
      "Epoch: 20/100, Loss: 0.6813555, Train Acc: 0.5706, Test Acc: 0.5390, Train AUC: 0.5986, Train AP: 0.5819, Valid. AUC: 0.5769, Valid AP: 0.5668\n",
      "Epoch: 21/100, Loss: 0.6766532, Train Acc: 0.5870, Test Acc: 0.5606, Train AUC: 0.6105, Train AP: 0.5921, Valid. AUC: 0.5818, Valid AP: 0.5690\n",
      "Epoch: 22/100, Loss: 0.6829472, Train Acc: 0.5553, Test Acc: 0.5548, Train AUC: 0.6049, Train AP: 0.5885, Valid. AUC: 0.5841, Valid AP: 0.5707\n",
      "Epoch: 23/100, Loss: 0.6765811, Train Acc: 0.5838, Test Acc: 0.5506, Train AUC: 0.6125, Train AP: 0.5949, Valid. AUC: 0.5862, Valid AP: 0.5734\n",
      "Epoch: 24/100, Loss: 0.6755915, Train Acc: 0.5893, Test Acc: 0.5521, Train AUC: 0.6123, Train AP: 0.5924, Valid. AUC: 0.5897, Valid AP: 0.5767\n",
      "Epoch: 25/100, Loss: 0.6747202, Train Acc: 0.5880, Test Acc: 0.5588, Train AUC: 0.6152, Train AP: 0.5966, Valid. AUC: 0.5957, Valid AP: 0.5811\n",
      "Epoch: 26/100, Loss: 0.6725973, Train Acc: 0.5912, Test Acc: 0.5823, Train AUC: 0.6160, Train AP: 0.6001, Valid. AUC: 0.6075, Valid AP: 0.5904\n",
      "Epoch: 27/100, Loss: 0.6758631, Train Acc: 0.5883, Test Acc: 0.5918, Train AUC: 0.6159, Train AP: 0.5970, Valid. AUC: 0.6141, Valid AP: 0.5960\n",
      "Epoch: 28/100, Loss: 0.6712291, Train Acc: 0.5918, Test Acc: 0.5932, Train AUC: 0.6209, Train AP: 0.6013, Valid. AUC: 0.6206, Valid AP: 0.6036\n",
      "Epoch: 29/100, Loss: 0.6706064, Train Acc: 0.5933, Test Acc: 0.5903, Train AUC: 0.6239, Train AP: 0.6034, Valid. AUC: 0.6267, Valid AP: 0.6096\n",
      "Epoch: 30/100, Loss: 0.6710538, Train Acc: 0.5964, Test Acc: 0.5914, Train AUC: 0.6261, Train AP: 0.6053, Valid. AUC: 0.6285, Valid AP: 0.6117\n",
      "Epoch: 31/100, Loss: 0.6711749, Train Acc: 0.5929, Test Acc: 0.5908, Train AUC: 0.6232, Train AP: 0.6035, Valid. AUC: 0.6281, Valid AP: 0.6129\n",
      "Epoch: 32/100, Loss: 0.6699716, Train Acc: 0.5938, Test Acc: 0.5882, Train AUC: 0.6263, Train AP: 0.6093, Valid. AUC: 0.6285, Valid AP: 0.6120\n",
      "Epoch: 33/100, Loss: 0.6688671, Train Acc: 0.5977, Test Acc: 0.5909, Train AUC: 0.6284, Train AP: 0.6055, Valid. AUC: 0.6279, Valid AP: 0.6123\n",
      "Epoch: 34/100, Loss: 0.6736303, Train Acc: 0.5800, Test Acc: 0.5815, Train AUC: 0.6141, Train AP: 0.5987, Valid. AUC: 0.6242, Valid AP: 0.6104\n",
      "Epoch: 35/100, Loss: 0.6695583, Train Acc: 0.5969, Test Acc: 0.5872, Train AUC: 0.6306, Train AP: 0.6125, Valid. AUC: 0.6328, Valid AP: 0.6150\n",
      "Epoch: 36/100, Loss: 0.6715999, Train Acc: 0.5956, Test Acc: 0.5979, Train AUC: 0.6336, Train AP: 0.6118, Valid. AUC: 0.6280, Valid AP: 0.6131\n",
      "Epoch: 37/100, Loss: 0.6673842, Train Acc: 0.5993, Test Acc: 0.5772, Train AUC: 0.6351, Train AP: 0.6151, Valid. AUC: 0.6211, Valid AP: 0.6075\n",
      "Epoch: 38/100, Loss: 0.6687915, Train Acc: 0.5950, Test Acc: 0.5889, Train AUC: 0.6314, Train AP: 0.6134, Valid. AUC: 0.6225, Valid AP: 0.6087\n",
      "Epoch: 39/100, Loss: 0.6656494, Train Acc: 0.5987, Test Acc: 0.5896, Train AUC: 0.6350, Train AP: 0.6172, Valid. AUC: 0.6268, Valid AP: 0.6117\n",
      "Epoch: 40/100, Loss: 0.6662689, Train Acc: 0.6009, Test Acc: 0.6037, Train AUC: 0.6358, Train AP: 0.6132, Valid. AUC: 0.6315, Valid AP: 0.6142\n",
      "Epoch: 41/100, Loss: 0.6640370, Train Acc: 0.6019, Test Acc: 0.6035, Train AUC: 0.6371, Train AP: 0.6186, Valid. AUC: 0.6352, Valid AP: 0.6163\n",
      "Epoch: 42/100, Loss: 0.6648679, Train Acc: 0.6008, Test Acc: 0.6034, Train AUC: 0.6369, Train AP: 0.6179, Valid. AUC: 0.6387, Valid AP: 0.6182\n",
      "Epoch: 43/100, Loss: 0.6624767, Train Acc: 0.6027, Test Acc: 0.5950, Train AUC: 0.6414, Train AP: 0.6202, Valid. AUC: 0.6414, Valid AP: 0.6199\n",
      "Epoch: 44/100, Loss: 0.6639994, Train Acc: 0.6035, Test Acc: 0.6028, Train AUC: 0.6414, Train AP: 0.6180, Valid. AUC: 0.6389, Valid AP: 0.6190\n",
      "Epoch: 45/100, Loss: 0.6677886, Train Acc: 0.6059, Test Acc: 0.5796, Train AUC: 0.6388, Train AP: 0.6183, Valid. AUC: 0.6408, Valid AP: 0.6207\n",
      "Epoch: 46/100, Loss: 0.6703833, Train Acc: 0.5837, Test Acc: 0.5936, Train AUC: 0.6333, Train AP: 0.6143, Valid. AUC: 0.6385, Valid AP: 0.6201\n",
      "Epoch: 47/100, Loss: 0.6628010, Train Acc: 0.6052, Test Acc: 0.5841, Train AUC: 0.6443, Train AP: 0.6222, Valid. AUC: 0.6285, Valid AP: 0.6127\n",
      "Epoch: 48/100, Loss: 0.6642909, Train Acc: 0.6042, Test Acc: 0.5954, Train AUC: 0.6433, Train AP: 0.6213, Valid. AUC: 0.6288, Valid AP: 0.6138\n",
      "Epoch: 49/100, Loss: 0.6616923, Train Acc: 0.6028, Test Acc: 0.5919, Train AUC: 0.6423, Train AP: 0.6195, Valid. AUC: 0.6296, Valid AP: 0.6149\n",
      "Epoch: 50/100, Loss: 0.6617141, Train Acc: 0.6027, Test Acc: 0.5942, Train AUC: 0.6445, Train AP: 0.6230, Valid. AUC: 0.6319, Valid AP: 0.6172\n",
      "Epoch: 51/100, Loss: 0.6610852, Train Acc: 0.6044, Test Acc: 0.5890, Train AUC: 0.6476, Train AP: 0.6265, Valid. AUC: 0.6332, Valid AP: 0.6186\n",
      "Epoch: 52/100, Loss: 0.6591328, Train Acc: 0.6058, Test Acc: 0.5873, Train AUC: 0.6485, Train AP: 0.6275, Valid. AUC: 0.6338, Valid AP: 0.6180\n",
      "Epoch: 53/100, Loss: 0.6608775, Train Acc: 0.6039, Test Acc: 0.5971, Train AUC: 0.6463, Train AP: 0.6263, Valid. AUC: 0.6367, Valid AP: 0.6203\n",
      "Epoch: 54/100, Loss: 0.6581886, Train Acc: 0.6070, Test Acc: 0.5970, Train AUC: 0.6486, Train AP: 0.6267, Valid. AUC: 0.6387, Valid AP: 0.6220\n",
      "Epoch: 55/100, Loss: 0.6588522, Train Acc: 0.6067, Test Acc: 0.5850, Train AUC: 0.6491, Train AP: 0.6277, Valid. AUC: 0.6385, Valid AP: 0.6225\n",
      "Epoch: 56/100, Loss: 0.6580130, Train Acc: 0.6030, Test Acc: 0.5953, Train AUC: 0.6487, Train AP: 0.6279, Valid. AUC: 0.6404, Valid AP: 0.6235\n",
      "Epoch: 57/100, Loss: 0.6578650, Train Acc: 0.6102, Test Acc: 0.6090, Train AUC: 0.6486, Train AP: 0.6282, Valid. AUC: 0.6426, Valid AP: 0.6243\n",
      "Epoch: 58/100, Loss: 0.6571005, Train Acc: 0.6087, Test Acc: 0.6066, Train AUC: 0.6512, Train AP: 0.6302, Valid. AUC: 0.6440, Valid AP: 0.6264\n",
      "Epoch: 59/100, Loss: 0.6563013, Train Acc: 0.6078, Test Acc: 0.6048, Train AUC: 0.6519, Train AP: 0.6308, Valid. AUC: 0.6434, Valid AP: 0.6271\n",
      "Epoch: 60/100, Loss: 0.6556269, Train Acc: 0.6078, Test Acc: 0.6045, Train AUC: 0.6525, Train AP: 0.6317, Valid. AUC: 0.6416, Valid AP: 0.6275\n",
      "Epoch: 61/100, Loss: 0.6564780, Train Acc: 0.6092, Test Acc: 0.5910, Train AUC: 0.6520, Train AP: 0.6339, Valid. AUC: 0.6462, Valid AP: 0.6304\n",
      "Epoch: 62/100, Loss: 0.6559458, Train Acc: 0.6068, Test Acc: 0.6092, Train AUC: 0.6528, Train AP: 0.6324, Valid. AUC: 0.6516, Valid AP: 0.6329\n",
      "Epoch: 63/100, Loss: 0.6536301, Train Acc: 0.6094, Test Acc: 0.6304, Train AUC: 0.6559, Train AP: 0.6347, Valid. AUC: 0.6515, Valid AP: 0.6323\n",
      "Epoch: 64/100, Loss: 0.6532388, Train Acc: 0.6114, Test Acc: 0.6192, Train AUC: 0.6577, Train AP: 0.6385, Valid. AUC: 0.6490, Valid AP: 0.6323\n",
      "Epoch: 65/100, Loss: 0.6584769, Train Acc: 0.6099, Test Acc: 0.5973, Train AUC: 0.6534, Train AP: 0.6325, Valid. AUC: 0.6372, Valid AP: 0.6201\n",
      "Epoch: 66/100, Loss: 0.6610179, Train Acc: 0.6069, Test Acc: 0.5970, Train AUC: 0.6498, Train AP: 0.6321, Valid. AUC: 0.6368, Valid AP: 0.6234\n",
      "Epoch: 67/100, Loss: 0.6537753, Train Acc: 0.6103, Test Acc: 0.6022, Train AUC: 0.6562, Train AP: 0.6380, Valid. AUC: 0.6364, Valid AP: 0.6253\n",
      "Epoch: 68/100, Loss: 0.6557568, Train Acc: 0.6071, Test Acc: 0.6055, Train AUC: 0.6546, Train AP: 0.6370, Valid. AUC: 0.6361, Valid AP: 0.6265\n",
      "Epoch: 69/100, Loss: 0.6515687, Train Acc: 0.6106, Test Acc: 0.5951, Train AUC: 0.6605, Train AP: 0.6432, Valid. AUC: 0.6383, Valid AP: 0.6275\n",
      "Epoch: 70/100, Loss: 0.6530891, Train Acc: 0.6052, Test Acc: 0.6011, Train AUC: 0.6602, Train AP: 0.6447, Valid. AUC: 0.6486, Valid AP: 0.6325\n",
      "Epoch: 71/100, Loss: 0.6521066, Train Acc: 0.6101, Test Acc: 0.5974, Train AUC: 0.6590, Train AP: 0.6385, Valid. AUC: 0.6411, Valid AP: 0.6246\n",
      "Epoch: 72/100, Loss: 0.6531290, Train Acc: 0.6126, Test Acc: 0.6108, Train AUC: 0.6596, Train AP: 0.6397, Valid. AUC: 0.6457, Valid AP: 0.6310\n",
      "Epoch: 73/100, Loss: 0.6492314, Train Acc: 0.6158, Test Acc: 0.6105, Train AUC: 0.6625, Train AP: 0.6425, Valid. AUC: 0.6453, Valid AP: 0.6315\n",
      "Epoch: 74/100, Loss: 0.6495450, Train Acc: 0.6135, Test Acc: 0.6224, Train AUC: 0.6632, Train AP: 0.6436, Valid. AUC: 0.6516, Valid AP: 0.6343\n",
      "Epoch: 75/100, Loss: 0.6488867, Train Acc: 0.6150, Test Acc: 0.6147, Train AUC: 0.6627, Train AP: 0.6421, Valid. AUC: 0.6525, Valid AP: 0.6334\n",
      "Epoch: 76/100, Loss: 0.6525996, Train Acc: 0.6150, Test Acc: 0.6286, Train AUC: 0.6651, Train AP: 0.6470, Valid. AUC: 0.6502, Valid AP: 0.6337\n",
      "Epoch: 77/100, Loss: 0.6556300, Train Acc: 0.6145, Test Acc: 0.6108, Train AUC: 0.6597, Train AP: 0.6413, Valid. AUC: 0.6600, Valid AP: 0.6417\n",
      "Epoch: 78/100, Loss: 0.6470228, Train Acc: 0.6178, Test Acc: 0.5770, Train AUC: 0.6686, Train AP: 0.6501, Valid. AUC: 0.6267, Valid AP: 0.6179\n",
      "Epoch: 79/100, Loss: 0.6601079, Train Acc: 0.5879, Test Acc: 0.6362, Train AUC: 0.6368, Train AP: 0.6269, Valid. AUC: 0.6652, Valid AP: 0.6409\n",
      "Epoch: 80/100, Loss: 0.6470633, Train Acc: 0.6248, Test Acc: 0.6120, Train AUC: 0.6733, Train AP: 0.6554, Valid. AUC: 0.6454, Valid AP: 0.6277\n",
      "Epoch: 81/100, Loss: 0.6688693, Train Acc: 0.6119, Test Acc: 0.6209, Train AUC: 0.6541, Train AP: 0.6351, Valid. AUC: 0.6541, Valid AP: 0.6310\n",
      "Epoch: 82/100, Loss: 0.6513773, Train Acc: 0.6134, Test Acc: 0.6345, Train AUC: 0.6582, Train AP: 0.6366, Valid. AUC: 0.6672, Valid AP: 0.6436\n",
      "Epoch: 83/100, Loss: 0.6531208, Train Acc: 0.6201, Test Acc: 0.6322, Train AUC: 0.6722, Train AP: 0.6537, Valid. AUC: 0.6638, Valid AP: 0.6425\n",
      "Epoch: 84/100, Loss: 0.6549298, Train Acc: 0.6250, Test Acc: 0.6069, Train AUC: 0.6751, Train AP: 0.6573, Valid. AUC: 0.6565, Valid AP: 0.6363\n",
      "Epoch: 85/100, Loss: 0.6466501, Train Acc: 0.6208, Test Acc: 0.6058, Train AUC: 0.6729, Train AP: 0.6527, Valid. AUC: 0.6463, Valid AP: 0.6299\n",
      "Epoch: 86/100, Loss: 0.6494601, Train Acc: 0.6166, Test Acc: 0.6047, Train AUC: 0.6647, Train AP: 0.6454, Valid. AUC: 0.6483, Valid AP: 0.6319\n",
      "Epoch: 87/100, Loss: 0.6480441, Train Acc: 0.6226, Test Acc: 0.6153, Train AUC: 0.6682, Train AP: 0.6484, Valid. AUC: 0.6571, Valid AP: 0.6396\n",
      "Epoch: 88/100, Loss: 0.6438577, Train Acc: 0.6275, Test Acc: 0.6182, Train AUC: 0.6758, Train AP: 0.6538, Valid. AUC: 0.6562, Valid AP: 0.6427\n",
      "Epoch: 89/100, Loss: 0.6423052, Train Acc: 0.6268, Test Acc: 0.6016, Train AUC: 0.6762, Train AP: 0.6599, Valid. AUC: 0.6473, Valid AP: 0.6380\n",
      "Epoch: 90/100, Loss: 0.6402583, Train Acc: 0.6291, Test Acc: 0.5916, Train AUC: 0.6809, Train AP: 0.6646, Valid. AUC: 0.6484, Valid AP: 0.6401\n",
      "Epoch: 91/100, Loss: 0.6378745, Train Acc: 0.6286, Test Acc: 0.6007, Train AUC: 0.6816, Train AP: 0.6639, Valid. AUC: 0.6503, Valid AP: 0.6408\n",
      "Epoch: 92/100, Loss: 0.6394879, Train Acc: 0.6275, Test Acc: 0.6010, Train AUC: 0.6806, Train AP: 0.6627, Valid. AUC: 0.6522, Valid AP: 0.6404\n",
      "Epoch: 93/100, Loss: 0.6407825, Train Acc: 0.6258, Test Acc: 0.6251, Train AUC: 0.6794, Train AP: 0.6648, Valid. AUC: 0.6623, Valid AP: 0.6501\n",
      "Epoch: 94/100, Loss: 0.6361960, Train Acc: 0.6307, Test Acc: 0.6066, Train AUC: 0.6860, Train AP: 0.6703, Valid. AUC: 0.6569, Valid AP: 0.6465\n",
      "Epoch: 95/100, Loss: 0.6423289, Train Acc: 0.6253, Test Acc: 0.6107, Train AUC: 0.6815, Train AP: 0.6639, Valid. AUC: 0.6533, Valid AP: 0.6342\n",
      "Epoch: 96/100, Loss: 0.6555470, Train Acc: 0.6215, Test Acc: 0.6311, Train AUC: 0.6682, Train AP: 0.6495, Valid. AUC: 0.6658, Valid AP: 0.6524\n",
      "Epoch: 97/100, Loss: 0.6379356, Train Acc: 0.6302, Test Acc: 0.6300, Train AUC: 0.6876, Train AP: 0.6751, Valid. AUC: 0.6640, Valid AP: 0.6505\n",
      "Epoch: 98/100, Loss: 0.6416616, Train Acc: 0.6235, Test Acc: 0.6349, Train AUC: 0.6796, Train AP: 0.6669, Valid. AUC: 0.6619, Valid AP: 0.6445\n",
      "Epoch: 99/100, Loss: 0.6412628, Train Acc: 0.6263, Test Acc: 0.6318, Train AUC: 0.6795, Train AP: 0.6604, Valid. AUC: 0.6598, Valid AP: 0.6424\n",
      "Epoch: 100/100, Loss: 0.6406850, Train Acc: 0.6306, Test Acc: 0.6009, Train AUC: 0.6801, Train AP: 0.6584, Valid. AUC: 0.6630, Valid AP: 0.6498\n",
      "/home/ubuntu/PA-Cancer-Immunotherapy/GNN/train_pa_all_tvt.py:212: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(configs['save_model']))\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.410 MB of 1.410 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.410 MB of 1.410 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.410 MB of 1.410 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▁▁▁▂▂▂▂▂▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        test_ap ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   test_roc_auc ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▁▁▂▁▂▄▄▅▆▆▆▆▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train_ap ▃▁▂▃▃▄▅▅▅▅▅▆▆▆▆▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇██████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_roc_auc ▁▁▂▂▂▄▅▅▅▅▆▆▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇███████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: valid_accuracy ▁▁▁▁▂▂▃▄▃▃▄▄▆▆▅▆▅▆▆▆▆▆▆▆▇▇▆▇▇██▅▇▇▇▆▇██▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       valid_ap ▂▁▁▁▁▃▃▃▄▄▅▅▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  valid_roc_auc ▃▁▂▂▂▃▃▄▅▅▆▆▇▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy 0.63579\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        test_ap 0.64553\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   test_roc_auc 0.66933\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.63061\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train_ap 0.65841\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.64068\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_roc_auc 0.68012\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: valid_accuracy 0.60087\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       valid_ap 0.64975\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  valid_roc_auc 0.663\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mblooming-glitter-9\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-allele_GNN/runs/k8vnt1db\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-allele_GNN\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 6 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241209_120454-k8vnt1db/logs\u001b[0m\n",
      "Test Acc: 0.6358, Test AUC: 0.6693, Test AUPR: 0.6455\n"
     ]
    }
   ],
   "source": [
    "# allele. mit lr = 0.01\n",
    "\n",
    "! python train_pa_all_tvt.py --gpu 0 --configs_path configs/PA_all_tvt_allele.yml --droup_out 0.1 --lr 0.01 --split StrictTCR\n",
    "# Rasults: bad. lr=0.01 does not help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f95b1d6a-ac1c-4478-a96e-48335cf31abe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(gpu=0, lr=0.0005, epochs=100, w_celoss=1, w_aucloss=0, add_same_type_edges=False, dynamic_graph=False, dynamic_ratio=0.05, droup_out=0.1, positive_weights=1, dynamic_epochs=30, distance_threshold=10, configs_path='configs/PA_all_tvt_gene.yml', split='StrictTCR', dataset='pMTnet')\n",
      "PROJECT_NAME: dataset-all-tvt-gene_GNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfrohoari\u001b[0m (\u001b[33mpa_cancerimmunotherapy\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/ubuntu/PA-Cancer-Immunotherapy/GNN/wandb/run-20241209_121629-1tr6uyot\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33miconic-paper-8\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-gene_GNN\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-gene_GNN/runs/1tr6uyot\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   6 of 6 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   6 of 6 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   6 of 6 files downloaded.  \n",
      "embeddings_path:   models/PA_all/gene_and_allele_embeddings.pkl\n",
      "train_file_list:   ['gene_train.csv']\n",
      "validation_file_list:   ['gene_validation.csv']\n",
      "test_file_list:   ['gene_test.csv']\n",
      "wandb logger initialisiert\n",
      "Epoch: 1/100, Loss: 0.6933187, Train Acc: 0.5015, Test Acc: 0.5050, Train AUC: 0.4987, Train AP: 0.4993, Valid. AUC: 0.5419, Valid AP: 0.5311\n",
      "Epoch: 2/100, Loss: 0.6911375, Train Acc: 0.5247, Test Acc: 0.5360, Train AUC: 0.5625, Train AP: 0.5490, Valid. AUC: 0.5490, Valid AP: 0.5397\n",
      "Epoch: 3/100, Loss: 0.6882558, Train Acc: 0.5586, Test Acc: 0.5495, Train AUC: 0.5829, Train AP: 0.5743, Valid. AUC: 0.5535, Valid AP: 0.5452\n",
      "Epoch: 4/100, Loss: 0.6873775, Train Acc: 0.5587, Test Acc: 0.5552, Train AUC: 0.5910, Train AP: 0.5804, Valid. AUC: 0.5534, Valid AP: 0.5461\n",
      "Epoch: 5/100, Loss: 0.6841842, Train Acc: 0.5678, Test Acc: 0.5524, Train AUC: 0.5947, Train AP: 0.5834, Valid. AUC: 0.5545, Valid AP: 0.5472\n",
      "Epoch: 6/100, Loss: 0.6816188, Train Acc: 0.5735, Test Acc: 0.5570, Train AUC: 0.5971, Train AP: 0.5857, Valid. AUC: 0.5581, Valid AP: 0.5507\n",
      "Epoch: 7/100, Loss: 0.6795266, Train Acc: 0.5785, Test Acc: 0.5573, Train AUC: 0.6037, Train AP: 0.5885, Valid. AUC: 0.5621, Valid AP: 0.5543\n",
      "Epoch: 8/100, Loss: 0.6786149, Train Acc: 0.5751, Test Acc: 0.5586, Train AUC: 0.6040, Train AP: 0.5922, Valid. AUC: 0.5658, Valid AP: 0.5565\n",
      "Epoch: 9/100, Loss: 0.6773833, Train Acc: 0.5726, Test Acc: 0.5554, Train AUC: 0.6071, Train AP: 0.5961, Valid. AUC: 0.5693, Valid AP: 0.5582\n",
      "Epoch: 10/100, Loss: 0.6764493, Train Acc: 0.5847, Test Acc: 0.5608, Train AUC: 0.6104, Train AP: 0.5963, Valid. AUC: 0.5783, Valid AP: 0.5659\n",
      "Epoch: 11/100, Loss: 0.6733829, Train Acc: 0.5885, Test Acc: 0.5651, Train AUC: 0.6160, Train AP: 0.6009, Valid. AUC: 0.5841, Valid AP: 0.5701\n",
      "Epoch: 12/100, Loss: 0.6714832, Train Acc: 0.5891, Test Acc: 0.5437, Train AUC: 0.6209, Train AP: 0.6072, Valid. AUC: 0.5897, Valid AP: 0.5735\n",
      "Epoch: 13/100, Loss: 0.6704032, Train Acc: 0.5931, Test Acc: 0.5574, Train AUC: 0.6242, Train AP: 0.6093, Valid. AUC: 0.5948, Valid AP: 0.5763\n",
      "Epoch: 14/100, Loss: 0.6707376, Train Acc: 0.5920, Test Acc: 0.5734, Train AUC: 0.6248, Train AP: 0.6071, Valid. AUC: 0.6003, Valid AP: 0.5801\n",
      "Epoch: 15/100, Loss: 0.6688185, Train Acc: 0.5962, Test Acc: 0.5747, Train AUC: 0.6275, Train AP: 0.6105, Valid. AUC: 0.6052, Valid AP: 0.5841\n",
      "Epoch: 16/100, Loss: 0.6686082, Train Acc: 0.5956, Test Acc: 0.5843, Train AUC: 0.6295, Train AP: 0.6125, Valid. AUC: 0.6092, Valid AP: 0.5875\n",
      "Epoch: 17/100, Loss: 0.6674489, Train Acc: 0.5990, Test Acc: 0.5726, Train AUC: 0.6305, Train AP: 0.6143, Valid. AUC: 0.6132, Valid AP: 0.5901\n",
      "Epoch: 18/100, Loss: 0.6675665, Train Acc: 0.5943, Test Acc: 0.5873, Train AUC: 0.6327, Train AP: 0.6175, Valid. AUC: 0.6156, Valid AP: 0.5923\n",
      "Epoch: 19/100, Loss: 0.6659961, Train Acc: 0.6004, Test Acc: 0.5768, Train AUC: 0.6341, Train AP: 0.6181, Valid. AUC: 0.6167, Valid AP: 0.5936\n",
      "Epoch: 20/100, Loss: 0.6669059, Train Acc: 0.6008, Test Acc: 0.5780, Train AUC: 0.6350, Train AP: 0.6183, Valid. AUC: 0.6170, Valid AP: 0.5941\n",
      "Epoch: 21/100, Loss: 0.6655059, Train Acc: 0.6015, Test Acc: 0.5860, Train AUC: 0.6345, Train AP: 0.6193, Valid. AUC: 0.6182, Valid AP: 0.5951\n",
      "Epoch: 22/100, Loss: 0.6647172, Train Acc: 0.6014, Test Acc: 0.5872, Train AUC: 0.6367, Train AP: 0.6214, Valid. AUC: 0.6189, Valid AP: 0.5959\n",
      "Epoch: 23/100, Loss: 0.6645607, Train Acc: 0.6035, Test Acc: 0.5850, Train AUC: 0.6374, Train AP: 0.6214, Valid. AUC: 0.6199, Valid AP: 0.5969\n",
      "Epoch: 24/100, Loss: 0.6639138, Train Acc: 0.6045, Test Acc: 0.5835, Train AUC: 0.6385, Train AP: 0.6235, Valid. AUC: 0.6212, Valid AP: 0.5982\n",
      "Epoch: 25/100, Loss: 0.6639141, Train Acc: 0.6049, Test Acc: 0.5886, Train AUC: 0.6407, Train AP: 0.6255, Valid. AUC: 0.6221, Valid AP: 0.5991\n",
      "Epoch: 26/100, Loss: 0.6631961, Train Acc: 0.6048, Test Acc: 0.5895, Train AUC: 0.6408, Train AP: 0.6255, Valid. AUC: 0.6224, Valid AP: 0.5998\n",
      "Epoch: 27/100, Loss: 0.6622497, Train Acc: 0.6056, Test Acc: 0.5895, Train AUC: 0.6428, Train AP: 0.6277, Valid. AUC: 0.6221, Valid AP: 0.5999\n",
      "Epoch: 28/100, Loss: 0.6635235, Train Acc: 0.6054, Test Acc: 0.5948, Train AUC: 0.6401, Train AP: 0.6254, Valid. AUC: 0.6223, Valid AP: 0.6001\n",
      "Epoch: 29/100, Loss: 0.6615096, Train Acc: 0.6077, Test Acc: 0.5917, Train AUC: 0.6446, Train AP: 0.6285, Valid. AUC: 0.6221, Valid AP: 0.6000\n",
      "Epoch: 30/100, Loss: 0.6616031, Train Acc: 0.6059, Test Acc: 0.5907, Train AUC: 0.6440, Train AP: 0.6282, Valid. AUC: 0.6206, Valid AP: 0.5990\n",
      "Epoch: 31/100, Loss: 0.6610394, Train Acc: 0.6062, Test Acc: 0.5874, Train AUC: 0.6447, Train AP: 0.6290, Valid. AUC: 0.6206, Valid AP: 0.5987\n",
      "Epoch: 32/100, Loss: 0.6610181, Train Acc: 0.6076, Test Acc: 0.5937, Train AUC: 0.6453, Train AP: 0.6291, Valid. AUC: 0.6221, Valid AP: 0.5996\n",
      "Epoch: 33/100, Loss: 0.6606530, Train Acc: 0.6069, Test Acc: 0.5915, Train AUC: 0.6457, Train AP: 0.6305, Valid. AUC: 0.6269, Valid AP: 0.6030\n",
      "Epoch: 34/100, Loss: 0.6607492, Train Acc: 0.6083, Test Acc: 0.5971, Train AUC: 0.6465, Train AP: 0.6294, Valid. AUC: 0.6294, Valid AP: 0.6045\n",
      "Epoch: 35/100, Loss: 0.6599447, Train Acc: 0.6087, Test Acc: 0.6141, Train AUC: 0.6477, Train AP: 0.6316, Valid. AUC: 0.6304, Valid AP: 0.6051\n",
      "Epoch: 36/100, Loss: 0.6597825, Train Acc: 0.6098, Test Acc: 0.6019, Train AUC: 0.6480, Train AP: 0.6308, Valid. AUC: 0.6314, Valid AP: 0.6058\n",
      "Epoch: 37/100, Loss: 0.6599070, Train Acc: 0.6106, Test Acc: 0.6188, Train AUC: 0.6487, Train AP: 0.6330, Valid. AUC: 0.6321, Valid AP: 0.6063\n",
      "Epoch: 38/100, Loss: 0.6593586, Train Acc: 0.6104, Test Acc: 0.6042, Train AUC: 0.6491, Train AP: 0.6333, Valid. AUC: 0.6323, Valid AP: 0.6067\n",
      "Epoch: 39/100, Loss: 0.6590864, Train Acc: 0.6086, Test Acc: 0.6201, Train AUC: 0.6499, Train AP: 0.6340, Valid. AUC: 0.6322, Valid AP: 0.6070\n",
      "Epoch: 40/100, Loss: 0.6585814, Train Acc: 0.6108, Test Acc: 0.5973, Train AUC: 0.6502, Train AP: 0.6342, Valid. AUC: 0.6326, Valid AP: 0.6075\n",
      "Epoch: 41/100, Loss: 0.6583459, Train Acc: 0.6117, Test Acc: 0.5940, Train AUC: 0.6502, Train AP: 0.6344, Valid. AUC: 0.6331, Valid AP: 0.6079\n",
      "Epoch: 42/100, Loss: 0.6589482, Train Acc: 0.6096, Test Acc: 0.5985, Train AUC: 0.6496, Train AP: 0.6348, Valid. AUC: 0.6337, Valid AP: 0.6082\n",
      "Epoch: 43/100, Loss: 0.6582534, Train Acc: 0.6117, Test Acc: 0.6120, Train AUC: 0.6514, Train AP: 0.6349, Valid. AUC: 0.6334, Valid AP: 0.6082\n",
      "Epoch: 44/100, Loss: 0.6577147, Train Acc: 0.6116, Test Acc: 0.5937, Train AUC: 0.6520, Train AP: 0.6360, Valid. AUC: 0.6318, Valid AP: 0.6073\n",
      "Epoch: 45/100, Loss: 0.6578712, Train Acc: 0.6115, Test Acc: 0.5909, Train AUC: 0.6527, Train AP: 0.6370, Valid. AUC: 0.6317, Valid AP: 0.6075\n",
      "Epoch: 46/100, Loss: 0.6572833, Train Acc: 0.6121, Test Acc: 0.5962, Train AUC: 0.6527, Train AP: 0.6365, Valid. AUC: 0.6315, Valid AP: 0.6076\n",
      "Epoch: 47/100, Loss: 0.6572717, Train Acc: 0.6135, Test Acc: 0.5958, Train AUC: 0.6544, Train AP: 0.6388, Valid. AUC: 0.6328, Valid AP: 0.6085\n",
      "Epoch: 48/100, Loss: 0.6570072, Train Acc: 0.6125, Test Acc: 0.6143, Train AUC: 0.6545, Train AP: 0.6391, Valid. AUC: 0.6349, Valid AP: 0.6097\n",
      "Epoch: 49/100, Loss: 0.6560035, Train Acc: 0.6127, Test Acc: 0.5790, Train AUC: 0.6548, Train AP: 0.6392, Valid. AUC: 0.6354, Valid AP: 0.6099\n",
      "Epoch: 50/100, Loss: 0.6560284, Train Acc: 0.6120, Test Acc: 0.5668, Train AUC: 0.6551, Train AP: 0.6395, Valid. AUC: 0.6360, Valid AP: 0.6103\n",
      "Epoch: 51/100, Loss: 0.6563962, Train Acc: 0.6115, Test Acc: 0.5845, Train AUC: 0.6549, Train AP: 0.6392, Valid. AUC: 0.6367, Valid AP: 0.6113\n",
      "Epoch: 52/100, Loss: 0.6553879, Train Acc: 0.6136, Test Acc: 0.6185, Train AUC: 0.6560, Train AP: 0.6404, Valid. AUC: 0.6378, Valid AP: 0.6131\n",
      "Epoch: 53/100, Loss: 0.6551742, Train Acc: 0.6130, Test Acc: 0.6196, Train AUC: 0.6562, Train AP: 0.6412, Valid. AUC: 0.6393, Valid AP: 0.6150\n",
      "Epoch: 54/100, Loss: 0.6556240, Train Acc: 0.6149, Test Acc: 0.6186, Train AUC: 0.6572, Train AP: 0.6414, Valid. AUC: 0.6400, Valid AP: 0.6162\n",
      "Epoch: 55/100, Loss: 0.6544499, Train Acc: 0.6154, Test Acc: 0.6148, Train AUC: 0.6590, Train AP: 0.6435, Valid. AUC: 0.6402, Valid AP: 0.6170\n",
      "Epoch: 56/100, Loss: 0.6542538, Train Acc: 0.6145, Test Acc: 0.6160, Train AUC: 0.6585, Train AP: 0.6430, Valid. AUC: 0.6406, Valid AP: 0.6174\n",
      "Epoch: 57/100, Loss: 0.6537505, Train Acc: 0.6149, Test Acc: 0.6240, Train AUC: 0.6595, Train AP: 0.6443, Valid. AUC: 0.6409, Valid AP: 0.6177\n",
      "Epoch: 58/100, Loss: 0.6532956, Train Acc: 0.6158, Test Acc: 0.6244, Train AUC: 0.6602, Train AP: 0.6456, Valid. AUC: 0.6422, Valid AP: 0.6190\n",
      "Epoch: 59/100, Loss: 0.6532400, Train Acc: 0.6163, Test Acc: 0.6250, Train AUC: 0.6601, Train AP: 0.6458, Valid. AUC: 0.6444, Valid AP: 0.6209\n",
      "Epoch: 60/100, Loss: 0.6519111, Train Acc: 0.6169, Test Acc: 0.6235, Train AUC: 0.6628, Train AP: 0.6482, Valid. AUC: 0.6467, Valid AP: 0.6225\n",
      "Epoch: 61/100, Loss: 0.6516058, Train Acc: 0.6174, Test Acc: 0.6153, Train AUC: 0.6642, Train AP: 0.6500, Valid. AUC: 0.6479, Valid AP: 0.6231\n",
      "Epoch: 62/100, Loss: 0.6512430, Train Acc: 0.6178, Test Acc: 0.6111, Train AUC: 0.6652, Train AP: 0.6496, Valid. AUC: 0.6476, Valid AP: 0.6230\n",
      "Epoch: 63/100, Loss: 0.6501690, Train Acc: 0.6205, Test Acc: 0.6091, Train AUC: 0.6667, Train AP: 0.6522, Valid. AUC: 0.6462, Valid AP: 0.6223\n",
      "Epoch: 64/100, Loss: 0.6497990, Train Acc: 0.6198, Test Acc: 0.6083, Train AUC: 0.6666, Train AP: 0.6524, Valid. AUC: 0.6463, Valid AP: 0.6229\n",
      "Epoch: 65/100, Loss: 0.6487582, Train Acc: 0.6205, Test Acc: 0.6127, Train AUC: 0.6677, Train AP: 0.6541, Valid. AUC: 0.6501, Valid AP: 0.6265\n",
      "Epoch: 66/100, Loss: 0.6479048, Train Acc: 0.6200, Test Acc: 0.6203, Train AUC: 0.6702, Train AP: 0.6546, Valid. AUC: 0.6549, Valid AP: 0.6310\n",
      "Epoch: 67/100, Loss: 0.6472265, Train Acc: 0.6260, Test Acc: 0.6136, Train AUC: 0.6743, Train AP: 0.6586, Valid. AUC: 0.6542, Valid AP: 0.6308\n",
      "Epoch: 68/100, Loss: 0.6452238, Train Acc: 0.6266, Test Acc: 0.6120, Train AUC: 0.6750, Train AP: 0.6601, Valid. AUC: 0.6541, Valid AP: 0.6313\n",
      "Epoch: 69/100, Loss: 0.6452494, Train Acc: 0.6268, Test Acc: 0.6166, Train AUC: 0.6750, Train AP: 0.6597, Valid. AUC: 0.6559, Valid AP: 0.6336\n",
      "Epoch: 70/100, Loss: 0.6437542, Train Acc: 0.6308, Test Acc: 0.6242, Train AUC: 0.6773, Train AP: 0.6629, Valid. AUC: 0.6613, Valid AP: 0.6391\n",
      "Epoch: 71/100, Loss: 0.6416643, Train Acc: 0.6369, Test Acc: 0.6261, Train AUC: 0.6834, Train AP: 0.6680, Valid. AUC: 0.6638, Valid AP: 0.6422\n",
      "Epoch: 72/100, Loss: 0.6416095, Train Acc: 0.6411, Test Acc: 0.6222, Train AUC: 0.6850, Train AP: 0.6680, Valid. AUC: 0.6593, Valid AP: 0.6377\n",
      "Epoch: 73/100, Loss: 0.6394559, Train Acc: 0.6415, Test Acc: 0.6234, Train AUC: 0.6853, Train AP: 0.6698, Valid. AUC: 0.6611, Valid AP: 0.6394\n",
      "Epoch: 74/100, Loss: 0.6375692, Train Acc: 0.6428, Test Acc: 0.6304, Train AUC: 0.6887, Train AP: 0.6743, Valid. AUC: 0.6687, Valid AP: 0.6480\n",
      "Epoch: 75/100, Loss: 0.6366065, Train Acc: 0.6496, Test Acc: 0.6276, Train AUC: 0.6952, Train AP: 0.6786, Valid. AUC: 0.6686, Valid AP: 0.6471\n",
      "Epoch: 76/100, Loss: 0.6348571, Train Acc: 0.6517, Test Acc: 0.6182, Train AUC: 0.6974, Train AP: 0.6806, Valid. AUC: 0.6585, Valid AP: 0.6354\n",
      "Epoch: 77/100, Loss: 0.6337369, Train Acc: 0.6466, Test Acc: 0.6261, Train AUC: 0.6944, Train AP: 0.6797, Valid. AUC: 0.6674, Valid AP: 0.6445\n",
      "Epoch: 78/100, Loss: 0.6297485, Train Acc: 0.6545, Test Acc: 0.6348, Train AUC: 0.7027, Train AP: 0.6875, Valid. AUC: 0.6744, Valid AP: 0.6534\n",
      "Epoch: 79/100, Loss: 0.6300573, Train Acc: 0.6543, Test Acc: 0.6297, Train AUC: 0.7051, Train AP: 0.6889, Valid. AUC: 0.6697, Valid AP: 0.6477\n",
      "Epoch: 80/100, Loss: 0.6270870, Train Acc: 0.6561, Test Acc: 0.6304, Train AUC: 0.7076, Train AP: 0.6915, Valid. AUC: 0.6699, Valid AP: 0.6473\n",
      "Epoch: 81/100, Loss: 0.6249197, Train Acc: 0.6556, Test Acc: 0.6345, Train AUC: 0.7086, Train AP: 0.6956, Valid. AUC: 0.6767, Valid AP: 0.6553\n",
      "Epoch: 82/100, Loss: 0.6239954, Train Acc: 0.6566, Test Acc: 0.6379, Train AUC: 0.7109, Train AP: 0.6970, Valid. AUC: 0.6772, Valid AP: 0.6567\n",
      "Epoch: 83/100, Loss: 0.6225772, Train Acc: 0.6593, Test Acc: 0.6387, Train AUC: 0.7131, Train AP: 0.6970, Valid. AUC: 0.6790, Valid AP: 0.6582\n",
      "Epoch: 84/100, Loss: 0.6207505, Train Acc: 0.6573, Test Acc: 0.6378, Train AUC: 0.7141, Train AP: 0.7032, Valid. AUC: 0.6764, Valid AP: 0.6537\n",
      "Epoch: 85/100, Loss: 0.6215037, Train Acc: 0.6577, Test Acc: 0.6387, Train AUC: 0.7127, Train AP: 0.7003, Valid. AUC: 0.6772, Valid AP: 0.6546\n",
      "Epoch: 86/100, Loss: 0.6179436, Train Acc: 0.6589, Test Acc: 0.6406, Train AUC: 0.7168, Train AP: 0.7067, Valid. AUC: 0.6813, Valid AP: 0.6600\n",
      "Epoch: 87/100, Loss: 0.6185118, Train Acc: 0.6582, Test Acc: 0.6335, Train AUC: 0.7160, Train AP: 0.7075, Valid. AUC: 0.6734, Valid AP: 0.6518\n",
      "Epoch: 88/100, Loss: 0.6169032, Train Acc: 0.6586, Test Acc: 0.6367, Train AUC: 0.7169, Train AP: 0.7091, Valid. AUC: 0.6775, Valid AP: 0.6556\n",
      "Epoch: 89/100, Loss: 0.6169173, Train Acc: 0.6592, Test Acc: 0.6433, Train AUC: 0.7187, Train AP: 0.7071, Valid. AUC: 0.6842, Valid AP: 0.6632\n",
      "Epoch: 90/100, Loss: 0.6150898, Train Acc: 0.6598, Test Acc: 0.6400, Train AUC: 0.7192, Train AP: 0.7090, Valid. AUC: 0.6857, Valid AP: 0.6646\n",
      "Epoch: 91/100, Loss: 0.6150913, Train Acc: 0.6589, Test Acc: 0.6359, Train AUC: 0.7193, Train AP: 0.7118, Valid. AUC: 0.6779, Valid AP: 0.6540\n",
      "Epoch: 92/100, Loss: 0.6137030, Train Acc: 0.6612, Test Acc: 0.6389, Train AUC: 0.7209, Train AP: 0.7130, Valid. AUC: 0.6836, Valid AP: 0.6598\n",
      "Epoch: 93/100, Loss: 0.6119064, Train Acc: 0.6622, Test Acc: 0.6427, Train AUC: 0.7231, Train AP: 0.7157, Valid. AUC: 0.6888, Valid AP: 0.6663\n",
      "Epoch: 94/100, Loss: 0.6132036, Train Acc: 0.6606, Test Acc: 0.6340, Train AUC: 0.7203, Train AP: 0.7138, Valid. AUC: 0.6784, Valid AP: 0.6564\n",
      "Epoch: 95/100, Loss: 0.6138668, Train Acc: 0.6601, Test Acc: 0.6408, Train AUC: 0.7216, Train AP: 0.7113, Valid. AUC: 0.6870, Valid AP: 0.6653\n",
      "Epoch: 96/100, Loss: 0.6099923, Train Acc: 0.6621, Test Acc: 0.6417, Train AUC: 0.7248, Train AP: 0.7184, Valid. AUC: 0.6913, Valid AP: 0.6692\n",
      "Epoch: 97/100, Loss: 0.6113133, Train Acc: 0.6608, Test Acc: 0.6443, Train AUC: 0.7239, Train AP: 0.7160, Valid. AUC: 0.6901, Valid AP: 0.6689\n",
      "Epoch: 98/100, Loss: 0.6083647, Train Acc: 0.6629, Test Acc: 0.6373, Train AUC: 0.7262, Train AP: 0.7206, Valid. AUC: 0.6834, Valid AP: 0.6625\n",
      "Epoch: 99/100, Loss: 0.6110839, Train Acc: 0.6607, Test Acc: 0.6346, Train AUC: 0.7242, Train AP: 0.7188, Valid. AUC: 0.6772, Valid AP: 0.6560\n",
      "Epoch: 100/100, Loss: 0.6117926, Train Acc: 0.6613, Test Acc: 0.6456, Train AUC: 0.7226, Train AP: 0.7150, Valid. AUC: 0.6926, Valid AP: 0.6709\n",
      "/home/ubuntu/PA-Cancer-Immunotherapy/GNN/train_pa_all_tvt.py:212: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(configs['save_model']))\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.388 MB of 1.388 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.389 MB of 1.389 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.389 MB of 1.389 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.389 MB of 1.389 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▁▁▁▁▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        test_ap ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   test_roc_auc ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▁▁▂▃▃▄▃▄▄▄▄▄▄▄▅▅▅▅▅▅▅▅▅▅▅▆▆▇▇▇██████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train_ap ▁▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▇▇▇▇▇█████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss ██▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▄▄▃▃▃▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_roc_auc ▁▃▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇██████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: valid_accuracy ▁▂▂▃▂▃▄▃▄▄▄▅▅▅▅▅▇▆▅▅▃▆▆▇▇▆▇▆▇▇▇▇▇████▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       valid_ap ▁▁▁▂▂▃▃▄▄▄▄▄▄▄▄▄▅▅▅▅▅▅▅▅▅▆▆▆▇▆▇▇▇▇▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  valid_roc_auc ▁▁▁▁▁▂▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇█▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy 0.64769\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        test_ap 0.67764\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   test_roc_auc 0.69765\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.66129\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train_ap 0.71496\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.61179\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_roc_auc 0.72257\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: valid_accuracy 0.64564\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       valid_ap 0.6709\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  valid_roc_auc 0.69257\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33miconic-paper-8\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-gene_GNN/runs/1tr6uyot\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-gene_GNN\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 6 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241209_121629-1tr6uyot/logs\u001b[0m\n",
      "Test Acc: 0.6477, Test AUC: 0.6976, Test AUPR: 0.6776\n"
     ]
    }
   ],
   "source": [
    "# for gene. Since lr = 0.01 was bad for allele. Let's try here 0.0005\n",
    "\n",
    "! python train_pa_all_tvt.py --gpu 0 --configs_path configs/PA_all_tvt_gene.yml --droup_out 0.1 --lr 0.0005 --split StrictTCR\n",
    "# Result: also not better than lr=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074d3027-8c4c-426e-87ae-3b9c131080d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39546391-5598-4a07-8f6f-99f8c9569af5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(gpu=0, lr=0.001, epochs=100, w_celoss=1, w_aucloss=0, add_same_type_edges=False, dynamic_graph=False, dynamic_ratio=0.05, droup_out=0.2, positive_weights=1, dynamic_epochs=30, distance_threshold=10, configs_path='configs/PA_all_tvt_allele.yml', split='StrictTCR', dataset='pMTnet')\n",
      "PROJECT_NAME: dataset-all-tvt-allele_GNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfrohoari\u001b[0m (\u001b[33mpa_cancerimmunotherapy\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/ubuntu/PA-Cancer-Immunotherapy/GNN/wandb/run-20241209_113305-po13d66f\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mglad-terrain-8\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-allele_GNN\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-allele_GNN/runs/po13d66f\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   6 of 6 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   6 of 6 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   6 of 6 files downloaded.  \n",
      "embeddings_path:   models/PA_all/gene_and_allele_embeddings.pkl\n",
      "train_file_list:   ['allele_train.csv']\n",
      "validation_file_list:   ['allele_validation.csv']\n",
      "test_file_list:   ['allele_test.csv']\n",
      "wandb logger initialisiert\n",
      "Epoch: 1/100, Loss: 0.6938508, Train Acc: 0.4866, Test Acc: 0.5024, Train AUC: 0.4810, Train AP: 0.4919, Valid. AUC: 0.5605, Valid AP: 0.5522\n",
      "Epoch: 2/100, Loss: 0.6916078, Train Acc: 0.5099, Test Acc: 0.5414, Train AUC: 0.5595, Train AP: 0.5451, Valid. AUC: 0.5704, Valid AP: 0.5614\n",
      "Epoch: 3/100, Loss: 0.6883261, Train Acc: 0.5531, Test Acc: 0.5566, Train AUC: 0.5854, Train AP: 0.5649, Valid. AUC: 0.5652, Valid AP: 0.5590\n",
      "Epoch: 4/100, Loss: 0.6860740, Train Acc: 0.5647, Test Acc: 0.5320, Train AUC: 0.5935, Train AP: 0.5816, Valid. AUC: 0.5597, Valid AP: 0.5537\n",
      "Epoch: 5/100, Loss: 0.6825075, Train Acc: 0.5740, Test Acc: 0.5366, Train AUC: 0.5948, Train AP: 0.5781, Valid. AUC: 0.5654, Valid AP: 0.5562\n",
      "Epoch: 6/100, Loss: 0.6800659, Train Acc: 0.5766, Test Acc: 0.5623, Train AUC: 0.5961, Train AP: 0.5770, Valid. AUC: 0.5720, Valid AP: 0.5581\n",
      "Epoch: 7/100, Loss: 0.6787968, Train Acc: 0.5746, Test Acc: 0.5558, Train AUC: 0.6032, Train AP: 0.5838, Valid. AUC: 0.5759, Valid AP: 0.5612\n",
      "Epoch: 8/100, Loss: 0.6776979, Train Acc: 0.5804, Test Acc: 0.5530, Train AUC: 0.6060, Train AP: 0.5849, Valid. AUC: 0.5812, Valid AP: 0.5678\n",
      "Epoch: 9/100, Loss: 0.6782219, Train Acc: 0.5835, Test Acc: 0.5539, Train AUC: 0.6103, Train AP: 0.5889, Valid. AUC: 0.5895, Valid AP: 0.5745\n",
      "Epoch: 10/100, Loss: 0.6732889, Train Acc: 0.5897, Test Acc: 0.5661, Train AUC: 0.6163, Train AP: 0.5920, Valid. AUC: 0.5974, Valid AP: 0.5817\n",
      "Epoch: 11/100, Loss: 0.6752197, Train Acc: 0.5879, Test Acc: 0.5707, Train AUC: 0.6204, Train AP: 0.5894, Valid. AUC: 0.6037, Valid AP: 0.5905\n",
      "Epoch: 12/100, Loss: 0.6713037, Train Acc: 0.5944, Test Acc: 0.5691, Train AUC: 0.6230, Train AP: 0.5981, Valid. AUC: 0.6057, Valid AP: 0.5928\n",
      "Epoch: 13/100, Loss: 0.6716014, Train Acc: 0.5967, Test Acc: 0.5784, Train AUC: 0.6232, Train AP: 0.5954, Valid. AUC: 0.6082, Valid AP: 0.5947\n",
      "Epoch: 14/100, Loss: 0.6687665, Train Acc: 0.5988, Test Acc: 0.5731, Train AUC: 0.6281, Train AP: 0.6046, Valid. AUC: 0.6124, Valid AP: 0.5976\n",
      "Epoch: 15/100, Loss: 0.6697108, Train Acc: 0.5976, Test Acc: 0.5753, Train AUC: 0.6273, Train AP: 0.6061, Valid. AUC: 0.6164, Valid AP: 0.6007\n",
      "Epoch: 16/100, Loss: 0.6682282, Train Acc: 0.5960, Test Acc: 0.5822, Train AUC: 0.6278, Train AP: 0.6020, Valid. AUC: 0.6201, Valid AP: 0.6038\n",
      "Epoch: 17/100, Loss: 0.6667598, Train Acc: 0.5990, Test Acc: 0.5849, Train AUC: 0.6331, Train AP: 0.6109, Valid. AUC: 0.6230, Valid AP: 0.6065\n",
      "Epoch: 18/100, Loss: 0.6666028, Train Acc: 0.6003, Test Acc: 0.5904, Train AUC: 0.6334, Train AP: 0.6076, Valid. AUC: 0.6259, Valid AP: 0.6094\n",
      "Epoch: 19/100, Loss: 0.6657875, Train Acc: 0.6007, Test Acc: 0.5879, Train AUC: 0.6339, Train AP: 0.6097, Valid. AUC: 0.6281, Valid AP: 0.6115\n",
      "Epoch: 20/100, Loss: 0.6658745, Train Acc: 0.6012, Test Acc: 0.5989, Train AUC: 0.6357, Train AP: 0.6127, Valid. AUC: 0.6296, Valid AP: 0.6128\n",
      "Epoch: 21/100, Loss: 0.6641937, Train Acc: 0.6041, Test Acc: 0.5831, Train AUC: 0.6377, Train AP: 0.6171, Valid. AUC: 0.6310, Valid AP: 0.6139\n",
      "Epoch: 22/100, Loss: 0.6642011, Train Acc: 0.6005, Test Acc: 0.5903, Train AUC: 0.6391, Train AP: 0.6141, Valid. AUC: 0.6314, Valid AP: 0.6145\n",
      "Epoch: 23/100, Loss: 0.6645728, Train Acc: 0.6064, Test Acc: 0.5914, Train AUC: 0.6408, Train AP: 0.6155, Valid. AUC: 0.6313, Valid AP: 0.6145\n",
      "Epoch: 24/100, Loss: 0.6631442, Train Acc: 0.6044, Test Acc: 0.5840, Train AUC: 0.6415, Train AP: 0.6169, Valid. AUC: 0.6314, Valid AP: 0.6146\n",
      "Epoch: 25/100, Loss: 0.6620425, Train Acc: 0.6063, Test Acc: 0.5831, Train AUC: 0.6421, Train AP: 0.6171, Valid. AUC: 0.6329, Valid AP: 0.6158\n",
      "Epoch: 26/100, Loss: 0.6610834, Train Acc: 0.6046, Test Acc: 0.6007, Train AUC: 0.6438, Train AP: 0.6199, Valid. AUC: 0.6358, Valid AP: 0.6179\n",
      "Epoch: 27/100, Loss: 0.6608879, Train Acc: 0.6041, Test Acc: 0.5999, Train AUC: 0.6434, Train AP: 0.6201, Valid. AUC: 0.6389, Valid AP: 0.6206\n",
      "Epoch: 28/100, Loss: 0.6600552, Train Acc: 0.6034, Test Acc: 0.6072, Train AUC: 0.6460, Train AP: 0.6236, Valid. AUC: 0.6439, Valid AP: 0.6239\n",
      "Epoch: 29/100, Loss: 0.6601061, Train Acc: 0.6072, Test Acc: 0.6093, Train AUC: 0.6454, Train AP: 0.6217, Valid. AUC: 0.6460, Valid AP: 0.6251\n",
      "Epoch: 30/100, Loss: 0.6590991, Train Acc: 0.6075, Test Acc: 0.6100, Train AUC: 0.6472, Train AP: 0.6245, Valid. AUC: 0.6474, Valid AP: 0.6256\n",
      "Epoch: 31/100, Loss: 0.6596794, Train Acc: 0.6099, Test Acc: 0.6221, Train AUC: 0.6477, Train AP: 0.6248, Valid. AUC: 0.6482, Valid AP: 0.6260\n",
      "Epoch: 32/100, Loss: 0.6588028, Train Acc: 0.6107, Test Acc: 0.6266, Train AUC: 0.6494, Train AP: 0.6259, Valid. AUC: 0.6485, Valid AP: 0.6265\n",
      "Epoch: 33/100, Loss: 0.6575541, Train Acc: 0.6106, Test Acc: 0.6110, Train AUC: 0.6506, Train AP: 0.6261, Valid. AUC: 0.6487, Valid AP: 0.6275\n",
      "Epoch: 34/100, Loss: 0.6567884, Train Acc: 0.6109, Test Acc: 0.6107, Train AUC: 0.6508, Train AP: 0.6287, Valid. AUC: 0.6479, Valid AP: 0.6277\n",
      "Epoch: 35/100, Loss: 0.6560202, Train Acc: 0.6097, Test Acc: 0.6072, Train AUC: 0.6531, Train AP: 0.6313, Valid. AUC: 0.6464, Valid AP: 0.6274\n",
      "Epoch: 36/100, Loss: 0.6563162, Train Acc: 0.6068, Test Acc: 0.6117, Train AUC: 0.6523, Train AP: 0.6321, Valid. AUC: 0.6458, Valid AP: 0.6270\n",
      "Epoch: 37/100, Loss: 0.6558205, Train Acc: 0.6104, Test Acc: 0.6019, Train AUC: 0.6527, Train AP: 0.6329, Valid. AUC: 0.6453, Valid AP: 0.6270\n",
      "Epoch: 38/100, Loss: 0.6541816, Train Acc: 0.6101, Test Acc: 0.6041, Train AUC: 0.6558, Train AP: 0.6347, Valid. AUC: 0.6455, Valid AP: 0.6275\n",
      "Epoch: 39/100, Loss: 0.6538469, Train Acc: 0.6100, Test Acc: 0.6055, Train AUC: 0.6561, Train AP: 0.6351, Valid. AUC: 0.6476, Valid AP: 0.6293\n",
      "Epoch: 40/100, Loss: 0.6522320, Train Acc: 0.6128, Test Acc: 0.6225, Train AUC: 0.6587, Train AP: 0.6381, Valid. AUC: 0.6500, Valid AP: 0.6313\n",
      "Epoch: 41/100, Loss: 0.6525087, Train Acc: 0.6135, Test Acc: 0.6119, Train AUC: 0.6583, Train AP: 0.6376, Valid. AUC: 0.6505, Valid AP: 0.6327\n",
      "Epoch: 42/100, Loss: 0.6513146, Train Acc: 0.6113, Test Acc: 0.6198, Train AUC: 0.6606, Train AP: 0.6408, Valid. AUC: 0.6522, Valid AP: 0.6331\n",
      "Epoch: 43/100, Loss: 0.6501521, Train Acc: 0.6145, Test Acc: 0.6191, Train AUC: 0.6640, Train AP: 0.6448, Valid. AUC: 0.6535, Valid AP: 0.6340\n",
      "Epoch: 44/100, Loss: 0.6489964, Train Acc: 0.6135, Test Acc: 0.6256, Train AUC: 0.6647, Train AP: 0.6460, Valid. AUC: 0.6551, Valid AP: 0.6352\n",
      "Epoch: 45/100, Loss: 0.6490480, Train Acc: 0.6157, Test Acc: 0.6172, Train AUC: 0.6651, Train AP: 0.6446, Valid. AUC: 0.6564, Valid AP: 0.6370\n",
      "Epoch: 46/100, Loss: 0.6494721, Train Acc: 0.6206, Test Acc: 0.6160, Train AUC: 0.6663, Train AP: 0.6471, Valid. AUC: 0.6569, Valid AP: 0.6408\n",
      "Epoch: 47/100, Loss: 0.6471311, Train Acc: 0.6154, Test Acc: 0.6118, Train AUC: 0.6672, Train AP: 0.6513, Valid. AUC: 0.6586, Valid AP: 0.6405\n",
      "Epoch: 48/100, Loss: 0.6456503, Train Acc: 0.6177, Test Acc: 0.6287, Train AUC: 0.6735, Train AP: 0.6558, Valid. AUC: 0.6597, Valid AP: 0.6409\n",
      "Epoch: 49/100, Loss: 0.6447231, Train Acc: 0.6211, Test Acc: 0.6201, Train AUC: 0.6727, Train AP: 0.6548, Valid. AUC: 0.6597, Valid AP: 0.6420\n",
      "Epoch: 50/100, Loss: 0.6433448, Train Acc: 0.6221, Test Acc: 0.6282, Train AUC: 0.6762, Train AP: 0.6592, Valid. AUC: 0.6607, Valid AP: 0.6445\n",
      "Epoch: 51/100, Loss: 0.6461282, Train Acc: 0.6167, Test Acc: 0.6116, Train AUC: 0.6700, Train AP: 0.6557, Valid. AUC: 0.6637, Valid AP: 0.6450\n",
      "Epoch: 52/100, Loss: 0.6429899, Train Acc: 0.6233, Test Acc: 0.6001, Train AUC: 0.6789, Train AP: 0.6614, Valid. AUC: 0.6586, Valid AP: 0.6406\n",
      "Epoch: 53/100, Loss: 0.6460068, Train Acc: 0.6261, Test Acc: 0.6344, Train AUC: 0.6789, Train AP: 0.6576, Valid. AUC: 0.6652, Valid AP: 0.6502\n",
      "Epoch: 54/100, Loss: 0.6383157, Train Acc: 0.6292, Test Acc: 0.6202, Train AUC: 0.6817, Train AP: 0.6672, Valid. AUC: 0.6627, Valid AP: 0.6482\n",
      "Epoch: 55/100, Loss: 0.6405706, Train Acc: 0.6304, Test Acc: 0.6288, Train AUC: 0.6795, Train AP: 0.6669, Valid. AUC: 0.6655, Valid AP: 0.6506\n",
      "Epoch: 56/100, Loss: 0.6380949, Train Acc: 0.6327, Test Acc: 0.6175, Train AUC: 0.6837, Train AP: 0.6693, Valid. AUC: 0.6544, Valid AP: 0.6394\n",
      "Epoch: 57/100, Loss: 0.6431230, Train Acc: 0.6266, Test Acc: 0.6267, Train AUC: 0.6797, Train AP: 0.6629, Valid. AUC: 0.6653, Valid AP: 0.6491\n",
      "Epoch: 58/100, Loss: 0.6363902, Train Acc: 0.6359, Test Acc: 0.6320, Train AUC: 0.6889, Train AP: 0.6713, Valid. AUC: 0.6653, Valid AP: 0.6510\n",
      "Epoch: 59/100, Loss: 0.6396362, Train Acc: 0.6319, Test Acc: 0.6286, Train AUC: 0.6812, Train AP: 0.6663, Valid. AUC: 0.6679, Valid AP: 0.6528\n",
      "Epoch: 60/100, Loss: 0.6365332, Train Acc: 0.6348, Test Acc: 0.6223, Train AUC: 0.6857, Train AP: 0.6691, Valid. AUC: 0.6601, Valid AP: 0.6462\n",
      "Epoch: 61/100, Loss: 0.6377320, Train Acc: 0.6361, Test Acc: 0.6262, Train AUC: 0.6887, Train AP: 0.6709, Valid. AUC: 0.6630, Valid AP: 0.6505\n",
      "Epoch: 62/100, Loss: 0.6376392, Train Acc: 0.6358, Test Acc: 0.6279, Train AUC: 0.6891, Train AP: 0.6723, Valid. AUC: 0.6693, Valid AP: 0.6580\n",
      "Epoch: 63/100, Loss: 0.6330473, Train Acc: 0.6362, Test Acc: 0.6228, Train AUC: 0.6912, Train AP: 0.6767, Valid. AUC: 0.6681, Valid AP: 0.6580\n",
      "Epoch: 64/100, Loss: 0.6311248, Train Acc: 0.6370, Test Acc: 0.6259, Train AUC: 0.6943, Train AP: 0.6808, Valid. AUC: 0.6690, Valid AP: 0.6592\n",
      "Epoch: 65/100, Loss: 0.6320439, Train Acc: 0.6382, Test Acc: 0.6104, Train AUC: 0.6932, Train AP: 0.6800, Valid. AUC: 0.6650, Valid AP: 0.6569\n",
      "Epoch: 66/100, Loss: 0.6313336, Train Acc: 0.6399, Test Acc: 0.6270, Train AUC: 0.6975, Train AP: 0.6827, Valid. AUC: 0.6709, Valid AP: 0.6593\n",
      "Epoch: 67/100, Loss: 0.6308568, Train Acc: 0.6401, Test Acc: 0.6400, Train AUC: 0.6973, Train AP: 0.6808, Valid. AUC: 0.6785, Valid AP: 0.6622\n",
      "Epoch: 68/100, Loss: 0.6301848, Train Acc: 0.6422, Test Acc: 0.6422, Train AUC: 0.6960, Train AP: 0.6781, Valid. AUC: 0.6810, Valid AP: 0.6634\n",
      "Epoch: 69/100, Loss: 0.6278262, Train Acc: 0.6454, Test Acc: 0.6399, Train AUC: 0.6997, Train AP: 0.6818, Valid. AUC: 0.6800, Valid AP: 0.6627\n",
      "Epoch: 70/100, Loss: 0.6264797, Train Acc: 0.6473, Test Acc: 0.6388, Train AUC: 0.7034, Train AP: 0.6854, Valid. AUC: 0.6798, Valid AP: 0.6639\n",
      "Epoch: 71/100, Loss: 0.6268094, Train Acc: 0.6419, Test Acc: 0.6397, Train AUC: 0.7003, Train AP: 0.6849, Valid. AUC: 0.6862, Valid AP: 0.6694\n",
      "Epoch: 72/100, Loss: 0.6238065, Train Acc: 0.6498, Test Acc: 0.6473, Train AUC: 0.7055, Train AP: 0.6910, Valid. AUC: 0.6874, Valid AP: 0.6706\n",
      "Epoch: 73/100, Loss: 0.6229042, Train Acc: 0.6512, Test Acc: 0.6295, Train AUC: 0.7074, Train AP: 0.6898, Valid. AUC: 0.6808, Valid AP: 0.6668\n",
      "Epoch: 74/100, Loss: 0.6225255, Train Acc: 0.6500, Test Acc: 0.6242, Train AUC: 0.7071, Train AP: 0.6896, Valid. AUC: 0.6761, Valid AP: 0.6644\n",
      "Epoch: 75/100, Loss: 0.6251817, Train Acc: 0.6460, Test Acc: 0.6274, Train AUC: 0.7018, Train AP: 0.6841, Valid. AUC: 0.6798, Valid AP: 0.6699\n",
      "Epoch: 76/100, Loss: 0.6189573, Train Acc: 0.6520, Test Acc: 0.6358, Train AUC: 0.7113, Train AP: 0.6948, Valid. AUC: 0.6849, Valid AP: 0.6731\n",
      "Epoch: 77/100, Loss: 0.6187747, Train Acc: 0.6556, Test Acc: 0.6362, Train AUC: 0.7127, Train AP: 0.6975, Valid. AUC: 0.6864, Valid AP: 0.6725\n",
      "Epoch: 78/100, Loss: 0.6228189, Train Acc: 0.6514, Test Acc: 0.6405, Train AUC: 0.7069, Train AP: 0.6909, Valid. AUC: 0.6881, Valid AP: 0.6753\n",
      "Epoch: 79/100, Loss: 0.6185821, Train Acc: 0.6545, Test Acc: 0.6390, Train AUC: 0.7127, Train AP: 0.6965, Valid. AUC: 0.6891, Valid AP: 0.6743\n",
      "Epoch: 80/100, Loss: 0.6179910, Train Acc: 0.6582, Test Acc: 0.6413, Train AUC: 0.7166, Train AP: 0.6975, Valid. AUC: 0.6926, Valid AP: 0.6760\n",
      "Epoch: 81/100, Loss: 0.6168683, Train Acc: 0.6547, Test Acc: 0.6402, Train AUC: 0.7149, Train AP: 0.6959, Valid. AUC: 0.6904, Valid AP: 0.6783\n",
      "Epoch: 82/100, Loss: 0.6134118, Train Acc: 0.6590, Test Acc: 0.6430, Train AUC: 0.7197, Train AP: 0.7029, Valid. AUC: 0.6928, Valid AP: 0.6796\n",
      "Epoch: 83/100, Loss: 0.6153244, Train Acc: 0.6602, Test Acc: 0.6384, Train AUC: 0.7204, Train AP: 0.7052, Valid. AUC: 0.6913, Valid AP: 0.6805\n",
      "Epoch: 84/100, Loss: 0.6138444, Train Acc: 0.6594, Test Acc: 0.6376, Train AUC: 0.7203, Train AP: 0.7025, Valid. AUC: 0.6907, Valid AP: 0.6803\n",
      "Epoch: 85/100, Loss: 0.6133567, Train Acc: 0.6604, Test Acc: 0.6492, Train AUC: 0.7214, Train AP: 0.7038, Valid. AUC: 0.7011, Valid AP: 0.6847\n",
      "Epoch: 86/100, Loss: 0.6085740, Train Acc: 0.6638, Test Acc: 0.6495, Train AUC: 0.7262, Train AP: 0.7082, Valid. AUC: 0.7004, Valid AP: 0.6872\n",
      "Epoch: 87/100, Loss: 0.6063234, Train Acc: 0.6651, Test Acc: 0.6465, Train AUC: 0.7284, Train AP: 0.7132, Valid. AUC: 0.6970, Valid AP: 0.6860\n",
      "Epoch: 88/100, Loss: 0.6071878, Train Acc: 0.6643, Test Acc: 0.6524, Train AUC: 0.7277, Train AP: 0.7130, Valid. AUC: 0.7034, Valid AP: 0.6879\n",
      "Epoch: 89/100, Loss: 0.6051412, Train Acc: 0.6666, Test Acc: 0.6453, Train AUC: 0.7311, Train AP: 0.7147, Valid. AUC: 0.6989, Valid AP: 0.6865\n",
      "Epoch: 90/100, Loss: 0.6069199, Train Acc: 0.6616, Test Acc: 0.6453, Train AUC: 0.7277, Train AP: 0.7126, Valid. AUC: 0.7012, Valid AP: 0.6901\n",
      "Epoch: 91/100, Loss: 0.6032757, Train Acc: 0.6667, Test Acc: 0.6505, Train AUC: 0.7334, Train AP: 0.7194, Valid. AUC: 0.7020, Valid AP: 0.6917\n",
      "Epoch: 92/100, Loss: 0.6026544, Train Acc: 0.6675, Test Acc: 0.6513, Train AUC: 0.7325, Train AP: 0.7211, Valid. AUC: 0.7043, Valid AP: 0.6930\n",
      "Epoch: 93/100, Loss: 0.6032795, Train Acc: 0.6658, Test Acc: 0.6240, Train AUC: 0.7326, Train AP: 0.7221, Valid. AUC: 0.6770, Valid AP: 0.6708\n",
      "Epoch: 94/100, Loss: 0.6042767, Train Acc: 0.6643, Test Acc: 0.6480, Train AUC: 0.7321, Train AP: 0.7222, Valid. AUC: 0.7032, Valid AP: 0.6940\n",
      "Epoch: 95/100, Loss: 0.5970973, Train Acc: 0.6714, Test Acc: 0.6511, Train AUC: 0.7403, Train AP: 0.7285, Valid. AUC: 0.7055, Valid AP: 0.6950\n",
      "Epoch: 96/100, Loss: 0.5994909, Train Acc: 0.6706, Test Acc: 0.6509, Train AUC: 0.7384, Train AP: 0.7256, Valid. AUC: 0.7057, Valid AP: 0.6970\n",
      "Epoch: 97/100, Loss: 0.5945297, Train Acc: 0.6723, Test Acc: 0.6419, Train AUC: 0.7427, Train AP: 0.7354, Valid. AUC: 0.6988, Valid AP: 0.6925\n",
      "Epoch: 98/100, Loss: 0.5947536, Train Acc: 0.6713, Test Acc: 0.6534, Train AUC: 0.7425, Train AP: 0.7343, Valid. AUC: 0.7058, Valid AP: 0.6963\n",
      "Epoch: 99/100, Loss: 0.5960056, Train Acc: 0.6723, Test Acc: 0.6566, Train AUC: 0.7409, Train AP: 0.7324, Valid. AUC: 0.7105, Valid AP: 0.7011\n",
      "Epoch: 100/100, Loss: 0.5929527, Train Acc: 0.6747, Test Acc: 0.6414, Train AUC: 0.7440, Train AP: 0.7339, Valid. AUC: 0.6970, Valid AP: 0.6903\n",
      "/home/ubuntu/PA-Cancer-Immunotherapy/GNN/train_pa_all_tvt.py:212: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(configs['save_model']))\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.411 MB of 1.411 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.412 MB of 1.412 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.418 MB of 1.418 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.418 MB of 1.418 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.418 MB of 1.418 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        test_ap ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   test_roc_auc ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▁▄▄▄▄▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇█████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train_ap ▁▃▄▃▄▄▄▄▄▄▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss ██▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▅▅▄▅▄▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_roc_auc ▁▄▄▄▄▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: valid_accuracy ▁▃▃▄▃▄▅▅▆▅▆▇▆▆▆▆▇▇▇▇▆▇▆▇▇▇▇▆▇██▇▇▇██████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       valid_ap ▁▁▁▁▁▃▄▄▄▄▄▄▅▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  valid_roc_auc ▁▁▁▁▁▃▃▃▃▃▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▇▇▆▇▇█▆███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy 0.65606\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        test_ap 0.70198\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   test_roc_auc 0.71189\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.6747\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train_ap 0.73393\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.59295\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_roc_auc 0.74398\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: valid_accuracy 0.64141\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       valid_ap 0.69027\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  valid_roc_auc 0.69699\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mglad-terrain-8\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-allele_GNN/runs/po13d66f\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-allele_GNN\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 8 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241209_113305-po13d66f/logs\u001b[0m\n",
      "Test Acc: 0.6561, Test AUC: 0.7119, Test AUPR: 0.7020\n"
     ]
    }
   ],
   "source": [
    "# allele. (Mit confusion Matrix) and AP (which actually is the same as the AUPC before)\n",
    "# drop_out = 0.2\n",
    "\n",
    "! python train_pa_all_tvt.py --gpu 0 --configs_path configs/PA_all_tvt_allele.yml --droup_out 0.2 --split StrictTCR\n",
    "# Result: not better than drop_out 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9e34b4f-97f7-49d2-bf8a-0f68fdb58332",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(gpu=0, lr=0.001, epochs=100, w_celoss=1, w_aucloss=0, add_same_type_edges=False, dynamic_graph=False, dynamic_ratio=0.05, droup_out=0.2, positive_weights=1, dynamic_epochs=30, distance_threshold=10, configs_path='configs/PA_all_tvt_gene.yml', split='StrictTCR', dataset='pMTnet')\n",
      "PROJECT_NAME: dataset-all-tvt-gene_GNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfrohoari\u001b[0m (\u001b[33mpa_cancerimmunotherapy\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/ubuntu/PA-Cancer-Immunotherapy/GNN/wandb/run-20241209_113947-i2anecei\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mvolcanic-puddle-7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-gene_GNN\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-gene_GNN/runs/i2anecei\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   6 of 6 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   6 of 6 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   6 of 6 files downloaded.  \n",
      "embeddings_path:   models/PA_all/gene_and_allele_embeddings.pkl\n",
      "train_file_list:   ['gene_train.csv']\n",
      "validation_file_list:   ['gene_validation.csv']\n",
      "test_file_list:   ['gene_test.csv']\n",
      "wandb logger initialisiert\n",
      "Epoch: 1/100, Loss: 0.6930629, Train Acc: 0.5101, Test Acc: 0.4991, Train AUC: 0.5091, Train AP: 0.5038, Valid. AUC: 0.5360, Valid AP: 0.5273\n",
      "Epoch: 2/100, Loss: 0.6911374, Train Acc: 0.5163, Test Acc: 0.5366, Train AUC: 0.5567, Train AP: 0.5465, Valid. AUC: 0.5488, Valid AP: 0.5430\n",
      "Epoch: 3/100, Loss: 0.6876543, Train Acc: 0.5455, Test Acc: 0.5495, Train AUC: 0.5837, Train AP: 0.5755, Valid. AUC: 0.5496, Valid AP: 0.5455\n",
      "Epoch: 4/100, Loss: 0.6849942, Train Acc: 0.5647, Test Acc: 0.5152, Train AUC: 0.5922, Train AP: 0.5791, Valid. AUC: 0.5480, Valid AP: 0.5421\n",
      "Epoch: 5/100, Loss: 0.6830565, Train Acc: 0.5661, Test Acc: 0.5358, Train AUC: 0.5916, Train AP: 0.5833, Valid. AUC: 0.5559, Valid AP: 0.5493\n",
      "Epoch: 6/100, Loss: 0.6801602, Train Acc: 0.5730, Test Acc: 0.5572, Train AUC: 0.5968, Train AP: 0.5863, Valid. AUC: 0.5612, Valid AP: 0.5543\n",
      "Epoch: 7/100, Loss: 0.6765136, Train Acc: 0.5800, Test Acc: 0.5582, Train AUC: 0.6078, Train AP: 0.5915, Valid. AUC: 0.5670, Valid AP: 0.5576\n",
      "Epoch: 8/100, Loss: 0.6773985, Train Acc: 0.5764, Test Acc: 0.5376, Train AUC: 0.6087, Train AP: 0.5958, Valid. AUC: 0.5725, Valid AP: 0.5599\n",
      "Epoch: 9/100, Loss: 0.6765500, Train Acc: 0.5836, Test Acc: 0.5445, Train AUC: 0.6134, Train AP: 0.6005, Valid. AUC: 0.5830, Valid AP: 0.5685\n",
      "Epoch: 10/100, Loss: 0.6723479, Train Acc: 0.5912, Test Acc: 0.5654, Train AUC: 0.6189, Train AP: 0.6030, Valid. AUC: 0.5922, Valid AP: 0.5750\n",
      "Epoch: 11/100, Loss: 0.6717014, Train Acc: 0.5897, Test Acc: 0.5741, Train AUC: 0.6225, Train AP: 0.6070, Valid. AUC: 0.5975, Valid AP: 0.5788\n",
      "Epoch: 12/100, Loss: 0.6718975, Train Acc: 0.5900, Test Acc: 0.5609, Train AUC: 0.6226, Train AP: 0.6101, Valid. AUC: 0.6017, Valid AP: 0.5818\n",
      "Epoch: 13/100, Loss: 0.6693898, Train Acc: 0.5940, Test Acc: 0.5676, Train AUC: 0.6296, Train AP: 0.6139, Valid. AUC: 0.6053, Valid AP: 0.5850\n",
      "Epoch: 14/100, Loss: 0.6696355, Train Acc: 0.5897, Test Acc: 0.5779, Train AUC: 0.6310, Train AP: 0.6155, Valid. AUC: 0.6077, Valid AP: 0.5866\n",
      "Epoch: 15/100, Loss: 0.6674880, Train Acc: 0.5992, Test Acc: 0.5736, Train AUC: 0.6317, Train AP: 0.6132, Valid. AUC: 0.6118, Valid AP: 0.5900\n",
      "Epoch: 16/100, Loss: 0.6686663, Train Acc: 0.5978, Test Acc: 0.5772, Train AUC: 0.6298, Train AP: 0.6112, Valid. AUC: 0.6152, Valid AP: 0.5934\n",
      "Epoch: 17/100, Loss: 0.6661888, Train Acc: 0.5983, Test Acc: 0.5822, Train AUC: 0.6339, Train AP: 0.6189, Valid. AUC: 0.6186, Valid AP: 0.5959\n",
      "Epoch: 18/100, Loss: 0.6651914, Train Acc: 0.6019, Test Acc: 0.5918, Train AUC: 0.6359, Train AP: 0.6188, Valid. AUC: 0.6218, Valid AP: 0.5980\n",
      "Epoch: 19/100, Loss: 0.6659597, Train Acc: 0.6009, Test Acc: 0.5905, Train AUC: 0.6368, Train AP: 0.6225, Valid. AUC: 0.6225, Valid AP: 0.5985\n",
      "Epoch: 20/100, Loss: 0.6649465, Train Acc: 0.6023, Test Acc: 0.5876, Train AUC: 0.6376, Train AP: 0.6227, Valid. AUC: 0.6229, Valid AP: 0.5989\n",
      "Epoch: 21/100, Loss: 0.6651896, Train Acc: 0.6051, Test Acc: 0.5818, Train AUC: 0.6375, Train AP: 0.6245, Valid. AUC: 0.6208, Valid AP: 0.5975\n",
      "Epoch: 22/100, Loss: 0.6643524, Train Acc: 0.6045, Test Acc: 0.5799, Train AUC: 0.6387, Train AP: 0.6228, Valid. AUC: 0.6193, Valid AP: 0.5964\n",
      "Epoch: 23/100, Loss: 0.6654209, Train Acc: 0.6029, Test Acc: 0.5856, Train AUC: 0.6400, Train AP: 0.6224, Valid. AUC: 0.6210, Valid AP: 0.5980\n",
      "Epoch: 24/100, Loss: 0.6628388, Train Acc: 0.6071, Test Acc: 0.5735, Train AUC: 0.6424, Train AP: 0.6266, Valid. AUC: 0.6221, Valid AP: 0.5991\n",
      "Epoch: 25/100, Loss: 0.6632466, Train Acc: 0.6035, Test Acc: 0.5871, Train AUC: 0.6432, Train AP: 0.6284, Valid. AUC: 0.6219, Valid AP: 0.5994\n",
      "Epoch: 26/100, Loss: 0.6637798, Train Acc: 0.6021, Test Acc: 0.5904, Train AUC: 0.6429, Train AP: 0.6260, Valid. AUC: 0.6222, Valid AP: 0.6003\n",
      "Epoch: 27/100, Loss: 0.6620309, Train Acc: 0.6051, Test Acc: 0.5930, Train AUC: 0.6447, Train AP: 0.6293, Valid. AUC: 0.6272, Valid AP: 0.6041\n",
      "Epoch: 28/100, Loss: 0.6614834, Train Acc: 0.6076, Test Acc: 0.5892, Train AUC: 0.6437, Train AP: 0.6289, Valid. AUC: 0.6287, Valid AP: 0.6055\n",
      "Epoch: 29/100, Loss: 0.6611590, Train Acc: 0.6084, Test Acc: 0.5905, Train AUC: 0.6457, Train AP: 0.6305, Valid. AUC: 0.6295, Valid AP: 0.6062\n",
      "Epoch: 30/100, Loss: 0.6612330, Train Acc: 0.6072, Test Acc: 0.5956, Train AUC: 0.6458, Train AP: 0.6310, Valid. AUC: 0.6303, Valid AP: 0.6062\n",
      "Epoch: 31/100, Loss: 0.6612071, Train Acc: 0.6074, Test Acc: 0.6143, Train AUC: 0.6444, Train AP: 0.6306, Valid. AUC: 0.6312, Valid AP: 0.6065\n",
      "Epoch: 32/100, Loss: 0.6596591, Train Acc: 0.6095, Test Acc: 0.5964, Train AUC: 0.6479, Train AP: 0.6313, Valid. AUC: 0.6322, Valid AP: 0.6066\n",
      "Epoch: 33/100, Loss: 0.6596789, Train Acc: 0.6084, Test Acc: 0.5767, Train AUC: 0.6485, Train AP: 0.6321, Valid. AUC: 0.6323, Valid AP: 0.6066\n",
      "Epoch: 34/100, Loss: 0.6601160, Train Acc: 0.6079, Test Acc: 0.6176, Train AUC: 0.6486, Train AP: 0.6312, Valid. AUC: 0.6334, Valid AP: 0.6077\n",
      "Epoch: 35/100, Loss: 0.6590400, Train Acc: 0.6099, Test Acc: 0.6001, Train AUC: 0.6494, Train AP: 0.6338, Valid. AUC: 0.6345, Valid AP: 0.6090\n",
      "Epoch: 36/100, Loss: 0.6586818, Train Acc: 0.6106, Test Acc: 0.5966, Train AUC: 0.6501, Train AP: 0.6324, Valid. AUC: 0.6352, Valid AP: 0.6102\n",
      "Epoch: 37/100, Loss: 0.6594532, Train Acc: 0.6106, Test Acc: 0.5967, Train AUC: 0.6502, Train AP: 0.6342, Valid. AUC: 0.6356, Valid AP: 0.6110\n",
      "Epoch: 38/100, Loss: 0.6585991, Train Acc: 0.6103, Test Acc: 0.6200, Train AUC: 0.6503, Train AP: 0.6346, Valid. AUC: 0.6358, Valid AP: 0.6112\n",
      "Epoch: 39/100, Loss: 0.6576989, Train Acc: 0.6113, Test Acc: 0.6256, Train AUC: 0.6513, Train AP: 0.6349, Valid. AUC: 0.6361, Valid AP: 0.6116\n",
      "Epoch: 40/100, Loss: 0.6580633, Train Acc: 0.6115, Test Acc: 0.6261, Train AUC: 0.6514, Train AP: 0.6364, Valid. AUC: 0.6365, Valid AP: 0.6123\n",
      "Epoch: 41/100, Loss: 0.6569607, Train Acc: 0.6123, Test Acc: 0.6222, Train AUC: 0.6527, Train AP: 0.6355, Valid. AUC: 0.6370, Valid AP: 0.6129\n",
      "Epoch: 42/100, Loss: 0.6568370, Train Acc: 0.6127, Test Acc: 0.6081, Train AUC: 0.6533, Train AP: 0.6371, Valid. AUC: 0.6373, Valid AP: 0.6134\n",
      "Epoch: 43/100, Loss: 0.6591481, Train Acc: 0.6097, Test Acc: 0.6075, Train AUC: 0.6507, Train AP: 0.6366, Valid. AUC: 0.6377, Valid AP: 0.6143\n",
      "Epoch: 44/100, Loss: 0.6566974, Train Acc: 0.6129, Test Acc: 0.6193, Train AUC: 0.6541, Train AP: 0.6378, Valid. AUC: 0.6379, Valid AP: 0.6148\n",
      "Epoch: 45/100, Loss: 0.6561670, Train Acc: 0.6126, Test Acc: 0.6210, Train AUC: 0.6544, Train AP: 0.6385, Valid. AUC: 0.6377, Valid AP: 0.6151\n",
      "Epoch: 46/100, Loss: 0.6561262, Train Acc: 0.6120, Test Acc: 0.6074, Train AUC: 0.6545, Train AP: 0.6385, Valid. AUC: 0.6379, Valid AP: 0.6161\n",
      "Epoch: 47/100, Loss: 0.6559129, Train Acc: 0.6124, Test Acc: 0.6032, Train AUC: 0.6547, Train AP: 0.6378, Valid. AUC: 0.6389, Valid AP: 0.6178\n",
      "Epoch: 48/100, Loss: 0.6553186, Train Acc: 0.6130, Test Acc: 0.6006, Train AUC: 0.6558, Train AP: 0.6398, Valid. AUC: 0.6399, Valid AP: 0.6193\n",
      "Epoch: 49/100, Loss: 0.6543387, Train Acc: 0.6130, Test Acc: 0.6069, Train AUC: 0.6575, Train AP: 0.6420, Valid. AUC: 0.6407, Valid AP: 0.6202\n",
      "Epoch: 50/100, Loss: 0.6537712, Train Acc: 0.6149, Test Acc: 0.6233, Train AUC: 0.6586, Train AP: 0.6444, Valid. AUC: 0.6414, Valid AP: 0.6210\n",
      "Epoch: 51/100, Loss: 0.6541331, Train Acc: 0.6146, Test Acc: 0.6228, Train AUC: 0.6592, Train AP: 0.6449, Valid. AUC: 0.6413, Valid AP: 0.6211\n",
      "Epoch: 52/100, Loss: 0.6528564, Train Acc: 0.6139, Test Acc: 0.6143, Train AUC: 0.6602, Train AP: 0.6462, Valid. AUC: 0.6418, Valid AP: 0.6215\n",
      "Epoch: 53/100, Loss: 0.6525494, Train Acc: 0.6135, Test Acc: 0.6171, Train AUC: 0.6609, Train AP: 0.6471, Valid. AUC: 0.6435, Valid AP: 0.6236\n",
      "Epoch: 54/100, Loss: 0.6526161, Train Acc: 0.6139, Test Acc: 0.6224, Train AUC: 0.6612, Train AP: 0.6455, Valid. AUC: 0.6456, Valid AP: 0.6259\n",
      "Epoch: 55/100, Loss: 0.6513793, Train Acc: 0.6150, Test Acc: 0.6248, Train AUC: 0.6644, Train AP: 0.6500, Valid. AUC: 0.6461, Valid AP: 0.6274\n",
      "Epoch: 56/100, Loss: 0.6499203, Train Acc: 0.6170, Test Acc: 0.6209, Train AUC: 0.6659, Train AP: 0.6522, Valid. AUC: 0.6462, Valid AP: 0.6281\n",
      "Epoch: 57/100, Loss: 0.6496041, Train Acc: 0.6164, Test Acc: 0.6227, Train AUC: 0.6659, Train AP: 0.6536, Valid. AUC: 0.6498, Valid AP: 0.6309\n",
      "Epoch: 58/100, Loss: 0.6490151, Train Acc: 0.6176, Test Acc: 0.6241, Train AUC: 0.6676, Train AP: 0.6544, Valid. AUC: 0.6529, Valid AP: 0.6333\n",
      "Epoch: 59/100, Loss: 0.6472722, Train Acc: 0.6169, Test Acc: 0.6193, Train AUC: 0.6706, Train AP: 0.6589, Valid. AUC: 0.6519, Valid AP: 0.6328\n",
      "Epoch: 60/100, Loss: 0.6458012, Train Acc: 0.6196, Test Acc: 0.6258, Train AUC: 0.6721, Train AP: 0.6605, Valid. AUC: 0.6567, Valid AP: 0.6371\n",
      "Epoch: 61/100, Loss: 0.6453061, Train Acc: 0.6273, Test Acc: 0.6253, Train AUC: 0.6751, Train AP: 0.6624, Valid. AUC: 0.6566, Valid AP: 0.6373\n",
      "Epoch: 62/100, Loss: 0.6436914, Train Acc: 0.6252, Test Acc: 0.6304, Train AUC: 0.6757, Train AP: 0.6645, Valid. AUC: 0.6631, Valid AP: 0.6431\n",
      "Epoch: 63/100, Loss: 0.6418375, Train Acc: 0.6307, Test Acc: 0.6291, Train AUC: 0.6821, Train AP: 0.6697, Valid. AUC: 0.6622, Valid AP: 0.6429\n",
      "Epoch: 64/100, Loss: 0.6401608, Train Acc: 0.6358, Test Acc: 0.6211, Train AUC: 0.6849, Train AP: 0.6719, Valid. AUC: 0.6582, Valid AP: 0.6389\n",
      "Epoch: 65/100, Loss: 0.6381477, Train Acc: 0.6364, Test Acc: 0.6279, Train AUC: 0.6865, Train AP: 0.6743, Valid. AUC: 0.6668, Valid AP: 0.6483\n",
      "Epoch: 66/100, Loss: 0.6363901, Train Acc: 0.6448, Test Acc: 0.6245, Train AUC: 0.6930, Train AP: 0.6802, Valid. AUC: 0.6676, Valid AP: 0.6491\n",
      "Epoch: 67/100, Loss: 0.6334068, Train Acc: 0.6476, Test Acc: 0.6119, Train AUC: 0.6983, Train AP: 0.6847, Valid. AUC: 0.6550, Valid AP: 0.6350\n",
      "Epoch: 68/100, Loss: 0.6352418, Train Acc: 0.6442, Test Acc: 0.6279, Train AUC: 0.6922, Train AP: 0.6792, Valid. AUC: 0.6730, Valid AP: 0.6549\n",
      "Epoch: 69/100, Loss: 0.6342584, Train Acc: 0.6480, Test Acc: 0.6250, Train AUC: 0.6989, Train AP: 0.6825, Valid. AUC: 0.6700, Valid AP: 0.6503\n",
      "Epoch: 70/100, Loss: 0.6304199, Train Acc: 0.6536, Test Acc: 0.6301, Train AUC: 0.7013, Train AP: 0.6863, Valid. AUC: 0.6701, Valid AP: 0.6501\n",
      "Epoch: 71/100, Loss: 0.6265138, Train Acc: 0.6540, Test Acc: 0.6342, Train AUC: 0.7068, Train AP: 0.6950, Valid. AUC: 0.6776, Valid AP: 0.6603\n",
      "Epoch: 72/100, Loss: 0.6267512, Train Acc: 0.6541, Test Acc: 0.6324, Train AUC: 0.7092, Train AP: 0.6978, Valid. AUC: 0.6708, Valid AP: 0.6511\n",
      "Epoch: 73/100, Loss: 0.6253692, Train Acc: 0.6570, Test Acc: 0.6330, Train AUC: 0.7084, Train AP: 0.6946, Valid. AUC: 0.6759, Valid AP: 0.6575\n",
      "Epoch: 74/100, Loss: 0.6224675, Train Acc: 0.6578, Test Acc: 0.6350, Train AUC: 0.7122, Train AP: 0.7010, Valid. AUC: 0.6774, Valid AP: 0.6608\n",
      "Epoch: 75/100, Loss: 0.6215048, Train Acc: 0.6548, Test Acc: 0.6330, Train AUC: 0.7130, Train AP: 0.7034, Valid. AUC: 0.6724, Valid AP: 0.6534\n",
      "Epoch: 76/100, Loss: 0.6185012, Train Acc: 0.6589, Test Acc: 0.6334, Train AUC: 0.7166, Train AP: 0.7046, Valid. AUC: 0.6723, Valid AP: 0.6533\n",
      "Epoch: 77/100, Loss: 0.6170561, Train Acc: 0.6599, Test Acc: 0.6346, Train AUC: 0.7182, Train AP: 0.7112, Valid. AUC: 0.6768, Valid AP: 0.6605\n",
      "Epoch: 78/100, Loss: 0.6195875, Train Acc: 0.6527, Test Acc: 0.6280, Train AUC: 0.7127, Train AP: 0.7048, Valid. AUC: 0.6661, Valid AP: 0.6503\n",
      "Epoch: 79/100, Loss: 0.6166560, Train Acc: 0.6593, Test Acc: 0.6229, Train AUC: 0.7189, Train AP: 0.7088, Valid. AUC: 0.6600, Valid AP: 0.6453\n",
      "Epoch: 80/100, Loss: 0.6212260, Train Acc: 0.6582, Test Acc: 0.6290, Train AUC: 0.7147, Train AP: 0.7067, Valid. AUC: 0.6720, Valid AP: 0.6549\n",
      "Epoch: 81/100, Loss: 0.6283671, Train Acc: 0.6415, Test Acc: 0.6343, Train AUC: 0.7001, Train AP: 0.6905, Valid. AUC: 0.6758, Valid AP: 0.6613\n",
      "Epoch: 82/100, Loss: 0.6113284, Train Acc: 0.6626, Test Acc: 0.6213, Train AUC: 0.7233, Train AP: 0.7160, Valid. AUC: 0.6613, Valid AP: 0.6444\n",
      "Epoch: 83/100, Loss: 0.6204766, Train Acc: 0.6586, Test Acc: 0.6289, Train AUC: 0.7147, Train AP: 0.7002, Valid. AUC: 0.6720, Valid AP: 0.6537\n",
      "Epoch: 84/100, Loss: 0.6137263, Train Acc: 0.6617, Test Acc: 0.6323, Train AUC: 0.7211, Train AP: 0.7119, Valid. AUC: 0.6793, Valid AP: 0.6621\n",
      "Epoch: 85/100, Loss: 0.6170889, Train Acc: 0.6558, Test Acc: 0.6306, Train AUC: 0.7157, Train AP: 0.7059, Valid. AUC: 0.6780, Valid AP: 0.6599\n",
      "Epoch: 86/100, Loss: 0.6159333, Train Acc: 0.6562, Test Acc: 0.6302, Train AUC: 0.7175, Train AP: 0.7093, Valid. AUC: 0.6769, Valid AP: 0.6594\n",
      "Epoch: 87/100, Loss: 0.6096590, Train Acc: 0.6625, Test Acc: 0.6210, Train AUC: 0.7252, Train AP: 0.7187, Valid. AUC: 0.6642, Valid AP: 0.6468\n",
      "Epoch: 88/100, Loss: 0.6142870, Train Acc: 0.6596, Test Acc: 0.6250, Train AUC: 0.7202, Train AP: 0.7118, Valid. AUC: 0.6697, Valid AP: 0.6537\n",
      "Epoch: 89/100, Loss: 0.6111250, Train Acc: 0.6623, Test Acc: 0.6355, Train AUC: 0.7233, Train AP: 0.7153, Valid. AUC: 0.6829, Valid AP: 0.6674\n",
      "Epoch: 90/100, Loss: 0.6079620, Train Acc: 0.6629, Test Acc: 0.6345, Train AUC: 0.7265, Train AP: 0.7221, Valid. AUC: 0.6789, Valid AP: 0.6634\n",
      "Epoch: 91/100, Loss: 0.6126460, Train Acc: 0.6589, Test Acc: 0.6384, Train AUC: 0.7204, Train AP: 0.7161, Valid. AUC: 0.6847, Valid AP: 0.6683\n",
      "Epoch: 92/100, Loss: 0.6074733, Train Acc: 0.6649, Test Acc: 0.6344, Train AUC: 0.7279, Train AP: 0.7213, Valid. AUC: 0.6746, Valid AP: 0.6561\n",
      "Epoch: 93/100, Loss: 0.6098727, Train Acc: 0.6642, Test Acc: 0.6343, Train AUC: 0.7255, Train AP: 0.7191, Valid. AUC: 0.6765, Valid AP: 0.6559\n",
      "Epoch: 94/100, Loss: 0.6085544, Train Acc: 0.6641, Test Acc: 0.6393, Train AUC: 0.7265, Train AP: 0.7193, Valid. AUC: 0.6851, Valid AP: 0.6638\n",
      "Epoch: 95/100, Loss: 0.6047586, Train Acc: 0.6665, Test Acc: 0.6403, Train AUC: 0.7295, Train AP: 0.7264, Valid. AUC: 0.6857, Valid AP: 0.6643\n",
      "Epoch: 96/100, Loss: 0.6101261, Train Acc: 0.6602, Test Acc: 0.6359, Train AUC: 0.7243, Train AP: 0.7207, Valid. AUC: 0.6814, Valid AP: 0.6615\n",
      "Epoch: 97/100, Loss: 0.6041281, Train Acc: 0.6677, Test Acc: 0.6345, Train AUC: 0.7306, Train AP: 0.7262, Valid. AUC: 0.6785, Valid AP: 0.6604\n",
      "Epoch: 98/100, Loss: 0.6073862, Train Acc: 0.6659, Test Acc: 0.6406, Train AUC: 0.7285, Train AP: 0.7229, Valid. AUC: 0.6877, Valid AP: 0.6701\n",
      "Epoch: 99/100, Loss: 0.6058633, Train Acc: 0.6657, Test Acc: 0.6389, Train AUC: 0.7279, Train AP: 0.7230, Valid. AUC: 0.6867, Valid AP: 0.6700\n",
      "Epoch: 100/100, Loss: 0.6028337, Train Acc: 0.6669, Test Acc: 0.6383, Train AUC: 0.7316, Train AP: 0.7279, Valid. AUC: 0.6865, Valid AP: 0.6698\n",
      "/home/ubuntu/PA-Cancer-Immunotherapy/GNN/train_pa_all_tvt.py:212: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(configs['save_model']))\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.388 MB of 1.388 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.389 MB of 1.389 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.396 MB of 1.396 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.396 MB of 1.396 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.396 MB of 1.396 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        test_ap ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   test_roc_auc ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▁▁▃▃▃▃▃▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▅▅▅▆▇▆▇█▇█▇█▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train_ap ▁▂▂▄▄▄▄▄▄▄▄▄▄▄▄▅▅▅▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇█████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss ██▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_roc_auc ▁▃▄▄▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇█████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: valid_accuracy ▂▃▁▂▃▄▅▅▆▅▅▅▅▇▆▆▆▆█▇▇▆▆▇▇▇▇▇▇▇█████▇██▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       valid_ap ▁▂▂▂▂▄▄▄▄▄▄▄▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇██▇▇█▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  valid_roc_auc ▁▁▂▂▂▄▄▅▅▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▆▇▇▇▇▇███████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy 0.64326\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        test_ap 0.67532\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   test_roc_auc 0.69213\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.66687\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train_ap 0.72795\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.60283\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_roc_auc 0.73159\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: valid_accuracy 0.63832\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       valid_ap 0.66981\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  valid_roc_auc 0.68648\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mvolcanic-puddle-7\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-gene_GNN/runs/i2anecei\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-gene_GNN\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 8 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241209_113947-i2anecei/logs\u001b[0m\n",
      "Test Acc: 0.6433, Test AUC: 0.6921, Test AUPR: 0.6753\n"
     ]
    }
   ],
   "source": [
    "# for gene. (Mit confusion Matrix) and AP\n",
    "# drop_out = 0.2\n",
    "! python train_pa_all_tvt.py --gpu 0 --configs_path configs/PA_all_tvt_gene.yml --droup_out 0.2 --split StrictTCR\n",
    "# Result: not better than drop_out 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e7ab6f-24c4-4cc7-baa7-795e20bed76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cd947d-5f5a-4c62-b9ef-6a0ceede6241",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef207b58-96cd-4175-a94a-965d44714594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>><<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c4399f-15a0-4a2f-a5d9-36762293237c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the gnn with 10_x datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "132fb4e8-ad84-4e56-883b-092f9744ad2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tcrpeg.TCRpeg import TCRpeg\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91177064-7d31-46ad-84ce-e13f7c1e0f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_unmapped(df_2b_cleaned):\n",
    "        \n",
    "    df_train = df_2b_cleaned['CDR3.beta'].values\n",
    "    \n",
    "    #create the TCRpeg class\n",
    "    model = TCRpeg(hidden_size=256, num_layers = 3, load_data=True, embedding_path='./pa_embeddings/TCRpeg/tcrpeg/data/embedding_32.txt', path_train=df_train)\n",
    "    #create the TCRpeg model. \n",
    "    model.create_model()\n",
    "    \n",
    "    # remove unmapped characters in CDR3.beta column\n",
    "    unique_chars_beta = set(''.join(df_2b_cleaned['CDR3.beta']))\n",
    "    unmapped_chars_beta = [ch for ch in unique_chars_beta if ch not in model.aa2idx]\n",
    "    print(\"Unmapped characters in beta:\", unmapped_chars_beta)\n",
    "    \n",
    "    # Create a regex pattern to match any of these characters\n",
    "    pattern = f\"[{''.join(unmapped_chars_beta)}]\"\n",
    "    \n",
    "    # Remove rows with any of the unmapped characters in 'CDR3.beta' column\n",
    "    df = df_2b_cleaned[~df_2b_cleaned['CDR3.beta'].str.contains(pattern)]\n",
    "    print('Length after removing unmapped chars in CDR3.beta= ', len(df))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c058fa5f-9682-46c3-9544-a5568bab96a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have loaded the data, total training seqs : 276241\n",
      "Unmapped characters in beta: ['*']\n",
      "Length after removing unmapped chars in CDR3.beta=  275950\n",
      "Have loaded the data, total training seqs : 174966\n",
      "Unmapped characters in beta: ['*']\n",
      "Length after removing unmapped chars in CDR3.beta=  174149\n",
      "Have loaded the data, total training seqs : 174764\n",
      "Unmapped characters in beta: ['*']\n",
      "Length after removing unmapped chars in CDR3.beta=  173910\n",
      "Saved: ./processed_data/PA_all_tvt_10x/allele_train.csv\n",
      "Saved: ./processed_data/PA_all_tvt_10x/allele_validation.csv\n",
      "Saved: ./processed_data/PA_all_tvt_10x/allele_test.csv\n",
      "Have loaded the data, total training seqs : 249305\n",
      "Unmapped characters in beta: ['*']\n",
      "Length after removing unmapped chars in CDR3.beta=  248760\n",
      "Have loaded the data, total training seqs : 158214\n",
      "Unmapped characters in beta: ['*']\n",
      "Length after removing unmapped chars in CDR3.beta=  157288\n",
      "Have loaded the data, total training seqs : 158196\n",
      "Unmapped characters in beta: ['*']\n",
      "Length after removing unmapped chars in CDR3.beta=  157209\n",
      "Saved: ./processed_data/PA_all_tvt_10x/gene_train.csv\n",
      "Saved: ./processed_data/PA_all_tvt_10x/gene_validation.csv\n",
      "Saved: ./processed_data/PA_all_tvt_10x/gene_test.csv\n"
     ]
    }
   ],
   "source": [
    "# version 17.12.\n",
    "import pandas as pd\n",
    "\n",
    "ppl_path = \"./data_for_training/splitted_datasets/\"\n",
    "precisions = [\"allele\", \"gene\"]\n",
    "for precision in precisions:\n",
    "    train = f\"{ppl_path}{precision}/beta/train_10x.tsv\"\n",
    "    valid = f\"{ppl_path}{precision}/beta/validation_10x.tsv\"\n",
    "    test = f\"{ppl_path}{precision}/beta/test_10x.tsv\"\n",
    "    train_df = pd.read_csv(train, sep='\\t')\n",
    "    train_df = train_df[['TRB_CDR3', 'Epitope', 'Binding']]\n",
    "    valid_df = pd.read_csv(valid, sep='\\t')\n",
    "    valid_df = valid_df[['TRB_CDR3', 'Epitope', 'Binding']]\n",
    "    test_df = pd.read_csv(test, sep='\\t')\n",
    "    test_df = test_df[['TRB_CDR3', 'Epitope', 'Binding', 'task']]\n",
    "\n",
    "    columns_to_rename = {'TRB_CDR3': 'CDR3.beta','Binding': 'Label'}\n",
    "    train_df.rename(columns=columns_to_rename, inplace=True)\n",
    "    valid_df.rename(columns=columns_to_rename, inplace=True)\n",
    "    test_df.rename(columns=columns_to_rename, inplace=True)\n",
    "    train_df = train_df[train_df['CDR3.beta'].apply(len) <= 30]\n",
    "    train_df = train_df[train_df['Epitope'].apply(len) <= 30]\n",
    "    valid_df = valid_df[valid_df['CDR3.beta'].apply(len) <= 30]\n",
    "    valid_df = valid_df[valid_df['Epitope'].apply(len) <= 30]\n",
    "    test_df = test_df[test_df['CDR3.beta'].apply(len) <= 30]\n",
    "    test_df = test_df[test_df['Epitope'].apply(len) <= 30]\n",
    "    train_df = remove_unmapped(train_df)\n",
    "    test_df = remove_unmapped(test_df)\n",
    "    valid_df = remove_unmapped(valid_df)\n",
    "    save_path_train = f\"./processed_data/PA_all_tvt_10x/{precision}_train.csv\"\n",
    "    save_path_valid = f\"./processed_data/PA_all_tvt_10x/{precision}_validation.csv\"\n",
    "    save_path_test = f\"./processed_data/PA_all_tvt_10x/{precision}_test.csv\"\n",
    "    train_df.to_csv(save_path_train, index=False)\n",
    "    print(f\"Saved: {save_path_train}\")\n",
    "    valid_df.to_csv(save_path_valid, index=False)\n",
    "    print(f\"Saved: {save_path_valid}\")\n",
    "    test_df.to_csv(save_path_test, index=False)\n",
    "    print(f\"Saved: {save_path_test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04becd9f-e5f5-42bf-9d2a-249ced8a5934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have loaded the data, total training seqs : 276241\n",
      "Unmapped characters in beta: ['*']\n",
      "Length after removing unmapped chars in CDR3.beta=  275950\n",
      "Have loaded the data, total training seqs : 174966\n",
      "Unmapped characters in beta: ['*']\n",
      "Length after removing unmapped chars in CDR3.beta=  174149\n",
      "Have loaded the data, total training seqs : 174764\n",
      "Unmapped characters in beta: ['*']\n",
      "Length after removing unmapped chars in CDR3.beta=  173910\n",
      "Saved: ./processed_data/PA_all_tvt_10x/allele_train.csv\n",
      "Saved: ./processed_data/PA_all_tvt_10x/allele_validation.csv\n",
      "Saved: ./processed_data/PA_all_tvt_10x/allele_test.csv\n",
      "Have loaded the data, total training seqs : 249305\n",
      "Unmapped characters in beta: ['*']\n",
      "Length after removing unmapped chars in CDR3.beta=  248760\n",
      "Have loaded the data, total training seqs : 158214\n",
      "Unmapped characters in beta: ['*']\n",
      "Length after removing unmapped chars in CDR3.beta=  157288\n",
      "Have loaded the data, total training seqs : 158196\n",
      "Unmapped characters in beta: ['*']\n",
      "Length after removing unmapped chars in CDR3.beta=  157209\n",
      "Saved: ./processed_data/PA_all_tvt_10x/gene_train.csv\n",
      "Saved: ./processed_data/PA_all_tvt_10x/gene_validation.csv\n",
      "Saved: ./processed_data/PA_all_tvt_10x/gene_test.csv\n"
     ]
    }
   ],
   "source": [
    "# as used before\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "ppl_path = \"./data_for_training/splitted_datasets/\"\n",
    "precisions = [\"allele\", \"gene\"]\n",
    "for precision in precisions:\n",
    "    train = f\"{ppl_path}{precision}/beta/train_10x.tsv\"\n",
    "    valid = f\"{ppl_path}{precision}/beta/validation_10x.tsv\"\n",
    "    test = f\"{ppl_path}{precision}/beta/test_10x.tsv\"\n",
    "    train_df = pd.read_csv(train, sep='\\t')\n",
    "    train_df = train_df[['TRB_CDR3', 'Epitope', 'Binding']]\n",
    "    valid_df = pd.read_csv(valid, sep='\\t')\n",
    "    valid_df = valid_df[['TRB_CDR3', 'Epitope', 'Binding']]\n",
    "    test_df = pd.read_csv(test, sep='\\t')\n",
    "    test_df = test_df[['TRB_CDR3', 'Epitope', 'Binding']]\n",
    "\n",
    "    columns_to_rename = {'TRB_CDR3': 'CDR3.beta','Binding': 'Label'}\n",
    "    train_df.rename(columns=columns_to_rename, inplace=True)\n",
    "    valid_df.rename(columns=columns_to_rename, inplace=True)\n",
    "    test_df.rename(columns=columns_to_rename, inplace=True)\n",
    "    train_df = train_df[train_df['CDR3.beta'].apply(len) <= 30]\n",
    "    train_df = train_df[train_df['Epitope'].apply(len) <= 30]\n",
    "    valid_df = valid_df[valid_df['CDR3.beta'].apply(len) <= 30]\n",
    "    valid_df = valid_df[valid_df['Epitope'].apply(len) <= 30]\n",
    "    test_df = test_df[test_df['CDR3.beta'].apply(len) <= 30]\n",
    "    test_df = test_df[test_df['Epitope'].apply(len) <= 30]\n",
    "    train_df = remove_unmapped(train_df)\n",
    "    test_df = remove_unmapped(test_df)\n",
    "    valid_df = remove_unmapped(valid_df)\n",
    "    save_path_train = f\"./processed_data/PA_all_tvt_10x/{precision}_train.csv\"\n",
    "    save_path_valid = f\"./processed_data/PA_all_tvt_10x/{precision}_validation.csv\"\n",
    "    save_path_test = f\"./processed_data/PA_all_tvt_10x/{precision}_test.csv\"\n",
    "    train_df.to_csv(save_path_train, index=False)\n",
    "    print(f\"Saved: {save_path_train}\")\n",
    "    valid_df.to_csv(save_path_valid, index=False)\n",
    "    print(f\"Saved: {save_path_valid}\")\n",
    "    test_df.to_csv(save_path_test, index=False)\n",
    "    print(f\"Saved: {save_path_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd242995-dfe4-47ec-83b7-4916363dc034",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploading dataset to dataset-all-tvt-10x-allele_GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfrohoari\u001b[0m (\u001b[33mpa_cancerimmunotherapy\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/PA-Cancer-Immunotherapy/GNN/wandb/run-20241211_231537-uqaad8e8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-allele_GNN/runs/uqaad8e8' target=\"_blank\">dazzling-sponge-1</a></strong> to <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-allele_GNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-allele_GNN' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-allele_GNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-allele_GNN/runs/uqaad8e8' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-allele_GNN/runs/uqaad8e8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./processed_data/PA_all_tvt_10x)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploading dataset to dataset-all-tvt-10x-allele_GNN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:uqaad8e8) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.286 MB of 33.242 MB uploaded\\r'), FloatProgress(value=0.03868627529284642, max=1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dazzling-sponge-1</strong> at: <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-allele_GNN/runs/uqaad8e8' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-allele_GNN/runs/uqaad8e8</a><br/> View project at: <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-allele_GNN' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-allele_GNN</a><br/>Synced 4 W&B file(s), 0 media file(s), 10 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241211_231537-uqaad8e8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:uqaad8e8). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/PA-Cancer-Immunotherapy/GNN/wandb/run-20241211_231538-b6y2zy23</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-allele_GNN/runs/b6y2zy23' target=\"_blank\">fragrant-flower-2</a></strong> to <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-allele_GNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-allele_GNN' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-allele_GNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-allele_GNN/runs/b6y2zy23' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-allele_GNN/runs/b6y2zy23</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./processed_data/PA_all_tvt_10x)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploading dataset to dataset-all-tvt-10x-allele_GNN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:b6y2zy23) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.239 MB of 33.242 MB uploaded\\r'), FloatProgress(value=0.03727615076397811, max=1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fragrant-flower-2</strong> at: <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-allele_GNN/runs/b6y2zy23' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-allele_GNN/runs/b6y2zy23</a><br/> View project at: <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-allele_GNN' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-allele_GNN</a><br/>Synced 5 W&B file(s), 0 media file(s), 7 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241211_231538-b6y2zy23/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:b6y2zy23). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/PA-Cancer-Immunotherapy/GNN/wandb/run-20241211_231546-cluqyobn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-allele_GNN/runs/cluqyobn' target=\"_blank\">lemon-wood-3</a></strong> to <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-allele_GNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-allele_GNN' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-allele_GNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-allele_GNN/runs/cluqyobn' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-allele_GNN/runs/cluqyobn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./processed_data/PA_all_tvt_10x)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploading dataset to dataset-all-tvt-10x-gene_GNN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:cluqyobn) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.520 MB of 33.242 MB uploaded\\r'), FloatProgress(value=0.045736843183367785, max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lemon-wood-3</strong> at: <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-allele_GNN/runs/cluqyobn' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-allele_GNN/runs/cluqyobn</a><br/> View project at: <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-allele_GNN' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-allele_GNN</a><br/>Synced 5 W&B file(s), 0 media file(s), 7 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241211_231546-cluqyobn/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:cluqyobn). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/PA-Cancer-Immunotherapy/GNN/wandb/run-20241211_231553-ar8vqkwf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-gene_GNN/runs/ar8vqkwf' target=\"_blank\">grateful-wood-1</a></strong> to <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-gene_GNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-gene_GNN' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-gene_GNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-gene_GNN/runs/ar8vqkwf' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-gene_GNN/runs/ar8vqkwf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./processed_data/PA_all_tvt_10x)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploading dataset to dataset-all-tvt-10x-gene_GNN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:ar8vqkwf) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.192 MB of 33.242 MB uploaded\\r'), FloatProgress(value=0.035865970914917604, max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">grateful-wood-1</strong> at: <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-gene_GNN/runs/ar8vqkwf' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-gene_GNN/runs/ar8vqkwf</a><br/> View project at: <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-gene_GNN' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-gene_GNN</a><br/>Synced 4 W&B file(s), 0 media file(s), 10 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241211_231553-ar8vqkwf/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:ar8vqkwf). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/PA-Cancer-Immunotherapy/GNN/wandb/run-20241211_231559-ebs9sf1e</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-gene_GNN/runs/ebs9sf1e' target=\"_blank\">divine-cloud-2</a></strong> to <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-gene_GNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-gene_GNN' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-gene_GNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-gene_GNN/runs/ebs9sf1e' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-gene_GNN/runs/ebs9sf1e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./processed_data/PA_all_tvt_10x)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploading dataset to dataset-all-tvt-10x-gene_GNN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:ebs9sf1e) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff7910e6908144c6a50000f435f894f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.177 MB of 33.242 MB uploaded\\r'), FloatProgress(value=0.03539592937832474, max=1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">divine-cloud-2</strong> at: <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-gene_GNN/runs/ebs9sf1e' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-gene_GNN/runs/ebs9sf1e</a><br/> View project at: <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-gene_GNN' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-gene_GNN</a><br/>Synced 5 W&B file(s), 0 media file(s), 7 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241211_231559-ebs9sf1e/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:ebs9sf1e). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/PA-Cancer-Immunotherapy/GNN/wandb/run-20241211_231607-qxu8lmtl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-gene_GNN/runs/qxu8lmtl' target=\"_blank\">robust-feather-3</a></strong> to <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-gene_GNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-gene_GNN' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-gene_GNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-gene_GNN/runs/qxu8lmtl' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-gene_GNN/runs/qxu8lmtl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./processed_data/PA_all_tvt_10x)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1744f9fff3e64a5b887090daa8ae5b88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.239 MB of 33.242 MB uploaded\\r'), FloatProgress(value=0.03727471454058825, max=1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">robust-feather-3</strong> at: <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-gene_GNN/runs/qxu8lmtl' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-gene_GNN/runs/qxu8lmtl</a><br/> View project at: <a href='https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-gene_GNN' target=\"_blank\">https://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-gene_GNN</a><br/>Synced 5 W&B file(s), 0 media file(s), 7 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241211_231607-qxu8lmtl/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Datan hochladen auf wandb\n",
    "\n",
    "import wandb\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "#/home/ubuntu/PA-Cancer-Immunotherapy/GNN/processed_data/PA_all\n",
    "# upload paired data\n",
    "path_to_data = './processed_data/PA_all_tvt_10x/' # path zu unseren Daten\n",
    "precisions = [\"allele\", \"gene\"]\n",
    "\n",
    "for precision in precisions:\n",
    "    \n",
    "    main_project_name = f\"dataset-all-tvt-10x-{precision}_GNN\" # das erscheint auf wandb projects \n",
    "    \n",
    "\n",
    "    datasets_names = ['train.csv', 'validation.csv', 'test.csv']\n",
    "    for dataset_name in datasets_names:\n",
    "        #main_project_name = os.getenv(\"MAIN_PROJECT_NAME\")\n",
    "        print(f\"uploading dataset to {main_project_name}\")\n",
    "        run = wandb.init(project=main_project_name, job_type=\"Upload Dataset\", entity=\"pa_cancerimmunotherapy\")\n",
    "        artifact = wandb.Artifact(name=dataset_name, type=\"dataset\")\n",
    "        artifact.add_dir(path_to_data, name=f\"{precision}_\")\n",
    "        run.log_artifact(artifact)\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e654b663-3f7f-47a7-b193-666d50ecb2b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(gpu=0, lr=0.001, epochs=100, w_celoss=1, w_aucloss=0, add_same_type_edges=False, dynamic_graph=False, dynamic_ratio=0.05, droup_out=0.1, positive_weights=1, dynamic_epochs=30, distance_threshold=10, configs_path='configs/PA_all_tvt_10x_allele.yml', split='StrictTCR', dataset='pMTnet')\n",
      "PROJECT_NAME: dataset-all-tvt-10x-allele_GNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfrohoari\u001b[0m (\u001b[33mpa_cancerimmunotherapy\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/ubuntu/PA-Cancer-Immunotherapy/GNN/wandb/run-20241217_005814-4ow4pt1r\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mcelestial-resonance-5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-allele_GNN\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-allele_GNN/runs/4ow4pt1r\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   6 of 6 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   6 of 6 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   6 of 6 files downloaded.  \n",
      "embeddings_path:   models/PA_all/gene_and_allele_embeddings_10x.pkl\n",
      "train_file_list:   ['allele_train.csv']\n",
      "validation_file_list:   ['allele_validation.csv']\n",
      "test_file_list:   ['allele_test.csv']\n",
      "wandb logger initialisiert\n",
      "Epoch: 1/100, Loss: 0.6904294, Train Acc: 0.5023, Valid. Acc: 0.7832, Train AUC: 0.5140, Train AP: 0.5232, Valid. AUC: 0.7101, Valid. AP: 0.2884\n",
      "Epoch: 2/100, Loss: 0.6838798, Train Acc: 0.5981, Valid. Acc: 0.6611, Train AUC: 0.6512, Train AP: 0.6359, Valid. AUC: 0.7211, Valid. AP: 0.3008\n",
      "Epoch: 3/100, Loss: 0.6777848, Train Acc: 0.5887, Valid. Acc: 0.8074, Train AUC: 0.6560, Train AP: 0.6446, Valid. AUC: 0.7090, Valid. AP: 0.3013\n",
      "Epoch: 4/100, Loss: 0.6716726, Train Acc: 0.5809, Valid. Acc: 0.7581, Train AUC: 0.6755, Train AP: 0.6585, Valid. AUC: 0.7259, Valid. AP: 0.3118\n",
      "Epoch: 5/100, Loss: 0.6616293, Train Acc: 0.6237, Valid. Acc: 0.7707, Train AUC: 0.6758, Train AP: 0.6623, Valid. AUC: 0.7301, Valid. AP: 0.3175\n",
      "Epoch: 6/100, Loss: 0.6514438, Train Acc: 0.6327, Valid. Acc: 0.7951, Train AUC: 0.6829, Train AP: 0.6661, Valid. AUC: 0.7364, Valid. AP: 0.3271\n",
      "Epoch: 7/100, Loss: 0.6432193, Train Acc: 0.6310, Valid. Acc: 0.7829, Train AUC: 0.6907, Train AP: 0.6704, Valid. AUC: 0.7563, Valid. AP: 0.3489\n",
      "Epoch: 8/100, Loss: 0.6329848, Train Acc: 0.6538, Valid. Acc: 0.7884, Train AUC: 0.7012, Train AP: 0.6782, Valid. AUC: 0.7697, Valid. AP: 0.3742\n",
      "Epoch: 9/100, Loss: 0.6248481, Train Acc: 0.6501, Valid. Acc: 0.8265, Train AUC: 0.7070, Train AP: 0.6852, Valid. AUC: 0.7763, Valid. AP: 0.3982\n",
      "Epoch: 10/100, Loss: 0.6242465, Train Acc: 0.6392, Valid. Acc: 0.6813, Train AUC: 0.7184, Train AP: 0.7060, Valid. AUC: 0.7860, Valid. AP: 0.4028\n",
      "Epoch: 11/100, Loss: 0.6720141, Train Acc: 0.6101, Valid. Acc: 0.8121, Train AUC: 0.7130, Train AP: 0.7023, Valid. AUC: 0.7876, Valid. AP: 0.4138\n",
      "Epoch: 12/100, Loss: 0.6076342, Train Acc: 0.6674, Valid. Acc: 0.8283, Train AUC: 0.7341, Train AP: 0.7231, Valid. AUC: 0.7835, Valid. AP: 0.4043\n",
      "Epoch: 13/100, Loss: 0.6366265, Train Acc: 0.6217, Valid. Acc: 0.8100, Train AUC: 0.7292, Train AP: 0.7208, Valid. AUC: 0.7863, Valid. AP: 0.3956\n",
      "Epoch: 14/100, Loss: 0.6087444, Train Acc: 0.6617, Valid. Acc: 0.7474, Train AUC: 0.7306, Train AP: 0.7221, Valid. AUC: 0.7923, Valid. AP: 0.3929\n",
      "Epoch: 15/100, Loss: 0.6162983, Train Acc: 0.6567, Valid. Acc: 0.7419, Train AUC: 0.7353, Train AP: 0.7213, Valid. AUC: 0.7989, Valid. AP: 0.4013\n",
      "Epoch: 16/100, Loss: 0.6137785, Train Acc: 0.6388, Valid. Acc: 0.7834, Train AUC: 0.7458, Train AP: 0.7461, Valid. AUC: 0.8027, Valid. AP: 0.4093\n",
      "Epoch: 17/100, Loss: 0.5970055, Train Acc: 0.6739, Valid. Acc: 0.8074, Train AUC: 0.7459, Train AP: 0.7456, Valid. AUC: 0.8046, Valid. AP: 0.4152\n",
      "Epoch: 18/100, Loss: 0.5969512, Train Acc: 0.6779, Valid. Acc: 0.8108, Train AUC: 0.7509, Train AP: 0.7483, Valid. AUC: 0.8059, Valid. AP: 0.4168\n",
      "Epoch: 19/100, Loss: 0.6023142, Train Acc: 0.6739, Valid. Acc: 0.8008, Train AUC: 0.7533, Train AP: 0.7539, Valid. AUC: 0.8069, Valid. AP: 0.4142\n",
      "Epoch: 20/100, Loss: 0.5916658, Train Acc: 0.6726, Valid. Acc: 0.7778, Train AUC: 0.7514, Train AP: 0.7527, Valid. AUC: 0.8074, Valid. AP: 0.4111\n",
      "Epoch: 21/100, Loss: 0.5875110, Train Acc: 0.6801, Valid. Acc: 0.7618, Train AUC: 0.7572, Train AP: 0.7575, Valid. AUC: 0.8065, Valid. AP: 0.4062\n",
      "Epoch: 22/100, Loss: 0.5905430, Train Acc: 0.6665, Valid. Acc: 0.7771, Train AUC: 0.7608, Train AP: 0.7633, Valid. AUC: 0.8057, Valid. AP: 0.3997\n",
      "Epoch: 23/100, Loss: 0.5820057, Train Acc: 0.6736, Valid. Acc: 0.7990, Train AUC: 0.7648, Train AP: 0.7676, Valid. AUC: 0.8055, Valid. AP: 0.3956\n",
      "Epoch: 24/100, Loss: 0.5814490, Train Acc: 0.6908, Valid. Acc: 0.8096, Train AUC: 0.7607, Train AP: 0.7608, Valid. AUC: 0.8064, Valid. AP: 0.3959\n",
      "Epoch: 25/100, Loss: 0.5820194, Train Acc: 0.6877, Valid. Acc: 0.7980, Train AUC: 0.7641, Train AP: 0.7615, Valid. AUC: 0.8068, Valid. AP: 0.3965\n",
      "Epoch: 26/100, Loss: 0.5720049, Train Acc: 0.6941, Valid. Acc: 0.7796, Train AUC: 0.7670, Train AP: 0.7684, Valid. AUC: 0.8067, Valid. AP: 0.3991\n",
      "Epoch: 27/100, Loss: 0.5726785, Train Acc: 0.6778, Valid. Acc: 0.7776, Train AUC: 0.7678, Train AP: 0.7713, Valid. AUC: 0.8069, Valid. AP: 0.4030\n",
      "Epoch: 28/100, Loss: 0.5699344, Train Acc: 0.6791, Valid. Acc: 0.7960, Train AUC: 0.7695, Train AP: 0.7781, Valid. AUC: 0.8085, Valid. AP: 0.4061\n",
      "Epoch: 29/100, Loss: 0.5646560, Train Acc: 0.6936, Valid. Acc: 0.8043, Train AUC: 0.7719, Train AP: 0.7807, Valid. AUC: 0.8099, Valid. AP: 0.4077\n",
      "Epoch: 30/100, Loss: 0.5643220, Train Acc: 0.6950, Valid. Acc: 0.7959, Train AUC: 0.7730, Train AP: 0.7804, Valid. AUC: 0.8103, Valid. AP: 0.4069\n",
      "Epoch: 31/100, Loss: 0.5607542, Train Acc: 0.6940, Valid. Acc: 0.7826, Train AUC: 0.7750, Train AP: 0.7833, Valid. AUC: 0.8102, Valid. AP: 0.4044\n",
      "Epoch: 32/100, Loss: 0.5601383, Train Acc: 0.6820, Valid. Acc: 0.7822, Train AUC: 0.7724, Train AP: 0.7843, Valid. AUC: 0.8108, Valid. AP: 0.3993\n",
      "Epoch: 33/100, Loss: 0.5571785, Train Acc: 0.6894, Valid. Acc: 0.7965, Train AUC: 0.7783, Train AP: 0.7870, Valid. AUC: 0.8122, Valid. AP: 0.3971\n",
      "Epoch: 34/100, Loss: 0.5561168, Train Acc: 0.6993, Valid. Acc: 0.7927, Train AUC: 0.7807, Train AP: 0.7877, Valid. AUC: 0.8124, Valid. AP: 0.3960\n",
      "Epoch: 35/100, Loss: 0.5541168, Train Acc: 0.6933, Valid. Acc: 0.7867, Train AUC: 0.7785, Train AP: 0.7885, Valid. AUC: 0.8117, Valid. AP: 0.3946\n",
      "Epoch: 36/100, Loss: 0.5516877, Train Acc: 0.6909, Valid. Acc: 0.7945, Train AUC: 0.7810, Train AP: 0.7937, Valid. AUC: 0.8117, Valid. AP: 0.3952\n",
      "Epoch: 37/100, Loss: 0.5500981, Train Acc: 0.6947, Valid. Acc: 0.8008, Train AUC: 0.7803, Train AP: 0.7922, Valid. AUC: 0.8118, Valid. AP: 0.3943\n",
      "Epoch: 38/100, Loss: 0.5475230, Train Acc: 0.7006, Valid. Acc: 0.8010, Train AUC: 0.7834, Train AP: 0.7964, Valid. AUC: 0.8111, Valid. AP: 0.3928\n",
      "Epoch: 39/100, Loss: 0.5471769, Train Acc: 0.7037, Valid. Acc: 0.7867, Train AUC: 0.7861, Train AP: 0.7961, Valid. AUC: 0.8097, Valid. AP: 0.3938\n",
      "Epoch: 40/100, Loss: 0.5456896, Train Acc: 0.6954, Valid. Acc: 0.7978, Train AUC: 0.7871, Train AP: 0.7974, Valid. AUC: 0.8097, Valid. AP: 0.3969\n",
      "Epoch: 41/100, Loss: 0.5416770, Train Acc: 0.6988, Valid. Acc: 0.8072, Train AUC: 0.7898, Train AP: 0.8043, Valid. AUC: 0.8100, Valid. AP: 0.3977\n",
      "Epoch: 42/100, Loss: 0.5417997, Train Acc: 0.7066, Valid. Acc: 0.7886, Train AUC: 0.7925, Train AP: 0.8059, Valid. AUC: 0.8087, Valid. AP: 0.3978\n",
      "Epoch: 43/100, Loss: 0.5405591, Train Acc: 0.6979, Valid. Acc: 0.7873, Train AUC: 0.7899, Train AP: 0.8089, Valid. AUC: 0.8085, Valid. AP: 0.3970\n",
      "Epoch: 44/100, Loss: 0.5388540, Train Acc: 0.6922, Valid. Acc: 0.8105, Train AUC: 0.7907, Train AP: 0.8105, Valid. AUC: 0.8109, Valid. AP: 0.3957\n",
      "Epoch: 45/100, Loss: 0.5350447, Train Acc: 0.7084, Valid. Acc: 0.8115, Train AUC: 0.7938, Train AP: 0.8127, Valid. AUC: 0.8114, Valid. AP: 0.3893\n",
      "Epoch: 46/100, Loss: 0.5337705, Train Acc: 0.7103, Valid. Acc: 0.8002, Train AUC: 0.7957, Train AP: 0.8123, Valid. AUC: 0.8099, Valid. AP: 0.3838\n",
      "Epoch: 47/100, Loss: 0.5367118, Train Acc: 0.7035, Valid. Acc: 0.8091, Train AUC: 0.7937, Train AP: 0.8072, Valid. AUC: 0.8106, Valid. AP: 0.3884\n",
      "Epoch: 48/100, Loss: 0.5336406, Train Acc: 0.7086, Valid. Acc: 0.7962, Train AUC: 0.7964, Train AP: 0.8124, Valid. AUC: 0.8105, Valid. AP: 0.3897\n",
      "Epoch: 49/100, Loss: 0.5283904, Train Acc: 0.7055, Valid. Acc: 0.7930, Train AUC: 0.7986, Train AP: 0.8181, Valid. AUC: 0.8115, Valid. AP: 0.3903\n",
      "Epoch: 50/100, Loss: 0.5288756, Train Acc: 0.7043, Valid. Acc: 0.7952, Train AUC: 0.7981, Train AP: 0.8182, Valid. AUC: 0.8132, Valid. AP: 0.3905\n",
      "Epoch: 51/100, Loss: 0.5302606, Train Acc: 0.6993, Valid. Acc: 0.7898, Train AUC: 0.7936, Train AP: 0.8152, Valid. AUC: 0.8145, Valid. AP: 0.3864\n",
      "Epoch: 52/100, Loss: 0.5258113, Train Acc: 0.7107, Valid. Acc: 0.7862, Train AUC: 0.8000, Train AP: 0.8186, Valid. AUC: 0.8140, Valid. AP: 0.3830\n",
      "Epoch: 53/100, Loss: 0.5289245, Train Acc: 0.7101, Valid. Acc: 0.7957, Train AUC: 0.7995, Train AP: 0.8159, Valid. AUC: 0.8139, Valid. AP: 0.3857\n",
      "Epoch: 54/100, Loss: 0.5280356, Train Acc: 0.7123, Valid. Acc: 0.8067, Train AUC: 0.7999, Train AP: 0.8155, Valid. AUC: 0.8142, Valid. AP: 0.3935\n",
      "Epoch: 55/100, Loss: 0.5230842, Train Acc: 0.7164, Valid. Acc: 0.8049, Train AUC: 0.8041, Train AP: 0.8233, Valid. AUC: 0.8120, Valid. AP: 0.3963\n",
      "Epoch: 56/100, Loss: 0.5236667, Train Acc: 0.7038, Valid. Acc: 0.7877, Train AUC: 0.7980, Train AP: 0.8209, Valid. AUC: 0.8109, Valid. AP: 0.3949\n",
      "Epoch: 57/100, Loss: 0.5243840, Train Acc: 0.6963, Valid. Acc: 0.8088, Train AUC: 0.7975, Train AP: 0.8218, Valid. AUC: 0.8142, Valid. AP: 0.3939\n",
      "Epoch: 58/100, Loss: 0.5208431, Train Acc: 0.7144, Valid. Acc: 0.8101, Train AUC: 0.8032, Train AP: 0.8240, Valid. AUC: 0.8153, Valid. AP: 0.3894\n",
      "Epoch: 59/100, Loss: 0.5205847, Train Acc: 0.7203, Valid. Acc: 0.7843, Train AUC: 0.8077, Train AP: 0.8279, Valid. AUC: 0.8138, Valid. AP: 0.3850\n",
      "Epoch: 60/100, Loss: 0.5189914, Train Acc: 0.7127, Valid. Acc: 0.7893, Train AUC: 0.8061, Train AP: 0.8262, Valid. AUC: 0.8137, Valid. AP: 0.3859\n",
      "Epoch: 61/100, Loss: 0.5196480, Train Acc: 0.7042, Valid. Acc: 0.8227, Train AUC: 0.8047, Train AP: 0.8247, Valid. AUC: 0.8162, Valid. AP: 0.3933\n",
      "Epoch: 62/100, Loss: 0.5184700, Train Acc: 0.7210, Valid. Acc: 0.8167, Train AUC: 0.8090, Train AP: 0.8302, Valid. AUC: 0.8153, Valid. AP: 0.3960\n",
      "Epoch: 63/100, Loss: 0.5142063, Train Acc: 0.7160, Valid. Acc: 0.7833, Train AUC: 0.8064, Train AP: 0.8298, Valid. AUC: 0.8132, Valid. AP: 0.3931\n",
      "Epoch: 64/100, Loss: 0.5189075, Train Acc: 0.6975, Valid. Acc: 0.8036, Train AUC: 0.8021, Train AP: 0.8270, Valid. AUC: 0.8159, Valid. AP: 0.3945\n",
      "Epoch: 65/100, Loss: 0.5110881, Train Acc: 0.7145, Valid. Acc: 0.8181, Train AUC: 0.8075, Train AP: 0.8307, Valid. AUC: 0.8177, Valid. AP: 0.3945\n",
      "Epoch: 66/100, Loss: 0.5127348, Train Acc: 0.7229, Valid. Acc: 0.8129, Train AUC: 0.8095, Train AP: 0.8315, Valid. AUC: 0.8170, Valid. AP: 0.3916\n",
      "Epoch: 67/100, Loss: 0.5131654, Train Acc: 0.7174, Valid. Acc: 0.7793, Train AUC: 0.8096, Train AP: 0.8314, Valid. AUC: 0.8137, Valid. AP: 0.3854\n",
      "Epoch: 68/100, Loss: 0.5134347, Train Acc: 0.7068, Valid. Acc: 0.7935, Train AUC: 0.8091, Train AP: 0.8319, Valid. AUC: 0.8154, Valid. AP: 0.3903\n",
      "Epoch: 69/100, Loss: 0.5072767, Train Acc: 0.7127, Valid. Acc: 0.8141, Train AUC: 0.8103, Train AP: 0.8339, Valid. AUC: 0.8179, Valid. AP: 0.3971\n",
      "Epoch: 70/100, Loss: 0.5096542, Train Acc: 0.7219, Valid. Acc: 0.8031, Train AUC: 0.8137, Train AP: 0.8370, Valid. AUC: 0.8177, Valid. AP: 0.3980\n",
      "Epoch: 71/100, Loss: 0.5064280, Train Acc: 0.7174, Valid. Acc: 0.7832, Train AUC: 0.8127, Train AP: 0.8353, Valid. AUC: 0.8168, Valid. AP: 0.3946\n",
      "Epoch: 72/100, Loss: 0.5090775, Train Acc: 0.7132, Valid. Acc: 0.7996, Train AUC: 0.8137, Train AP: 0.8369, Valid. AUC: 0.8180, Valid. AP: 0.3958\n",
      "Epoch: 73/100, Loss: 0.5038397, Train Acc: 0.7192, Valid. Acc: 0.8200, Train AUC: 0.8115, Train AP: 0.8356, Valid. AUC: 0.8192, Valid. AP: 0.3972\n",
      "Epoch: 74/100, Loss: 0.5055473, Train Acc: 0.7190, Valid. Acc: 0.8181, Train AUC: 0.8112, Train AP: 0.8352, Valid. AUC: 0.8188, Valid. AP: 0.3935\n",
      "Epoch: 75/100, Loss: 0.5034655, Train Acc: 0.7243, Valid. Acc: 0.7963, Train AUC: 0.8150, Train AP: 0.8377, Valid. AUC: 0.8160, Valid. AP: 0.3870\n",
      "Epoch: 76/100, Loss: 0.5064972, Train Acc: 0.7180, Valid. Acc: 0.7972, Train AUC: 0.8113, Train AP: 0.8342, Valid. AUC: 0.8181, Valid. AP: 0.3948\n",
      "Epoch: 77/100, Loss: 0.5018383, Train Acc: 0.7167, Valid. Acc: 0.8147, Train AUC: 0.8150, Train AP: 0.8380, Valid. AUC: 0.8207, Valid. AP: 0.4039\n",
      "Epoch: 78/100, Loss: 0.5032566, Train Acc: 0.7272, Valid. Acc: 0.8093, Train AUC: 0.8166, Train AP: 0.8392, Valid. AUC: 0.8211, Valid. AP: 0.4034\n",
      "Epoch: 79/100, Loss: 0.5017170, Train Acc: 0.7286, Valid. Acc: 0.7938, Train AUC: 0.8172, Train AP: 0.8401, Valid. AUC: 0.8202, Valid. AP: 0.4016\n",
      "Epoch: 80/100, Loss: 0.5020486, Train Acc: 0.7171, Valid. Acc: 0.8029, Train AUC: 0.8137, Train AP: 0.8391, Valid. AUC: 0.8207, Valid. AP: 0.3998\n",
      "Epoch: 81/100, Loss: 0.4996118, Train Acc: 0.7191, Valid. Acc: 0.8162, Train AUC: 0.8133, Train AP: 0.8386, Valid. AUC: 0.8218, Valid. AP: 0.4001\n",
      "Epoch: 82/100, Loss: 0.4985080, Train Acc: 0.7293, Valid. Acc: 0.8179, Train AUC: 0.8186, Train AP: 0.8421, Valid. AUC: 0.8215, Valid. AP: 0.3977\n",
      "Epoch: 83/100, Loss: 0.4972178, Train Acc: 0.7272, Valid. Acc: 0.8138, Train AUC: 0.8180, Train AP: 0.8409, Valid. AUC: 0.8203, Valid. AP: 0.3957\n",
      "Epoch: 84/100, Loss: 0.4960545, Train Acc: 0.7291, Valid. Acc: 0.8064, Train AUC: 0.8184, Train AP: 0.8414, Valid. AUC: 0.8199, Valid. AP: 0.3988\n",
      "Epoch: 85/100, Loss: 0.4988256, Train Acc: 0.7177, Valid. Acc: 0.8206, Train AUC: 0.8141, Train AP: 0.8391, Valid. AUC: 0.8222, Valid. AP: 0.4064\n",
      "Epoch: 86/100, Loss: 0.4961587, Train Acc: 0.7340, Valid. Acc: 0.8159, Train AUC: 0.8185, Train AP: 0.8424, Valid. AUC: 0.8230, Valid. AP: 0.4079\n",
      "Epoch: 87/100, Loss: 0.4957222, Train Acc: 0.7305, Valid. Acc: 0.7995, Train AUC: 0.8200, Train AP: 0.8436, Valid. AUC: 0.8222, Valid. AP: 0.4041\n",
      "Epoch: 88/100, Loss: 0.4947993, Train Acc: 0.7171, Valid. Acc: 0.8023, Train AUC: 0.8179, Train AP: 0.8419, Valid. AUC: 0.8229, Valid. AP: 0.4026\n",
      "Epoch: 89/100, Loss: 0.4914906, Train Acc: 0.7244, Valid. Acc: 0.8119, Train AUC: 0.8194, Train AP: 0.8443, Valid. AUC: 0.8247, Valid. AP: 0.4055\n",
      "Epoch: 90/100, Loss: 0.4918045, Train Acc: 0.7306, Valid. Acc: 0.8149, Train AUC: 0.8218, Train AP: 0.8456, Valid. AUC: 0.8253, Valid. AP: 0.4073\n",
      "Epoch: 91/100, Loss: 0.4910476, Train Acc: 0.7302, Valid. Acc: 0.8090, Train AUC: 0.8209, Train AP: 0.8445, Valid. AUC: 0.8249, Valid. AP: 0.4078\n",
      "Epoch: 92/100, Loss: 0.4907102, Train Acc: 0.7289, Valid. Acc: 0.8052, Train AUC: 0.8194, Train AP: 0.8441, Valid. AUC: 0.8245, Valid. AP: 0.4088\n",
      "Epoch: 93/100, Loss: 0.4893085, Train Acc: 0.7245, Valid. Acc: 0.8052, Train AUC: 0.8205, Train AP: 0.8457, Valid. AUC: 0.8250, Valid. AP: 0.4100\n",
      "Epoch: 94/100, Loss: 0.4883111, Train Acc: 0.7318, Valid. Acc: 0.8124, Train AUC: 0.8234, Train AP: 0.8471, Valid. AUC: 0.8254, Valid. AP: 0.4106\n",
      "Epoch: 95/100, Loss: 0.4877153, Train Acc: 0.7346, Valid. Acc: 0.8146, Train AUC: 0.8227, Train AP: 0.8468, Valid. AUC: 0.8250, Valid. AP: 0.4099\n",
      "Epoch: 96/100, Loss: 0.4881670, Train Acc: 0.7288, Valid. Acc: 0.8174, Train AUC: 0.8219, Train AP: 0.8458, Valid. AUC: 0.8258, Valid. AP: 0.4110\n",
      "Epoch: 97/100, Loss: 0.4873173, Train Acc: 0.7305, Valid. Acc: 0.8190, Train AUC: 0.8222, Train AP: 0.8466, Valid. AUC: 0.8277, Valid. AP: 0.4164\n",
      "Epoch: 98/100, Loss: 0.4849902, Train Acc: 0.7345, Valid. Acc: 0.8194, Train AUC: 0.8246, Train AP: 0.8490, Valid. AUC: 0.8292, Valid. AP: 0.4228\n",
      "Epoch: 99/100, Loss: 0.4854327, Train Acc: 0.7385, Valid. Acc: 0.8161, Train AUC: 0.8257, Train AP: 0.8499, Valid. AUC: 0.8293, Valid. AP: 0.4270\n",
      "Epoch: 100/100, Loss: 0.4845709, Train Acc: 0.7365, Valid. Acc: 0.8165, Train AUC: 0.8247, Train AP: 0.8506, Valid. AUC: 0.8292, Valid. AP: 0.4277\n",
      "/home/ubuntu/PA-Cancer-Immunotherapy/GNN/train_pa_all_tvt_10x.py:212: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(configs['save_model']))\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.849 MB of 1.849 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.850 MB of 1.850 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.850 MB of 1.850 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.850 MB of 1.850 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.850 MB of 1.850 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▁▁▁▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇█████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        test_ap ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   test_roc_auc ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▁▃▄▄▄▅▆▅▆▆▆▆▆▇▇▇▇▆▇▇▆▇▇▇▆▇▇▇▇▇███▇█▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train_ap ▁▃▄▄▄▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss █▇▆█▇▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_roc_auc ▁▂▂▃▃▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇███████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: valid_accuracy ▅▆█▁▇▄▇▇▆▇▇▇▇▆▆▇▆▆▇▇▆▆▆▇▇█▆▆▆▇▇▇▆▇▇▇▇▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       valid_ap ▁▇▇▆▇▆▆▆▆▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▆▆▆▇▇▇▇▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  valid_roc_auc ▁▂▂▄▅▆▅▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇██▇██████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy 0.81777\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        test_ap 0.43036\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   test_roc_auc 0.83114\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.73648\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train_ap 0.85063\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.48457\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_roc_auc 0.82471\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: valid_accuracy 0.81655\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       valid_ap 0.42775\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  valid_roc_auc 0.82925\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mcelestial-resonance-5\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-allele_GNN/runs/4ow4pt1r\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-allele_GNN\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 4 W&B file(s), 0 media file(s), 8 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241217_005814-4ow4pt1r/logs\u001b[0m\n",
      "Test Acc: 0.8178, Test AUC: 0.8311, Test AP: 0.4304\n"
     ]
    }
   ],
   "source": [
    "# first for allele\n",
    "\n",
    "! python train_pa_all_tvt_10x.py --gpu 0 --configs_path configs/PA_all_tvt_10x_allele.yml --droup_out 0.1 --split StrictTCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "868fcde5-9810-4d75-a19c-6a9c5b46a076",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(gpu=0, lr=0.001, epochs=100, w_celoss=1, w_aucloss=0, add_same_type_edges=False, dynamic_graph=False, dynamic_ratio=0.05, droup_out=0.1, positive_weights=1, dynamic_epochs=30, distance_threshold=10, configs_path='configs/PA_all_tvt_10x_gene.yml', split='StrictTCR', dataset='pMTnet')\n",
      "PROJECT_NAME: dataset-all-tvt-10x-gene_GNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfrohoari\u001b[0m (\u001b[33mpa_cancerimmunotherapy\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/ubuntu/PA-Cancer-Immunotherapy/GNN/wandb/run-20241211_233445-09om8etu\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33myoung-plasma-4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-gene_GNN\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-gene_GNN/runs/09om8etu\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   6 of 6 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   6 of 6 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   6 of 6 files downloaded.  \n",
      "embeddings_path:   models/PA_all/gene_and_allele_embeddings_10x.pkl\n",
      "train_file_list:   ['gene_train.csv']\n",
      "validation_file_list:   ['gene_validation.csv']\n",
      "test_file_list:   ['gene_test.csv']\n",
      "wandb logger initialisiert\n",
      "Epoch: 1/100, Loss: 0.6913584, Train Acc: 0.4946, Test Acc: 0.7197, Train AUC: 0.5005, Train AP: 0.5119, Valid. AUC: 0.7996, Valid AP: 0.3951\n",
      "Epoch: 2/100, Loss: 0.6802936, Train Acc: 0.6560, Test Acc: 0.8005, Train AUC: 0.7125, Train AP: 0.6858, Valid. AUC: 0.8170, Valid AP: 0.4063\n",
      "Epoch: 3/100, Loss: 0.6680257, Train Acc: 0.6714, Test Acc: 0.7869, Train AUC: 0.7372, Train AP: 0.7119, Valid. AUC: 0.8166, Valid AP: 0.4085\n",
      "Epoch: 4/100, Loss: 0.6499577, Train Acc: 0.6750, Test Acc: 0.8279, Train AUC: 0.7338, Train AP: 0.7023, Valid. AUC: 0.8218, Valid AP: 0.4144\n",
      "Epoch: 5/100, Loss: 0.6321557, Train Acc: 0.6595, Test Acc: 0.7965, Train AUC: 0.7363, Train AP: 0.7040, Valid. AUC: 0.8272, Valid AP: 0.4206\n",
      "Epoch: 6/100, Loss: 0.6116672, Train Acc: 0.6830, Test Acc: 0.8308, Train AUC: 0.7424, Train AP: 0.7083, Valid. AUC: 0.8354, Valid AP: 0.4291\n",
      "Epoch: 7/100, Loss: 0.6016097, Train Acc: 0.6529, Test Acc: 0.8015, Train AUC: 0.7610, Train AP: 0.7248, Valid. AUC: 0.8449, Valid AP: 0.4397\n",
      "Epoch: 8/100, Loss: 0.5898773, Train Acc: 0.6966, Test Acc: 0.8246, Train AUC: 0.7619, Train AP: 0.7255, Valid. AUC: 0.8524, Valid AP: 0.4515\n",
      "Epoch: 9/100, Loss: 0.5649714, Train Acc: 0.6918, Test Acc: 0.8332, Train AUC: 0.7761, Train AP: 0.7413, Valid. AUC: 0.8584, Valid AP: 0.4607\n",
      "Epoch: 10/100, Loss: 0.5606217, Train Acc: 0.6921, Test Acc: 0.8110, Train AUC: 0.7865, Train AP: 0.7436, Valid. AUC: 0.8648, Valid AP: 0.4689\n",
      "Epoch: 11/100, Loss: 0.5564932, Train Acc: 0.7203, Test Acc: 0.8216, Train AUC: 0.7903, Train AP: 0.7471, Valid. AUC: 0.8682, Valid AP: 0.4745\n",
      "Epoch: 12/100, Loss: 0.5315081, Train Acc: 0.7199, Test Acc: 0.8246, Train AUC: 0.7967, Train AP: 0.7551, Valid. AUC: 0.8701, Valid AP: 0.4781\n",
      "Epoch: 13/100, Loss: 0.5455219, Train Acc: 0.6970, Test Acc: 0.8254, Train AUC: 0.8020, Train AP: 0.7588, Valid. AUC: 0.8733, Valid AP: 0.4800\n",
      "Epoch: 14/100, Loss: 0.5217268, Train Acc: 0.7298, Test Acc: 0.8248, Train AUC: 0.8060, Train AP: 0.7631, Valid. AUC: 0.8743, Valid AP: 0.4811\n",
      "Epoch: 15/100, Loss: 0.5211977, Train Acc: 0.7270, Test Acc: 0.8200, Train AUC: 0.8089, Train AP: 0.7686, Valid. AUC: 0.8744, Valid AP: 0.4871\n",
      "Epoch: 16/100, Loss: 0.5110590, Train Acc: 0.7312, Test Acc: 0.8193, Train AUC: 0.8166, Train AP: 0.7762, Valid. AUC: 0.8752, Valid AP: 0.4907\n",
      "Epoch: 17/100, Loss: 0.5039412, Train Acc: 0.7403, Test Acc: 0.8242, Train AUC: 0.8201, Train AP: 0.7856, Valid. AUC: 0.8762, Valid AP: 0.4884\n",
      "Epoch: 18/100, Loss: 0.5054533, Train Acc: 0.7462, Test Acc: 0.8270, Train AUC: 0.8227, Train AP: 0.7864, Valid. AUC: 0.8775, Valid AP: 0.4884\n",
      "Epoch: 19/100, Loss: 0.4954423, Train Acc: 0.7435, Test Acc: 0.8227, Train AUC: 0.8259, Train AP: 0.7984, Valid. AUC: 0.8784, Valid AP: 0.4897\n",
      "Epoch: 20/100, Loss: 0.4998257, Train Acc: 0.7345, Test Acc: 0.8252, Train AUC: 0.8303, Train AP: 0.7990, Valid. AUC: 0.8787, Valid AP: 0.4838\n",
      "Epoch: 21/100, Loss: 0.4884964, Train Acc: 0.7452, Test Acc: 0.8259, Train AUC: 0.8316, Train AP: 0.7995, Valid. AUC: 0.8782, Valid AP: 0.4796\n",
      "Epoch: 22/100, Loss: 0.4929229, Train Acc: 0.7401, Test Acc: 0.8261, Train AUC: 0.8340, Train AP: 0.8103, Valid. AUC: 0.8780, Valid AP: 0.4814\n",
      "Epoch: 23/100, Loss: 0.4786916, Train Acc: 0.7459, Test Acc: 0.8242, Train AUC: 0.8379, Train AP: 0.8219, Valid. AUC: 0.8774, Valid AP: 0.4821\n",
      "Epoch: 24/100, Loss: 0.4844106, Train Acc: 0.7497, Test Acc: 0.8246, Train AUC: 0.8425, Train AP: 0.8203, Valid. AUC: 0.8766, Valid AP: 0.4764\n",
      "Epoch: 25/100, Loss: 0.4738297, Train Acc: 0.7520, Test Acc: 0.8193, Train AUC: 0.8420, Train AP: 0.8259, Valid. AUC: 0.8757, Valid AP: 0.4694\n",
      "Epoch: 26/100, Loss: 0.4706904, Train Acc: 0.7535, Test Acc: 0.8183, Train AUC: 0.8469, Train AP: 0.8305, Valid. AUC: 0.8755, Valid AP: 0.4633\n",
      "Epoch: 27/100, Loss: 0.4674248, Train Acc: 0.7520, Test Acc: 0.8192, Train AUC: 0.8484, Train AP: 0.8343, Valid. AUC: 0.8759, Valid AP: 0.4604\n",
      "Epoch: 28/100, Loss: 0.4649344, Train Acc: 0.7527, Test Acc: 0.8216, Train AUC: 0.8494, Train AP: 0.8361, Valid. AUC: 0.8767, Valid AP: 0.4599\n",
      "Epoch: 29/100, Loss: 0.4643290, Train Acc: 0.7540, Test Acc: 0.8224, Train AUC: 0.8498, Train AP: 0.8375, Valid. AUC: 0.8776, Valid AP: 0.4602\n",
      "Epoch: 30/100, Loss: 0.4595987, Train Acc: 0.7551, Test Acc: 0.8272, Train AUC: 0.8521, Train AP: 0.8418, Valid. AUC: 0.8783, Valid AP: 0.4615\n",
      "Epoch: 31/100, Loss: 0.4590436, Train Acc: 0.7546, Test Acc: 0.8288, Train AUC: 0.8541, Train AP: 0.8454, Valid. AUC: 0.8788, Valid AP: 0.4637\n",
      "Epoch: 32/100, Loss: 0.4569657, Train Acc: 0.7544, Test Acc: 0.8259, Train AUC: 0.8538, Train AP: 0.8454, Valid. AUC: 0.8794, Valid AP: 0.4653\n",
      "Epoch: 33/100, Loss: 0.4553775, Train Acc: 0.7597, Test Acc: 0.8248, Train AUC: 0.8550, Train AP: 0.8442, Valid. AUC: 0.8794, Valid AP: 0.4659\n",
      "Epoch: 34/100, Loss: 0.4553476, Train Acc: 0.7604, Test Acc: 0.8205, Train AUC: 0.8576, Train AP: 0.8475, Valid. AUC: 0.8786, Valid AP: 0.4635\n",
      "Epoch: 35/100, Loss: 0.4511357, Train Acc: 0.7620, Test Acc: 0.8181, Train AUC: 0.8591, Train AP: 0.8513, Valid. AUC: 0.8781, Valid AP: 0.4632\n",
      "Epoch: 36/100, Loss: 0.4508683, Train Acc: 0.7611, Test Acc: 0.8243, Train AUC: 0.8598, Train AP: 0.8519, Valid. AUC: 0.8785, Valid AP: 0.4656\n",
      "Epoch: 37/100, Loss: 0.4476656, Train Acc: 0.7637, Test Acc: 0.8258, Train AUC: 0.8602, Train AP: 0.8528, Valid. AUC: 0.8792, Valid AP: 0.4683\n",
      "Epoch: 38/100, Loss: 0.4487613, Train Acc: 0.7628, Test Acc: 0.8226, Train AUC: 0.8606, Train AP: 0.8549, Valid. AUC: 0.8794, Valid AP: 0.4684\n",
      "Epoch: 39/100, Loss: 0.4477423, Train Acc: 0.7619, Test Acc: 0.8237, Train AUC: 0.8607, Train AP: 0.8538, Valid. AUC: 0.8796, Valid AP: 0.4678\n",
      "Epoch: 40/100, Loss: 0.4441252, Train Acc: 0.7619, Test Acc: 0.8231, Train AUC: 0.8625, Train AP: 0.8569, Valid. AUC: 0.8799, Valid AP: 0.4681\n",
      "Epoch: 41/100, Loss: 0.4430485, Train Acc: 0.7655, Test Acc: 0.8234, Train AUC: 0.8645, Train AP: 0.8582, Valid. AUC: 0.8799, Valid AP: 0.4663\n",
      "Epoch: 42/100, Loss: 0.4398805, Train Acc: 0.7677, Test Acc: 0.8208, Train AUC: 0.8674, Train AP: 0.8626, Valid. AUC: 0.8794, Valid AP: 0.4621\n",
      "Epoch: 43/100, Loss: 0.4408353, Train Acc: 0.7639, Test Acc: 0.8235, Train AUC: 0.8672, Train AP: 0.8634, Valid. AUC: 0.8798, Valid AP: 0.4638\n",
      "Epoch: 44/100, Loss: 0.4386284, Train Acc: 0.7670, Test Acc: 0.8229, Train AUC: 0.8677, Train AP: 0.8643, Valid. AUC: 0.8800, Valid AP: 0.4631\n",
      "Epoch: 45/100, Loss: 0.4365046, Train Acc: 0.7665, Test Acc: 0.8236, Train AUC: 0.8684, Train AP: 0.8661, Valid. AUC: 0.8800, Valid AP: 0.4637\n",
      "Epoch: 46/100, Loss: 0.4348418, Train Acc: 0.7679, Test Acc: 0.8236, Train AUC: 0.8697, Train AP: 0.8676, Valid. AUC: 0.8802, Valid AP: 0.4644\n",
      "Epoch: 47/100, Loss: 0.4358211, Train Acc: 0.7635, Test Acc: 0.8245, Train AUC: 0.8684, Train AP: 0.8676, Valid. AUC: 0.8815, Valid AP: 0.4664\n",
      "Epoch: 48/100, Loss: 0.4331172, Train Acc: 0.7678, Test Acc: 0.8251, Train AUC: 0.8699, Train AP: 0.8689, Valid. AUC: 0.8817, Valid AP: 0.4661\n",
      "Epoch: 49/100, Loss: 0.4334634, Train Acc: 0.7683, Test Acc: 0.8316, Train AUC: 0.8698, Train AP: 0.8679, Valid. AUC: 0.8814, Valid AP: 0.4643\n",
      "Epoch: 50/100, Loss: 0.4344365, Train Acc: 0.7669, Test Acc: 0.8265, Train AUC: 0.8691, Train AP: 0.8657, Valid. AUC: 0.8820, Valid AP: 0.4652\n",
      "Epoch: 51/100, Loss: 0.4284497, Train Acc: 0.7702, Test Acc: 0.8254, Train AUC: 0.8733, Train AP: 0.8730, Valid. AUC: 0.8815, Valid AP: 0.4638\n",
      "Epoch: 52/100, Loss: 0.4310705, Train Acc: 0.7695, Test Acc: 0.8259, Train AUC: 0.8712, Train AP: 0.8710, Valid. AUC: 0.8795, Valid AP: 0.4609\n",
      "Epoch: 53/100, Loss: 0.4280705, Train Acc: 0.7699, Test Acc: 0.8246, Train AUC: 0.8737, Train AP: 0.8746, Valid. AUC: 0.8789, Valid AP: 0.4604\n",
      "Epoch: 54/100, Loss: 0.4288080, Train Acc: 0.7696, Test Acc: 0.8231, Train AUC: 0.8731, Train AP: 0.8734, Valid. AUC: 0.8798, Valid AP: 0.4627\n",
      "Epoch: 55/100, Loss: 0.4300811, Train Acc: 0.7675, Test Acc: 0.8246, Train AUC: 0.8728, Train AP: 0.8731, Valid. AUC: 0.8831, Valid AP: 0.4712\n",
      "Epoch: 56/100, Loss: 0.4266013, Train Acc: 0.7698, Test Acc: 0.8273, Train AUC: 0.8735, Train AP: 0.8758, Valid. AUC: 0.8828, Valid AP: 0.4703\n",
      "Epoch: 57/100, Loss: 0.4325895, Train Acc: 0.7673, Test Acc: 0.8344, Train AUC: 0.8729, Train AP: 0.8744, Valid. AUC: 0.8815, Valid AP: 0.4648\n",
      "Epoch: 58/100, Loss: 0.4374678, Train Acc: 0.7599, Test Acc: 0.8305, Train AUC: 0.8733, Train AP: 0.8758, Valid. AUC: 0.8826, Valid AP: 0.4649\n",
      "Epoch: 59/100, Loss: 0.4260690, Train Acc: 0.7693, Test Acc: 0.8271, Train AUC: 0.8740, Train AP: 0.8753, Valid. AUC: 0.8841, Valid AP: 0.4690\n",
      "Epoch: 60/100, Loss: 0.4358034, Train Acc: 0.7668, Test Acc: 0.8244, Train AUC: 0.8766, Train AP: 0.8788, Valid. AUC: 0.8824, Valid AP: 0.4637\n",
      "Epoch: 61/100, Loss: 0.4239298, Train Acc: 0.7694, Test Acc: 0.8213, Train AUC: 0.8750, Train AP: 0.8767, Valid. AUC: 0.8802, Valid AP: 0.4589\n",
      "Epoch: 62/100, Loss: 0.4303180, Train Acc: 0.7634, Test Acc: 0.8244, Train AUC: 0.8749, Train AP: 0.8770, Valid. AUC: 0.8817, Valid AP: 0.4632\n",
      "Epoch: 63/100, Loss: 0.4208846, Train Acc: 0.7739, Test Acc: 0.8274, Train AUC: 0.8774, Train AP: 0.8791, Valid. AUC: 0.8831, Valid AP: 0.4670\n",
      "Epoch: 64/100, Loss: 0.4260062, Train Acc: 0.7687, Test Acc: 0.8256, Train AUC: 0.8762, Train AP: 0.8780, Valid. AUC: 0.8833, Valid AP: 0.4669\n",
      "Epoch: 65/100, Loss: 0.4187438, Train Acc: 0.7723, Test Acc: 0.8347, Train AUC: 0.8771, Train AP: 0.8798, Valid. AUC: 0.8831, Valid AP: 0.4667\n",
      "Epoch: 66/100, Loss: 0.4237879, Train Acc: 0.7708, Test Acc: 0.8348, Train AUC: 0.8770, Train AP: 0.8791, Valid. AUC: 0.8837, Valid AP: 0.4673\n",
      "Epoch: 67/100, Loss: 0.4180045, Train Acc: 0.7734, Test Acc: 0.8312, Train AUC: 0.8780, Train AP: 0.8807, Valid. AUC: 0.8842, Valid AP: 0.4674\n",
      "Epoch: 68/100, Loss: 0.4199645, Train Acc: 0.7717, Test Acc: 0.8274, Train AUC: 0.8779, Train AP: 0.8810, Valid. AUC: 0.8842, Valid AP: 0.4663\n",
      "Epoch: 69/100, Loss: 0.4187962, Train Acc: 0.7717, Test Acc: 0.8235, Train AUC: 0.8775, Train AP: 0.8807, Valid. AUC: 0.8838, Valid AP: 0.4646\n",
      "Epoch: 70/100, Loss: 0.4180461, Train Acc: 0.7699, Test Acc: 0.8240, Train AUC: 0.8769, Train AP: 0.8807, Valid. AUC: 0.8834, Valid AP: 0.4633\n",
      "Epoch: 71/100, Loss: 0.4165643, Train Acc: 0.7738, Test Acc: 0.8243, Train AUC: 0.8789, Train AP: 0.8820, Valid. AUC: 0.8837, Valid AP: 0.4643\n",
      "Epoch: 72/100, Loss: 0.4165427, Train Acc: 0.7737, Test Acc: 0.8256, Train AUC: 0.8784, Train AP: 0.8814, Valid. AUC: 0.8841, Valid AP: 0.4666\n",
      "Epoch: 73/100, Loss: 0.4200167, Train Acc: 0.7722, Test Acc: 0.8240, Train AUC: 0.8780, Train AP: 0.8811, Valid. AUC: 0.8841, Valid AP: 0.4673\n",
      "Epoch: 74/100, Loss: 0.4149552, Train Acc: 0.7732, Test Acc: 0.8261, Train AUC: 0.8780, Train AP: 0.8817, Valid. AUC: 0.8838, Valid AP: 0.4676\n",
      "Epoch: 75/100, Loss: 0.4151405, Train Acc: 0.7725, Test Acc: 0.8263, Train AUC: 0.8788, Train AP: 0.8826, Valid. AUC: 0.8843, Valid AP: 0.4687\n",
      "Epoch: 76/100, Loss: 0.4135305, Train Acc: 0.7749, Test Acc: 0.8263, Train AUC: 0.8804, Train AP: 0.8840, Valid. AUC: 0.8848, Valid AP: 0.4692\n",
      "Epoch: 77/100, Loss: 0.4127978, Train Acc: 0.7729, Test Acc: 0.8267, Train AUC: 0.8795, Train AP: 0.8835, Valid. AUC: 0.8844, Valid AP: 0.4673\n",
      "Epoch: 78/100, Loss: 0.4132326, Train Acc: 0.7724, Test Acc: 0.8273, Train AUC: 0.8789, Train AP: 0.8834, Valid. AUC: 0.8839, Valid AP: 0.4657\n",
      "Epoch: 79/100, Loss: 0.4117225, Train Acc: 0.7746, Test Acc: 0.8276, Train AUC: 0.8806, Train AP: 0.8849, Valid. AUC: 0.8832, Valid AP: 0.4635\n",
      "Epoch: 80/100, Loss: 0.4107557, Train Acc: 0.7732, Test Acc: 0.8275, Train AUC: 0.8798, Train AP: 0.8849, Valid. AUC: 0.8823, Valid AP: 0.4620\n",
      "Epoch: 81/100, Loss: 0.4122126, Train Acc: 0.7724, Test Acc: 0.8278, Train AUC: 0.8794, Train AP: 0.8844, Valid. AUC: 0.8834, Valid AP: 0.4656\n",
      "Epoch: 82/100, Loss: 0.4100205, Train Acc: 0.7739, Test Acc: 0.8272, Train AUC: 0.8807, Train AP: 0.8850, Valid. AUC: 0.8849, Valid AP: 0.4697\n",
      "Epoch: 83/100, Loss: 0.4115089, Train Acc: 0.7760, Test Acc: 0.8279, Train AUC: 0.8816, Train AP: 0.8859, Valid. AUC: 0.8850, Valid AP: 0.4697\n",
      "Epoch: 84/100, Loss: 0.4102811, Train Acc: 0.7760, Test Acc: 0.8295, Train AUC: 0.8811, Train AP: 0.8857, Valid. AUC: 0.8854, Valid AP: 0.4702\n",
      "Epoch: 85/100, Loss: 0.4102241, Train Acc: 0.7761, Test Acc: 0.8288, Train AUC: 0.8810, Train AP: 0.8849, Valid. AUC: 0.8863, Valid AP: 0.4720\n",
      "Epoch: 86/100, Loss: 0.4079767, Train Acc: 0.7759, Test Acc: 0.8286, Train AUC: 0.8818, Train AP: 0.8865, Valid. AUC: 0.8866, Valid AP: 0.4724\n",
      "Epoch: 87/100, Loss: 0.4084234, Train Acc: 0.7759, Test Acc: 0.8283, Train AUC: 0.8821, Train AP: 0.8867, Valid. AUC: 0.8857, Valid AP: 0.4694\n",
      "Epoch: 88/100, Loss: 0.4076070, Train Acc: 0.7750, Test Acc: 0.8281, Train AUC: 0.8817, Train AP: 0.8866, Valid. AUC: 0.8849, Valid AP: 0.4667\n",
      "Epoch: 89/100, Loss: 0.4075175, Train Acc: 0.7740, Test Acc: 0.8277, Train AUC: 0.8816, Train AP: 0.8867, Valid. AUC: 0.8849, Valid AP: 0.4671\n",
      "Epoch: 90/100, Loss: 0.4061492, Train Acc: 0.7765, Test Acc: 0.8268, Train AUC: 0.8824, Train AP: 0.8872, Valid. AUC: 0.8850, Valid AP: 0.4683\n",
      "Epoch: 91/100, Loss: 0.4072888, Train Acc: 0.7743, Test Acc: 0.8266, Train AUC: 0.8820, Train AP: 0.8868, Valid. AUC: 0.8854, Valid AP: 0.4702\n",
      "Epoch: 92/100, Loss: 0.4050798, Train Acc: 0.7764, Test Acc: 0.8266, Train AUC: 0.8829, Train AP: 0.8878, Valid. AUC: 0.8858, Valid AP: 0.4724\n",
      "Epoch: 93/100, Loss: 0.4046472, Train Acc: 0.7770, Test Acc: 0.8271, Train AUC: 0.8827, Train AP: 0.8875, Valid. AUC: 0.8864, Valid AP: 0.4744\n",
      "Epoch: 94/100, Loss: 0.4048579, Train Acc: 0.7769, Test Acc: 0.8267, Train AUC: 0.8828, Train AP: 0.8876, Valid. AUC: 0.8871, Valid AP: 0.4766\n",
      "Epoch: 95/100, Loss: 0.4053837, Train Acc: 0.7748, Test Acc: 0.8271, Train AUC: 0.8825, Train AP: 0.8874, Valid. AUC: 0.8868, Valid AP: 0.4743\n",
      "Epoch: 96/100, Loss: 0.4040824, Train Acc: 0.7747, Test Acc: 0.8276, Train AUC: 0.8827, Train AP: 0.8880, Valid. AUC: 0.8856, Valid AP: 0.4705\n",
      "Epoch: 97/100, Loss: 0.4037364, Train Acc: 0.7779, Test Acc: 0.8275, Train AUC: 0.8836, Train AP: 0.8886, Valid. AUC: 0.8852, Valid AP: 0.4690\n",
      "Epoch: 98/100, Loss: 0.4038785, Train Acc: 0.7777, Test Acc: 0.8280, Train AUC: 0.8830, Train AP: 0.8885, Valid. AUC: 0.8857, Valid AP: 0.4705\n",
      "Epoch: 99/100, Loss: 0.4034157, Train Acc: 0.7774, Test Acc: 0.8278, Train AUC: 0.8842, Train AP: 0.8891, Valid. AUC: 0.8856, Valid AP: 0.4706\n",
      "Epoch: 100/100, Loss: 0.4059220, Train Acc: 0.7777, Test Acc: 0.8274, Train AUC: 0.8844, Train AP: 0.8896, Valid. AUC: 0.8849, Valid AP: 0.4687\n",
      "/home/ubuntu/PA-Cancer-Immunotherapy/GNN/train_pa_all_tvt_10x.py:212: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(configs['save_model']))\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.784 MB of 1.784 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.785 MB of 1.785 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.791 MB of 1.791 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.791 MB of 1.791 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 1.791 MB of 1.791 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        test_ap ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   test_roc_auc ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▁▂▁▁▅▃▅▅▅▆▆▇▇▇▇▇▇▇▇▇█▇█▇▇███████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train_ap ▁▅▅▅▅▆▆▆▇▇▇▇▇▇▇█████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss ██▇▅▅▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_roc_auc ▁▅▅▆▆▇▇▇▇███████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: valid_accuracy ▁▅█▆██▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇█▇▇██▇▇█▇▇▇▇██████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       valid_ap ▁▁▅▆▆▇█▇█▇▆▆▆▆▆▆▆▆▆▆▇▆▆▆▆▆▆▆▆▆▆▆▇▆▆▇▇▇▇▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  valid_roc_auc ▁▂▅▆▇▇▇▇▇▇▇▇▇▇▇▇███▇████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy 0.82589\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        test_ap 0.47746\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   test_roc_auc 0.88731\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.77775\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train_ap 0.88956\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.40592\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_roc_auc 0.88443\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: valid_accuracy 0.82737\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       valid_ap 0.46868\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  valid_roc_auc 0.88494\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33myoung-plasma-4\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-gene_GNN/runs/09om8etu\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-gene_GNN\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 4 W&B file(s), 0 media file(s), 9 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241211_233445-09om8etu/logs\u001b[0m\n",
      "Test Acc: 0.8259, Test AUC: 0.8873, Test AP: 0.4775\n"
     ]
    }
   ],
   "source": [
    "# for gene\n",
    "\n",
    "! python train_pa_all_tvt_10x.py --gpu 0 --configs_path configs/PA_all_tvt_10x_gene.yml --droup_out 0.1 --split StrictTCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0eb944d-c866-4681-9233-dd9a0cba09ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606f08db-402d-477a-a93f-45f9ab7ef808",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082eef41-597d-434f-a6d4-22ff29481bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^___________________^^^^^^^^^^^^^^^^^^^^^^^^^^^^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc73c615-03f6-4dc4-9c02-eccee9d9ee63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e08b9b9-798c-49d1-adeb-f0847c2bab2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82667f45-8845-45d2-a687-a68bde13a3c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(gpu=0, lr=0.001, epochs=100, w_celoss=1, w_aucloss=0, add_same_type_edges=False, dynamic_graph=False, dynamic_ratio=0.05, droup_out=0.1, positive_weights=1, dynamic_epochs=30, distance_threshold=10, configs_path='configs/PA_all_tvt_10x_allele.yml', split='StrictTCR', dataset='pMTnet')\n",
      "PROJECT_NAME: dataset-all-tvt-10x-allele_GNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfrohoari\u001b[0m (\u001b[33mpa_cancerimmunotherapy\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/ubuntu/PA-Cancer-Immunotherapy/GNN/wandb/run-20241217_123310-6oephdt9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mhelpful-resonance-7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-allele_GNN\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-allele_GNN/runs/6oephdt9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   6 of 6 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   6 of 6 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   6 of 6 files downloaded.  \n",
      "embeddings_path:   models/PA_all/gene_and_allele_embeddings_10x.pkl\n",
      "train_file_list:   ['allele_train.csv']\n",
      "validation_file_list:   ['allele_validation.csv']\n",
      "test_file_list:   ['allele_test.csv']\n",
      "wandb logger initialisiert\n",
      "Epoch: 1/100, Loss: 0.6904294, Train Acc: 0.5023, Valid. Acc: 0.7832, Train AUC: 0.5140, Train AP: 0.5232, Valid. AUC: 0.7101, Valid. AP: 0.2884\n",
      "Epoch: 2/100, Loss: 0.6838798, Train Acc: 0.5981, Valid. Acc: 0.6611, Train AUC: 0.6512, Train AP: 0.6359, Valid. AUC: 0.7211, Valid. AP: 0.3008\n",
      "Epoch: 3/100, Loss: 0.6777848, Train Acc: 0.5887, Valid. Acc: 0.8074, Train AUC: 0.6560, Train AP: 0.6446, Valid. AUC: 0.7090, Valid. AP: 0.3013\n",
      "Epoch: 4/100, Loss: 0.6716725, Train Acc: 0.5809, Valid. Acc: 0.7581, Train AUC: 0.6755, Train AP: 0.6585, Valid. AUC: 0.7259, Valid. AP: 0.3118\n",
      "Epoch: 5/100, Loss: 0.6616295, Train Acc: 0.6237, Valid. Acc: 0.7707, Train AUC: 0.6758, Train AP: 0.6623, Valid. AUC: 0.7301, Valid. AP: 0.3176\n",
      "Epoch: 6/100, Loss: 0.6514442, Train Acc: 0.6327, Valid. Acc: 0.7951, Train AUC: 0.6829, Train AP: 0.6661, Valid. AUC: 0.7364, Valid. AP: 0.3271\n",
      "Epoch: 7/100, Loss: 0.6432214, Train Acc: 0.6309, Valid. Acc: 0.7829, Train AUC: 0.6907, Train AP: 0.6704, Valid. AUC: 0.7563, Valid. AP: 0.3489\n",
      "Epoch: 8/100, Loss: 0.6329895, Train Acc: 0.6538, Valid. Acc: 0.7885, Train AUC: 0.7012, Train AP: 0.6782, Valid. AUC: 0.7697, Valid. AP: 0.3742\n",
      "Epoch: 9/100, Loss: 0.6248440, Train Acc: 0.6501, Valid. Acc: 0.8263, Train AUC: 0.7070, Train AP: 0.6852, Valid. AUC: 0.7763, Valid. AP: 0.3982\n",
      "Epoch: 10/100, Loss: 0.6239766, Train Acc: 0.6397, Valid. Acc: 0.6809, Train AUC: 0.7183, Train AP: 0.7059, Valid. AUC: 0.7861, Valid. AP: 0.4028\n",
      "Epoch: 11/100, Loss: 0.6723387, Train Acc: 0.6100, Valid. Acc: 0.8126, Train AUC: 0.7131, Train AP: 0.7024, Valid. AUC: 0.7877, Valid. AP: 0.4139\n",
      "Epoch: 12/100, Loss: 0.6078568, Train Acc: 0.6672, Valid. Acc: 0.8283, Train AUC: 0.7341, Train AP: 0.7231, Valid. AUC: 0.7835, Valid. AP: 0.4043\n",
      "Epoch: 13/100, Loss: 0.6369628, Train Acc: 0.6211, Valid. Acc: 0.8100, Train AUC: 0.7292, Train AP: 0.7208, Valid. AUC: 0.7863, Valid. AP: 0.3956\n",
      "Epoch: 14/100, Loss: 0.6087582, Train Acc: 0.6618, Valid. Acc: 0.7473, Train AUC: 0.7306, Train AP: 0.7221, Valid. AUC: 0.7922, Valid. AP: 0.3929\n",
      "Epoch: 15/100, Loss: 0.6164351, Train Acc: 0.6566, Valid. Acc: 0.7417, Train AUC: 0.7353, Train AP: 0.7213, Valid. AUC: 0.7988, Valid. AP: 0.4013\n",
      "Epoch: 16/100, Loss: 0.6140798, Train Acc: 0.6383, Valid. Acc: 0.7828, Train AUC: 0.7457, Train AP: 0.7460, Valid. AUC: 0.8026, Valid. AP: 0.4093\n",
      "Epoch: 17/100, Loss: 0.5970705, Train Acc: 0.6739, Valid. Acc: 0.8073, Train AUC: 0.7459, Train AP: 0.7456, Valid. AUC: 0.8044, Valid. AP: 0.4150\n",
      "Epoch: 18/100, Loss: 0.5969835, Train Acc: 0.6779, Valid. Acc: 0.8110, Train AUC: 0.7509, Train AP: 0.7483, Valid. AUC: 0.8058, Valid. AP: 0.4166\n",
      "Epoch: 19/100, Loss: 0.6025461, Train Acc: 0.6738, Valid. Acc: 0.8010, Train AUC: 0.7533, Train AP: 0.7538, Valid. AUC: 0.8069, Valid. AP: 0.4141\n",
      "Epoch: 20/100, Loss: 0.5918997, Train Acc: 0.6725, Valid. Acc: 0.7781, Train AUC: 0.7513, Train AP: 0.7525, Valid. AUC: 0.8074, Valid. AP: 0.4111\n",
      "Epoch: 21/100, Loss: 0.5876464, Train Acc: 0.6800, Valid. Acc: 0.7617, Train AUC: 0.7571, Train AP: 0.7573, Valid. AUC: 0.8065, Valid. AP: 0.4062\n",
      "Epoch: 22/100, Loss: 0.5907656, Train Acc: 0.6665, Valid. Acc: 0.7765, Train AUC: 0.7607, Train AP: 0.7632, Valid. AUC: 0.8057, Valid. AP: 0.3997\n",
      "Epoch: 23/100, Loss: 0.5824780, Train Acc: 0.6726, Valid. Acc: 0.7980, Train AUC: 0.7648, Train AP: 0.7675, Valid. AUC: 0.8055, Valid. AP: 0.3955\n",
      "Epoch: 24/100, Loss: 0.5813732, Train Acc: 0.6906, Valid. Acc: 0.8095, Train AUC: 0.7606, Train AP: 0.7607, Valid. AUC: 0.8064, Valid. AP: 0.3956\n",
      "Epoch: 25/100, Loss: 0.5821830, Train Acc: 0.6874, Valid. Acc: 0.7985, Train AUC: 0.7640, Train AP: 0.7613, Valid. AUC: 0.8069, Valid. AP: 0.3962\n",
      "Epoch: 26/100, Loss: 0.5724481, Train Acc: 0.6944, Valid. Acc: 0.7804, Train AUC: 0.7669, Train AP: 0.7680, Valid. AUC: 0.8067, Valid. AP: 0.3987\n",
      "Epoch: 27/100, Loss: 0.5723566, Train Acc: 0.6793, Valid. Acc: 0.7769, Train AUC: 0.7677, Train AP: 0.7710, Valid. AUC: 0.8069, Valid. AP: 0.4027\n",
      "Epoch: 28/100, Loss: 0.5703054, Train Acc: 0.6786, Valid. Acc: 0.7946, Train AUC: 0.7695, Train AP: 0.7779, Valid. AUC: 0.8084, Valid. AP: 0.4059\n",
      "Epoch: 29/100, Loss: 0.5646230, Train Acc: 0.6927, Valid. Acc: 0.8041, Train AUC: 0.7718, Train AP: 0.7805, Valid. AUC: 0.8099, Valid. AP: 0.4078\n",
      "Epoch: 30/100, Loss: 0.5644284, Train Acc: 0.6948, Valid. Acc: 0.7980, Train AUC: 0.7728, Train AP: 0.7802, Valid. AUC: 0.8105, Valid. AP: 0.4073\n",
      "Epoch: 31/100, Loss: 0.5610724, Train Acc: 0.6947, Valid. Acc: 0.7837, Train AUC: 0.7750, Train AP: 0.7832, Valid. AUC: 0.8104, Valid. AP: 0.4047\n",
      "Epoch: 32/100, Loss: 0.5600482, Train Acc: 0.6822, Valid. Acc: 0.7799, Train AUC: 0.7724, Train AP: 0.7843, Valid. AUC: 0.8108, Valid. AP: 0.3993\n",
      "Epoch: 33/100, Loss: 0.5578279, Train Acc: 0.6883, Valid. Acc: 0.7953, Train AUC: 0.7781, Train AP: 0.7868, Valid. AUC: 0.8122, Valid. AP: 0.3970\n",
      "Epoch: 34/100, Loss: 0.5560160, Train Acc: 0.6988, Valid. Acc: 0.7944, Train AUC: 0.7805, Train AP: 0.7874, Valid. AUC: 0.8126, Valid. AP: 0.3962\n",
      "Epoch: 35/100, Loss: 0.5544203, Train Acc: 0.6939, Valid. Acc: 0.7884, Train AUC: 0.7785, Train AP: 0.7882, Valid. AUC: 0.8119, Valid. AP: 0.3950\n",
      "Epoch: 36/100, Loss: 0.5514771, Train Acc: 0.6918, Valid. Acc: 0.7923, Train AUC: 0.7812, Train AP: 0.7936, Valid. AUC: 0.8118, Valid. AP: 0.3954\n",
      "Epoch: 37/100, Loss: 0.5504090, Train Acc: 0.6937, Valid. Acc: 0.7999, Train AUC: 0.7801, Train AP: 0.7919, Valid. AUC: 0.8117, Valid. AP: 0.3945\n",
      "Epoch: 38/100, Loss: 0.5476021, Train Acc: 0.7001, Valid. Acc: 0.8026, Train AUC: 0.7832, Train AP: 0.7962, Valid. AUC: 0.8112, Valid. AP: 0.3934\n",
      "Epoch: 39/100, Loss: 0.5476351, Train Acc: 0.7043, Valid. Acc: 0.7879, Train AUC: 0.7860, Train AP: 0.7960, Valid. AUC: 0.8097, Valid. AP: 0.3942\n",
      "Epoch: 40/100, Loss: 0.5457736, Train Acc: 0.6952, Valid. Acc: 0.7950, Train AUC: 0.7868, Train AP: 0.7972, Valid. AUC: 0.8094, Valid. AP: 0.3969\n",
      "Epoch: 41/100, Loss: 0.5419779, Train Acc: 0.6972, Valid. Acc: 0.8066, Train AUC: 0.7894, Train AP: 0.8040, Valid. AUC: 0.8099, Valid. AP: 0.3976\n",
      "Epoch: 42/100, Loss: 0.5420058, Train Acc: 0.7065, Valid. Acc: 0.7892, Train AUC: 0.7926, Train AP: 0.8058, Valid. AUC: 0.8088, Valid. AP: 0.3978\n",
      "Epoch: 43/100, Loss: 0.5404898, Train Acc: 0.6988, Valid. Acc: 0.7859, Train AUC: 0.7900, Train AP: 0.8087, Valid. AUC: 0.8085, Valid. AP: 0.3968\n",
      "Epoch: 44/100, Loss: 0.5391650, Train Acc: 0.6917, Valid. Acc: 0.8093, Train AUC: 0.7907, Train AP: 0.8104, Valid. AUC: 0.8106, Valid. AP: 0.3958\n",
      "Epoch: 45/100, Loss: 0.5351475, Train Acc: 0.7081, Valid. Acc: 0.8122, Train AUC: 0.7936, Train AP: 0.8125, Valid. AUC: 0.8112, Valid. AP: 0.3897\n",
      "Epoch: 46/100, Loss: 0.5340394, Train Acc: 0.7105, Valid. Acc: 0.8000, Train AUC: 0.7957, Train AP: 0.8124, Valid. AUC: 0.8098, Valid. AP: 0.3843\n",
      "Epoch: 47/100, Loss: 0.5367527, Train Acc: 0.7034, Valid. Acc: 0.8078, Train AUC: 0.7936, Train AP: 0.8071, Valid. AUC: 0.8105, Valid. AP: 0.3885\n",
      "Epoch: 48/100, Loss: 0.5333782, Train Acc: 0.7083, Valid. Acc: 0.7974, Train AUC: 0.7963, Train AP: 0.8123, Valid. AUC: 0.8106, Valid. AP: 0.3900\n",
      "Epoch: 49/100, Loss: 0.5283122, Train Acc: 0.7058, Valid. Acc: 0.7941, Train AUC: 0.7986, Train AP: 0.8180, Valid. AUC: 0.8115, Valid. AP: 0.3901\n",
      "Epoch: 50/100, Loss: 0.5287526, Train Acc: 0.7049, Valid. Acc: 0.7936, Train AUC: 0.7983, Train AP: 0.8182, Valid. AUC: 0.8130, Valid. AP: 0.3897\n",
      "Epoch: 51/100, Loss: 0.5301518, Train Acc: 0.6989, Valid. Acc: 0.7894, Train AUC: 0.7937, Train AP: 0.8151, Valid. AUC: 0.8143, Valid. AP: 0.3863\n",
      "Epoch: 52/100, Loss: 0.5260471, Train Acc: 0.7102, Valid. Acc: 0.7872, Train AUC: 0.7998, Train AP: 0.8184, Valid. AUC: 0.8140, Valid. AP: 0.3837\n",
      "Epoch: 53/100, Loss: 0.5282682, Train Acc: 0.7108, Valid. Acc: 0.7957, Train AUC: 0.7999, Train AP: 0.8165, Valid. AUC: 0.8137, Valid. AP: 0.3862\n",
      "Epoch: 54/100, Loss: 0.5279725, Train Acc: 0.7120, Valid. Acc: 0.8072, Train AUC: 0.7998, Train AP: 0.8156, Valid. AUC: 0.8138, Valid. AP: 0.3934\n",
      "Epoch: 55/100, Loss: 0.5231512, Train Acc: 0.7155, Valid. Acc: 0.8065, Train AUC: 0.8039, Train AP: 0.8229, Valid. AUC: 0.8118, Valid. AP: 0.3962\n",
      "Epoch: 56/100, Loss: 0.5237806, Train Acc: 0.7042, Valid. Acc: 0.7883, Train AUC: 0.7979, Train AP: 0.8207, Valid. AUC: 0.8109, Valid. AP: 0.3946\n",
      "Epoch: 57/100, Loss: 0.5241632, Train Acc: 0.6963, Valid. Acc: 0.8080, Train AUC: 0.7977, Train AP: 0.8220, Valid. AUC: 0.8141, Valid. AP: 0.3932\n",
      "Epoch: 58/100, Loss: 0.5209861, Train Acc: 0.7143, Valid. Acc: 0.8119, Train AUC: 0.8028, Train AP: 0.8235, Valid. AUC: 0.8153, Valid. AP: 0.3895\n",
      "Epoch: 59/100, Loss: 0.5209420, Train Acc: 0.7206, Valid. Acc: 0.7848, Train AUC: 0.8077, Train AP: 0.8280, Valid. AUC: 0.8138, Valid. AP: 0.3849\n",
      "Epoch: 60/100, Loss: 0.5186379, Train Acc: 0.7124, Valid. Acc: 0.7870, Train AUC: 0.8063, Train AP: 0.8266, Valid. AUC: 0.8135, Valid. AP: 0.3855\n",
      "Epoch: 61/100, Loss: 0.5199518, Train Acc: 0.7033, Valid. Acc: 0.8226, Train AUC: 0.8048, Train AP: 0.8250, Valid. AUC: 0.8160, Valid. AP: 0.3930\n",
      "Epoch: 62/100, Loss: 0.5183743, Train Acc: 0.7207, Valid. Acc: 0.8177, Train AUC: 0.8089, Train AP: 0.8300, Valid. AUC: 0.8155, Valid. AP: 0.3958\n",
      "Epoch: 63/100, Loss: 0.5145118, Train Acc: 0.7167, Valid. Acc: 0.7829, Train AUC: 0.8066, Train AP: 0.8300, Valid. AUC: 0.8133, Valid. AP: 0.3929\n",
      "Epoch: 64/100, Loss: 0.5186027, Train Acc: 0.6987, Valid. Acc: 0.8004, Train AUC: 0.8026, Train AP: 0.8273, Valid. AUC: 0.8157, Valid. AP: 0.3941\n",
      "Epoch: 65/100, Loss: 0.5111933, Train Acc: 0.7134, Valid. Acc: 0.8178, Train AUC: 0.8075, Train AP: 0.8306, Valid. AUC: 0.8176, Valid. AP: 0.3947\n",
      "Epoch: 66/100, Loss: 0.5128561, Train Acc: 0.7232, Valid. Acc: 0.8144, Train AUC: 0.8096, Train AP: 0.8315, Valid. AUC: 0.8170, Valid. AP: 0.3928\n",
      "Epoch: 67/100, Loss: 0.5137523, Train Acc: 0.7175, Valid. Acc: 0.7804, Train AUC: 0.8099, Train AP: 0.8317, Valid. AUC: 0.8136, Valid. AP: 0.3863\n",
      "Epoch: 68/100, Loss: 0.5130255, Train Acc: 0.7070, Valid. Acc: 0.7889, Train AUC: 0.8091, Train AP: 0.8320, Valid. AUC: 0.8150, Valid. AP: 0.3902\n",
      "Epoch: 69/100, Loss: 0.5081542, Train Acc: 0.7105, Valid. Acc: 0.8143, Train AUC: 0.8097, Train AP: 0.8334, Valid. AUC: 0.8179, Valid. AP: 0.3977\n",
      "Epoch: 70/100, Loss: 0.5092325, Train Acc: 0.7218, Valid. Acc: 0.8070, Train AUC: 0.8137, Train AP: 0.8371, Valid. AUC: 0.8180, Valid. AP: 0.3993\n",
      "Epoch: 71/100, Loss: 0.5072863, Train Acc: 0.7188, Valid. Acc: 0.7835, Train AUC: 0.8131, Train AP: 0.8356, Valid. AUC: 0.8168, Valid. AP: 0.3955\n",
      "Epoch: 72/100, Loss: 0.5080853, Train Acc: 0.7141, Valid. Acc: 0.7927, Train AUC: 0.8139, Train AP: 0.8370, Valid. AUC: 0.8174, Valid. AP: 0.3958\n",
      "Epoch: 73/100, Loss: 0.5047819, Train Acc: 0.7169, Valid. Acc: 0.8181, Train AUC: 0.8109, Train AP: 0.8352, Valid. AUC: 0.8188, Valid. AP: 0.3979\n",
      "Epoch: 74/100, Loss: 0.5049151, Train Acc: 0.7178, Valid. Acc: 0.8217, Train AUC: 0.8110, Train AP: 0.8349, Valid. AUC: 0.8189, Valid. AP: 0.3951\n",
      "Epoch: 75/100, Loss: 0.5050899, Train Acc: 0.7228, Valid. Acc: 0.7965, Train AUC: 0.8153, Train AP: 0.8378, Valid. AUC: 0.8161, Valid. AP: 0.3873\n",
      "Epoch: 76/100, Loss: 0.5055389, Train Acc: 0.7190, Valid. Acc: 0.7911, Train AUC: 0.8116, Train AP: 0.8343, Valid. AUC: 0.8173, Valid. AP: 0.3920\n",
      "Epoch: 77/100, Loss: 0.5039308, Train Acc: 0.7132, Valid. Acc: 0.8111, Train AUC: 0.8141, Train AP: 0.8372, Valid. AUC: 0.8204, Valid. AP: 0.4027\n",
      "Epoch: 78/100, Loss: 0.5020993, Train Acc: 0.7266, Valid. Acc: 0.8106, Train AUC: 0.8165, Train AP: 0.8395, Valid. AUC: 0.8212, Valid. AP: 0.4024\n",
      "Epoch: 79/100, Loss: 0.5028225, Train Acc: 0.7298, Valid. Acc: 0.7981, Train AUC: 0.8171, Train AP: 0.8398, Valid. AUC: 0.8204, Valid. AP: 0.4013\n",
      "Epoch: 80/100, Loss: 0.5012633, Train Acc: 0.7190, Valid. Acc: 0.8006, Train AUC: 0.8140, Train AP: 0.8392, Valid. AUC: 0.8203, Valid. AP: 0.3987\n",
      "Epoch: 81/100, Loss: 0.5006950, Train Acc: 0.7181, Valid. Acc: 0.8126, Train AUC: 0.8131, Train AP: 0.8385, Valid. AUC: 0.8215, Valid. AP: 0.3996\n",
      "Epoch: 82/100, Loss: 0.4976192, Train Acc: 0.7280, Valid. Acc: 0.8191, Train AUC: 0.8183, Train AP: 0.8420, Valid. AUC: 0.8218, Valid. AP: 0.3993\n",
      "Epoch: 83/100, Loss: 0.4978352, Train Acc: 0.7271, Valid. Acc: 0.8154, Train AUC: 0.8181, Train AP: 0.8411, Valid. AUC: 0.8210, Valid. AP: 0.3981\n",
      "Epoch: 84/100, Loss: 0.4959916, Train Acc: 0.7304, Valid. Acc: 0.8054, Train AUC: 0.8186, Train AP: 0.8416, Valid. AUC: 0.8198, Valid. AP: 0.3991\n",
      "Epoch: 85/100, Loss: 0.4996263, Train Acc: 0.7157, Valid. Acc: 0.8174, Train AUC: 0.8131, Train AP: 0.8385, Valid. AUC: 0.8222, Valid. AP: 0.4062\n",
      "Epoch: 86/100, Loss: 0.4955579, Train Acc: 0.7323, Valid. Acc: 0.8190, Train AUC: 0.8179, Train AP: 0.8420, Valid. AUC: 0.8232, Valid. AP: 0.4085\n",
      "Epoch: 87/100, Loss: 0.4963654, Train Acc: 0.7314, Valid. Acc: 0.8062, Train AUC: 0.8199, Train AP: 0.8432, Valid. AUC: 0.8225, Valid. AP: 0.4056\n",
      "Epoch: 88/100, Loss: 0.4943002, Train Acc: 0.7217, Valid. Acc: 0.8016, Train AUC: 0.8188, Train AP: 0.8423, Valid. AUC: 0.8225, Valid. AP: 0.4022\n",
      "Epoch: 89/100, Loss: 0.4919692, Train Acc: 0.7246, Valid. Acc: 0.8093, Train AUC: 0.8196, Train AP: 0.8444, Valid. AUC: 0.8239, Valid. AP: 0.4043\n",
      "Epoch: 90/100, Loss: 0.4914458, Train Acc: 0.7300, Valid. Acc: 0.8159, Train AUC: 0.8213, Train AP: 0.8453, Valid. AUC: 0.8248, Valid. AP: 0.4075\n",
      "Epoch: 91/100, Loss: 0.4908977, Train Acc: 0.7301, Valid. Acc: 0.8137, Train AUC: 0.8207, Train AP: 0.8445, Valid. AUC: 0.8248, Valid. AP: 0.4090\n",
      "Epoch: 92/100, Loss: 0.4908216, Train Acc: 0.7299, Valid. Acc: 0.8080, Train AUC: 0.8195, Train AP: 0.8443, Valid. AUC: 0.8241, Valid. AP: 0.4076\n",
      "Epoch: 93/100, Loss: 0.4895108, Train Acc: 0.7245, Valid. Acc: 0.8032, Train AUC: 0.8205, Train AP: 0.8456, Valid. AUC: 0.8243, Valid. AP: 0.4072\n",
      "Epoch: 94/100, Loss: 0.4883170, Train Acc: 0.7307, Valid. Acc: 0.8112, Train AUC: 0.8231, Train AP: 0.8470, Valid. AUC: 0.8249, Valid. AP: 0.4085\n",
      "Epoch: 95/100, Loss: 0.4878208, Train Acc: 0.7344, Valid. Acc: 0.8179, Train AUC: 0.8227, Train AP: 0.8466, Valid. AUC: 0.8250, Valid. AP: 0.4094\n",
      "Epoch: 96/100, Loss: 0.4890099, Train Acc: 0.7294, Valid. Acc: 0.8166, Train AUC: 0.8219, Train AP: 0.8454, Valid. AUC: 0.8254, Valid. AP: 0.4097\n",
      "Epoch: 97/100, Loss: 0.4871328, Train Acc: 0.7308, Valid. Acc: 0.8143, Train AUC: 0.8225, Train AP: 0.8468, Valid. AUC: 0.8266, Valid. AP: 0.4133\n",
      "Epoch: 98/100, Loss: 0.4856577, Train Acc: 0.7333, Valid. Acc: 0.8196, Train AUC: 0.8237, Train AP: 0.8483, Valid. AUC: 0.8285, Valid. AP: 0.4216\n",
      "Epoch: 99/100, Loss: 0.4856403, Train Acc: 0.7384, Valid. Acc: 0.8182, Train AUC: 0.8253, Train AP: 0.8497, Valid. AUC: 0.8291, Valid. AP: 0.4267\n",
      "Epoch: 100/100, Loss: 0.4845810, Train Acc: 0.7374, Valid. Acc: 0.8168, Train AUC: 0.8251, Train AP: 0.8509, Valid. AUC: 0.8288, Valid. AP: 0.4264\n",
      "/home/ubuntu/PA-Cancer-Immunotherapy/GNN/train_pa_all_tvt_10x.py:212: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(configs['save_model']))\n",
      "Task-wise AP and ROC AUC:\n",
      "Task: TPP1, AP: 0.4466, ROC AUC: 0.8682\n",
      "Task: TPP2, AP: 0.4127, ROC AUC: 0.7215\n",
      "Task: TPP4, AP and ROC AUC cannot be calculated (only one class present).\n",
      "Task: TPP3, AP: 0.7120, ROC AUC: 0.5804\n",
      "\n",
      "Overall AP and ROC AUC:\n",
      "Overall AP: 0.4300, Overall ROC AUC: 0.8309\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 2.263 MB of 2.680 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 2.680 MB of 2.680 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 2.680 MB of 2.680 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 2.680 MB of 2.680 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        test_ap ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   test_roc_auc ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▁▂▃▃▂▅▅▅▆▆▅▆▆▆▆▆▆▇▆▆▇▇▇▇▇▇▆▇▇▇▇▇▇█▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train_ap ▁▂▂▃▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇███████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss ███▇▇▆▇▅▆▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_roc_auc ▁▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇███████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: valid_accuracy ▁▇▆▇▆▂█▆▇▆▆▇▇▆▆▆▇▆▇▇▇▇▇▆▆▇▇█▆▇█▇▇▇▇▇▇▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       valid_ap ▁▁▂▃▅▇▇▆▆▇▇▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  valid_roc_auc ▁▁▃▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇██████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy 0.82014\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        test_ap 0.43003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   test_roc_auc 0.83092\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.73742\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train_ap 0.85091\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.48458\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_roc_auc 0.8251\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: valid_accuracy 0.81678\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       valid_ap 0.42642\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  valid_roc_auc 0.82877\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mhelpful-resonance-7\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-allele_GNN/runs/6oephdt9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-allele_GNN\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 6 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241217_123310-6oephdt9/logs\u001b[0m\n",
      "Test Acc: 0.8201, Test AUC: 0.8309, Test AP: 0.4300\n"
     ]
    }
   ],
   "source": [
    "# run to get TTP\n",
    "# first for allele\n",
    "\n",
    "! python train_pa_all_tvt_10x.py --gpu 0 --configs_path configs/PA_all_tvt_10x_allele.yml --droup_out 0.1 --split StrictTCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa7e57a9-549f-43ff-b0b6-d28f79a51279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(gpu=0, lr=0.001, epochs=100, w_celoss=1, w_aucloss=0, add_same_type_edges=False, dynamic_graph=False, dynamic_ratio=0.05, droup_out=0.1, positive_weights=1, dynamic_epochs=30, distance_threshold=10, configs_path='configs/PA_all_tvt_10x_gene.yml', split='StrictTCR', dataset='pMTnet')\n",
      "PROJECT_NAME: dataset-all-tvt-10x-gene_GNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfrohoari\u001b[0m (\u001b[33mpa_cancerimmunotherapy\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/ubuntu/PA-Cancer-Immunotherapy/GNN/wandb/run-20241217_124802-ct27crgz\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mchocolate-music-5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-gene_GNN\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-gene_GNN/runs/ct27crgz\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   6 of 6 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   6 of 6 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   6 of 6 files downloaded.  \n",
      "embeddings_path:   models/PA_all/gene_and_allele_embeddings_10x.pkl\n",
      "train_file_list:   ['gene_train.csv']\n",
      "validation_file_list:   ['gene_validation.csv']\n",
      "test_file_list:   ['gene_test.csv']\n",
      "wandb logger initialisiert\n",
      "Epoch: 1/100, Loss: 0.6913584, Train Acc: 0.4946, Valid. Acc: 0.7197, Train AUC: 0.5005, Train AP: 0.5119, Valid. AUC: 0.7996, Valid. AP: 0.3951\n",
      "Epoch: 2/100, Loss: 0.6802936, Train Acc: 0.6560, Valid. Acc: 0.8005, Train AUC: 0.7125, Train AP: 0.6858, Valid. AUC: 0.8170, Valid. AP: 0.4063\n",
      "Epoch: 3/100, Loss: 0.6680257, Train Acc: 0.6714, Valid. Acc: 0.7869, Train AUC: 0.7372, Train AP: 0.7119, Valid. AUC: 0.8166, Valid. AP: 0.4085\n",
      "Epoch: 4/100, Loss: 0.6499577, Train Acc: 0.6750, Valid. Acc: 0.8279, Train AUC: 0.7338, Train AP: 0.7023, Valid. AUC: 0.8218, Valid. AP: 0.4144\n",
      "Epoch: 5/100, Loss: 0.6321558, Train Acc: 0.6595, Valid. Acc: 0.7965, Train AUC: 0.7363, Train AP: 0.7040, Valid. AUC: 0.8272, Valid. AP: 0.4206\n",
      "Epoch: 6/100, Loss: 0.6116681, Train Acc: 0.6830, Valid. Acc: 0.8308, Train AUC: 0.7424, Train AP: 0.7083, Valid. AUC: 0.8354, Valid. AP: 0.4291\n",
      "Epoch: 7/100, Loss: 0.6016117, Train Acc: 0.6529, Valid. Acc: 0.8015, Train AUC: 0.7610, Train AP: 0.7248, Valid. AUC: 0.8449, Valid. AP: 0.4397\n",
      "Epoch: 8/100, Loss: 0.5898728, Train Acc: 0.6966, Valid. Acc: 0.8244, Train AUC: 0.7619, Train AP: 0.7255, Valid. AUC: 0.8524, Valid. AP: 0.4515\n",
      "Epoch: 9/100, Loss: 0.5649678, Train Acc: 0.6919, Valid. Acc: 0.8332, Train AUC: 0.7761, Train AP: 0.7413, Valid. AUC: 0.8584, Valid. AP: 0.4608\n",
      "Epoch: 10/100, Loss: 0.5606607, Train Acc: 0.6919, Valid. Acc: 0.8111, Train AUC: 0.7865, Train AP: 0.7436, Valid. AUC: 0.8648, Valid. AP: 0.4690\n",
      "Epoch: 11/100, Loss: 0.5564737, Train Acc: 0.7203, Valid. Acc: 0.8215, Train AUC: 0.7903, Train AP: 0.7471, Valid. AUC: 0.8682, Valid. AP: 0.4745\n",
      "Epoch: 12/100, Loss: 0.5315508, Train Acc: 0.7200, Valid. Acc: 0.8246, Train AUC: 0.7967, Train AP: 0.7551, Valid. AUC: 0.8701, Valid. AP: 0.4782\n",
      "Epoch: 13/100, Loss: 0.5455410, Train Acc: 0.6969, Valid. Acc: 0.8254, Train AUC: 0.8020, Train AP: 0.7588, Valid. AUC: 0.8733, Valid. AP: 0.4800\n",
      "Epoch: 14/100, Loss: 0.5215639, Train Acc: 0.7298, Valid. Acc: 0.8249, Train AUC: 0.8061, Train AP: 0.7631, Valid. AUC: 0.8744, Valid. AP: 0.4811\n",
      "Epoch: 15/100, Loss: 0.5214304, Train Acc: 0.7270, Valid. Acc: 0.8200, Train AUC: 0.8089, Train AP: 0.7687, Valid. AUC: 0.8745, Valid. AP: 0.4870\n",
      "Epoch: 16/100, Loss: 0.5110461, Train Acc: 0.7311, Valid. Acc: 0.8194, Train AUC: 0.8166, Train AP: 0.7762, Valid. AUC: 0.8752, Valid. AP: 0.4906\n",
      "Epoch: 17/100, Loss: 0.5041295, Train Acc: 0.7402, Valid. Acc: 0.8242, Train AUC: 0.8201, Train AP: 0.7855, Valid. AUC: 0.8761, Valid. AP: 0.4883\n",
      "Epoch: 18/100, Loss: 0.5055815, Train Acc: 0.7461, Valid. Acc: 0.8267, Train AUC: 0.8227, Train AP: 0.7863, Valid. AUC: 0.8775, Valid. AP: 0.4884\n",
      "Epoch: 19/100, Loss: 0.4956004, Train Acc: 0.7436, Valid. Acc: 0.8227, Train AUC: 0.8259, Train AP: 0.7984, Valid. AUC: 0.8784, Valid. AP: 0.4899\n",
      "Epoch: 20/100, Loss: 0.4997550, Train Acc: 0.7347, Valid. Acc: 0.8253, Train AUC: 0.8303, Train AP: 0.7991, Valid. AUC: 0.8788, Valid. AP: 0.4841\n",
      "Epoch: 21/100, Loss: 0.4886901, Train Acc: 0.7451, Valid. Acc: 0.8260, Train AUC: 0.8315, Train AP: 0.7996, Valid. AUC: 0.8783, Valid. AP: 0.4797\n",
      "Epoch: 22/100, Loss: 0.4926662, Train Acc: 0.7401, Valid. Acc: 0.8262, Train AUC: 0.8340, Train AP: 0.8103, Valid. AUC: 0.8780, Valid. AP: 0.4813\n",
      "Epoch: 23/100, Loss: 0.4789238, Train Acc: 0.7458, Valid. Acc: 0.8241, Train AUC: 0.8378, Train AP: 0.8218, Valid. AUC: 0.8774, Valid. AP: 0.4821\n",
      "Epoch: 24/100, Loss: 0.4840452, Train Acc: 0.7499, Valid. Acc: 0.8245, Train AUC: 0.8425, Train AP: 0.8202, Valid. AUC: 0.8767, Valid. AP: 0.4764\n",
      "Epoch: 25/100, Loss: 0.4739204, Train Acc: 0.7518, Valid. Acc: 0.8190, Train AUC: 0.8419, Train AP: 0.8259, Valid. AUC: 0.8757, Valid. AP: 0.4693\n",
      "Epoch: 26/100, Loss: 0.4705203, Train Acc: 0.7535, Valid. Acc: 0.8182, Train AUC: 0.8468, Train AP: 0.8305, Valid. AUC: 0.8755, Valid. AP: 0.4631\n",
      "Epoch: 27/100, Loss: 0.4675801, Train Acc: 0.7520, Valid. Acc: 0.8190, Train AUC: 0.8484, Train AP: 0.8342, Valid. AUC: 0.8759, Valid. AP: 0.4601\n",
      "Epoch: 28/100, Loss: 0.4649695, Train Acc: 0.7526, Valid. Acc: 0.8215, Train AUC: 0.8494, Train AP: 0.8358, Valid. AUC: 0.8767, Valid. AP: 0.4598\n",
      "Epoch: 29/100, Loss: 0.4642835, Train Acc: 0.7539, Valid. Acc: 0.8225, Train AUC: 0.8498, Train AP: 0.8376, Valid. AUC: 0.8777, Valid. AP: 0.4603\n",
      "Epoch: 30/100, Loss: 0.4596530, Train Acc: 0.7551, Valid. Acc: 0.8272, Train AUC: 0.8521, Train AP: 0.8418, Valid. AUC: 0.8783, Valid. AP: 0.4615\n",
      "Epoch: 31/100, Loss: 0.4590177, Train Acc: 0.7546, Valid. Acc: 0.8289, Train AUC: 0.8540, Train AP: 0.8454, Valid. AUC: 0.8789, Valid. AP: 0.4638\n",
      "Epoch: 32/100, Loss: 0.4569871, Train Acc: 0.7545, Valid. Acc: 0.8261, Train AUC: 0.8538, Train AP: 0.8454, Valid. AUC: 0.8794, Valid. AP: 0.4654\n",
      "Epoch: 33/100, Loss: 0.4552539, Train Acc: 0.7596, Valid. Acc: 0.8251, Train AUC: 0.8550, Train AP: 0.8442, Valid. AUC: 0.8794, Valid. AP: 0.4660\n",
      "Epoch: 34/100, Loss: 0.4554758, Train Acc: 0.7604, Valid. Acc: 0.8206, Train AUC: 0.8576, Train AP: 0.8476, Valid. AUC: 0.8787, Valid. AP: 0.4636\n",
      "Epoch: 35/100, Loss: 0.4509823, Train Acc: 0.7621, Valid. Acc: 0.8182, Train AUC: 0.8591, Train AP: 0.8513, Valid. AUC: 0.8781, Valid. AP: 0.4632\n",
      "Epoch: 36/100, Loss: 0.4509509, Train Acc: 0.7610, Valid. Acc: 0.8244, Train AUC: 0.8598, Train AP: 0.8521, Valid. AUC: 0.8785, Valid. AP: 0.4656\n",
      "Epoch: 37/100, Loss: 0.4475178, Train Acc: 0.7640, Valid. Acc: 0.8261, Train AUC: 0.8603, Train AP: 0.8530, Valid. AUC: 0.8792, Valid. AP: 0.4684\n",
      "Epoch: 38/100, Loss: 0.4489297, Train Acc: 0.7629, Valid. Acc: 0.8228, Train AUC: 0.8607, Train AP: 0.8550, Valid. AUC: 0.8794, Valid. AP: 0.4684\n",
      "Epoch: 39/100, Loss: 0.4476427, Train Acc: 0.7620, Valid. Acc: 0.8237, Train AUC: 0.8608, Train AP: 0.8539, Valid. AUC: 0.8796, Valid. AP: 0.4677\n",
      "Epoch: 40/100, Loss: 0.4442557, Train Acc: 0.7618, Valid. Acc: 0.8233, Train AUC: 0.8626, Train AP: 0.8569, Valid. AUC: 0.8800, Valid. AP: 0.4681\n",
      "Epoch: 41/100, Loss: 0.4431758, Train Acc: 0.7656, Valid. Acc: 0.8234, Train AUC: 0.8645, Train AP: 0.8581, Valid. AUC: 0.8800, Valid. AP: 0.4664\n",
      "Epoch: 42/100, Loss: 0.4399950, Train Acc: 0.7680, Valid. Acc: 0.8208, Train AUC: 0.8674, Train AP: 0.8627, Valid. AUC: 0.8794, Valid. AP: 0.4621\n",
      "Epoch: 43/100, Loss: 0.4407296, Train Acc: 0.7641, Valid. Acc: 0.8234, Train AUC: 0.8672, Train AP: 0.8636, Valid. AUC: 0.8798, Valid. AP: 0.4636\n",
      "Epoch: 44/100, Loss: 0.4385890, Train Acc: 0.7669, Valid. Acc: 0.8227, Train AUC: 0.8676, Train AP: 0.8643, Valid. AUC: 0.8799, Valid. AP: 0.4629\n",
      "Epoch: 45/100, Loss: 0.4364518, Train Acc: 0.7666, Valid. Acc: 0.8236, Train AUC: 0.8684, Train AP: 0.8661, Valid. AUC: 0.8799, Valid. AP: 0.4635\n",
      "Epoch: 46/100, Loss: 0.4348876, Train Acc: 0.7679, Valid. Acc: 0.8235, Train AUC: 0.8696, Train AP: 0.8675, Valid. AUC: 0.8802, Valid. AP: 0.4643\n",
      "Epoch: 47/100, Loss: 0.4356627, Train Acc: 0.7640, Valid. Acc: 0.8245, Train AUC: 0.8685, Train AP: 0.8677, Valid. AUC: 0.8816, Valid. AP: 0.4665\n",
      "Epoch: 48/100, Loss: 0.4330978, Train Acc: 0.7679, Valid. Acc: 0.8250, Train AUC: 0.8699, Train AP: 0.8689, Valid. AUC: 0.8817, Valid. AP: 0.4662\n",
      "Epoch: 49/100, Loss: 0.4335856, Train Acc: 0.7682, Valid. Acc: 0.8313, Train AUC: 0.8697, Train AP: 0.8677, Valid. AUC: 0.8814, Valid. AP: 0.4644\n",
      "Epoch: 50/100, Loss: 0.4345599, Train Acc: 0.7672, Valid. Acc: 0.8264, Train AUC: 0.8690, Train AP: 0.8655, Valid. AUC: 0.8820, Valid. AP: 0.4654\n",
      "Epoch: 51/100, Loss: 0.4284443, Train Acc: 0.7701, Valid. Acc: 0.8253, Train AUC: 0.8733, Train AP: 0.8730, Valid. AUC: 0.8815, Valid. AP: 0.4640\n",
      "Epoch: 52/100, Loss: 0.4313084, Train Acc: 0.7690, Valid. Acc: 0.8262, Train AUC: 0.8710, Train AP: 0.8709, Valid. AUC: 0.8794, Valid. AP: 0.4609\n",
      "Epoch: 53/100, Loss: 0.4282309, Train Acc: 0.7698, Valid. Acc: 0.8246, Train AUC: 0.8735, Train AP: 0.8744, Valid. AUC: 0.8788, Valid. AP: 0.4602\n",
      "Epoch: 54/100, Loss: 0.4289488, Train Acc: 0.7694, Valid. Acc: 0.8231, Train AUC: 0.8730, Train AP: 0.8733, Valid. AUC: 0.8798, Valid. AP: 0.4625\n",
      "Epoch: 55/100, Loss: 0.4299392, Train Acc: 0.7678, Valid. Acc: 0.8246, Train AUC: 0.8731, Train AP: 0.8735, Valid. AUC: 0.8831, Valid. AP: 0.4708\n",
      "Epoch: 56/100, Loss: 0.4265433, Train Acc: 0.7701, Valid. Acc: 0.8270, Train AUC: 0.8737, Train AP: 0.8760, Valid. AUC: 0.8829, Valid. AP: 0.4699\n",
      "Epoch: 57/100, Loss: 0.4330422, Train Acc: 0.7674, Valid. Acc: 0.8344, Train AUC: 0.8730, Train AP: 0.8745, Valid. AUC: 0.8816, Valid. AP: 0.4640\n",
      "Epoch: 58/100, Loss: 0.4372427, Train Acc: 0.7603, Valid. Acc: 0.8303, Train AUC: 0.8735, Train AP: 0.8760, Valid. AUC: 0.8827, Valid. AP: 0.4642\n",
      "Epoch: 59/100, Loss: 0.4258843, Train Acc: 0.7693, Valid. Acc: 0.8275, Train AUC: 0.8743, Train AP: 0.8757, Valid. AUC: 0.8841, Valid. AP: 0.4688\n",
      "Epoch: 60/100, Loss: 0.4351530, Train Acc: 0.7672, Valid. Acc: 0.8245, Train AUC: 0.8766, Train AP: 0.8788, Valid. AUC: 0.8825, Valid. AP: 0.4640\n",
      "Epoch: 61/100, Loss: 0.4238817, Train Acc: 0.7692, Valid. Acc: 0.8217, Train AUC: 0.8749, Train AP: 0.8766, Valid. AUC: 0.8803, Valid. AP: 0.4594\n",
      "Epoch: 62/100, Loss: 0.4294196, Train Acc: 0.7641, Valid. Acc: 0.8245, Train AUC: 0.8750, Train AP: 0.8772, Valid. AUC: 0.8817, Valid. AP: 0.4634\n",
      "Epoch: 63/100, Loss: 0.4207157, Train Acc: 0.7737, Valid. Acc: 0.8270, Train AUC: 0.8775, Train AP: 0.8793, Valid. AUC: 0.8831, Valid. AP: 0.4672\n",
      "Epoch: 64/100, Loss: 0.4253069, Train Acc: 0.7689, Valid. Acc: 0.8257, Train AUC: 0.8764, Train AP: 0.8782, Valid. AUC: 0.8833, Valid. AP: 0.4671\n",
      "Epoch: 65/100, Loss: 0.4187877, Train Acc: 0.7721, Valid. Acc: 0.8346, Train AUC: 0.8771, Train AP: 0.8798, Valid. AUC: 0.8831, Valid. AP: 0.4665\n",
      "Epoch: 66/100, Loss: 0.4232409, Train Acc: 0.7710, Valid. Acc: 0.8350, Train AUC: 0.8771, Train AP: 0.8793, Valid. AUC: 0.8838, Valid. AP: 0.4671\n",
      "Epoch: 67/100, Loss: 0.4178599, Train Acc: 0.7734, Valid. Acc: 0.8313, Train AUC: 0.8780, Train AP: 0.8808, Valid. AUC: 0.8843, Valid. AP: 0.4672\n",
      "Epoch: 68/100, Loss: 0.4196961, Train Acc: 0.7718, Valid. Acc: 0.8280, Train AUC: 0.8779, Train AP: 0.8811, Valid. AUC: 0.8843, Valid. AP: 0.4660\n",
      "Epoch: 69/100, Loss: 0.4187926, Train Acc: 0.7714, Valid. Acc: 0.8232, Train AUC: 0.8773, Train AP: 0.8807, Valid. AUC: 0.8838, Valid. AP: 0.4643\n",
      "Epoch: 70/100, Loss: 0.4181133, Train Acc: 0.7695, Valid. Acc: 0.8240, Train AUC: 0.8767, Train AP: 0.8805, Valid. AUC: 0.8835, Valid. AP: 0.4631\n",
      "Epoch: 71/100, Loss: 0.4164033, Train Acc: 0.7738, Valid. Acc: 0.8243, Train AUC: 0.8788, Train AP: 0.8819, Valid. AUC: 0.8836, Valid. AP: 0.4641\n",
      "Epoch: 72/100, Loss: 0.4162331, Train Acc: 0.7735, Valid. Acc: 0.8258, Train AUC: 0.8785, Train AP: 0.8816, Valid. AUC: 0.8840, Valid. AP: 0.4663\n",
      "Epoch: 73/100, Loss: 0.4194439, Train Acc: 0.7722, Valid. Acc: 0.8239, Train AUC: 0.8782, Train AP: 0.8814, Valid. AUC: 0.8837, Valid. AP: 0.4668\n",
      "Epoch: 74/100, Loss: 0.4148077, Train Acc: 0.7732, Valid. Acc: 0.8254, Train AUC: 0.8781, Train AP: 0.8818, Valid. AUC: 0.8836, Valid. AP: 0.4672\n",
      "Epoch: 75/100, Loss: 0.4150675, Train Acc: 0.7723, Valid. Acc: 0.8257, Train AUC: 0.8788, Train AP: 0.8827, Valid. AUC: 0.8841, Valid. AP: 0.4686\n",
      "Epoch: 76/100, Loss: 0.4133748, Train Acc: 0.7748, Valid. Acc: 0.8262, Train AUC: 0.8805, Train AP: 0.8842, Valid. AUC: 0.8847, Valid. AP: 0.4692\n",
      "Epoch: 77/100, Loss: 0.4127997, Train Acc: 0.7729, Valid. Acc: 0.8268, Train AUC: 0.8796, Train AP: 0.8837, Valid. AUC: 0.8843, Valid. AP: 0.4673\n",
      "Epoch: 78/100, Loss: 0.4133454, Train Acc: 0.7720, Valid. Acc: 0.8275, Train AUC: 0.8789, Train AP: 0.8834, Valid. AUC: 0.8839, Valid. AP: 0.4656\n",
      "Epoch: 79/100, Loss: 0.4113200, Train Acc: 0.7745, Valid. Acc: 0.8277, Train AUC: 0.8808, Train AP: 0.8852, Valid. AUC: 0.8833, Valid. AP: 0.4637\n",
      "Epoch: 80/100, Loss: 0.4106555, Train Acc: 0.7733, Valid. Acc: 0.8275, Train AUC: 0.8798, Train AP: 0.8850, Valid. AUC: 0.8827, Valid. AP: 0.4626\n",
      "Epoch: 81/100, Loss: 0.4117667, Train Acc: 0.7731, Valid. Acc: 0.8273, Train AUC: 0.8795, Train AP: 0.8845, Valid. AUC: 0.8839, Valid. AP: 0.4664\n",
      "Epoch: 82/100, Loss: 0.4097776, Train Acc: 0.7737, Valid. Acc: 0.8269, Train AUC: 0.8807, Train AP: 0.8851, Valid. AUC: 0.8852, Valid. AP: 0.4704\n",
      "Epoch: 83/100, Loss: 0.4112123, Train Acc: 0.7759, Valid. Acc: 0.8273, Train AUC: 0.8816, Train AP: 0.8859, Valid. AUC: 0.8851, Valid. AP: 0.4699\n",
      "Epoch: 84/100, Loss: 0.4099995, Train Acc: 0.7763, Valid. Acc: 0.8293, Train AUC: 0.8812, Train AP: 0.8859, Valid. AUC: 0.8855, Valid. AP: 0.4705\n",
      "Epoch: 85/100, Loss: 0.4100578, Train Acc: 0.7758, Valid. Acc: 0.8286, Train AUC: 0.8809, Train AP: 0.8849, Valid. AUC: 0.8864, Valid. AP: 0.4721\n",
      "Epoch: 86/100, Loss: 0.4080168, Train Acc: 0.7756, Valid. Acc: 0.8287, Train AUC: 0.8817, Train AP: 0.8864, Valid. AUC: 0.8866, Valid. AP: 0.4722\n",
      "Epoch: 87/100, Loss: 0.4079320, Train Acc: 0.7759, Valid. Acc: 0.8287, Train AUC: 0.8821, Train AP: 0.8868, Valid. AUC: 0.8857, Valid. AP: 0.4695\n",
      "Epoch: 88/100, Loss: 0.4078219, Train Acc: 0.7744, Valid. Acc: 0.8286, Train AUC: 0.8814, Train AP: 0.8864, Valid. AUC: 0.8850, Valid. AP: 0.4675\n",
      "Epoch: 89/100, Loss: 0.4071147, Train Acc: 0.7744, Valid. Acc: 0.8283, Train AUC: 0.8817, Train AP: 0.8868, Valid. AUC: 0.8851, Valid. AP: 0.4679\n",
      "Epoch: 90/100, Loss: 0.4059633, Train Acc: 0.7770, Valid. Acc: 0.8273, Train AUC: 0.8827, Train AP: 0.8873, Valid. AUC: 0.8850, Valid. AP: 0.4689\n",
      "Epoch: 91/100, Loss: 0.4072619, Train Acc: 0.7739, Valid. Acc: 0.8270, Train AUC: 0.8819, Train AP: 0.8868, Valid. AUC: 0.8855, Valid. AP: 0.4710\n",
      "Epoch: 92/100, Loss: 0.4052329, Train Acc: 0.7762, Valid. Acc: 0.8269, Train AUC: 0.8829, Train AP: 0.8877, Valid. AUC: 0.8860, Valid. AP: 0.4734\n",
      "Epoch: 93/100, Loss: 0.4044146, Train Acc: 0.7770, Valid. Acc: 0.8271, Train AUC: 0.8828, Train AP: 0.8875, Valid. AUC: 0.8866, Valid. AP: 0.4752\n",
      "Epoch: 94/100, Loss: 0.4047600, Train Acc: 0.7768, Valid. Acc: 0.8267, Train AUC: 0.8828, Train AP: 0.8876, Valid. AUC: 0.8873, Valid. AP: 0.4772\n",
      "Epoch: 95/100, Loss: 0.4053329, Train Acc: 0.7751, Valid. Acc: 0.8272, Train AUC: 0.8826, Train AP: 0.8874, Valid. AUC: 0.8868, Valid. AP: 0.4741\n",
      "Epoch: 96/100, Loss: 0.4040679, Train Acc: 0.7749, Valid. Acc: 0.8275, Train AUC: 0.8826, Train AP: 0.8880, Valid. AUC: 0.8855, Valid. AP: 0.4697\n",
      "Epoch: 97/100, Loss: 0.4040402, Train Acc: 0.7779, Valid. Acc: 0.8274, Train AUC: 0.8834, Train AP: 0.8885, Valid. AUC: 0.8851, Valid. AP: 0.4682\n",
      "Epoch: 98/100, Loss: 0.4040308, Train Acc: 0.7772, Valid. Acc: 0.8280, Train AUC: 0.8828, Train AP: 0.8884, Valid. AUC: 0.8856, Valid. AP: 0.4701\n",
      "Epoch: 99/100, Loss: 0.4039481, Train Acc: 0.7773, Valid. Acc: 0.8279, Train AUC: 0.8842, Train AP: 0.8890, Valid. AUC: 0.8855, Valid. AP: 0.4701\n",
      "Epoch: 100/100, Loss: 0.4054680, Train Acc: 0.7778, Valid. Acc: 0.8269, Train AUC: 0.8844, Train AP: 0.8895, Valid. AUC: 0.8847, Valid. AP: 0.4682\n",
      "/home/ubuntu/PA-Cancer-Immunotherapy/GNN/train_pa_all_tvt_10x.py:212: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(configs['save_model']))\n",
      "Task-wise AP and ROC AUC:\n",
      "Task: TPP1, AP: 0.4519, ROC AUC: 0.9050\n",
      "Task: TPP2, AP: 0.5146, ROC AUC: 0.8089\n",
      "Task: TPP3, AP: 0.7523, ROC AUC: 0.4929\n",
      "Task: TPP4, AP: 0.3262, ROC AUC: 0.7516\n",
      "\n",
      "Overall AP and ROC AUC:\n",
      "Overall AP: 0.4779, Overall ROC AUC: 0.8874\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 2.263 MB of 2.535 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 2.535 MB of 2.535 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 2.535 MB of 2.535 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 2.535 MB of 2.535 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 2.535 MB of 2.535 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 2.535 MB of 2.535 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        test_ap ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   test_roc_auc ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▂▁▃▁▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇██▇█▇██████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train_ap ▁▂▂▂▃▃▃▄▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss ██▇▆▆▅▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_roc_auc ▁▂▂▃▄▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: valid_accuracy ▁▅█▇▇▇▇█▇▇▇▇▇▇▇▇▇██▇█▇▇██▇▇▇▇▇██████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       valid_ap ▁▂▃▃▅▇▇███▇▇▆▆▆▆▆▆▆▆▆▆▆▇▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  valid_roc_auc ▁▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇███▇██████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy 0.82611\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        test_ap 0.47787\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   test_roc_auc 0.88741\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.77777\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train_ap 0.88954\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.40547\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_roc_auc 0.88442\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: valid_accuracy 0.82693\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       valid_ap 0.46817\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  valid_roc_auc 0.88467\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mchocolate-music-5\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-gene_GNN/runs/ct27crgz\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-gene_GNN\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 4 W&B file(s), 0 media file(s), 8 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241217_124802-ct27crgz/logs\u001b[0m\n",
      "Test Acc: 0.8261, Test AUC: 0.8874, Test AP: 0.4779\n"
     ]
    }
   ],
   "source": [
    "# run to get TTP\n",
    "# for gene\n",
    "\n",
    "! python train_pa_all_tvt_10x.py --gpu 0 --configs_path configs/PA_all_tvt_10x_gene.yml --droup_out 0.1 --split StrictTCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca54fa4b-6e6b-4e72-8601-e538a952f252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(gpu=0, lr=0.001, epochs=100, w_celoss=1, w_aucloss=0, add_same_type_edges=False, dynamic_graph=False, dynamic_ratio=0.05, droup_out=0.1, positive_weights=1, dynamic_epochs=30, distance_threshold=10, configs_path='configs/PA_all_tvt_10x_gene.yml', split='StrictTCR', dataset='pMTnet')\n",
      "PROJECT_NAME: dataset-all-tvt-10x-gene_GNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfrohoari\u001b[0m (\u001b[33mpa_cancerimmunotherapy\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/ubuntu/PA-Cancer-Immunotherapy/GNN/wandb/run-20241218_015647-4ow1ibuy\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33miconic-glitter-6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-gene_GNN\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-gene_GNN/runs/4ow1ibuy\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   6 of 6 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   6 of 6 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   6 of 6 files downloaded.  \n",
      "embeddings_path:   models/PA_all/gene_and_allele_embeddings_10x.pkl\n",
      "train_file_list:   ['gene_train.csv']\n",
      "validation_file_list:   ['gene_validation.csv']\n",
      "test_file_list:   ['gene_test.csv']\n",
      "wandb logger initialisiert\n",
      "Epoch: 1/100, Loss: 0.6913584, Train Acc: 0.4946, Valid. Acc: 0.7197, Train AUC: 0.5005, Train AP: 0.5119, Valid. AUC: 0.7996, Valid. AP: 0.3951\n",
      "Epoch: 2/100, Loss: 0.6802936, Train Acc: 0.6560, Valid. Acc: 0.8005, Train AUC: 0.7125, Train AP: 0.6858, Valid. AUC: 0.8170, Valid. AP: 0.4063\n",
      "Epoch: 3/100, Loss: 0.6680257, Train Acc: 0.6714, Valid. Acc: 0.7869, Train AUC: 0.7372, Train AP: 0.7119, Valid. AUC: 0.8166, Valid. AP: 0.4085\n",
      "Epoch: 4/100, Loss: 0.6499577, Train Acc: 0.6750, Valid. Acc: 0.8279, Train AUC: 0.7338, Train AP: 0.7023, Valid. AUC: 0.8218, Valid. AP: 0.4144\n",
      "Epoch: 5/100, Loss: 0.6321561, Train Acc: 0.6595, Valid. Acc: 0.7965, Train AUC: 0.7363, Train AP: 0.7040, Valid. AUC: 0.8272, Valid. AP: 0.4206\n",
      "Epoch: 6/100, Loss: 0.6116681, Train Acc: 0.6830, Valid. Acc: 0.8308, Train AUC: 0.7424, Train AP: 0.7083, Valid. AUC: 0.8354, Valid. AP: 0.4291\n",
      "Epoch: 7/100, Loss: 0.6016095, Train Acc: 0.6529, Valid. Acc: 0.8015, Train AUC: 0.7610, Train AP: 0.7248, Valid. AUC: 0.8449, Valid. AP: 0.4397\n",
      "Epoch: 8/100, Loss: 0.5898743, Train Acc: 0.6966, Valid. Acc: 0.8246, Train AUC: 0.7619, Train AP: 0.7255, Valid. AUC: 0.8524, Valid. AP: 0.4515\n",
      "Epoch: 9/100, Loss: 0.5649711, Train Acc: 0.6918, Valid. Acc: 0.8332, Train AUC: 0.7761, Train AP: 0.7413, Valid. AUC: 0.8584, Valid. AP: 0.4607\n",
      "Epoch: 10/100, Loss: 0.5606177, Train Acc: 0.6921, Valid. Acc: 0.8110, Train AUC: 0.7865, Train AP: 0.7436, Valid. AUC: 0.8648, Valid. AP: 0.4689\n",
      "Epoch: 11/100, Loss: 0.5564952, Train Acc: 0.7203, Valid. Acc: 0.8216, Train AUC: 0.7903, Train AP: 0.7471, Valid. AUC: 0.8682, Valid. AP: 0.4745\n",
      "Epoch: 12/100, Loss: 0.5315003, Train Acc: 0.7199, Valid. Acc: 0.8246, Train AUC: 0.7967, Train AP: 0.7551, Valid. AUC: 0.8701, Valid. AP: 0.4781\n",
      "Epoch: 13/100, Loss: 0.5455135, Train Acc: 0.6970, Valid. Acc: 0.8254, Train AUC: 0.8020, Train AP: 0.7588, Valid. AUC: 0.8733, Valid. AP: 0.4800\n",
      "Epoch: 14/100, Loss: 0.5217525, Train Acc: 0.7298, Valid. Acc: 0.8249, Train AUC: 0.8060, Train AP: 0.7630, Valid. AUC: 0.8743, Valid. AP: 0.4811\n",
      "Epoch: 15/100, Loss: 0.5211743, Train Acc: 0.7270, Valid. Acc: 0.8200, Train AUC: 0.8089, Train AP: 0.7686, Valid. AUC: 0.8744, Valid. AP: 0.4871\n",
      "Epoch: 16/100, Loss: 0.5110789, Train Acc: 0.7312, Valid. Acc: 0.8193, Train AUC: 0.8166, Train AP: 0.7762, Valid. AUC: 0.8752, Valid. AP: 0.4907\n",
      "Epoch: 17/100, Loss: 0.5039238, Train Acc: 0.7402, Valid. Acc: 0.8242, Train AUC: 0.8201, Train AP: 0.7856, Valid. AUC: 0.8762, Valid. AP: 0.4884\n",
      "Epoch: 18/100, Loss: 0.5054795, Train Acc: 0.7462, Valid. Acc: 0.8270, Train AUC: 0.8227, Train AP: 0.7864, Valid. AUC: 0.8775, Valid. AP: 0.4884\n",
      "Epoch: 19/100, Loss: 0.4954208, Train Acc: 0.7436, Valid. Acc: 0.8227, Train AUC: 0.8259, Train AP: 0.7984, Valid. AUC: 0.8784, Valid. AP: 0.4898\n",
      "Epoch: 20/100, Loss: 0.4998710, Train Acc: 0.7344, Valid. Acc: 0.8251, Train AUC: 0.8303, Train AP: 0.7990, Valid. AUC: 0.8787, Valid. AP: 0.4839\n",
      "Epoch: 21/100, Loss: 0.4885073, Train Acc: 0.7452, Valid. Acc: 0.8259, Train AUC: 0.8315, Train AP: 0.7994, Valid. AUC: 0.8782, Valid. AP: 0.4796\n",
      "Epoch: 22/100, Loss: 0.4929610, Train Acc: 0.7400, Valid. Acc: 0.8259, Train AUC: 0.8340, Train AP: 0.8102, Valid. AUC: 0.8780, Valid. AP: 0.4814\n",
      "Epoch: 23/100, Loss: 0.4787248, Train Acc: 0.7458, Valid. Acc: 0.8243, Train AUC: 0.8378, Train AP: 0.8218, Valid. AUC: 0.8774, Valid. AP: 0.4822\n",
      "Epoch: 24/100, Loss: 0.4844118, Train Acc: 0.7496, Valid. Acc: 0.8246, Train AUC: 0.8425, Train AP: 0.8203, Valid. AUC: 0.8767, Valid. AP: 0.4765\n",
      "Epoch: 25/100, Loss: 0.4738453, Train Acc: 0.7520, Valid. Acc: 0.8191, Train AUC: 0.8420, Train AP: 0.8259, Valid. AUC: 0.8757, Valid. AP: 0.4694\n",
      "Epoch: 26/100, Loss: 0.4707040, Train Acc: 0.7534, Valid. Acc: 0.8183, Train AUC: 0.8469, Train AP: 0.8305, Valid. AUC: 0.8755, Valid. AP: 0.4633\n",
      "Epoch: 27/100, Loss: 0.4674608, Train Acc: 0.7520, Valid. Acc: 0.8192, Train AUC: 0.8484, Train AP: 0.8343, Valid. AUC: 0.8759, Valid. AP: 0.4604\n",
      "Epoch: 28/100, Loss: 0.4649498, Train Acc: 0.7526, Valid. Acc: 0.8215, Train AUC: 0.8495, Train AP: 0.8361, Valid. AUC: 0.8767, Valid. AP: 0.4600\n",
      "Epoch: 29/100, Loss: 0.4643072, Train Acc: 0.7539, Valid. Acc: 0.8223, Train AUC: 0.8499, Train AP: 0.8376, Valid. AUC: 0.8776, Valid. AP: 0.4602\n",
      "Epoch: 30/100, Loss: 0.4596513, Train Acc: 0.7550, Valid. Acc: 0.8271, Train AUC: 0.8521, Train AP: 0.8418, Valid. AUC: 0.8783, Valid. AP: 0.4614\n",
      "Epoch: 31/100, Loss: 0.4590076, Train Acc: 0.7545, Valid. Acc: 0.8288, Train AUC: 0.8541, Train AP: 0.8454, Valid. AUC: 0.8788, Valid. AP: 0.4636\n",
      "Epoch: 32/100, Loss: 0.4570700, Train Acc: 0.7542, Valid. Acc: 0.8258, Train AUC: 0.8537, Train AP: 0.8454, Valid. AUC: 0.8793, Valid. AP: 0.4652\n",
      "Epoch: 33/100, Loss: 0.4553392, Train Acc: 0.7594, Valid. Acc: 0.8247, Train AUC: 0.8550, Train AP: 0.8442, Valid. AUC: 0.8793, Valid. AP: 0.4658\n",
      "Epoch: 34/100, Loss: 0.4553712, Train Acc: 0.7605, Valid. Acc: 0.8204, Train AUC: 0.8576, Train AP: 0.8476, Valid. AUC: 0.8786, Valid. AP: 0.4634\n",
      "Epoch: 35/100, Loss: 0.4510449, Train Acc: 0.7620, Valid. Acc: 0.8180, Train AUC: 0.8591, Train AP: 0.8514, Valid. AUC: 0.8780, Valid. AP: 0.4632\n",
      "Epoch: 36/100, Loss: 0.4509256, Train Acc: 0.7610, Valid. Acc: 0.8244, Train AUC: 0.8598, Train AP: 0.8519, Valid. AUC: 0.8784, Valid. AP: 0.4656\n",
      "Epoch: 37/100, Loss: 0.4477225, Train Acc: 0.7638, Valid. Acc: 0.8259, Train AUC: 0.8602, Train AP: 0.8528, Valid. AUC: 0.8791, Valid. AP: 0.4684\n",
      "Epoch: 38/100, Loss: 0.4486922, Train Acc: 0.7628, Valid. Acc: 0.8226, Train AUC: 0.8606, Train AP: 0.8550, Valid. AUC: 0.8793, Valid. AP: 0.4685\n",
      "Epoch: 39/100, Loss: 0.4476573, Train Acc: 0.7619, Valid. Acc: 0.8235, Train AUC: 0.8607, Train AP: 0.8539, Valid. AUC: 0.8795, Valid. AP: 0.4678\n",
      "Epoch: 40/100, Loss: 0.4440956, Train Acc: 0.7619, Valid. Acc: 0.8231, Train AUC: 0.8625, Train AP: 0.8569, Valid. AUC: 0.8797, Valid. AP: 0.4680\n",
      "Epoch: 41/100, Loss: 0.4429184, Train Acc: 0.7654, Valid. Acc: 0.8235, Train AUC: 0.8645, Train AP: 0.8583, Valid. AUC: 0.8796, Valid. AP: 0.4661\n",
      "Epoch: 42/100, Loss: 0.4398795, Train Acc: 0.7677, Valid. Acc: 0.8207, Train AUC: 0.8674, Train AP: 0.8627, Valid. AUC: 0.8791, Valid. AP: 0.4619\n",
      "Epoch: 43/100, Loss: 0.4407643, Train Acc: 0.7641, Valid. Acc: 0.8236, Train AUC: 0.8672, Train AP: 0.8635, Valid. AUC: 0.8796, Valid. AP: 0.4635\n",
      "Epoch: 44/100, Loss: 0.4386042, Train Acc: 0.7667, Valid. Acc: 0.8228, Train AUC: 0.8676, Train AP: 0.8643, Valid. AUC: 0.8799, Valid. AP: 0.4630\n",
      "Epoch: 45/100, Loss: 0.4365651, Train Acc: 0.7665, Valid. Acc: 0.8235, Train AUC: 0.8683, Train AP: 0.8661, Valid. AUC: 0.8800, Valid. AP: 0.4638\n",
      "Epoch: 46/100, Loss: 0.4348336, Train Acc: 0.7679, Valid. Acc: 0.8236, Train AUC: 0.8697, Train AP: 0.8676, Valid. AUC: 0.8804, Valid. AP: 0.4646\n",
      "Epoch: 47/100, Loss: 0.4357085, Train Acc: 0.7639, Valid. Acc: 0.8244, Train AUC: 0.8684, Train AP: 0.8676, Valid. AUC: 0.8816, Valid. AP: 0.4665\n",
      "Epoch: 48/100, Loss: 0.4332024, Train Acc: 0.7678, Valid. Acc: 0.8252, Train AUC: 0.8699, Train AP: 0.8689, Valid. AUC: 0.8817, Valid. AP: 0.4662\n",
      "Epoch: 49/100, Loss: 0.4336113, Train Acc: 0.7684, Valid. Acc: 0.8311, Train AUC: 0.8697, Train AP: 0.8678, Valid. AUC: 0.8813, Valid. AP: 0.4642\n",
      "Epoch: 50/100, Loss: 0.4345693, Train Acc: 0.7670, Valid. Acc: 0.8258, Train AUC: 0.8690, Train AP: 0.8656, Valid. AUC: 0.8819, Valid. AP: 0.4652\n",
      "Epoch: 51/100, Loss: 0.4283170, Train Acc: 0.7700, Valid. Acc: 0.8249, Train AUC: 0.8733, Train AP: 0.8731, Valid. AUC: 0.8812, Valid. AP: 0.4637\n",
      "Epoch: 52/100, Loss: 0.4313907, Train Acc: 0.7691, Valid. Acc: 0.8264, Train AUC: 0.8709, Train AP: 0.8708, Valid. AUC: 0.8793, Valid. AP: 0.4609\n",
      "Epoch: 53/100, Loss: 0.4285016, Train Acc: 0.7695, Valid. Acc: 0.8245, Train AUC: 0.8734, Train AP: 0.8742, Valid. AUC: 0.8788, Valid. AP: 0.4604\n",
      "Epoch: 54/100, Loss: 0.4285174, Train Acc: 0.7702, Valid. Acc: 0.8233, Train AUC: 0.8733, Train AP: 0.8737, Valid. AUC: 0.8797, Valid. AP: 0.4628\n",
      "Epoch: 55/100, Loss: 0.4298432, Train Acc: 0.7680, Valid. Acc: 0.8247, Train AUC: 0.8728, Train AP: 0.8730, Valid. AUC: 0.8831, Valid. AP: 0.4712\n",
      "Epoch: 56/100, Loss: 0.4265403, Train Acc: 0.7699, Valid. Acc: 0.8269, Train AUC: 0.8735, Train AP: 0.8757, Valid. AUC: 0.8829, Valid. AP: 0.4701\n",
      "Epoch: 57/100, Loss: 0.4329605, Train Acc: 0.7676, Valid. Acc: 0.8345, Train AUC: 0.8729, Train AP: 0.8743, Valid. AUC: 0.8816, Valid. AP: 0.4646\n",
      "Epoch: 58/100, Loss: 0.4381474, Train Acc: 0.7600, Valid. Acc: 0.8301, Train AUC: 0.8732, Train AP: 0.8754, Valid. AUC: 0.8828, Valid. AP: 0.4648\n",
      "Epoch: 59/100, Loss: 0.4258609, Train Acc: 0.7695, Valid. Acc: 0.8275, Train AUC: 0.8741, Train AP: 0.8754, Valid. AUC: 0.8842, Valid. AP: 0.4693\n",
      "Epoch: 60/100, Loss: 0.4359423, Train Acc: 0.7668, Valid. Acc: 0.8243, Train AUC: 0.8766, Train AP: 0.8788, Valid. AUC: 0.8825, Valid. AP: 0.4641\n",
      "Epoch: 61/100, Loss: 0.4239357, Train Acc: 0.7693, Valid. Acc: 0.8213, Train AUC: 0.8750, Train AP: 0.8768, Valid. AUC: 0.8802, Valid. AP: 0.4595\n",
      "Epoch: 62/100, Loss: 0.4304948, Train Acc: 0.7632, Valid. Acc: 0.8241, Train AUC: 0.8749, Train AP: 0.8771, Valid. AUC: 0.8819, Valid. AP: 0.4639\n",
      "Epoch: 63/100, Loss: 0.4210013, Train Acc: 0.7739, Valid. Acc: 0.8268, Train AUC: 0.8774, Train AP: 0.8791, Valid. AUC: 0.8833, Valid. AP: 0.4678\n",
      "Epoch: 64/100, Loss: 0.4256728, Train Acc: 0.7689, Valid. Acc: 0.8259, Train AUC: 0.8766, Train AP: 0.8784, Valid. AUC: 0.8833, Valid. AP: 0.4669\n",
      "Epoch: 65/100, Loss: 0.4188556, Train Acc: 0.7724, Valid. Acc: 0.8347, Train AUC: 0.8771, Train AP: 0.8799, Valid. AUC: 0.8831, Valid. AP: 0.4665\n",
      "Epoch: 66/100, Loss: 0.4237453, Train Acc: 0.7708, Valid. Acc: 0.8350, Train AUC: 0.8770, Train AP: 0.8791, Valid. AUC: 0.8837, Valid. AP: 0.4669\n",
      "Epoch: 67/100, Loss: 0.4181187, Train Acc: 0.7732, Valid. Acc: 0.8310, Train AUC: 0.8778, Train AP: 0.8806, Valid. AUC: 0.8842, Valid. AP: 0.4671\n",
      "Epoch: 68/100, Loss: 0.4198447, Train Acc: 0.7716, Valid. Acc: 0.8276, Train AUC: 0.8779, Train AP: 0.8811, Valid. AUC: 0.8842, Valid. AP: 0.4661\n",
      "Epoch: 69/100, Loss: 0.4190766, Train Acc: 0.7715, Valid. Acc: 0.8235, Train AUC: 0.8773, Train AP: 0.8806, Valid. AUC: 0.8837, Valid. AP: 0.4644\n",
      "Epoch: 70/100, Loss: 0.4178757, Train Acc: 0.7702, Valid. Acc: 0.8234, Train AUC: 0.8770, Train AP: 0.8807, Valid. AUC: 0.8833, Valid. AP: 0.4631\n",
      "Epoch: 71/100, Loss: 0.4165868, Train Acc: 0.7735, Valid. Acc: 0.8245, Train AUC: 0.8789, Train AP: 0.8821, Valid. AUC: 0.8836, Valid. AP: 0.4643\n",
      "Epoch: 72/100, Loss: 0.4161742, Train Acc: 0.7739, Valid. Acc: 0.8261, Train AUC: 0.8786, Train AP: 0.8817, Valid. AUC: 0.8841, Valid. AP: 0.4668\n",
      "Epoch: 73/100, Loss: 0.4197346, Train Acc: 0.7722, Valid. Acc: 0.8244, Train AUC: 0.8781, Train AP: 0.8813, Valid. AUC: 0.8841, Valid. AP: 0.4675\n",
      "Epoch: 74/100, Loss: 0.4147515, Train Acc: 0.7732, Valid. Acc: 0.8254, Train AUC: 0.8782, Train AP: 0.8819, Valid. AUC: 0.8837, Valid. AP: 0.4674\n",
      "Epoch: 75/100, Loss: 0.4152441, Train Acc: 0.7723, Valid. Acc: 0.8256, Train AUC: 0.8789, Train AP: 0.8827, Valid. AUC: 0.8842, Valid. AP: 0.4683\n",
      "Epoch: 76/100, Loss: 0.4135461, Train Acc: 0.7751, Valid. Acc: 0.8263, Train AUC: 0.8805, Train AP: 0.8841, Valid. AUC: 0.8849, Valid. AP: 0.4693\n",
      "Epoch: 77/100, Loss: 0.4127233, Train Acc: 0.7731, Valid. Acc: 0.8269, Train AUC: 0.8796, Train AP: 0.8836, Valid. AUC: 0.8846, Valid. AP: 0.4680\n",
      "Epoch: 78/100, Loss: 0.4130134, Train Acc: 0.7730, Valid. Acc: 0.8275, Train AUC: 0.8792, Train AP: 0.8836, Valid. AUC: 0.8838, Valid. AP: 0.4657\n",
      "Epoch: 79/100, Loss: 0.4118516, Train Acc: 0.7744, Valid. Acc: 0.8276, Train AUC: 0.8806, Train AP: 0.8849, Valid. AUC: 0.8828, Valid. AP: 0.4631\n",
      "Epoch: 80/100, Loss: 0.4109223, Train Acc: 0.7727, Valid. Acc: 0.8272, Train AUC: 0.8794, Train AP: 0.8846, Valid. AUC: 0.8823, Valid. AP: 0.4623\n",
      "Epoch: 81/100, Loss: 0.4122492, Train Acc: 0.7722, Valid. Acc: 0.8273, Train AUC: 0.8793, Train AP: 0.8842, Valid. AUC: 0.8839, Valid. AP: 0.4670\n",
      "Epoch: 82/100, Loss: 0.4098732, Train Acc: 0.7741, Valid. Acc: 0.8275, Train AUC: 0.8808, Train AP: 0.8851, Valid. AUC: 0.8853, Valid. AP: 0.4708\n",
      "Epoch: 83/100, Loss: 0.4118882, Train Acc: 0.7759, Valid. Acc: 0.8276, Train AUC: 0.8816, Train AP: 0.8858, Valid. AUC: 0.8852, Valid. AP: 0.4701\n",
      "Epoch: 84/100, Loss: 0.4104121, Train Acc: 0.7760, Valid. Acc: 0.8310, Train AUC: 0.8810, Train AP: 0.8857, Valid. AUC: 0.8856, Valid. AP: 0.4705\n",
      "Epoch: 85/100, Loss: 0.4108247, Train Acc: 0.7754, Valid. Acc: 0.8289, Train AUC: 0.8808, Train AP: 0.8846, Valid. AUC: 0.8865, Valid. AP: 0.4723\n",
      "Epoch: 86/100, Loss: 0.4080343, Train Acc: 0.7758, Valid. Acc: 0.8287, Train AUC: 0.8818, Train AP: 0.8865, Valid. AUC: 0.8868, Valid. AP: 0.4728\n",
      "Epoch: 87/100, Loss: 0.4086291, Train Acc: 0.7756, Valid. Acc: 0.8285, Train AUC: 0.8821, Train AP: 0.8867, Valid. AUC: 0.8858, Valid. AP: 0.4698\n",
      "Epoch: 88/100, Loss: 0.4077827, Train Acc: 0.7748, Valid. Acc: 0.8284, Train AUC: 0.8816, Train AP: 0.8865, Valid. AUC: 0.8848, Valid. AP: 0.4669\n",
      "Epoch: 89/100, Loss: 0.4075186, Train Acc: 0.7744, Valid. Acc: 0.8279, Train AUC: 0.8818, Train AP: 0.8868, Valid. AUC: 0.8848, Valid. AP: 0.4672\n",
      "Epoch: 90/100, Loss: 0.4061658, Train Acc: 0.7768, Valid. Acc: 0.8272, Train AUC: 0.8825, Train AP: 0.8871, Valid. AUC: 0.8851, Valid. AP: 0.4690\n",
      "Epoch: 91/100, Loss: 0.4074243, Train Acc: 0.7739, Valid. Acc: 0.8269, Train AUC: 0.8821, Train AP: 0.8868, Valid. AUC: 0.8855, Valid. AP: 0.4711\n",
      "Epoch: 92/100, Loss: 0.4050985, Train Acc: 0.7766, Valid. Acc: 0.8271, Train AUC: 0.8830, Train AP: 0.8878, Valid. AUC: 0.8858, Valid. AP: 0.4730\n",
      "Epoch: 93/100, Loss: 0.4044988, Train Acc: 0.7768, Valid. Acc: 0.8267, Train AUC: 0.8828, Train AP: 0.8876, Valid. AUC: 0.8863, Valid. AP: 0.4746\n",
      "Epoch: 94/100, Loss: 0.4050486, Train Acc: 0.7763, Valid. Acc: 0.8270, Train AUC: 0.8827, Train AP: 0.8875, Valid. AUC: 0.8872, Valid. AP: 0.4771\n",
      "Epoch: 95/100, Loss: 0.4052072, Train Acc: 0.7750, Valid. Acc: 0.8272, Train AUC: 0.8825, Train AP: 0.8874, Valid. AUC: 0.8870, Valid. AP: 0.4749\n",
      "Epoch: 96/100, Loss: 0.4047328, Train Acc: 0.7741, Valid. Acc: 0.8276, Train AUC: 0.8822, Train AP: 0.8876, Valid. AUC: 0.8857, Valid. AP: 0.4706\n",
      "Epoch: 97/100, Loss: 0.4037861, Train Acc: 0.7779, Valid. Acc: 0.8269, Train AUC: 0.8834, Train AP: 0.8885, Valid. AUC: 0.8850, Valid. AP: 0.4680\n",
      "Epoch: 98/100, Loss: 0.4047185, Train Acc: 0.7766, Valid. Acc: 0.8276, Train AUC: 0.8827, Train AP: 0.8883, Valid. AUC: 0.8854, Valid. AP: 0.4693\n",
      "Epoch: 99/100, Loss: 0.4035016, Train Acc: 0.7774, Valid. Acc: 0.8276, Train AUC: 0.8841, Train AP: 0.8890, Valid. AUC: 0.8855, Valid. AP: 0.4700\n",
      "Epoch: 100/100, Loss: 0.4068424, Train Acc: 0.7779, Valid. Acc: 0.8267, Train AUC: 0.8845, Train AP: 0.8895, Valid. AUC: 0.8848, Valid. AP: 0.4681\n",
      "/home/ubuntu/PA-Cancer-Immunotherapy/GNN/train_pa_all_tvt_10x.py:212: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(configs['save_model']))\n",
      "Task-wise AP and ROC AUC:\n",
      "Task: TPP1, AP: 0.4527, ROC AUC: 0.9050\n",
      "Task: TPP2, AP: 0.5134, ROC AUC: 0.8084\n",
      "Task: TPP3, AP: 0.7529, ROC AUC: 0.4924\n",
      "Task: TPP4, AP: 0.3328, ROC AUC: 0.7615\n",
      "\n",
      "Overall AP and ROC AUC:\n",
      "Overall AP: 0.4779, Overall ROC AUC: 0.8874\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 2.263 MB of 2.535 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 2.535 MB of 2.535 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 2.535 MB of 2.535 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 2.535 MB of 2.535 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▁▁▁▂▂▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇█████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        test_ap ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   test_roc_auc ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▁▂▃▃▅▅▆▆▆▆▇▇▇▇▇▇▇██▇▇█▇█████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train_ap ▁▂▂▂▂▃▄▄▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇███████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss █▇▆▅▅▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_roc_auc ▁▅▅▅▆▇▇▇▇▇▇▇▇▇██████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: valid_accuracy ▁▆▇█▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇█▇██▇█████████▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       valid_ap ▁▁▂▅▆███▇▅▆▆▆▆▆▆▆▆▆▅▆▆▆▆▆▆▆▆▆▆▆▆▆▇▆▆▇▇▆▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  valid_roc_auc ▁▄▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇█████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy 0.82629\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        test_ap 0.47793\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   test_roc_auc 0.88739\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.7779\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train_ap 0.88954\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.40684\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_roc_auc 0.88445\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: valid_accuracy 0.82672\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       valid_ap 0.46815\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  valid_roc_auc 0.88479\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33miconic-glitter-6\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-gene_GNN/runs/4ow1ibuy\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-gene_GNN\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 6 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241218_015647-4ow1ibuy/logs\u001b[0m\n",
      "Test Acc: 0.8263, Test AUC: 0.8874, Test AP: 0.4779\n"
     ]
    }
   ],
   "source": [
    "# another run for gene, after the astonishing discovery of exact train losses in wandb\n",
    "# for gene\n",
    "\n",
    "! python train_pa_all_tvt_10x.py --gpu 0 --configs_path configs/PA_all_tvt_10x_gene.yml --droup_out 0.1 --split StrictTCR\n",
    "\n",
    "# still, the loss looks the same!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3b2e73c-c8e2-4ffa-b5df-8d5bd1466a79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(gpu=0, lr=0.001, epochs=100, w_celoss=1, w_aucloss=0, add_same_type_edges=False, dynamic_graph=False, dynamic_ratio=0.05, droup_out=0.4, positive_weights=1, dynamic_epochs=30, distance_threshold=10, configs_path='configs/PA_all_tvt_10x_gene.yml', split='StrictTCR', dataset='pMTnet')\n",
      "PROJECT_NAME: dataset-all-tvt-10x-gene_GNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfrohoari\u001b[0m (\u001b[33mpa_cancerimmunotherapy\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/ubuntu/PA-Cancer-Immunotherapy/GNN/wandb/run-20241218_020428-7obdkze0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mroyal-monkey-7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-gene_GNN\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-gene_GNN/runs/7obdkze0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   6 of 6 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   6 of 6 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   6 of 6 files downloaded.  \n",
      "embeddings_path:   models/PA_all/gene_and_allele_embeddings_10x.pkl\n",
      "train_file_list:   ['gene_train.csv']\n",
      "validation_file_list:   ['gene_validation.csv']\n",
      "test_file_list:   ['gene_test.csv']\n",
      "wandb logger initialisiert\n",
      "Epoch: 1/100, Loss: 0.6919470, Train Acc: 0.4907, Valid. Acc: 0.7387, Train AUC: 0.4924, Train AP: 0.5070, Valid. AUC: 0.7835, Valid. AP: 0.3792\n",
      "Epoch: 2/100, Loss: 0.6841689, Train Acc: 0.5816, Valid. Acc: 0.7841, Train AUC: 0.6339, Train AP: 0.6258, Valid. AUC: 0.8163, Valid. AP: 0.4048\n",
      "Epoch: 3/100, Loss: 0.6786925, Train Acc: 0.5971, Valid. Acc: 0.8038, Train AUC: 0.6510, Train AP: 0.6356, Valid. AUC: 0.8179, Valid. AP: 0.4014\n",
      "Epoch: 4/100, Loss: 0.6650081, Train Acc: 0.6503, Valid. Acc: 0.8241, Train AUC: 0.7021, Train AP: 0.6669, Valid. AUC: 0.8194, Valid. AP: 0.4049\n",
      "Epoch: 5/100, Loss: 0.6517621, Train Acc: 0.6526, Valid. Acc: 0.8162, Train AUC: 0.7078, Train AP: 0.6826, Valid. AUC: 0.8220, Valid. AP: 0.4100\n",
      "Epoch: 6/100, Loss: 0.6345785, Train Acc: 0.6673, Valid. Acc: 0.8266, Train AUC: 0.7201, Train AP: 0.6897, Valid. AUC: 0.8268, Valid. AP: 0.4155\n",
      "Epoch: 7/100, Loss: 0.6201385, Train Acc: 0.6703, Valid. Acc: 0.8224, Train AUC: 0.7346, Train AP: 0.7040, Valid. AUC: 0.8341, Valid. AP: 0.4240\n",
      "Epoch: 8/100, Loss: 0.6065103, Train Acc: 0.6690, Valid. Acc: 0.8305, Train AUC: 0.7347, Train AP: 0.7034, Valid. AUC: 0.8424, Valid. AP: 0.4354\n",
      "Epoch: 9/100, Loss: 0.5904823, Train Acc: 0.6735, Valid. Acc: 0.8300, Train AUC: 0.7452, Train AP: 0.7081, Valid. AUC: 0.8452, Valid. AP: 0.4431\n",
      "Epoch: 10/100, Loss: 0.5822130, Train Acc: 0.6724, Valid. Acc: 0.8077, Train AUC: 0.7654, Train AP: 0.7293, Valid. AUC: 0.8535, Valid. AP: 0.4510\n",
      "Epoch: 11/100, Loss: 0.5997249, Train Acc: 0.7036, Valid. Acc: 0.8281, Train AUC: 0.7621, Train AP: 0.7235, Valid. AUC: 0.8549, Valid. AP: 0.4535\n",
      "Epoch: 12/100, Loss: 0.5576320, Train Acc: 0.6955, Valid. Acc: 0.8236, Train AUC: 0.7772, Train AP: 0.7397, Valid. AUC: 0.8591, Valid. AP: 0.4576\n",
      "Epoch: 13/100, Loss: 0.5753980, Train Acc: 0.6685, Valid. Acc: 0.8238, Train AUC: 0.7670, Train AP: 0.7348, Valid. AUC: 0.8654, Valid. AP: 0.4631\n",
      "Epoch: 14/100, Loss: 0.5521021, Train Acc: 0.7095, Valid. Acc: 0.8203, Train AUC: 0.7803, Train AP: 0.7382, Valid. AUC: 0.8693, Valid. AP: 0.4632\n",
      "Epoch: 15/100, Loss: 0.5562384, Train Acc: 0.7136, Valid. Acc: 0.8262, Train AUC: 0.7803, Train AP: 0.7414, Valid. AUC: 0.8711, Valid. AP: 0.4666\n",
      "Epoch: 16/100, Loss: 0.5373163, Train Acc: 0.7188, Valid. Acc: 0.8226, Train AUC: 0.7942, Train AP: 0.7577, Valid. AUC: 0.8719, Valid. AP: 0.4715\n",
      "Epoch: 17/100, Loss: 0.5395845, Train Acc: 0.7063, Valid. Acc: 0.8208, Train AUC: 0.7986, Train AP: 0.7687, Valid. AUC: 0.8736, Valid. AP: 0.4761\n",
      "Epoch: 18/100, Loss: 0.5288999, Train Acc: 0.7187, Valid. Acc: 0.8246, Train AUC: 0.8024, Train AP: 0.7670, Valid. AUC: 0.8751, Valid. AP: 0.4811\n",
      "Epoch: 19/100, Loss: 0.5258077, Train Acc: 0.7323, Valid. Acc: 0.8243, Train AUC: 0.8047, Train AP: 0.7676, Valid. AUC: 0.8758, Valid. AP: 0.4834\n",
      "Epoch: 20/100, Loss: 0.5233077, Train Acc: 0.7304, Valid. Acc: 0.8234, Train AUC: 0.8103, Train AP: 0.7789, Valid. AUC: 0.8764, Valid. AP: 0.4880\n",
      "Epoch: 21/100, Loss: 0.5100783, Train Acc: 0.7299, Valid. Acc: 0.8218, Train AUC: 0.8166, Train AP: 0.7883, Valid. AUC: 0.8760, Valid. AP: 0.4841\n",
      "Epoch: 22/100, Loss: 0.5093318, Train Acc: 0.7325, Valid. Acc: 0.8233, Train AUC: 0.8173, Train AP: 0.7910, Valid. AUC: 0.8757, Valid. AP: 0.4778\n",
      "Epoch: 23/100, Loss: 0.4976313, Train Acc: 0.7419, Valid. Acc: 0.8237, Train AUC: 0.8231, Train AP: 0.7968, Valid. AUC: 0.8760, Valid. AP: 0.4740\n",
      "Epoch: 24/100, Loss: 0.4962421, Train Acc: 0.7427, Valid. Acc: 0.8255, Train AUC: 0.8237, Train AP: 0.7936, Valid. AUC: 0.8763, Valid. AP: 0.4678\n",
      "Epoch: 25/100, Loss: 0.5012987, Train Acc: 0.7372, Valid. Acc: 0.8213, Train AUC: 0.8210, Train AP: 0.8001, Valid. AUC: 0.8767, Valid. AP: 0.4634\n",
      "Epoch: 26/100, Loss: 0.4875702, Train Acc: 0.7405, Valid. Acc: 0.8204, Train AUC: 0.8280, Train AP: 0.8084, Valid. AUC: 0.8771, Valid. AP: 0.4609\n",
      "Epoch: 27/100, Loss: 0.5002428, Train Acc: 0.7286, Valid. Acc: 0.8240, Train AUC: 0.8270, Train AP: 0.8047, Valid. AUC: 0.8769, Valid. AP: 0.4558\n",
      "Epoch: 28/100, Loss: 0.4839576, Train Acc: 0.7435, Valid. Acc: 0.8254, Train AUC: 0.8335, Train AP: 0.8164, Valid. AUC: 0.8769, Valid. AP: 0.4534\n",
      "Epoch: 29/100, Loss: 0.4826997, Train Acc: 0.7478, Valid. Acc: 0.8264, Train AUC: 0.8364, Train AP: 0.8188, Valid. AUC: 0.8773, Valid. AP: 0.4543\n",
      "Epoch: 30/100, Loss: 0.4795620, Train Acc: 0.7503, Valid. Acc: 0.8265, Train AUC: 0.8382, Train AP: 0.8181, Valid. AUC: 0.8777, Valid. AP: 0.4556\n",
      "Epoch: 31/100, Loss: 0.4791529, Train Acc: 0.7465, Valid. Acc: 0.8268, Train AUC: 0.8359, Train AP: 0.8181, Valid. AUC: 0.8781, Valid. AP: 0.4570\n",
      "Epoch: 32/100, Loss: 0.4763631, Train Acc: 0.7401, Valid. Acc: 0.8231, Train AUC: 0.8366, Train AP: 0.8232, Valid. AUC: 0.8789, Valid. AP: 0.4614\n",
      "Epoch: 33/100, Loss: 0.4734852, Train Acc: 0.7461, Valid. Acc: 0.8223, Train AUC: 0.8415, Train AP: 0.8290, Valid. AUC: 0.8796, Valid. AP: 0.4663\n",
      "Epoch: 34/100, Loss: 0.4817246, Train Acc: 0.7449, Valid. Acc: 0.8305, Train AUC: 0.8421, Train AP: 0.8290, Valid. AUC: 0.8801, Valid. AP: 0.4659\n",
      "Epoch: 35/100, Loss: 0.4692169, Train Acc: 0.7486, Valid. Acc: 0.8296, Train AUC: 0.8437, Train AP: 0.8327, Valid. AUC: 0.8804, Valid. AP: 0.4668\n",
      "Epoch: 36/100, Loss: 0.4705968, Train Acc: 0.7528, Valid. Acc: 0.8297, Train AUC: 0.8451, Train AP: 0.8323, Valid. AUC: 0.8809, Valid. AP: 0.4673\n",
      "Epoch: 37/100, Loss: 0.4686490, Train Acc: 0.7502, Valid. Acc: 0.8243, Train AUC: 0.8460, Train AP: 0.8345, Valid. AUC: 0.8818, Valid. AP: 0.4691\n",
      "Epoch: 38/100, Loss: 0.4646274, Train Acc: 0.7516, Valid. Acc: 0.8233, Train AUC: 0.8454, Train AP: 0.8327, Valid. AUC: 0.8822, Valid. AP: 0.4698\n",
      "Epoch: 39/100, Loss: 0.4667989, Train Acc: 0.7463, Valid. Acc: 0.8229, Train AUC: 0.8452, Train AP: 0.8367, Valid. AUC: 0.8818, Valid. AP: 0.4688\n",
      "Epoch: 40/100, Loss: 0.4637454, Train Acc: 0.7490, Valid. Acc: 0.8194, Train AUC: 0.8480, Train AP: 0.8405, Valid. AUC: 0.8802, Valid. AP: 0.4634\n",
      "Epoch: 41/100, Loss: 0.4639105, Train Acc: 0.7535, Valid. Acc: 0.8301, Train AUC: 0.8501, Train AP: 0.8414, Valid. AUC: 0.8781, Valid. AP: 0.4551\n",
      "Epoch: 42/100, Loss: 0.4702643, Train Acc: 0.7517, Valid. Acc: 0.8300, Train AUC: 0.8436, Train AP: 0.8316, Valid. AUC: 0.8785, Valid. AP: 0.4543\n",
      "Epoch: 43/100, Loss: 0.4665688, Train Acc: 0.7518, Valid. Acc: 0.8328, Train AUC: 0.8518, Train AP: 0.8408, Valid. AUC: 0.8806, Valid. AP: 0.4594\n",
      "Epoch: 44/100, Loss: 0.4574810, Train Acc: 0.7587, Valid. Acc: 0.8308, Train AUC: 0.8551, Train AP: 0.8457, Valid. AUC: 0.8823, Valid. AP: 0.4639\n",
      "Epoch: 45/100, Loss: 0.4545715, Train Acc: 0.7598, Valid. Acc: 0.8274, Train AUC: 0.8564, Train AP: 0.8487, Valid. AUC: 0.8831, Valid. AP: 0.4664\n",
      "Epoch: 46/100, Loss: 0.4548921, Train Acc: 0.7577, Valid. Acc: 0.8245, Train AUC: 0.8538, Train AP: 0.8428, Valid. AUC: 0.8837, Valid. AP: 0.4687\n",
      "Epoch: 47/100, Loss: 0.4589472, Train Acc: 0.7550, Valid. Acc: 0.8259, Train AUC: 0.8502, Train AP: 0.8366, Valid. AUC: 0.8842, Valid. AP: 0.4716\n",
      "Epoch: 48/100, Loss: 0.4553101, Train Acc: 0.7617, Valid. Acc: 0.8274, Train AUC: 0.8555, Train AP: 0.8447, Valid. AUC: 0.8846, Valid. AP: 0.4743\n",
      "Epoch: 49/100, Loss: 0.4604387, Train Acc: 0.7497, Valid. Acc: 0.8275, Train AUC: 0.8485, Train AP: 0.8407, Valid. AUC: 0.8846, Valid. AP: 0.4740\n",
      "Epoch: 50/100, Loss: 0.4467860, Train Acc: 0.7616, Valid. Acc: 0.8279, Train AUC: 0.8594, Train AP: 0.8537, Valid. AUC: 0.8840, Valid. AP: 0.4725\n",
      "Epoch: 51/100, Loss: 0.4478877, Train Acc: 0.7614, Valid. Acc: 0.8268, Train AUC: 0.8603, Train AP: 0.8543, Valid. AUC: 0.8835, Valid. AP: 0.4709\n",
      "Epoch: 52/100, Loss: 0.4516680, Train Acc: 0.7582, Valid. Acc: 0.8265, Train AUC: 0.8574, Train AP: 0.8500, Valid. AUC: 0.8838, Valid. AP: 0.4711\n",
      "Epoch: 53/100, Loss: 0.4459240, Train Acc: 0.7599, Valid. Acc: 0.8268, Train AUC: 0.8595, Train AP: 0.8548, Valid. AUC: 0.8840, Valid. AP: 0.4703\n",
      "Epoch: 54/100, Loss: 0.4451818, Train Acc: 0.7585, Valid. Acc: 0.8259, Train AUC: 0.8604, Train AP: 0.8548, Valid. AUC: 0.8847, Valid. AP: 0.4721\n",
      "Epoch: 55/100, Loss: 0.4479226, Train Acc: 0.7651, Valid. Acc: 0.8249, Train AUC: 0.8634, Train AP: 0.8572, Valid. AUC: 0.8846, Valid. AP: 0.4704\n",
      "Epoch: 56/100, Loss: 0.4411083, Train Acc: 0.7629, Valid. Acc: 0.8254, Train AUC: 0.8620, Train AP: 0.8576, Valid. AUC: 0.8847, Valid. AP: 0.4696\n",
      "Epoch: 57/100, Loss: 0.4401573, Train Acc: 0.7615, Valid. Acc: 0.8262, Train AUC: 0.8631, Train AP: 0.8596, Valid. AUC: 0.8851, Valid. AP: 0.4706\n",
      "Epoch: 58/100, Loss: 0.4408227, Train Acc: 0.7658, Valid. Acc: 0.8266, Train AUC: 0.8646, Train AP: 0.8609, Valid. AUC: 0.8853, Valid. AP: 0.4706\n",
      "Epoch: 59/100, Loss: 0.4376344, Train Acc: 0.7645, Valid. Acc: 0.8279, Train AUC: 0.8644, Train AP: 0.8613, Valid. AUC: 0.8853, Valid. AP: 0.4715\n",
      "Epoch: 60/100, Loss: 0.4365963, Train Acc: 0.7673, Valid. Acc: 0.8288, Train AUC: 0.8665, Train AP: 0.8633, Valid. AUC: 0.8852, Valid. AP: 0.4719\n",
      "Epoch: 61/100, Loss: 0.4341258, Train Acc: 0.7695, Valid. Acc: 0.8291, Train AUC: 0.8683, Train AP: 0.8655, Valid. AUC: 0.8849, Valid. AP: 0.4709\n",
      "Epoch: 62/100, Loss: 0.4358223, Train Acc: 0.7674, Valid. Acc: 0.8289, Train AUC: 0.8671, Train AP: 0.8653, Valid. AUC: 0.8846, Valid. AP: 0.4691\n",
      "Epoch: 63/100, Loss: 0.4359940, Train Acc: 0.7674, Valid. Acc: 0.8283, Train AUC: 0.8658, Train AP: 0.8636, Valid. AUC: 0.8849, Valid. AP: 0.4684\n",
      "Epoch: 64/100, Loss: 0.4334598, Train Acc: 0.7676, Valid. Acc: 0.8279, Train AUC: 0.8685, Train AP: 0.8669, Valid. AUC: 0.8854, Valid. AP: 0.4687\n",
      "Epoch: 65/100, Loss: 0.4330178, Train Acc: 0.7658, Valid. Acc: 0.8273, Train AUC: 0.8672, Train AP: 0.8660, Valid. AUC: 0.8859, Valid. AP: 0.4700\n",
      "Epoch: 66/100, Loss: 0.4332136, Train Acc: 0.7631, Valid. Acc: 0.8268, Train AUC: 0.8672, Train AP: 0.8665, Valid. AUC: 0.8863, Valid. AP: 0.4712\n",
      "Epoch: 67/100, Loss: 0.4311686, Train Acc: 0.7698, Valid. Acc: 0.8275, Train AUC: 0.8698, Train AP: 0.8686, Valid. AUC: 0.8863, Valid. AP: 0.4713\n",
      "Epoch: 68/100, Loss: 0.4287485, Train Acc: 0.7729, Valid. Acc: 0.8296, Train AUC: 0.8719, Train AP: 0.8711, Valid. AUC: 0.8861, Valid. AP: 0.4708\n",
      "Epoch: 69/100, Loss: 0.4306810, Train Acc: 0.7678, Valid. Acc: 0.8301, Train AUC: 0.8700, Train AP: 0.8699, Valid. AUC: 0.8858, Valid. AP: 0.4699\n",
      "Epoch: 70/100, Loss: 0.4292404, Train Acc: 0.7642, Valid. Acc: 0.8301, Train AUC: 0.8701, Train AP: 0.8705, Valid. AUC: 0.8860, Valid. AP: 0.4715\n",
      "Epoch: 71/100, Loss: 0.4294871, Train Acc: 0.7668, Valid. Acc: 0.8299, Train AUC: 0.8698, Train AP: 0.8705, Valid. AUC: 0.8865, Valid. AP: 0.4739\n",
      "Epoch: 72/100, Loss: 0.4264158, Train Acc: 0.7706, Valid. Acc: 0.8292, Train AUC: 0.8720, Train AP: 0.8728, Valid. AUC: 0.8869, Valid. AP: 0.4759\n",
      "Epoch: 73/100, Loss: 0.4270074, Train Acc: 0.7733, Valid. Acc: 0.8293, Train AUC: 0.8734, Train AP: 0.8733, Valid. AUC: 0.8870, Valid. AP: 0.4761\n",
      "Epoch: 74/100, Loss: 0.4253452, Train Acc: 0.7693, Valid. Acc: 0.8299, Train AUC: 0.8713, Train AP: 0.8722, Valid. AUC: 0.8869, Valid. AP: 0.4751\n",
      "Epoch: 75/100, Loss: 0.4240139, Train Acc: 0.7710, Valid. Acc: 0.8302, Train AUC: 0.8725, Train AP: 0.8732, Valid. AUC: 0.8868, Valid. AP: 0.4746\n",
      "Epoch: 76/100, Loss: 0.4234628, Train Acc: 0.7687, Valid. Acc: 0.8311, Train AUC: 0.8717, Train AP: 0.8729, Valid. AUC: 0.8871, Valid. AP: 0.4752\n",
      "Epoch: 77/100, Loss: 0.4231603, Train Acc: 0.7727, Valid. Acc: 0.8322, Train AUC: 0.8735, Train AP: 0.8748, Valid. AUC: 0.8871, Valid. AP: 0.4756\n",
      "Epoch: 78/100, Loss: 0.4213662, Train Acc: 0.7718, Valid. Acc: 0.8332, Train AUC: 0.8741, Train AP: 0.8752, Valid. AUC: 0.8873, Valid. AP: 0.4760\n",
      "Epoch: 79/100, Loss: 0.4205079, Train Acc: 0.7706, Valid. Acc: 0.8336, Train AUC: 0.8736, Train AP: 0.8754, Valid. AUC: 0.8875, Valid. AP: 0.4766\n",
      "Epoch: 80/100, Loss: 0.4209217, Train Acc: 0.7735, Valid. Acc: 0.8322, Train AUC: 0.8753, Train AP: 0.8770, Valid. AUC: 0.8875, Valid. AP: 0.4772\n",
      "Epoch: 81/100, Loss: 0.4202669, Train Acc: 0.7725, Valid. Acc: 0.8311, Train AUC: 0.8750, Train AP: 0.8774, Valid. AUC: 0.8875, Valid. AP: 0.4776\n",
      "Epoch: 82/100, Loss: 0.4233394, Train Acc: 0.7683, Valid. Acc: 0.8311, Train AUC: 0.8722, Train AP: 0.8745, Valid. AUC: 0.8878, Valid. AP: 0.4781\n",
      "Epoch: 83/100, Loss: 0.4179169, Train Acc: 0.7750, Valid. Acc: 0.8307, Train AUC: 0.8769, Train AP: 0.8787, Valid. AUC: 0.8880, Valid. AP: 0.4779\n",
      "Epoch: 84/100, Loss: 0.4199547, Train Acc: 0.7719, Valid. Acc: 0.8310, Train AUC: 0.8742, Train AP: 0.8764, Valid. AUC: 0.8884, Valid. AP: 0.4775\n",
      "Epoch: 85/100, Loss: 0.4177683, Train Acc: 0.7725, Valid. Acc: 0.8318, Train AUC: 0.8756, Train AP: 0.8778, Valid. AUC: 0.8888, Valid. AP: 0.4786\n",
      "Epoch: 86/100, Loss: 0.4181060, Train Acc: 0.7728, Valid. Acc: 0.8330, Train AUC: 0.8759, Train AP: 0.8784, Valid. AUC: 0.8891, Valid. AP: 0.4788\n",
      "Epoch: 87/100, Loss: 0.4170020, Train Acc: 0.7746, Valid. Acc: 0.8349, Train AUC: 0.8767, Train AP: 0.8783, Valid. AUC: 0.8893, Valid. AP: 0.4793\n",
      "Epoch: 88/100, Loss: 0.4188074, Train Acc: 0.7729, Valid. Acc: 0.8346, Train AUC: 0.8754, Train AP: 0.8772, Valid. AUC: 0.8892, Valid. AP: 0.4791\n",
      "Epoch: 89/100, Loss: 0.4158998, Train Acc: 0.7742, Valid. Acc: 0.8334, Train AUC: 0.8765, Train AP: 0.8782, Valid. AUC: 0.8888, Valid. AP: 0.4786\n",
      "Epoch: 90/100, Loss: 0.4156546, Train Acc: 0.7719, Valid. Acc: 0.8316, Train AUC: 0.8763, Train AP: 0.8793, Valid. AUC: 0.8882, Valid. AP: 0.4768\n",
      "Epoch: 91/100, Loss: 0.4138025, Train Acc: 0.7743, Valid. Acc: 0.8312, Train AUC: 0.8779, Train AP: 0.8806, Valid. AUC: 0.8883, Valid. AP: 0.4769\n",
      "Epoch: 92/100, Loss: 0.4124972, Train Acc: 0.7741, Valid. Acc: 0.8316, Train AUC: 0.8783, Train AP: 0.8813, Valid. AUC: 0.8885, Valid. AP: 0.4779\n",
      "Epoch: 93/100, Loss: 0.4141620, Train Acc: 0.7750, Valid. Acc: 0.8319, Train AUC: 0.8779, Train AP: 0.8805, Valid. AUC: 0.8888, Valid. AP: 0.4786\n",
      "Epoch: 94/100, Loss: 0.4130847, Train Acc: 0.7751, Valid. Acc: 0.8330, Train AUC: 0.8783, Train AP: 0.8814, Valid. AUC: 0.8896, Valid. AP: 0.4818\n",
      "Epoch: 95/100, Loss: 0.4137566, Train Acc: 0.7744, Valid. Acc: 0.8333, Train AUC: 0.8776, Train AP: 0.8803, Valid. AUC: 0.8895, Valid. AP: 0.4816\n",
      "Epoch: 96/100, Loss: 0.4128791, Train Acc: 0.7761, Valid. Acc: 0.8331, Train AUC: 0.8789, Train AP: 0.8818, Valid. AUC: 0.8891, Valid. AP: 0.4794\n",
      "Epoch: 97/100, Loss: 0.4123152, Train Acc: 0.7751, Valid. Acc: 0.8331, Train AUC: 0.8784, Train AP: 0.8815, Valid. AUC: 0.8891, Valid. AP: 0.4782\n",
      "Epoch: 98/100, Loss: 0.4117544, Train Acc: 0.7762, Valid. Acc: 0.8339, Train AUC: 0.8793, Train AP: 0.8826, Valid. AUC: 0.8896, Valid. AP: 0.4792\n",
      "Epoch: 99/100, Loss: 0.4133305, Train Acc: 0.7720, Valid. Acc: 0.8332, Train AUC: 0.8770, Train AP: 0.8809, Valid. AUC: 0.8898, Valid. AP: 0.4782\n",
      "Epoch: 100/100, Loss: 0.4106131, Train Acc: 0.7757, Valid. Acc: 0.8328, Train AUC: 0.8793, Train AP: 0.8827, Valid. AUC: 0.8901, Valid. AP: 0.4789\n",
      "/home/ubuntu/PA-Cancer-Immunotherapy/GNN/train_pa_all_tvt_10x.py:212: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(configs['save_model']))\n",
      "Task-wise AP and ROC AUC:\n",
      "Task: TPP1, AP: 0.4523, ROC AUC: 0.9068\n",
      "Task: TPP2, AP: 0.5227, ROC AUC: 0.8157\n",
      "Task: TPP3, AP: 0.7438, ROC AUC: 0.4935\n",
      "Task: TPP4, AP: 0.1660, ROC AUC: 0.6891\n",
      "\n",
      "Overall AP and ROC AUC:\n",
      "Overall AP: 0.4807, Overall ROC AUC: 0.8904\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 2.295 MB of 2.535 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 2.535 MB of 2.535 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 2.535 MB of 2.535 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 2.535 MB of 2.535 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        test_ap ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   test_roc_auc ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▁▂▃▄▄▄▅▄▆▆▆▆▇▇▆▇▇▇▇█▇███████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train_ap ▁▂▂▂▃▃▄▄▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇███████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss ██▇▇▅▅▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_roc_auc ▁▁▃▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: valid_accuracy ▁▄▇█▄▇▆▆▇▇▇▇▆▇▇▇▇▇▆██▇▇▇▇▇▇▇▇▇██████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       valid_ap ▁▃▃▃▃▅▆▇▇▇█▇▇▇▆▇▇▇▇▆▇▇██▇▇▇▇▇▇██████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  valid_roc_auc ▁▃▄▄▅▆▆▆▇▇▇▇▇▇▇▇▇███████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy 0.83266\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        test_ap 0.48068\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   test_roc_auc 0.89036\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.77574\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train_ap 0.88275\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.41061\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_roc_auc 0.8793\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: valid_accuracy 0.83276\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       valid_ap 0.47889\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  valid_roc_auc 0.89007\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mroyal-monkey-7\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-gene_GNN/runs/7obdkze0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-gene_GNN\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 6 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241218_020428-7obdkze0/logs\u001b[0m\n",
      "Test Acc: 0.8327, Test AUC: 0.8904, Test AP: 0.4807\n"
     ]
    }
   ],
   "source": [
    "# another run for gene, with strong dopout 0.4\n",
    "# for gene\n",
    "\n",
    "! python train_pa_all_tvt_10x.py --gpu 0 --configs_path configs/PA_all_tvt_10x_gene.yml --droup_out 0.4 --split StrictTCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e74d2c3e-db4c-4606-8660-b6a15120f21c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(gpu=0, lr=0.001, epochs=150, w_celoss=1, w_aucloss=0, add_same_type_edges=False, dynamic_graph=False, dynamic_ratio=0.05, droup_out=0.4, positive_weights=1, dynamic_epochs=30, distance_threshold=10, configs_path='configs/PA_all_tvt_10x_gene.yml', split='StrictTCR', dataset='pMTnet')\n",
      "PROJECT_NAME: dataset-all-tvt-10x-gene_GNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfrohoari\u001b[0m (\u001b[33mpa_cancerimmunotherapy\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/ubuntu/PA-Cancer-Immunotherapy/GNN/wandb/run-20241218_101411-eedy8ajp\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33munique-thunder-8\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-gene_GNN\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-gene_GNN/runs/eedy8ajp\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   6 of 6 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   6 of 6 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   6 of 6 files downloaded.  \n",
      "embeddings_path:   models/PA_all/gene_and_allele_embeddings_10x.pkl\n",
      "train_file_list:   ['gene_train.csv']\n",
      "validation_file_list:   ['gene_validation.csv']\n",
      "test_file_list:   ['gene_test.csv']\n",
      "wandb logger initialisiert\n",
      "Epoch: 1/150, Loss: 0.6919470, Train Acc: 0.4907, Valid. Acc: 0.7387, Train AUC: 0.4924, Train AP: 0.5070, Valid. AUC: 0.7835, Valid. AP: 0.3792\n",
      "Epoch: 2/150, Loss: 0.6841689, Train Acc: 0.5816, Valid. Acc: 0.7841, Train AUC: 0.6339, Train AP: 0.6258, Valid. AUC: 0.8163, Valid. AP: 0.4048\n",
      "Epoch: 3/150, Loss: 0.6786925, Train Acc: 0.5971, Valid. Acc: 0.8038, Train AUC: 0.6510, Train AP: 0.6356, Valid. AUC: 0.8179, Valid. AP: 0.4014\n",
      "Epoch: 4/150, Loss: 0.6650082, Train Acc: 0.6503, Valid. Acc: 0.8241, Train AUC: 0.7021, Train AP: 0.6669, Valid. AUC: 0.8194, Valid. AP: 0.4049\n",
      "Epoch: 5/150, Loss: 0.6517627, Train Acc: 0.6526, Valid. Acc: 0.8163, Train AUC: 0.7078, Train AP: 0.6826, Valid. AUC: 0.8220, Valid. AP: 0.4100\n",
      "Epoch: 6/150, Loss: 0.6345819, Train Acc: 0.6673, Valid. Acc: 0.8267, Train AUC: 0.7201, Train AP: 0.6897, Valid. AUC: 0.8268, Valid. AP: 0.4155\n",
      "Epoch: 7/150, Loss: 0.6201361, Train Acc: 0.6703, Valid. Acc: 0.8224, Train AUC: 0.7346, Train AP: 0.7040, Valid. AUC: 0.8341, Valid. AP: 0.4240\n",
      "Epoch: 8/150, Loss: 0.6065086, Train Acc: 0.6690, Valid. Acc: 0.8305, Train AUC: 0.7347, Train AP: 0.7034, Valid. AUC: 0.8424, Valid. AP: 0.4354\n",
      "Epoch: 9/150, Loss: 0.5904737, Train Acc: 0.6737, Valid. Acc: 0.8298, Train AUC: 0.7452, Train AP: 0.7081, Valid. AUC: 0.8452, Valid. AP: 0.4431\n",
      "Epoch: 10/150, Loss: 0.5823004, Train Acc: 0.6723, Valid. Acc: 0.8075, Train AUC: 0.7653, Train AP: 0.7292, Valid. AUC: 0.8535, Valid. AP: 0.4510\n",
      "Epoch: 11/150, Loss: 0.5999349, Train Acc: 0.7036, Valid. Acc: 0.8280, Train AUC: 0.7621, Train AP: 0.7235, Valid. AUC: 0.8550, Valid. AP: 0.4535\n",
      "Epoch: 12/150, Loss: 0.5575507, Train Acc: 0.6957, Valid. Acc: 0.8235, Train AUC: 0.7773, Train AP: 0.7397, Valid. AUC: 0.8591, Valid. AP: 0.4575\n",
      "Epoch: 13/150, Loss: 0.5757525, Train Acc: 0.6681, Valid. Acc: 0.8239, Train AUC: 0.7669, Train AP: 0.7348, Valid. AUC: 0.8654, Valid. AP: 0.4630\n",
      "Epoch: 14/150, Loss: 0.5521693, Train Acc: 0.7093, Valid. Acc: 0.8201, Train AUC: 0.7803, Train AP: 0.7383, Valid. AUC: 0.8692, Valid. AP: 0.4629\n",
      "Epoch: 15/150, Loss: 0.5566117, Train Acc: 0.7137, Valid. Acc: 0.8263, Train AUC: 0.7803, Train AP: 0.7415, Valid. AUC: 0.8711, Valid. AP: 0.4665\n",
      "Epoch: 16/150, Loss: 0.5374786, Train Acc: 0.7189, Valid. Acc: 0.8226, Train AUC: 0.7942, Train AP: 0.7578, Valid. AUC: 0.8719, Valid. AP: 0.4714\n",
      "Epoch: 17/150, Loss: 0.5397454, Train Acc: 0.7061, Valid. Acc: 0.8209, Train AUC: 0.7984, Train AP: 0.7685, Valid. AUC: 0.8736, Valid. AP: 0.4760\n",
      "Epoch: 18/150, Loss: 0.5292802, Train Acc: 0.7182, Valid. Acc: 0.8248, Train AUC: 0.8023, Train AP: 0.7670, Valid. AUC: 0.8751, Valid. AP: 0.4810\n",
      "Epoch: 19/150, Loss: 0.5256168, Train Acc: 0.7322, Valid. Acc: 0.8241, Train AUC: 0.8047, Train AP: 0.7677, Valid. AUC: 0.8757, Valid. AP: 0.4831\n",
      "Epoch: 20/150, Loss: 0.5240820, Train Acc: 0.7301, Valid. Acc: 0.8234, Train AUC: 0.8100, Train AP: 0.7785, Valid. AUC: 0.8764, Valid. AP: 0.4878\n",
      "Epoch: 21/150, Loss: 0.5097630, Train Acc: 0.7306, Valid. Acc: 0.8221, Train AUC: 0.8166, Train AP: 0.7884, Valid. AUC: 0.8760, Valid. AP: 0.4842\n",
      "Epoch: 22/150, Loss: 0.5092475, Train Acc: 0.7326, Valid. Acc: 0.8226, Train AUC: 0.8175, Train AP: 0.7913, Valid. AUC: 0.8757, Valid. AP: 0.4781\n",
      "Epoch: 23/150, Loss: 0.4973579, Train Acc: 0.7418, Valid. Acc: 0.8236, Train AUC: 0.8230, Train AP: 0.7968, Valid. AUC: 0.8760, Valid. AP: 0.4742\n",
      "Epoch: 24/150, Loss: 0.4967758, Train Acc: 0.7421, Valid. Acc: 0.8256, Train AUC: 0.8235, Train AP: 0.7933, Valid. AUC: 0.8762, Valid. AP: 0.4680\n",
      "Epoch: 25/150, Loss: 0.5021548, Train Acc: 0.7372, Valid. Acc: 0.8218, Train AUC: 0.8208, Train AP: 0.7998, Valid. AUC: 0.8767, Valid. AP: 0.4633\n",
      "Epoch: 26/150, Loss: 0.4875366, Train Acc: 0.7408, Valid. Acc: 0.8204, Train AUC: 0.8280, Train AP: 0.8082, Valid. AUC: 0.8771, Valid. AP: 0.4609\n",
      "Epoch: 27/150, Loss: 0.4999815, Train Acc: 0.7289, Valid. Acc: 0.8222, Train AUC: 0.8272, Train AP: 0.8049, Valid. AUC: 0.8770, Valid. AP: 0.4557\n",
      "Epoch: 28/150, Loss: 0.4838648, Train Acc: 0.7438, Valid. Acc: 0.8254, Train AUC: 0.8335, Train AP: 0.8162, Valid. AUC: 0.8769, Valid. AP: 0.4534\n",
      "Epoch: 29/150, Loss: 0.4827605, Train Acc: 0.7475, Valid. Acc: 0.8257, Train AUC: 0.8362, Train AP: 0.8185, Valid. AUC: 0.8773, Valid. AP: 0.4542\n",
      "Epoch: 30/150, Loss: 0.4794289, Train Acc: 0.7503, Valid. Acc: 0.8260, Train AUC: 0.8383, Train AP: 0.8181, Valid. AUC: 0.8777, Valid. AP: 0.4556\n",
      "Epoch: 31/150, Loss: 0.4793637, Train Acc: 0.7464, Valid. Acc: 0.8263, Train AUC: 0.8357, Train AP: 0.8177, Valid. AUC: 0.8782, Valid. AP: 0.4570\n",
      "Epoch: 32/150, Loss: 0.4764278, Train Acc: 0.7402, Valid. Acc: 0.8228, Train AUC: 0.8365, Train AP: 0.8232, Valid. AUC: 0.8789, Valid. AP: 0.4612\n",
      "Epoch: 33/150, Loss: 0.4738968, Train Acc: 0.7453, Valid. Acc: 0.8222, Train AUC: 0.8409, Train AP: 0.8285, Valid. AUC: 0.8796, Valid. AP: 0.4661\n",
      "Epoch: 34/150, Loss: 0.4837048, Train Acc: 0.7429, Valid. Acc: 0.8305, Train AUC: 0.8412, Train AP: 0.8278, Valid. AUC: 0.8802, Valid. AP: 0.4651\n",
      "Epoch: 35/150, Loss: 0.4696852, Train Acc: 0.7480, Valid. Acc: 0.8294, Train AUC: 0.8434, Train AP: 0.8320, Valid. AUC: 0.8804, Valid. AP: 0.4658\n",
      "Epoch: 36/150, Loss: 0.4711736, Train Acc: 0.7521, Valid. Acc: 0.8303, Train AUC: 0.8453, Train AP: 0.8327, Valid. AUC: 0.8809, Valid. AP: 0.4669\n",
      "Epoch: 37/150, Loss: 0.4682036, Train Acc: 0.7509, Valid. Acc: 0.8216, Train AUC: 0.8462, Train AP: 0.8347, Valid. AUC: 0.8819, Valid. AP: 0.4692\n",
      "Epoch: 38/150, Loss: 0.4646599, Train Acc: 0.7519, Valid. Acc: 0.8241, Train AUC: 0.8457, Train AP: 0.8328, Valid. AUC: 0.8824, Valid. AP: 0.4698\n",
      "Epoch: 39/150, Loss: 0.4659413, Train Acc: 0.7481, Valid. Acc: 0.8224, Train AUC: 0.8464, Train AP: 0.8378, Valid. AUC: 0.8819, Valid. AP: 0.4688\n",
      "Epoch: 40/150, Loss: 0.4633462, Train Acc: 0.7494, Valid. Acc: 0.8199, Train AUC: 0.8476, Train AP: 0.8400, Valid. AUC: 0.8803, Valid. AP: 0.4631\n",
      "Epoch: 41/150, Loss: 0.4632363, Train Acc: 0.7531, Valid. Acc: 0.8294, Train AUC: 0.8500, Train AP: 0.8416, Valid. AUC: 0.8783, Valid. AP: 0.4552\n",
      "Epoch: 42/150, Loss: 0.4704818, Train Acc: 0.7511, Valid. Acc: 0.8303, Train AUC: 0.8436, Train AP: 0.8320, Valid. AUC: 0.8787, Valid. AP: 0.4545\n",
      "Epoch: 43/150, Loss: 0.4657401, Train Acc: 0.7526, Valid. Acc: 0.8321, Train AUC: 0.8520, Train AP: 0.8413, Valid. AUC: 0.8808, Valid. AP: 0.4594\n",
      "Epoch: 44/150, Loss: 0.4577145, Train Acc: 0.7589, Valid. Acc: 0.8306, Train AUC: 0.8550, Train AP: 0.8455, Valid. AUC: 0.8824, Valid. AP: 0.4639\n",
      "Epoch: 45/150, Loss: 0.4550934, Train Acc: 0.7587, Valid. Acc: 0.8264, Train AUC: 0.8557, Train AP: 0.8477, Valid. AUC: 0.8833, Valid. AP: 0.4666\n",
      "Epoch: 46/150, Loss: 0.4542113, Train Acc: 0.7588, Valid. Acc: 0.8254, Train AUC: 0.8545, Train AP: 0.8442, Valid. AUC: 0.8839, Valid. AP: 0.4686\n",
      "Epoch: 47/150, Loss: 0.4583170, Train Acc: 0.7550, Valid. Acc: 0.8265, Train AUC: 0.8507, Train AP: 0.8377, Valid. AUC: 0.8844, Valid. AP: 0.4713\n",
      "Epoch: 48/150, Loss: 0.4544322, Train Acc: 0.7621, Valid. Acc: 0.8278, Train AUC: 0.8562, Train AP: 0.8462, Valid. AUC: 0.8849, Valid. AP: 0.4735\n",
      "Epoch: 49/150, Loss: 0.4588046, Train Acc: 0.7511, Valid. Acc: 0.8280, Train AUC: 0.8493, Train AP: 0.8414, Valid. AUC: 0.8849, Valid. AP: 0.4741\n",
      "Epoch: 50/150, Loss: 0.4456666, Train Acc: 0.7628, Valid. Acc: 0.8280, Train AUC: 0.8606, Train AP: 0.8550, Valid. AUC: 0.8844, Valid. AP: 0.4733\n",
      "Epoch: 51/150, Loss: 0.4474896, Train Acc: 0.7612, Valid. Acc: 0.8272, Train AUC: 0.8607, Train AP: 0.8550, Valid. AUC: 0.8840, Valid. AP: 0.4726\n",
      "Epoch: 52/150, Loss: 0.4512517, Train Acc: 0.7598, Valid. Acc: 0.8264, Train AUC: 0.8565, Train AP: 0.8489, Valid. AUC: 0.8841, Valid. AP: 0.4719\n",
      "Epoch: 53/150, Loss: 0.4472866, Train Acc: 0.7582, Valid. Acc: 0.8261, Train AUC: 0.8584, Train AP: 0.8538, Valid. AUC: 0.8840, Valid. AP: 0.4699\n",
      "Epoch: 54/150, Loss: 0.4458438, Train Acc: 0.7573, Valid. Acc: 0.8255, Train AUC: 0.8600, Train AP: 0.8545, Valid. AUC: 0.8846, Valid. AP: 0.4713\n",
      "Epoch: 55/150, Loss: 0.4446286, Train Acc: 0.7665, Valid. Acc: 0.8240, Train AUC: 0.8642, Train AP: 0.8585, Valid. AUC: 0.8844, Valid. AP: 0.4696\n",
      "Epoch: 56/150, Loss: 0.4411103, Train Acc: 0.7625, Valid. Acc: 0.8245, Train AUC: 0.8621, Train AP: 0.8577, Valid. AUC: 0.8845, Valid. AP: 0.4690\n",
      "Epoch: 57/150, Loss: 0.4398353, Train Acc: 0.7622, Valid. Acc: 0.8250, Train AUC: 0.8633, Train AP: 0.8596, Valid. AUC: 0.8850, Valid. AP: 0.4703\n",
      "Epoch: 58/150, Loss: 0.4396017, Train Acc: 0.7661, Valid. Acc: 0.8257, Train AUC: 0.8650, Train AP: 0.8612, Valid. AUC: 0.8852, Valid. AP: 0.4705\n",
      "Epoch: 59/150, Loss: 0.4369672, Train Acc: 0.7648, Valid. Acc: 0.8270, Train AUC: 0.8649, Train AP: 0.8622, Valid. AUC: 0.8852, Valid. AP: 0.4714\n",
      "Epoch: 60/150, Loss: 0.4358286, Train Acc: 0.7673, Valid. Acc: 0.8277, Train AUC: 0.8668, Train AP: 0.8639, Valid. AUC: 0.8850, Valid. AP: 0.4720\n",
      "Epoch: 61/150, Loss: 0.4337617, Train Acc: 0.7695, Valid. Acc: 0.8281, Train AUC: 0.8686, Train AP: 0.8661, Valid. AUC: 0.8848, Valid. AP: 0.4713\n",
      "Epoch: 62/150, Loss: 0.4350051, Train Acc: 0.7673, Valid. Acc: 0.8284, Train AUC: 0.8673, Train AP: 0.8658, Valid. AUC: 0.8848, Valid. AP: 0.4703\n",
      "Epoch: 63/150, Loss: 0.4350652, Train Acc: 0.7685, Valid. Acc: 0.8278, Train AUC: 0.8664, Train AP: 0.8643, Valid. AUC: 0.8851, Valid. AP: 0.4701\n",
      "Epoch: 64/150, Loss: 0.4336361, Train Acc: 0.7695, Valid. Acc: 0.8277, Train AUC: 0.8689, Train AP: 0.8673, Valid. AUC: 0.8855, Valid. AP: 0.4699\n",
      "Epoch: 65/150, Loss: 0.4315987, Train Acc: 0.7668, Valid. Acc: 0.8277, Train AUC: 0.8680, Train AP: 0.8673, Valid. AUC: 0.8859, Valid. AP: 0.4706\n",
      "Epoch: 66/150, Loss: 0.4325321, Train Acc: 0.7643, Valid. Acc: 0.8277, Train AUC: 0.8677, Train AP: 0.8671, Valid. AUC: 0.8863, Valid. AP: 0.4711\n",
      "Epoch: 67/150, Loss: 0.4306965, Train Acc: 0.7686, Valid. Acc: 0.8284, Train AUC: 0.8696, Train AP: 0.8688, Valid. AUC: 0.8863, Valid. AP: 0.4708\n",
      "Epoch: 68/150, Loss: 0.4269718, Train Acc: 0.7726, Valid. Acc: 0.8296, Train AUC: 0.8721, Train AP: 0.8715, Valid. AUC: 0.8862, Valid. AP: 0.4706\n",
      "Epoch: 69/150, Loss: 0.4297236, Train Acc: 0.7688, Valid. Acc: 0.8302, Train AUC: 0.8706, Train AP: 0.8706, Valid. AUC: 0.8860, Valid. AP: 0.4697\n",
      "Epoch: 70/150, Loss: 0.4285268, Train Acc: 0.7673, Valid. Acc: 0.8307, Train AUC: 0.8712, Train AP: 0.8715, Valid. AUC: 0.8861, Valid. AP: 0.4705\n",
      "Epoch: 71/150, Loss: 0.4283444, Train Acc: 0.7673, Valid. Acc: 0.8305, Train AUC: 0.8703, Train AP: 0.8712, Valid. AUC: 0.8865, Valid. AP: 0.4722\n",
      "Epoch: 72/150, Loss: 0.4252691, Train Acc: 0.7721, Valid. Acc: 0.8303, Train AUC: 0.8727, Train AP: 0.8732, Valid. AUC: 0.8868, Valid. AP: 0.4733\n",
      "Epoch: 73/150, Loss: 0.4255341, Train Acc: 0.7733, Valid. Acc: 0.8300, Train AUC: 0.8738, Train AP: 0.8739, Valid. AUC: 0.8870, Valid. AP: 0.4741\n",
      "Epoch: 74/150, Loss: 0.4246657, Train Acc: 0.7690, Valid. Acc: 0.8306, Train AUC: 0.8712, Train AP: 0.8724, Valid. AUC: 0.8871, Valid. AP: 0.4753\n",
      "Epoch: 75/150, Loss: 0.4243755, Train Acc: 0.7696, Valid. Acc: 0.8310, Train AUC: 0.8719, Train AP: 0.8731, Valid. AUC: 0.8873, Valid. AP: 0.4763\n",
      "Epoch: 76/150, Loss: 0.4219633, Train Acc: 0.7704, Valid. Acc: 0.8322, Train AUC: 0.8727, Train AP: 0.8739, Valid. AUC: 0.8874, Valid. AP: 0.4767\n",
      "Epoch: 77/150, Loss: 0.4227550, Train Acc: 0.7725, Valid. Acc: 0.8322, Train AUC: 0.8737, Train AP: 0.8751, Valid. AUC: 0.8872, Valid. AP: 0.4762\n",
      "Epoch: 78/150, Loss: 0.4211005, Train Acc: 0.7715, Valid. Acc: 0.8324, Train AUC: 0.8741, Train AP: 0.8754, Valid. AUC: 0.8872, Valid. AP: 0.4759\n",
      "Epoch: 79/150, Loss: 0.4194938, Train Acc: 0.7701, Valid. Acc: 0.8322, Train AUC: 0.8740, Train AP: 0.8761, Valid. AUC: 0.8872, Valid. AP: 0.4759\n",
      "Epoch: 80/150, Loss: 0.4194311, Train Acc: 0.7739, Valid. Acc: 0.8319, Train AUC: 0.8758, Train AP: 0.8774, Valid. AUC: 0.8872, Valid. AP: 0.4763\n",
      "Epoch: 81/150, Loss: 0.4201598, Train Acc: 0.7718, Valid. Acc: 0.8319, Train AUC: 0.8748, Train AP: 0.8772, Valid. AUC: 0.8874, Valid. AP: 0.4771\n",
      "Epoch: 82/150, Loss: 0.4214737, Train Acc: 0.7704, Valid. Acc: 0.8321, Train AUC: 0.8737, Train AP: 0.8758, Valid. AUC: 0.8880, Valid. AP: 0.4788\n",
      "Epoch: 83/150, Loss: 0.4187383, Train Acc: 0.7757, Valid. Acc: 0.8316, Train AUC: 0.8771, Train AP: 0.8791, Valid. AUC: 0.8881, Valid. AP: 0.4790\n",
      "Epoch: 84/150, Loss: 0.4217189, Train Acc: 0.7710, Valid. Acc: 0.8309, Train AUC: 0.8733, Train AP: 0.8756, Valid. AUC: 0.8882, Valid. AP: 0.4769\n",
      "Epoch: 85/150, Loss: 0.4179746, Train Acc: 0.7721, Valid. Acc: 0.8315, Train AUC: 0.8755, Train AP: 0.8778, Valid. AUC: 0.8885, Valid. AP: 0.4775\n",
      "Epoch: 86/150, Loss: 0.4185944, Train Acc: 0.7723, Valid. Acc: 0.8319, Train AUC: 0.8756, Train AP: 0.8782, Valid. AUC: 0.8889, Valid. AP: 0.4780\n",
      "Epoch: 87/150, Loss: 0.4176665, Train Acc: 0.7735, Valid. Acc: 0.8344, Train AUC: 0.8764, Train AP: 0.8780, Valid. AUC: 0.8894, Valid. AP: 0.4790\n",
      "Epoch: 88/150, Loss: 0.4205201, Train Acc: 0.7705, Valid. Acc: 0.8345, Train AUC: 0.8741, Train AP: 0.8753, Valid. AUC: 0.8894, Valid. AP: 0.4791\n",
      "Epoch: 89/150, Loss: 0.4167564, Train Acc: 0.7750, Valid. Acc: 0.8334, Train AUC: 0.8761, Train AP: 0.8775, Valid. AUC: 0.8891, Valid. AP: 0.4787\n",
      "Epoch: 90/150, Loss: 0.4155548, Train Acc: 0.7723, Valid. Acc: 0.8319, Train AUC: 0.8767, Train AP: 0.8796, Valid. AUC: 0.8882, Valid. AP: 0.4763\n",
      "Epoch: 91/150, Loss: 0.4143574, Train Acc: 0.7742, Valid. Acc: 0.8305, Train AUC: 0.8776, Train AP: 0.8801, Valid. AUC: 0.8879, Valid. AP: 0.4751\n",
      "Epoch: 92/150, Loss: 0.4132880, Train Acc: 0.7735, Valid. Acc: 0.8306, Train AUC: 0.8776, Train AP: 0.8806, Valid. AUC: 0.8882, Valid. AP: 0.4764\n",
      "Epoch: 93/150, Loss: 0.4144971, Train Acc: 0.7741, Valid. Acc: 0.8317, Train AUC: 0.8771, Train AP: 0.8796, Valid. AUC: 0.8890, Valid. AP: 0.4789\n",
      "Epoch: 94/150, Loss: 0.4130449, Train Acc: 0.7751, Valid. Acc: 0.8333, Train AUC: 0.8782, Train AP: 0.8812, Valid. AUC: 0.8900, Valid. AP: 0.4826\n",
      "Epoch: 95/150, Loss: 0.4140415, Train Acc: 0.7737, Valid. Acc: 0.8334, Train AUC: 0.8773, Train AP: 0.8804, Valid. AUC: 0.8899, Valid. AP: 0.4823\n",
      "Epoch: 96/150, Loss: 0.4134724, Train Acc: 0.7770, Valid. Acc: 0.8334, Train AUC: 0.8794, Train AP: 0.8824, Valid. AUC: 0.8892, Valid. AP: 0.4794\n",
      "Epoch: 97/150, Loss: 0.4125436, Train Acc: 0.7748, Valid. Acc: 0.8333, Train AUC: 0.8787, Train AP: 0.8818, Valid. AUC: 0.8890, Valid. AP: 0.4774\n",
      "Epoch: 98/150, Loss: 0.4129456, Train Acc: 0.7751, Valid. Acc: 0.8335, Train AUC: 0.8788, Train AP: 0.8819, Valid. AUC: 0.8894, Valid. AP: 0.4783\n",
      "Epoch: 99/150, Loss: 0.4117400, Train Acc: 0.7756, Valid. Acc: 0.8332, Train AUC: 0.8786, Train AP: 0.8822, Valid. AUC: 0.8897, Valid. AP: 0.4781\n",
      "Epoch: 100/150, Loss: 0.4104928, Train Acc: 0.7751, Valid. Acc: 0.8330, Train AUC: 0.8792, Train AP: 0.8827, Valid. AUC: 0.8901, Valid. AP: 0.4799\n",
      "Epoch: 101/150, Loss: 0.4106585, Train Acc: 0.7752, Valid. Acc: 0.8336, Train AUC: 0.8794, Train AP: 0.8827, Valid. AUC: 0.8904, Valid. AP: 0.4823\n",
      "Epoch: 102/150, Loss: 0.4103508, Train Acc: 0.7786, Valid. Acc: 0.8345, Train AUC: 0.8804, Train AP: 0.8831, Valid. AUC: 0.8907, Valid. AP: 0.4833\n",
      "Epoch: 103/150, Loss: 0.4084395, Train Acc: 0.7766, Valid. Acc: 0.8349, Train AUC: 0.8800, Train AP: 0.8838, Valid. AUC: 0.8907, Valid. AP: 0.4834\n",
      "Epoch: 104/150, Loss: 0.4082053, Train Acc: 0.7767, Valid. Acc: 0.8351, Train AUC: 0.8801, Train AP: 0.8837, Valid. AUC: 0.8907, Valid. AP: 0.4833\n",
      "Epoch: 105/150, Loss: 0.4083082, Train Acc: 0.7769, Valid. Acc: 0.8346, Train AUC: 0.8809, Train AP: 0.8842, Valid. AUC: 0.8906, Valid. AP: 0.4829\n",
      "Epoch: 106/150, Loss: 0.4080817, Train Acc: 0.7768, Valid. Acc: 0.8333, Train AUC: 0.8802, Train AP: 0.8837, Valid. AUC: 0.8904, Valid. AP: 0.4824\n",
      "Epoch: 107/150, Loss: 0.4073048, Train Acc: 0.7766, Valid. Acc: 0.8333, Train AUC: 0.8807, Train AP: 0.8844, Valid. AUC: 0.8905, Valid. AP: 0.4831\n",
      "Epoch: 108/150, Loss: 0.4073293, Train Acc: 0.7779, Valid. Acc: 0.8339, Train AUC: 0.8813, Train AP: 0.8847, Valid. AUC: 0.8910, Valid. AP: 0.4854\n",
      "Epoch: 109/150, Loss: 0.4055540, Train Acc: 0.7787, Valid. Acc: 0.8343, Train AUC: 0.8824, Train AP: 0.8861, Valid. AUC: 0.8917, Valid. AP: 0.4881\n",
      "Epoch: 110/150, Loss: 0.4076974, Train Acc: 0.7782, Valid. Acc: 0.8343, Train AUC: 0.8814, Train AP: 0.8852, Valid. AUC: 0.8917, Valid. AP: 0.4875\n",
      "Epoch: 111/150, Loss: 0.4062511, Train Acc: 0.7790, Valid. Acc: 0.8343, Train AUC: 0.8817, Train AP: 0.8853, Valid. AUC: 0.8913, Valid. AP: 0.4855\n",
      "Epoch: 112/150, Loss: 0.4057488, Train Acc: 0.7790, Valid. Acc: 0.8348, Train AUC: 0.8820, Train AP: 0.8857, Valid. AUC: 0.8912, Valid. AP: 0.4846\n",
      "Epoch: 113/150, Loss: 0.4070024, Train Acc: 0.7767, Valid. Acc: 0.8347, Train AUC: 0.8805, Train AP: 0.8850, Valid. AUC: 0.8916, Valid. AP: 0.4845\n",
      "Epoch: 114/150, Loss: 0.4035582, Train Acc: 0.7797, Valid. Acc: 0.8353, Train AUC: 0.8832, Train AP: 0.8872, Valid. AUC: 0.8918, Valid. AP: 0.4845\n",
      "Epoch: 115/150, Loss: 0.4045867, Train Acc: 0.7782, Valid. Acc: 0.8348, Train AUC: 0.8826, Train AP: 0.8868, Valid. AUC: 0.8918, Valid. AP: 0.4851\n",
      "Epoch: 116/150, Loss: 0.4072487, Train Acc: 0.7764, Valid. Acc: 0.8343, Train AUC: 0.8804, Train AP: 0.8845, Valid. AUC: 0.8914, Valid. AP: 0.4840\n",
      "Epoch: 117/150, Loss: 0.4050978, Train Acc: 0.7782, Valid. Acc: 0.8330, Train AUC: 0.8821, Train AP: 0.8862, Valid. AUC: 0.8910, Valid. AP: 0.4828\n",
      "Epoch: 118/150, Loss: 0.4052240, Train Acc: 0.7789, Valid. Acc: 0.8330, Train AUC: 0.8817, Train AP: 0.8861, Valid. AUC: 0.8914, Valid. AP: 0.4839\n",
      "Epoch: 119/150, Loss: 0.4048608, Train Acc: 0.7774, Valid. Acc: 0.8341, Train AUC: 0.8817, Train AP: 0.8859, Valid. AUC: 0.8919, Valid. AP: 0.4857\n",
      "Epoch: 120/150, Loss: 0.4040169, Train Acc: 0.7784, Valid. Acc: 0.8346, Train AUC: 0.8822, Train AP: 0.8861, Valid. AUC: 0.8919, Valid. AP: 0.4865\n",
      "Epoch: 121/150, Loss: 0.4037896, Train Acc: 0.7794, Valid. Acc: 0.8333, Train AUC: 0.8829, Train AP: 0.8866, Valid. AUC: 0.8911, Valid. AP: 0.4849\n",
      "Epoch: 122/150, Loss: 0.4039677, Train Acc: 0.7803, Valid. Acc: 0.8326, Train AUC: 0.8837, Train AP: 0.8877, Valid. AUC: 0.8898, Valid. AP: 0.4793\n",
      "Epoch: 123/150, Loss: 0.4034037, Train Acc: 0.7796, Valid. Acc: 0.8331, Train AUC: 0.8835, Train AP: 0.8874, Valid. AUC: 0.8896, Valid. AP: 0.4776\n",
      "Epoch: 124/150, Loss: 0.4039961, Train Acc: 0.7777, Valid. Acc: 0.8321, Train AUC: 0.8828, Train AP: 0.8871, Valid. AUC: 0.8904, Valid. AP: 0.4805\n",
      "Epoch: 125/150, Loss: 0.4028047, Train Acc: 0.7808, Valid. Acc: 0.8324, Train AUC: 0.8839, Train AP: 0.8885, Valid. AUC: 0.8914, Valid. AP: 0.4842\n",
      "Epoch: 126/150, Loss: 0.4029841, Train Acc: 0.7786, Valid. Acc: 0.8334, Train AUC: 0.8831, Train AP: 0.8876, Valid. AUC: 0.8922, Valid. AP: 0.4863\n",
      "Epoch: 127/150, Loss: 0.4020649, Train Acc: 0.7803, Valid. Acc: 0.8333, Train AUC: 0.8840, Train AP: 0.8882, Valid. AUC: 0.8922, Valid. AP: 0.4851\n",
      "Epoch: 128/150, Loss: 0.4024526, Train Acc: 0.7788, Valid. Acc: 0.8331, Train AUC: 0.8832, Train AP: 0.8873, Valid. AUC: 0.8923, Valid. AP: 0.4851\n",
      "Epoch: 129/150, Loss: 0.4052343, Train Acc: 0.7751, Valid. Acc: 0.8330, Train AUC: 0.8811, Train AP: 0.8860, Valid. AUC: 0.8922, Valid. AP: 0.4848\n",
      "Epoch: 130/150, Loss: 0.4016831, Train Acc: 0.7792, Valid. Acc: 0.8333, Train AUC: 0.8837, Train AP: 0.8884, Valid. AUC: 0.8923, Valid. AP: 0.4851\n",
      "Epoch: 131/150, Loss: 0.4038129, Train Acc: 0.7751, Valid. Acc: 0.8330, Train AUC: 0.8815, Train AP: 0.8863, Valid. AUC: 0.8925, Valid. AP: 0.4862\n",
      "Epoch: 132/150, Loss: 0.4024217, Train Acc: 0.7792, Valid. Acc: 0.8335, Train AUC: 0.8831, Train AP: 0.8876, Valid. AUC: 0.8925, Valid. AP: 0.4872\n",
      "Epoch: 133/150, Loss: 0.4011108, Train Acc: 0.7804, Valid. Acc: 0.8337, Train AUC: 0.8844, Train AP: 0.8885, Valid. AUC: 0.8923, Valid. AP: 0.4879\n",
      "Epoch: 134/150, Loss: 0.4013653, Train Acc: 0.7807, Valid. Acc: 0.8334, Train AUC: 0.8838, Train AP: 0.8881, Valid. AUC: 0.8921, Valid. AP: 0.4862\n",
      "Epoch: 135/150, Loss: 0.4004571, Train Acc: 0.7802, Valid. Acc: 0.8330, Train AUC: 0.8848, Train AP: 0.8893, Valid. AUC: 0.8923, Valid. AP: 0.4861\n",
      "Epoch: 136/150, Loss: 0.4016325, Train Acc: 0.7795, Valid. Acc: 0.8334, Train AUC: 0.8833, Train AP: 0.8879, Valid. AUC: 0.8930, Valid. AP: 0.4885\n",
      "Epoch: 137/150, Loss: 0.4012000, Train Acc: 0.7785, Valid. Acc: 0.8347, Train AUC: 0.8836, Train AP: 0.8881, Valid. AUC: 0.8935, Valid. AP: 0.4898\n",
      "Epoch: 138/150, Loss: 0.3997535, Train Acc: 0.7800, Valid. Acc: 0.8358, Train AUC: 0.8850, Train AP: 0.8894, Valid. AUC: 0.8941, Valid. AP: 0.4911\n",
      "Epoch: 139/150, Loss: 0.4009795, Train Acc: 0.7789, Valid. Acc: 0.8354, Train AUC: 0.8833, Train AP: 0.8882, Valid. AUC: 0.8940, Valid. AP: 0.4909\n",
      "Epoch: 140/150, Loss: 0.3994307, Train Acc: 0.7809, Valid. Acc: 0.8346, Train AUC: 0.8850, Train AP: 0.8898, Valid. AUC: 0.8936, Valid. AP: 0.4902\n",
      "Epoch: 141/150, Loss: 0.4002526, Train Acc: 0.7789, Valid. Acc: 0.8332, Train AUC: 0.8841, Train AP: 0.8885, Valid. AUC: 0.8931, Valid. AP: 0.4889\n",
      "Epoch: 142/150, Loss: 0.3993004, Train Acc: 0.7807, Valid. Acc: 0.8331, Train AUC: 0.8844, Train AP: 0.8891, Valid. AUC: 0.8925, Valid. AP: 0.4881\n",
      "Epoch: 143/150, Loss: 0.3997525, Train Acc: 0.7793, Valid. Acc: 0.8339, Train AUC: 0.8842, Train AP: 0.8892, Valid. AUC: 0.8922, Valid. AP: 0.4881\n",
      "Epoch: 144/150, Loss: 0.3993117, Train Acc: 0.7802, Valid. Acc: 0.8332, Train AUC: 0.8856, Train AP: 0.8900, Valid. AUC: 0.8916, Valid. AP: 0.4852\n",
      "Epoch: 145/150, Loss: 0.4005192, Train Acc: 0.7811, Valid. Acc: 0.8335, Train AUC: 0.8853, Train AP: 0.8897, Valid. AUC: 0.8914, Valid. AP: 0.4823\n",
      "Epoch: 146/150, Loss: 0.3979527, Train Acc: 0.7807, Valid. Acc: 0.8342, Train AUC: 0.8858, Train AP: 0.8904, Valid. AUC: 0.8916, Valid. AP: 0.4822\n",
      "Epoch: 147/150, Loss: 0.3979194, Train Acc: 0.7810, Valid. Acc: 0.8345, Train AUC: 0.8856, Train AP: 0.8901, Valid. AUC: 0.8921, Valid. AP: 0.4854\n",
      "Epoch: 148/150, Loss: 0.4019648, Train Acc: 0.7770, Valid. Acc: 0.8350, Train AUC: 0.8834, Train AP: 0.8880, Valid. AUC: 0.8930, Valid. AP: 0.4920\n",
      "Epoch: 149/150, Loss: 0.3994164, Train Acc: 0.7810, Valid. Acc: 0.8360, Train AUC: 0.8850, Train AP: 0.8896, Valid. AUC: 0.8934, Valid. AP: 0.4959\n",
      "Epoch: 150/150, Loss: 0.4000486, Train Acc: 0.7803, Valid. Acc: 0.8376, Train AUC: 0.8851, Train AP: 0.8901, Valid. AUC: 0.8928, Valid. AP: 0.4929\n",
      "/home/ubuntu/PA-Cancer-Immunotherapy/GNN/train_pa_all_tvt_10x.py:212: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(configs['save_model']))\n",
      "Task-wise AP and ROC AUC:\n",
      "Task: TPP1, AP: 0.4676, ROC AUC: 0.9109\n",
      "Task: TPP2, AP: 0.5356, ROC AUC: 0.8219\n",
      "Task: TPP3, AP: 0.7545, ROC AUC: 0.5038\n",
      "Task: TPP4, AP: 0.0998, ROC AUC: 0.7418\n",
      "\n",
      "Overall AP and ROC AUC:\n",
      "Overall AP: 0.4948, Overall ROC AUC: 0.8948\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 2.302 MB of 2.542 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 2.542 MB of 2.542 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 2.542 MB of 2.542 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 2.542 MB of 2.542 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▆▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        test_ap ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   test_roc_auc ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▁▃▃▃▁▃▃▄▅▄▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇███████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train_ap ▁▂▂▃▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇██▇█████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss ███▆▅▄▄▄▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_roc_auc ▁▃▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: valid_accuracy ▁▇▆▅▅▅▅▆▆▆▇▇▅▇▆▆▆▆▆▆▇▇▇▇▇▇▇▇████▇▇▇█▇▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       valid_ap ▁▁▁▂▃▅▆▇██▆▅▅▆▆▅▅▆▆▇▇▇▆▆▇▇▇▇▇▇▇█▇███████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  valid_roc_auc ▁▃▅▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 150\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy 0.83558\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        test_ap 0.49482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   test_roc_auc 0.89479\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.78029\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train_ap 0.89008\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.40005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_roc_auc 0.88515\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: valid_accuracy 0.83758\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       valid_ap 0.49286\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  valid_roc_auc 0.89281\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33munique-thunder-8\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-gene_GNN/runs/eedy8ajp\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/pa_cancerimmunotherapy/dataset-all-tvt-10x-gene_GNN\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 6 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241218_101411-eedy8ajp/logs\u001b[0m\n",
      "Test Acc: 0.8356, Test AUC: 0.8948, Test AP: 0.4948\n"
     ]
    }
   ],
   "source": [
    "# one more run for gene, with strong dopout 0.5 AND Epochs = 150\n",
    "# for gene\n",
    "\n",
    "! python train_pa_all_tvt_10x.py --gpu 0 --configs_path configs/PA_all_tvt_10x_gene.yml --droup_out 0.4 --split StrictTCR --epochs 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d057f87-b305-4f1c-89c3-4afd3f85b287",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed05fd5-461f-4a99-8f20-fc80ffdcd856",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b396e440-1cc0-4209-953a-3a635f9b48c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "316f4400-43e5-42db-950a-6af9ea0c0a21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100, Loss: 1.2597733, Train Acc: 0.7216, Test Acc: 0.5915, Train AUC: 0.5206, Train APUR: 0.1000, Test AUC: 0.6023, Test AUPR: 0.2286\n",
      "Epoch: 2/100, Loss: 1.2536905, Train Acc: 0.5677, Test Acc: 0.6716, Train AUC: 0.6029, Train APUR: 0.1578, Test AUC: 0.6248, Test AUPR: 0.2403\n",
      "Epoch: 3/100, Loss: 1.2450564, Train Acc: 0.6699, Test Acc: 0.6159, Train AUC: 0.6216, Train APUR: 0.1733, Test AUC: 0.6352, Test AUPR: 0.3075\n",
      "Epoch: 4/100, Loss: 1.2304919, Train Acc: 0.6089, Test Acc: 0.6419, Train AUC: 0.6343, Train APUR: 0.2752, Test AUC: 0.6504, Test AUPR: 0.3396\n",
      "Epoch: 5/100, Loss: 1.2160655, Train Acc: 0.6385, Test Acc: 0.6539, Train AUC: 0.6475, Train APUR: 0.2645, Test AUC: 0.6680, Test AUPR: 0.3648\n",
      "Epoch: 6/100, Loss: 1.1975286, Train Acc: 0.6411, Test Acc: 0.6697, Train AUC: 0.6567, Train APUR: 0.3405, Test AUC: 0.6927, Test AUPR: 0.3995\n",
      "Epoch: 7/100, Loss: 1.1749332, Train Acc: 0.6664, Test Acc: 0.6154, Train AUC: 0.6841, Train APUR: 0.3522, Test AUC: 0.7067, Test AUPR: 0.4645\n",
      "Epoch: 8/100, Loss: 1.1437231, Train Acc: 0.6284, Test Acc: 0.6380, Train AUC: 0.7062, Train APUR: 0.4290, Test AUC: 0.7317, Test AUPR: 0.4841\n",
      "Epoch: 9/100, Loss: 1.1061903, Train Acc: 0.6463, Test Acc: 0.6361, Train AUC: 0.7285, Train APUR: 0.4712, Test AUC: 0.7487, Test AUPR: 0.4959\n",
      "Epoch: 10/100, Loss: 1.0559474, Train Acc: 0.6518, Test Acc: 0.5590, Train AUC: 0.7471, Train APUR: 0.4957, Test AUC: 0.7775, Test AUPR: 0.5190\n",
      "Epoch: 11/100, Loss: 1.0183924, Train Acc: 0.5842, Test Acc: 0.6568, Train AUC: 0.7667, Train APUR: 0.5137, Test AUC: 0.8494, Test AUPR: 0.5808\n",
      "Epoch: 12/100, Loss: 0.9616297, Train Acc: 0.6330, Test Acc: 0.7198, Train AUC: 0.8343, Train APUR: 0.5652, Test AUC: 0.8870, Test AUPR: 0.6154\n",
      "Epoch: 13/100, Loss: 0.9140093, Train Acc: 0.7119, Test Acc: 0.7334, Train AUC: 0.8768, Train APUR: 0.6085, Test AUC: 0.8961, Test AUPR: 0.6266\n",
      "Epoch: 14/100, Loss: 0.8377826, Train Acc: 0.7290, Test Acc: 0.7368, Train AUC: 0.8937, Train APUR: 0.6244, Test AUC: 0.8987, Test AUPR: 0.6316\n",
      "Epoch: 15/100, Loss: 0.7800775, Train Acc: 0.7377, Test Acc: 0.7388, Train AUC: 0.8977, Train APUR: 0.6313, Test AUC: 0.8991, Test AUPR: 0.6303\n",
      "Epoch: 16/100, Loss: 0.7278419, Train Acc: 0.7368, Test Acc: 0.7461, Train AUC: 0.8970, Train APUR: 0.6253, Test AUC: 0.9018, Test AUPR: 0.6375\n",
      "Epoch: 17/100, Loss: 0.7147699, Train Acc: 0.7474, Test Acc: 0.7537, Train AUC: 0.9010, Train APUR: 0.6359, Test AUC: 0.9025, Test AUPR: 0.6396\n",
      "Epoch: 18/100, Loss: 0.6950031, Train Acc: 0.7579, Test Acc: 0.7492, Train AUC: 0.8997, Train APUR: 0.6372, Test AUC: 0.9018, Test AUPR: 0.6344\n",
      "Epoch: 19/100, Loss: 0.6809899, Train Acc: 0.7495, Test Acc: 0.7523, Train AUC: 0.8999, Train APUR: 0.6313, Test AUC: 0.9026, Test AUPR: 0.6365\n",
      "Epoch: 20/100, Loss: 0.6762926, Train Acc: 0.7538, Test Acc: 0.7643, Train AUC: 0.9016, Train APUR: 0.6337, Test AUC: 0.9041, Test AUPR: 0.6418\n",
      "Epoch: 21/100, Loss: 0.6711173, Train Acc: 0.7612, Test Acc: 0.7672, Train AUC: 0.9026, Train APUR: 0.6380, Test AUC: 0.9040, Test AUPR: 0.6418\n",
      "Epoch: 22/100, Loss: 0.6658851, Train Acc: 0.7743, Test Acc: 0.7541, Train AUC: 0.9037, Train APUR: 0.6406, Test AUC: 0.9055, Test AUPR: 0.6448\n",
      "Epoch: 23/100, Loss: 0.6595368, Train Acc: 0.7564, Test Acc: 0.7439, Train AUC: 0.9047, Train APUR: 0.6420, Test AUC: 0.9066, Test AUPR: 0.6471\n",
      "Epoch: 24/100, Loss: 0.6549515, Train Acc: 0.7445, Test Acc: 0.7405, Train AUC: 0.9058, Train APUR: 0.6444, Test AUC: 0.9069, Test AUPR: 0.6487\n",
      "Epoch: 25/100, Loss: 0.6516502, Train Acc: 0.7408, Test Acc: 0.7453, Train AUC: 0.9064, Train APUR: 0.6449, Test AUC: 0.9071, Test AUPR: 0.6505\n",
      "Epoch: 26/100, Loss: 0.6485040, Train Acc: 0.7511, Test Acc: 0.7446, Train AUC: 0.9059, Train APUR: 0.6464, Test AUC: 0.9077, Test AUPR: 0.6516\n",
      "Epoch: 27/100, Loss: 0.6491331, Train Acc: 0.7556, Test Acc: 0.7391, Train AUC: 0.9051, Train APUR: 0.6410, Test AUC: 0.9086, Test AUPR: 0.6523\n",
      "Epoch: 28/100, Loss: 0.6379759, Train Acc: 0.7368, Test Acc: 0.7387, Train AUC: 0.9079, Train APUR: 0.6505, Test AUC: 0.9085, Test AUPR: 0.6518\n",
      "Epoch: 29/100, Loss: 0.6369174, Train Acc: 0.7370, Test Acc: 0.7372, Train AUC: 0.9088, Train APUR: 0.6526, Test AUC: 0.9076, Test AUPR: 0.6493\n",
      "Epoch: 30/100, Loss: 0.6394047, Train Acc: 0.7460, Test Acc: 0.7347, Train AUC: 0.9077, Train APUR: 0.6504, Test AUC: 0.9075, Test AUPR: 0.6494\n",
      "Epoch: 31/100, Loss: 0.6536286, Train Acc: 0.7357, Test Acc: 0.7338, Train AUC: 0.9058, Train APUR: 0.6473, Test AUC: 0.9082, Test AUPR: 0.6520\n",
      "Epoch: 32/100, Loss: 0.6437494, Train Acc: 0.7342, Test Acc: 0.7382, Train AUC: 0.9081, Train APUR: 0.6507, Test AUC: 0.9081, Test AUPR: 0.6515\n",
      "Epoch: 33/100, Loss: 0.6441446, Train Acc: 0.7385, Test Acc: 0.7513, Train AUC: 0.9077, Train APUR: 0.6496, Test AUC: 0.9078, Test AUPR: 0.6490\n",
      "Epoch: 34/100, Loss: 0.6375123, Train Acc: 0.7478, Test Acc: 0.7508, Train AUC: 0.9089, Train APUR: 0.6523, Test AUC: 0.9067, Test AUPR: 0.6447\n",
      "Epoch: 35/100, Loss: 0.6409240, Train Acc: 0.7567, Test Acc: 0.7246, Train AUC: 0.9072, Train APUR: 0.6469, Test AUC: 0.9071, Test AUPR: 0.6462\n",
      "Epoch: 36/100, Loss: 0.6341611, Train Acc: 0.7249, Test Acc: 0.7157, Train AUC: 0.9069, Train APUR: 0.6436, Test AUC: 0.9086, Test AUPR: 0.6513\n",
      "Epoch: 37/100, Loss: 0.6367794, Train Acc: 0.7199, Test Acc: 0.7171, Train AUC: 0.9102, Train APUR: 0.6553, Test AUC: 0.9091, Test AUPR: 0.6529\n",
      "Epoch: 38/100, Loss: 0.6306676, Train Acc: 0.7214, Test Acc: 0.7245, Train AUC: 0.9103, Train APUR: 0.6543, Test AUC: 0.9095, Test AUPR: 0.6537\n",
      "Epoch: 39/100, Loss: 0.6275582, Train Acc: 0.7267, Test Acc: 0.7356, Train AUC: 0.9099, Train APUR: 0.6534, Test AUC: 0.9096, Test AUPR: 0.6534\n",
      "Epoch: 40/100, Loss: 0.6284303, Train Acc: 0.7295, Test Acc: 0.7470, Train AUC: 0.9097, Train APUR: 0.6520, Test AUC: 0.9099, Test AUPR: 0.6534\n",
      "Epoch: 41/100, Loss: 0.6298209, Train Acc: 0.7521, Test Acc: 0.7436, Train AUC: 0.9109, Train APUR: 0.6550, Test AUC: 0.9099, Test AUPR: 0.6532\n",
      "Epoch: 42/100, Loss: 0.6300806, Train Acc: 0.7546, Test Acc: 0.7340, Train AUC: 0.9111, Train APUR: 0.6556, Test AUC: 0.9100, Test AUPR: 0.6535\n",
      "Epoch: 43/100, Loss: 0.6217125, Train Acc: 0.7331, Test Acc: 0.7301, Train AUC: 0.9119, Train APUR: 0.6567, Test AUC: 0.9099, Test AUPR: 0.6536\n",
      "Epoch: 44/100, Loss: 0.6289833, Train Acc: 0.7326, Test Acc: 0.7257, Train AUC: 0.9112, Train APUR: 0.6549, Test AUC: 0.9100, Test AUPR: 0.6531\n",
      "Epoch: 45/100, Loss: 0.6240495, Train Acc: 0.7273, Test Acc: 0.7255, Train AUC: 0.9121, Train APUR: 0.6573, Test AUC: 0.9100, Test AUPR: 0.6526\n",
      "Epoch: 46/100, Loss: 0.6218148, Train Acc: 0.7291, Test Acc: 0.7309, Train AUC: 0.9121, Train APUR: 0.6564, Test AUC: 0.9098, Test AUPR: 0.6522\n",
      "Epoch: 47/100, Loss: 0.6200981, Train Acc: 0.7382, Test Acc: 0.7467, Train AUC: 0.9123, Train APUR: 0.6570, Test AUC: 0.9095, Test AUPR: 0.6517\n",
      "Epoch: 48/100, Loss: 0.6226802, Train Acc: 0.7519, Test Acc: 0.7406, Train AUC: 0.9119, Train APUR: 0.6528, Test AUC: 0.9096, Test AUPR: 0.6525\n",
      "Epoch: 49/100, Loss: 0.6226536, Train Acc: 0.7538, Test Acc: 0.7278, Train AUC: 0.9116, Train APUR: 0.6544, Test AUC: 0.9100, Test AUPR: 0.6529\n",
      "Epoch: 50/100, Loss: 0.6157916, Train Acc: 0.7356, Test Acc: 0.7247, Train AUC: 0.9127, Train APUR: 0.6565, Test AUC: 0.9104, Test AUPR: 0.6529\n",
      "Epoch: 51/100, Loss: 0.6152609, Train Acc: 0.7325, Test Acc: 0.7258, Train AUC: 0.9135, Train APUR: 0.6587, Test AUC: 0.9105, Test AUPR: 0.6530\n",
      "Epoch: 52/100, Loss: 0.6184638, Train Acc: 0.7281, Test Acc: 0.7285, Train AUC: 0.9127, Train APUR: 0.6577, Test AUC: 0.9108, Test AUPR: 0.6529\n",
      "Epoch: 53/100, Loss: 0.6153068, Train Acc: 0.7288, Test Acc: 0.7359, Train AUC: 0.9136, Train APUR: 0.6586, Test AUC: 0.9109, Test AUPR: 0.6532\n",
      "Epoch: 54/100, Loss: 0.6110649, Train Acc: 0.7383, Test Acc: 0.7446, Train AUC: 0.9139, Train APUR: 0.6597, Test AUC: 0.9110, Test AUPR: 0.6531\n",
      "Epoch: 55/100, Loss: 0.6173511, Train Acc: 0.7611, Test Acc: 0.7394, Train AUC: 0.9142, Train APUR: 0.6595, Test AUC: 0.9109, Test AUPR: 0.6532\n",
      "Epoch: 56/100, Loss: 0.6106005, Train Acc: 0.7449, Test Acc: 0.7292, Train AUC: 0.9142, Train APUR: 0.6604, Test AUC: 0.9107, Test AUPR: 0.6529\n",
      "Epoch: 57/100, Loss: 0.6092578, Train Acc: 0.7349, Test Acc: 0.7222, Train AUC: 0.9142, Train APUR: 0.6600, Test AUC: 0.9106, Test AUPR: 0.6525\n",
      "Epoch: 58/100, Loss: 0.6102914, Train Acc: 0.7247, Test Acc: 0.7211, Train AUC: 0.9141, Train APUR: 0.6589, Test AUC: 0.9108, Test AUPR: 0.6525\n",
      "Epoch: 59/100, Loss: 0.6096048, Train Acc: 0.7248, Test Acc: 0.7244, Train AUC: 0.9144, Train APUR: 0.6602, Test AUC: 0.9112, Test AUPR: 0.6531\n",
      "Epoch: 60/100, Loss: 0.6089699, Train Acc: 0.7265, Test Acc: 0.7332, Train AUC: 0.9144, Train APUR: 0.6595, Test AUC: 0.9115, Test AUPR: 0.6529\n",
      "Epoch: 61/100, Loss: 0.6117190, Train Acc: 0.7382, Test Acc: 0.7408, Train AUC: 0.9144, Train APUR: 0.6599, Test AUC: 0.9115, Test AUPR: 0.6536\n",
      "Epoch: 62/100, Loss: 0.6087624, Train Acc: 0.7445, Test Acc: 0.7410, Train AUC: 0.9145, Train APUR: 0.6602, Test AUC: 0.9115, Test AUPR: 0.6536\n",
      "Epoch: 63/100, Loss: 0.6066002, Train Acc: 0.7433, Test Acc: 0.7358, Train AUC: 0.9150, Train APUR: 0.6612, Test AUC: 0.9117, Test AUPR: 0.6538\n",
      "Epoch: 64/100, Loss: 0.6040633, Train Acc: 0.7378, Test Acc: 0.7295, Train AUC: 0.9151, Train APUR: 0.6615, Test AUC: 0.9118, Test AUPR: 0.6536\n",
      "Epoch: 65/100, Loss: 0.6034102, Train Acc: 0.7291, Test Acc: 0.7264, Train AUC: 0.9155, Train APUR: 0.6627, Test AUC: 0.9117, Test AUPR: 0.6533\n",
      "Epoch: 66/100, Loss: 0.6038132, Train Acc: 0.7316, Test Acc: 0.7266, Train AUC: 0.9157, Train APUR: 0.6615, Test AUC: 0.9118, Test AUPR: 0.6538\n",
      "Epoch: 67/100, Loss: 0.6029289, Train Acc: 0.7291, Test Acc: 0.7293, Train AUC: 0.9157, Train APUR: 0.6626, Test AUC: 0.9119, Test AUPR: 0.6541\n",
      "Epoch: 68/100, Loss: 0.6025006, Train Acc: 0.7324, Test Acc: 0.7327, Train AUC: 0.9158, Train APUR: 0.6629, Test AUC: 0.9121, Test AUPR: 0.6541\n",
      "Epoch: 69/100, Loss: 0.6015928, Train Acc: 0.7380, Test Acc: 0.7351, Train AUC: 0.9163, Train APUR: 0.6645, Test AUC: 0.9121, Test AUPR: 0.6541\n",
      "Epoch: 70/100, Loss: 0.6015424, Train Acc: 0.7362, Test Acc: 0.7348, Train AUC: 0.9159, Train APUR: 0.6624, Test AUC: 0.9121, Test AUPR: 0.6541\n",
      "Epoch: 71/100, Loss: 0.6000635, Train Acc: 0.7358, Test Acc: 0.7328, Train AUC: 0.9163, Train APUR: 0.6641, Test AUC: 0.9122, Test AUPR: 0.6542\n",
      "Epoch: 72/100, Loss: 0.6000456, Train Acc: 0.7432, Test Acc: 0.7280, Train AUC: 0.9169, Train APUR: 0.6655, Test AUC: 0.9121, Test AUPR: 0.6542\n",
      "Epoch: 73/100, Loss: 0.5989579, Train Acc: 0.7310, Test Acc: 0.7267, Train AUC: 0.9168, Train APUR: 0.6644, Test AUC: 0.9121, Test AUPR: 0.6544\n",
      "Epoch: 74/100, Loss: 0.5992343, Train Acc: 0.7302, Test Acc: 0.7296, Train AUC: 0.9163, Train APUR: 0.6632, Test AUC: 0.9120, Test AUPR: 0.6543\n",
      "Epoch: 75/100, Loss: 0.5972451, Train Acc: 0.7334, Test Acc: 0.7320, Train AUC: 0.9171, Train APUR: 0.6660, Test AUC: 0.9121, Test AUPR: 0.6543\n",
      "Epoch: 76/100, Loss: 0.5972508, Train Acc: 0.7367, Test Acc: 0.7331, Train AUC: 0.9168, Train APUR: 0.6650, Test AUC: 0.9123, Test AUPR: 0.6547\n",
      "Epoch: 77/100, Loss: 0.5959190, Train Acc: 0.7374, Test Acc: 0.7341, Train AUC: 0.9175, Train APUR: 0.6665, Test AUC: 0.9123, Test AUPR: 0.6548\n",
      "Epoch: 78/100, Loss: 0.5951290, Train Acc: 0.7408, Test Acc: 0.7321, Train AUC: 0.9174, Train APUR: 0.6671, Test AUC: 0.9122, Test AUPR: 0.6544\n",
      "Epoch: 79/100, Loss: 0.5949999, Train Acc: 0.7340, Test Acc: 0.7336, Train AUC: 0.9173, Train APUR: 0.6665, Test AUC: 0.9124, Test AUPR: 0.6548\n",
      "Epoch: 80/100, Loss: 0.5936743, Train Acc: 0.7387, Test Acc: 0.7346, Train AUC: 0.9179, Train APUR: 0.6680, Test AUC: 0.9124, Test AUPR: 0.6549\n",
      "Epoch: 81/100, Loss: 0.5948814, Train Acc: 0.7368, Test Acc: 0.7347, Train AUC: 0.9174, Train APUR: 0.6676, Test AUC: 0.9125, Test AUPR: 0.6549\n",
      "Epoch: 82/100, Loss: 0.5939537, Train Acc: 0.7385, Test Acc: 0.7338, Train AUC: 0.9177, Train APUR: 0.6679, Test AUC: 0.9125, Test AUPR: 0.6549\n",
      "Epoch: 83/100, Loss: 0.5927722, Train Acc: 0.7321, Test Acc: 0.7328, Train AUC: 0.9180, Train APUR: 0.6687, Test AUC: 0.9124, Test AUPR: 0.6546\n",
      "Epoch: 84/100, Loss: 0.5926924, Train Acc: 0.7354, Test Acc: 0.7349, Train AUC: 0.9182, Train APUR: 0.6684, Test AUC: 0.9126, Test AUPR: 0.6549\n",
      "Epoch: 85/100, Loss: 0.5904426, Train Acc: 0.7399, Test Acc: 0.7364, Train AUC: 0.9188, Train APUR: 0.6698, Test AUC: 0.9123, Test AUPR: 0.6541\n",
      "Epoch: 86/100, Loss: 0.5936848, Train Acc: 0.7344, Test Acc: 0.7334, Train AUC: 0.9172, Train APUR: 0.6665, Test AUC: 0.9127, Test AUPR: 0.6550\n",
      "Epoch: 87/100, Loss: 0.5941923, Train Acc: 0.7410, Test Acc: 0.7257, Train AUC: 0.9183, Train APUR: 0.6697, Test AUC: 0.9123, Test AUPR: 0.6539\n",
      "Epoch: 88/100, Loss: 0.5929589, Train Acc: 0.7267, Test Acc: 0.7299, Train AUC: 0.9189, Train APUR: 0.6714, Test AUC: 0.9126, Test AUPR: 0.6545\n",
      "Epoch: 89/100, Loss: 0.5892398, Train Acc: 0.7330, Test Acc: 0.7395, Train AUC: 0.9185, Train APUR: 0.6692, Test AUC: 0.9124, Test AUPR: 0.6541\n",
      "Epoch: 90/100, Loss: 0.5879222, Train Acc: 0.7420, Test Acc: 0.7438, Train AUC: 0.9194, Train APUR: 0.6720, Test AUC: 0.9124, Test AUPR: 0.6541\n",
      "Epoch: 91/100, Loss: 0.5890588, Train Acc: 0.7514, Test Acc: 0.7374, Train AUC: 0.9190, Train APUR: 0.6703, Test AUC: 0.9126, Test AUPR: 0.6546\n",
      "Epoch: 92/100, Loss: 0.5866011, Train Acc: 0.7379, Test Acc: 0.7302, Train AUC: 0.9194, Train APUR: 0.6711, Test AUC: 0.9126, Test AUPR: 0.6546\n",
      "Epoch: 93/100, Loss: 0.5869002, Train Acc: 0.7320, Test Acc: 0.7309, Train AUC: 0.9196, Train APUR: 0.6711, Test AUC: 0.9126, Test AUPR: 0.6546\n",
      "Epoch: 94/100, Loss: 0.5855352, Train Acc: 0.7317, Test Acc: 0.7372, Train AUC: 0.9198, Train APUR: 0.6722, Test AUC: 0.9126, Test AUPR: 0.6546\n",
      "Epoch: 95/100, Loss: 0.5845206, Train Acc: 0.7392, Test Acc: 0.7408, Train AUC: 0.9199, Train APUR: 0.6724, Test AUC: 0.9125, Test AUPR: 0.6543\n",
      "Epoch: 96/100, Loss: 0.5857790, Train Acc: 0.7415, Test Acc: 0.7411, Train AUC: 0.9192, Train APUR: 0.6706, Test AUC: 0.9126, Test AUPR: 0.6540\n",
      "Epoch: 97/100, Loss: 0.5863234, Train Acc: 0.7434, Test Acc: 0.7410, Train AUC: 0.9199, Train APUR: 0.6733, Test AUC: 0.9127, Test AUPR: 0.6545\n",
      "Epoch: 98/100, Loss: 0.5836337, Train Acc: 0.7445, Test Acc: 0.7349, Train AUC: 0.9205, Train APUR: 0.6741, Test AUC: 0.9125, Test AUPR: 0.6541\n",
      "Epoch: 99/100, Loss: 0.5829116, Train Acc: 0.7375, Test Acc: 0.7316, Train AUC: 0.9202, Train APUR: 0.6729, Test AUC: 0.9126, Test AUPR: 0.6544\n",
      "Epoch: 100/100, Loss: 0.5843982, Train Acc: 0.7347, Test Acc: 0.7360, Train AUC: 0.9208, Train APUR: 0.6749, Test AUC: 0.9119, Test AUPR: 0.6535\n",
      "/home/ubuntu/PA-Cancer-Immunotherapy/GNN/train.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(configs['save_model']))\n",
      "Test Acc: 0.7410, Test AUC: 0.9127, Test AUPR: 0.6545\n"
     ]
    }
   ],
   "source": [
    "# as an experiment: we run the train.py and see the results we get. Are they comparable to the paper's results?\n",
    "# They claim: \n",
    "# for pMTnet AUC: 0.911± 0.003 ;  AUPR: 0.655± 0.007\n",
    "\n",
    "! python train.py --gpu 0 --configs_path configs/pMTnet.yml --droup_out 0.1 --split StrictTCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcc116a-80bc-428c-8710-ce82045d2d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the above result reflects the metrics presented in the paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0b0b97-4009-429d-be2d-4ef0d27659f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1153e02e-8df6-4d09-9293-1d0727800ef8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "688ab7c1-4ae8-4efb-b2ac-2389dc0903a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Precision (AP): 1.00\n",
      "Area Under the Precision-Recall Curve (AUPR): 1.00\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, auc\n",
    "\n",
    "# Generate some example data\n",
    "# True labels (1 for positive, 0 for negative)\n",
    "y_true = np.array([0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1])\n",
    "\n",
    "# Predicted probabilities for the positive class\n",
    "y_scores = np.array([0.1, 0.2, 0.8, 0.9, 0.7, 0.3, 0.6, 0.4, 0.75, 0.85, 0.2, 0.15, 0.65, 0.05, 0.95])\n",
    "\n",
    "# Calculate precision, recall, and thresholds\n",
    "precision, recall, thresholds = precision_recall_curve(y_true, y_scores)\n",
    "\n",
    "# Calculate Average Precision (AP)\n",
    "average_precision = average_precision_score(y_true, y_scores)\n",
    "\n",
    "# Calculate AUPR (area under the PR curve)\n",
    "aupr = auc(recall, precision)\n",
    "\n",
    "# Plot the Precision-Recall curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.step(recall, precision, where='post', label=f'PR Curve (AUPR = {aupr:.2f})', color='b', linewidth=2)\n",
    "plt.fill_between(recall, precision, alpha=0.2, color='b')  # Add shading for better visualization\n",
    "plt.axhline(y=np.mean(y_true), color='r', linestyle='--', label=f'Baseline (Random Classifier)')\n",
    "plt.xlabel('Recall', fontsize=14)\n",
    "plt.ylabel('Precision', fontsize=14)\n",
    "plt.title('Precision-Recall Curve', fontsize=16)\n",
    "plt.legend(loc='lower left', fontsize=12)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Average Precision (AP): {average_precision:.2f}\")\n",
    "print(f\"Area Under the Precision-Recall Curve (AUPR): {aupr:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cba43b8-998d-4e5f-9706-eefca82ce878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "import pandas as pd\n",
    "# from sklearn.metrics.pairwise import pairwise_distances\n",
    "# from arg_parser import parse_args\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "def TEINet_embeddings_5vfold(config_path):\n",
    "    # args = parse_args()\n",
    "\n",
    "    with open(config_path) as file:\n",
    "        config = yaml.safe_load(file)\n",
    "\n",
    "    with open(config[\"embeddings_path\"], 'rb') as f:\n",
    "        embedding_dict = pickle.load(f)\n",
    "\n",
    "    train_file_list = config['StrictTCR']['train_data']['file_list']\n",
    "    test_file_list = config['StrictTCR']['test_data']['file_list']\n",
    "    file_path = config['path']\n",
    "\n",
    "    train_data = []\n",
    "    for file_name in train_file_list:\n",
    "        data = pd.read_csv(os.path.join(file_path, file_name))\n",
    "        train_data.append(data)\n",
    "    train_data = pd.concat(train_data)\n",
    "\n",
    "\n",
    "    test_data = []\n",
    "    for file_name in test_file_list:\n",
    "        data = pd.read_csv(os.path.join(file_path, file_name))\n",
    "        test_data.append(data)\n",
    "    test_data = pd.concat(test_data) \n",
    "\n",
    "    all_data = []\n",
    "    for data in [train_data, test_data]:\n",
    "        node_index = {} \n",
    "        num_nodes = 0\n",
    "        edge_list = []\n",
    "        X = []\n",
    "        y_list = []\n",
    "        for _, row in data.iterrows():\n",
    "            label = float(row[\"Label\"])\n",
    "            nodes = [row[\"Epitope\"], row[\"CDR3.beta\"]]\n",
    "            for node in nodes:\n",
    "                if node not in node_index:\n",
    "                    node_index[node] = num_nodes\n",
    "                    num_nodes += 1\n",
    "                    X.append(embedding_dict[node])\n",
    "            y_list.append(label)\n",
    "            edge_list.append((node_index[nodes[0]], node_index[nodes[1]]))\n",
    "\n",
    "        \n",
    "        X = torch.tensor(np.array(X), dtype=torch.float)\n",
    "        edge_index = torch.tensor(edge_list, dtype=torch.long).t().contiguous()\n",
    "        y = torch.tensor(y_list, dtype=torch.float)\n",
    "\n",
    "        all_data.append(Data(x=X, edge_index=edge_index, y=y, num_nodes=num_nodes))\n",
    "\n",
    "    return all_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a423311-e136-470b-9481-2895a8035417",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'c' argument has 355416 elements, which is inconsistent with 'x' and 'y' with size 206981.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/GTE/lib/python3.11/site-packages/matplotlib/axes/_axes.py:4618\u001b[0m, in \u001b[0;36mAxes._parse_scatter_color_args\u001b[0;34m(c, edgecolors, kwargs, xsize, get_next_color_func)\u001b[0m\n\u001b[1;32m   4617\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:  \u001b[38;5;66;03m# Is 'c' acceptable as PathCollection facecolors?\u001b[39;00m\n\u001b[0;32m-> 4618\u001b[0m     colors \u001b[38;5;241m=\u001b[39m mcolors\u001b[38;5;241m.\u001b[39mto_rgba_array(c)\n\u001b[1;32m   4619\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/envs/GTE/lib/python3.11/site-packages/matplotlib/colors.py:512\u001b[0m, in \u001b[0;36mto_rgba_array\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 512\u001b[0m     rgba \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([to_rgba(cc) \u001b[38;5;28;01mfor\u001b[39;00m cc \u001b[38;5;129;01min\u001b[39;00m c])\n\u001b[1;32m    514\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m alpha \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/GTE/lib/python3.11/site-packages/matplotlib/colors.py:512\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 512\u001b[0m     rgba \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([to_rgba(cc) \u001b[38;5;28;01mfor\u001b[39;00m cc \u001b[38;5;129;01min\u001b[39;00m c])\n\u001b[1;32m    514\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m alpha \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/GTE/lib/python3.11/site-packages/matplotlib/colors.py:314\u001b[0m, in \u001b[0;36mto_rgba\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rgba \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# Suppress exception chaining of cache lookup failure.\u001b[39;00m\n\u001b[0;32m--> 314\u001b[0m     rgba \u001b[38;5;241m=\u001b[39m _to_rgba_no_colorcycle(c, alpha)\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/GTE/lib/python3.11/site-packages/matplotlib/colors.py:398\u001b[0m, in \u001b[0;36m_to_rgba_no_colorcycle\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39miterable(c):\n\u001b[0;32m--> 398\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid RGBA argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00morig_c\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(c) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m]:\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid RGBA argument: np.float64(1.0)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 63\u001b[0m\n\u001b[1;32m     61\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m     62\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 63\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(embeddings_pca[:, \u001b[38;5;241m0\u001b[39m], embeddings_pca[:, \u001b[38;5;241m1\u001b[39m], c\u001b[38;5;241m=\u001b[39mlabels, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoolwarm\u001b[39m\u001b[38;5;124m'\u001b[39m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m)\n\u001b[1;32m     64\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPCA of Embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     65\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPCA Component 1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/GTE/lib/python3.11/site-packages/matplotlib/pyplot.py:3903\u001b[0m, in \u001b[0;36mscatter\u001b[0;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, data, **kwargs)\u001b[0m\n\u001b[1;32m   3884\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mscatter)\n\u001b[1;32m   3885\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscatter\u001b[39m(\n\u001b[1;32m   3886\u001b[0m     x: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m ArrayLike,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3901\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3902\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PathCollection:\n\u001b[0;32m-> 3903\u001b[0m     __ret \u001b[38;5;241m=\u001b[39m gca()\u001b[38;5;241m.\u001b[39mscatter(\n\u001b[1;32m   3904\u001b[0m         x,\n\u001b[1;32m   3905\u001b[0m         y,\n\u001b[1;32m   3906\u001b[0m         s\u001b[38;5;241m=\u001b[39ms,\n\u001b[1;32m   3907\u001b[0m         c\u001b[38;5;241m=\u001b[39mc,\n\u001b[1;32m   3908\u001b[0m         marker\u001b[38;5;241m=\u001b[39mmarker,\n\u001b[1;32m   3909\u001b[0m         cmap\u001b[38;5;241m=\u001b[39mcmap,\n\u001b[1;32m   3910\u001b[0m         norm\u001b[38;5;241m=\u001b[39mnorm,\n\u001b[1;32m   3911\u001b[0m         vmin\u001b[38;5;241m=\u001b[39mvmin,\n\u001b[1;32m   3912\u001b[0m         vmax\u001b[38;5;241m=\u001b[39mvmax,\n\u001b[1;32m   3913\u001b[0m         alpha\u001b[38;5;241m=\u001b[39malpha,\n\u001b[1;32m   3914\u001b[0m         linewidths\u001b[38;5;241m=\u001b[39mlinewidths,\n\u001b[1;32m   3915\u001b[0m         edgecolors\u001b[38;5;241m=\u001b[39medgecolors,\n\u001b[1;32m   3916\u001b[0m         plotnonfinite\u001b[38;5;241m=\u001b[39mplotnonfinite,\n\u001b[1;32m   3917\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data} \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[1;32m   3918\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3919\u001b[0m     )\n\u001b[1;32m   3920\u001b[0m     sci(__ret)\n\u001b[1;32m   3921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m __ret\n",
      "File \u001b[0;32m~/anaconda3/envs/GTE/lib/python3.11/site-packages/matplotlib/__init__.py:1473\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m   1471\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1472\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1473\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\n\u001b[1;32m   1474\u001b[0m             ax,\n\u001b[1;32m   1475\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mmap\u001b[39m(sanitize_sequence, args),\n\u001b[1;32m   1476\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{k: sanitize_sequence(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems()})\n\u001b[1;32m   1478\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1479\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[1;32m   1480\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m~/anaconda3/envs/GTE/lib/python3.11/site-packages/matplotlib/axes/_axes.py:4805\u001b[0m, in \u001b[0;36mAxes.scatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[1;32m   4802\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m edgecolors \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4803\u001b[0m     orig_edgecolor \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medgecolor\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   4804\u001b[0m c, colors, edgecolors \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m-> 4805\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_scatter_color_args(\n\u001b[1;32m   4806\u001b[0m         c, edgecolors, kwargs, x\u001b[38;5;241m.\u001b[39msize,\n\u001b[1;32m   4807\u001b[0m         get_next_color_func\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_patches_for_fill\u001b[38;5;241m.\u001b[39mget_next_color)\n\u001b[1;32m   4809\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m plotnonfinite \u001b[38;5;129;01mand\u001b[39;00m colors \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4810\u001b[0m     c \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mma\u001b[38;5;241m.\u001b[39mmasked_invalid(c)\n",
      "File \u001b[0;32m~/anaconda3/envs/GTE/lib/python3.11/site-packages/matplotlib/axes/_axes.py:4624\u001b[0m, in \u001b[0;36mAxes._parse_scatter_color_args\u001b[0;34m(c, edgecolors, kwargs, xsize, get_next_color_func)\u001b[0m\n\u001b[1;32m   4622\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4623\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m valid_shape:\n\u001b[0;32m-> 4624\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m invalid_shape_exception(c\u001b[38;5;241m.\u001b[39msize, xsize) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   4625\u001b[0m     \u001b[38;5;66;03m# Both the mapping *and* the RGBA conversion failed: pretty\u001b[39;00m\n\u001b[1;32m   4626\u001b[0m     \u001b[38;5;66;03m# severe failure => one may appreciate a verbose feedback.\u001b[39;00m\n\u001b[1;32m   4627\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   4628\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m argument must be a color, a sequence of colors, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4629\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor a sequence of numbers, not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mc\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: 'c' argument has 355416 elements, which is inconsistent with 'x' and 'y' with size 206981."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualizing embeddings to check if that's the problem for no-learning in training\n",
    "\n",
    "\n",
    "\n",
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# from data_processing import TEINet_embeddings_5fold # , esm_embeddings_5fold\n",
    "# from model import GraphNet\n",
    "# from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "# import pandas as pd\n",
    "# from libauc.losses import AUCMLoss\n",
    "# from libauc.optimizers import PESG\n",
    "# from arg_parser import parse_args\n",
    "# import numpy as np\n",
    "# import collections\n",
    "# from torch_geometric.data import Data\n",
    "import random\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# import yaml\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import torch\n",
    "\n",
    "seed = 18\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "data_list = TEINet_embeddings_5vfold(\"./configs/PA_all_gene.yml\")\n",
    "data_list = [data.to(device) for data in data_list]\n",
    "\n",
    "train_data = data_list[0]\n",
    "test_data = data_list[1]\n",
    "\n",
    "# Extract embeddings and labels\n",
    "train_embeddings = train_data.x.detach().cpu().numpy()  # Convert to NumPy array\n",
    "train_labels = train_data.y.detach().cpu().numpy()      # Labels as NumPy array\n",
    "\n",
    "test_embeddings = test_data.x.detach().cpu().numpy()\n",
    "test_labels = test_data.y.detach().cpu().numpy()\n",
    "\n",
    "# Combine train and test data for visualization (optional)\n",
    "embeddings = np.concatenate([train_embeddings, test_embeddings], axis=0)\n",
    "labels = np.concatenate([train_labels, test_labels], axis=0)\n",
    "\n",
    "# Option 1: PCA for Dimensionality Reduction\n",
    "pca = PCA(n_components=2)\n",
    "embeddings_pca = pca.fit_transform(embeddings)\n",
    "\n",
    "# Option 2: t-SNE for Dimensionality Reduction\n",
    "tsne = TSNE(n_components=2, perplexity=30, random_state=42)\n",
    "embeddings_tsne = tsne.fit_transform(embeddings)\n",
    "\n",
    "# Plot PCA results\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(embeddings_pca[:, 0], embeddings_pca[:, 1], c=labels, cmap='coolwarm', alpha=0.7)\n",
    "plt.title(\"PCA of Embeddings\")\n",
    "plt.xlabel(\"PCA Component 1\")\n",
    "plt.ylabel(\"PCA Component 2\")\n",
    "plt.colorbar(label=\"Class\")\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot t-SNE results\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(embeddings_tsne[:, 0], embeddings_tsne[:, 1], c=labels, cmap='coolwarm', alpha=0.7)\n",
    "plt.title(\"t-SNE of Embeddings\")\n",
    "plt.xlabel(\"t-SNE Dimension 1\")\n",
    "plt.ylabel(\"t-SNE Dimension 2\")\n",
    "plt.colorbar(label=\"Class\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104ac3e2-7a83-44e0-a305-d4183b53b452",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95db4594-a5ea-4fba-9573-f584a77fa1b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7a6406-9d14-4542-855c-ea5a83e0af7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### as py file  # train_vanilla.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc45349-0bb8-4074-8876-a2c966246ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    precision = \"allele\" # \"allele or gene\"\n",
    "    embed_base_dir = f\"../../data_10x/embeddings/paired/{precision}\" ### Embeddings!!\n",
    "    hyperparameter_tuning_with_WnB = True  # False!!\n",
    "\n",
    "    # -----------------------------------------------------------------------------\n",
    "    # W&B Setup\n",
    "    # -----------------------------------------------------------------------------\n",
    "\n",
    "    experiment_name = f\"Experiment - {MODEL_NAME}\"\n",
    "    load_dotenv()\n",
    "    PROJECT_NAME = os.getenv(\"MAIN_PROJECT_NAME\")\n",
    "    PROJECT_NAME = f'dataset-{precision}_10x' ## GNN\n",
    "    print(f\"PROJECT_NAME: {PROJECT_NAME}\")\n",
    "    run = wandb.init(project=PROJECT_NAME, job_type=f\"{experiment_name}\", entity=\"pa_cancerimmunotherapy\")\n",
    "    config = wandb.config\n",
    "\n",
    "    # -----------------------------------------------------------------------------\n",
    "    # data (from W&B)\n",
    "    # -----------------------------------------------------------------------------\n",
    "    # Download corresponding artifact (= dataset) from W&B\n",
    "    dataset_name = f\"paired_{precision}\"  # beta_\n",
    "    artifact = run.use_artifact(f\"{dataset_name}:latest\")\n",
    "    data_dir = artifact.download(f\"./WnB_Experiments_Datasets/paired_{precision}\") ## auch.. hier beta\n",
    "    \n",
    "    train_file_path = f\"{data_dir}/{precision}/train.tsv\"\n",
    "    test_file_path = f\"{data_dir}/{precision}/test.tsv\"\n",
    "    val_file_path = f\"{data_dir}/{precision}/validation.tsv\"\n",
    "\n",
    "    df_train = pd.read_csv(train_file_path, sep=\"\\t\")\n",
    "    df_test = pd.read_csv(test_file_path, sep=\"\\t\")\n",
    "    df_val = pd.read_csv(val_file_path, sep=\"\\t\")\n",
    "    df_full = pd.concat([df_train, df_test, df_val])\n",
    "\n",
    "    # Überprüfen, ob es NaN-Werte gibt\n",
    "    nan_counts = df_full.isna().sum()\n",
    "    print(\"Anzahl NaN-Werte pro Spalte:\\n\", nan_counts)\n",
    "    \n",
    "    # Zeilen mit NaN-Werten anzeigen\n",
    "    rows_with_nans = df_full[df_full.isna().any(axis=1)]\n",
    "    print(\"Zeilen mit NaN-Werten:\\n\", rows_with_nans)\n",
    "    \n",
    "    # NaN-Werte in der Spalte 'TRA_CDR3' zählen\n",
    "    nan_tra_cdr3 = df_full[\"TRA_CDR3\"].isna().sum()\n",
    "    print(f\"Anzahl NaN-Werte in TRA_CDR3: {nan_tra_cdr3}\")\n",
    "    \n",
    "    # Zeilen mit NaN-Werten in 'TRA_CDR3' anzeigen\n",
    "    rows_with_nan_tra_cdr3 = df_full[df_full[\"TRA_CDR3\"].isna()]\n",
    "    print(\"Zeilen mit NaN-Werten in TRA_CDR3:\\n\", rows_with_nan_tra_cdr3)\n",
    "\n",
    "    \n",
    "    traV_dict = column_to_dictionray(df_full, \"TRAV\")\n",
    "    traJ_dict = column_to_dictionray(df_full, \"TRAJ\")\n",
    "    trbV_dict = column_to_dictionray(df_full, \"TRBV\")\n",
    "    trbJ_dict = column_to_dictionray(df_full, \"TRBJ\")\n",
    "    mhc_dict = column_to_dictionray(df_full, \"MHC\")           \n",
    "    \n",
    "    traV_embed_len = get_embed_len(df_full, \"TRAV\")\n",
    "    traJ_embed_len = get_embed_len(df_full, \"TRAJ\")\n",
    "    trbV_embed_len = get_embed_len(df_full, \"TRBV\")\n",
    "    trbJ_embed_len = get_embed_len(df_full, \"TRBJ\")\n",
    "    mhc_embed_len = get_embed_len(df_full, \"MHC\")\n",
    "\n",
    "    print(\"erster Stopp\")\n",
    "    train_dataset = PairedVanilla(train_file_path, embed_base_dir, traV_dict, traJ_dict, trbV_dict, trbJ_dict, mhc_dict)\n",
    "    print(\"erster zweiter Stopp\")\n",
    "    #train_dataset.print_sample()\n",
    "    test_dataset = PairedVanilla(test_file_path, embed_base_dir, traV_dict, traJ_dict, trbV_dict, trbJ_dict, mhc_dict)\n",
    "    print(\"erster dritter Stopp\")\n",
    "    #test_dataset.print_sample()\n",
    "    val_dataset = PairedVanilla(val_file_path, embed_base_dir, traV_dict, traJ_dict, trbV_dict, trbJ_dict, mhc_dict)\n",
    "    print(\"zweiter Stopp\")\n",
    "    #val_dataset.print_sample()\n",
    "    \n",
    "    SEQ_MAX_LENGTH = max(train_dataset.get_max_length(), test_dataset.get_max_length(), val_dataset.get_max_length())\n",
    "    print(f\"this is SEQ_MAX_LENGTH: {SEQ_MAX_LENGTH}\")\n",
    "\n",
    "    pad_collate = PadCollate(SEQ_MAX_LENGTH).pad_collate\n",
    "\n",
    "    # For reproducability\n",
    "    generator = torch.Generator().manual_seed(42)\n",
    "    train_sampler = RandomSampler(train_dataset, generator=generator)\n",
    "    val_sampler = RandomSampler(val_dataset, generator=generator) \n",
    "    test_sampler = SequentialSampler(test_dataset)\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        sampler=train_sampler,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        collate_fn=pad_collate,\n",
    "    )\n",
    "\n",
    "    val_dataloader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        sampler=val_sampler,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        collate_fn=pad_collate,\n",
    "\n",
    "    )\n",
    "\n",
    "    test_dataloader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=1,\n",
    "        sampler=test_sampler,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        collate_fn=pad_collate,\n",
    "    )\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    # model \n",
    "    # ---------------------------------------------------------------------------------\n",
    "    if hyperparameter_tuning_with_WnB:\n",
    "        hyperparameters = set_hyperparameters(config)\n",
    "    else:\n",
    "        hyperparameters = {}\n",
    "        hyperparameters[\"optimizer\"] = \"sgd\" #adam\n",
    "        hyperparameters[\"learning_rate\"] = 5e-3\n",
    "        hyperparameters[\"weight_decay\"] = 0.075\n",
    "        hyperparameters[\"dropout_attention\"] = 0.3\n",
    "        hyperparameters[\"dropout_linear\"] = 0.45\n",
    "    \n",
    "    model = VanillaModel(EMBEDDING_SIZE, SEQ_MAX_LENGTH, DEVICE, traV_embed_len, traJ_embed_len, trbV_embed_len, trbJ_embed_len, mhc_embed_len, hyperparameters)\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    # training\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    # Initialize loggers\n",
    "    wandb_logger = WandbLogger(project=PROJECT_NAME, name=experiment_name)\n",
    "    # This logs gradients\n",
    "    wandb_logger.watch(model)\n",
    "    tensorboard_logger = TensorBoardLogger(\"tb_logs\", name=f\"{MODEL_NAME}\")\n",
    "\n",
    "    # Callbacks\n",
    "    run_name = wandb.run.name  \n",
    "    checkpoint_dir = f\"checkpoints/{run_name}\"\n",
    "    model_checkpoint = ModelCheckpoint(\n",
    "        dirpath=checkpoint_dir,\n",
    "        filename=\"{epoch:02d}-{val_loss:.2f}\",\n",
    "        monitor=\"AP_Val\",  \n",
    "        mode=\"max\",\n",
    "        save_top_k=1  \n",
    "    )\n",
    "\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor=\"AP_Val\",  \n",
    "        patience=5,        \n",
    "        verbose=True,\n",
    "        mode=\"max\"        \n",
    "    )\n",
    "\n",
    "    lr_monitor = LearningRateMonitor(logging_interval=\"epoch\")\n",
    "    swa = StochasticWeightAveraging(swa_lrs=hyperparameters[\"learning_rate\"]*0.1, swa_epoch_start=45)\n",
    "\n",
    "    # Training\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=EPOCHS,\n",
    "        logger=[wandb_logger, tensorboard_logger],\n",
    "        callbacks=[model_checkpoint, early_stopping, lr_monitor, swa],  \n",
    "        accelerator=\"gpu\"\n",
    "    ) # add mixed precision\n",
    "\n",
    "    trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)\n",
    "    best_model_path = model_checkpoint.best_model_path\n",
    "    print(f\"Best model saved at {best_model_path}\")\n",
    "    # Testing\n",
    "    test_RES = trainer.test(model, dataloaders=test_dataloader)\n",
    "    print(f\"test_RES: {test_RES}\")\n",
    "    validate_RES = trainer.validate(model, dataloaders=val_dataloader)\n",
    "    print(f\"validate_RES: {validate_RES}\")\n",
    "    # Close W&B run\n",
    "    wandb_logger.experiment.finish()\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    # save model\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    torch.save(model.state_dict(), MODEL_OUT)\n",
    "    print(f\"Saved PyTorch Model State to {MODEL_OUT}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6191cbc8-b4c5-4b6b-a2b0-013418675cb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7893a7f-7778-4714-b184-40152c57ccdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60bbff4f-c7bc-4e8f-9b1a-fe18a36fe004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed_data/PA_all/allele_fold_0.csv\n",
      "Length of df: 78914\n",
      "Percent of positive samples: 0.5033707580403984\n",
      "processed_data/PA_all/allele_fold_1.csv\n",
      "Length of df: 78914\n",
      "Percent of positive samples: 0.49821324479813467\n",
      "processed_data/PA_all/allele_fold_2.csv\n",
      "Length of df: 78914\n",
      "Percent of positive samples: 0.5012291862027016\n",
      "processed_data/PA_all/allele_fold_3.csv\n",
      "Length of df: 78914\n",
      "Percent of positive samples: 0.5026991408368604\n",
      "processed_data/PA_all/allele_fold_4.csv\n",
      "Length of df: 78914\n",
      "Percent of positive samples: 0.5046633043566414\n"
     ]
    }
   ],
   "source": [
    "# some investigations on the data we're using for training/testing.  PA_all\n",
    "\n",
    "paths = []\n",
    "for i in range(5):\n",
    "    path = f\"processed_data/PA_all/allele_fold_{i}.csv\"\n",
    "    paths.append(path)\n",
    "for path in paths:\n",
    "    df=pd.read_csv(path)\n",
    "    print(path)\n",
    "    print(f\"Length of df: {len(df)}\")\n",
    "    count_ones = (df['Label'] == 1).sum()\n",
    "    print(f\"Percent of positive samples: {count_ones/len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f75de5-bf50-4715-9d7e-c8bf5b9d01bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here I should check if the length of the BA train+validation+test == PA_all.\n",
    "# What does the Kfold method ecxactly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "322aec68-a326-4d16-b20a-c8e81f28210f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_for_training/splitted_datasets/allele/beta/train.tsv\n",
      "Length of df: 279012\n",
      "Percent of positive samples: 0.5004981864579301\n",
      "data_for_training/splitted_datasets/allele/beta/test.tsv\n",
      "Length of df: 59798\n",
      "Percent of positive samples: 0.5004347971504064\n",
      "data_for_training/splitted_datasets/allele/beta/validation.tsv\n",
      "Length of df: 59771\n",
      "Percent of positive samples: 0.5006106640343979\n"
     ]
    }
   ],
   "source": [
    "\n",
    "paths = [\"data_for_training/splitted_datasets/allele/beta/train.tsv\",\n",
    "         \"data_for_training/splitted_datasets/allele/beta/test.tsv\",\n",
    "         \"data_for_training/splitted_datasets/allele/beta/validation.tsv\"]\n",
    "for path in paths:\n",
    "    df=pd.read_csv(path, sep=\"\\t\")\n",
    "    print(path)\n",
    "    print(f\"Length of df: {len(df)}\")\n",
    "    count_ones = (df['Binding'] == 1).sum()\n",
    "    print(f\"Percent of positive samples: {count_ones/len(df)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21c33b17-49ae-4863-9ce8-3e6944109e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed_data/pMTnet/StrictTCR/StrictTCR_fold_0.csv\n",
      "Length of df: 69003\n",
      "Percent of positive samples: 0.09090909090909091\n",
      "processed_data/pMTnet/StrictTCR/StrictTCR_fold_1.csv\n",
      "Length of df: 68629\n",
      "Percent of positive samples: 0.09090909090909091\n",
      "processed_data/pMTnet/StrictTCR/StrictTCR_fold_2.csv\n",
      "Length of df: 68244\n",
      "Percent of positive samples: 0.09090909090909091\n",
      "processed_data/pMTnet/StrictTCR/StrictTCR_fold_3.csv\n",
      "Length of df: 68772\n",
      "Percent of positive samples: 0.09090909090909091\n",
      "processed_data/pMTnet/StrictTCR/StrictTCR_fold_4.csv\n",
      "Length of df: 68585\n",
      "Percent of positive samples: 0.09090909090909091\n"
     ]
    }
   ],
   "source": [
    "# Let's check the number of samples in pMTnet, what we used to replicate the results of the paper.\n",
    "\n",
    "paths = [\"processed_data/pMTnet/StrictTCR/StrictTCR_fold_0.csv\",\n",
    "        \"processed_data/pMTnet/StrictTCR/StrictTCR_fold_1.csv\",\n",
    "        \"processed_data/pMTnet/StrictTCR/StrictTCR_fold_2.csv\",\n",
    "        \"processed_data/pMTnet/StrictTCR/StrictTCR_fold_3.csv\",\n",
    "        \"processed_data/pMTnet/StrictTCR/StrictTCR_fold_4.csv\"]\n",
    "for path in paths:\n",
    "    df=pd.read_csv(path)\n",
    "    print(path)\n",
    "    print(f\"Length of df: {len(df)}\")\n",
    "    count_ones = (df['Label'] == 1).sum()\n",
    "    print(f\"Percent of positive samples: {count_ones/len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d555bc-5e49-47a4-a393-81705ec354e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dc0663-085a-4127-89f2-613d889164f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02000e4-7f29-4b6a-a456-14f64e05c1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# discovering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02d924f4-3e72-44f3-b218-91ffa5bf786f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of common cdrs: 274083\n",
      "Number of common epitopes: 275700\n"
     ]
    }
   ],
   "source": [
    "# what's the difference between allele and gene in terms of cdr.3 and epitopes?\n",
    "path_allele_training = \"data_for_training/splitted_datasets/allele/beta/train.tsv\"\n",
    "path_gene_training = \"data_for_training/splitted_datasets/gene/beta/train.tsv\"\n",
    "df_allele = pd.read_csv(path_allele_training, sep='\\t')\n",
    "df_gene = pd.read_csv(path_gene_training, sep='\\t')\n",
    "common_cdrs_count = df_allele['TRB_CDR3'].isin(df_gene['TRB_CDR3']).sum()\n",
    "common_epitopes_count = df_allele['Epitope'].isin(df_gene['Epitope']).sum()\n",
    "print( \"Length of allele_training: \", len(df_allele),'\\n', f\"Number of common cdrs: {common_cdrs_count}\")\n",
    "print(f\"Number of common epitopes: {common_epitopes_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec6b2d85-845e-4dc1-9814-a441cc76b3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279012\n",
      "251686\n"
     ]
    }
   ],
   "source": [
    "print(len(df_allele))\n",
    "print(len(df_gene))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12d17408-9541-47e1-86e4-c214b70318b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of common combinations: 139028\n"
     ]
    }
   ],
   "source": [
    "# check combinations cdr-epitope\n",
    "\n",
    "\n",
    "# Create a combination column as tuples\n",
    "df_allele['combo'] = list(zip(df_allele['TRB_CDR3'], df_allele['Epitope']))\n",
    "df_gene['combo'] = list(zip(df_gene['TRB_CDR3'], df_gene['Epitope']))\n",
    "\n",
    "# Check how many combinations in df_A['combo'] are in df_B['combo']\n",
    "common_combos_count = df_allele['combo'].isin(df_gene['combo']).sum()\n",
    "\n",
    "print(f\"Number of common combinations: {common_combos_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e97891-d929-4926-9623-29637a4db467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the inspection above raise the question if the splitting allele/gene is necessary, since so many cdr-epitope combinations are present in both datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3d44d00-4db7-4e74-b9de-a1359c01ba79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TCR_name</th>\n",
       "      <th>TRBV</th>\n",
       "      <th>TRBJ</th>\n",
       "      <th>TRB_CDR3</th>\n",
       "      <th>TRBC</th>\n",
       "      <th>Epitope</th>\n",
       "      <th>MHC</th>\n",
       "      <th>Binding</th>\n",
       "      <th>task</th>\n",
       "      <th>combo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>TRBV16*01</td>\n",
       "      <td>TRBJ2-1*01</td>\n",
       "      <td>CASSQSGVGNEQFF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KLGGALQAK</td>\n",
       "      <td>HLA-A*03:01</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(CASSQSGVGNEQFF, KLGGALQAK)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>TRBV5-1*01</td>\n",
       "      <td>TRBJ1-4*01</td>\n",
       "      <td>CASSGTGTSAFATNEKLFF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KLGGALQAK</td>\n",
       "      <td>HLA-A*03:01</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(CASSGTGTSAFATNEKLFF, KLGGALQAK)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>TRBV27*01</td>\n",
       "      <td>TRBJ1-2*01</td>\n",
       "      <td>CASSPGTGASGYTF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AVFDRKSDAK</td>\n",
       "      <td>HLA-A*11:01</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(CASSPGTGASGYTF, AVFDRKSDAK)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>TRBV7-9*01</td>\n",
       "      <td>TRBJ2-1*01</td>\n",
       "      <td>CASSLADGGGYNEQFF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KLGGALQAK</td>\n",
       "      <td>HLA-A*03:01</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(CASSLADGGGYNEQFF, KLGGALQAK)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>TRBV7-2*01</td>\n",
       "      <td>TRBJ2-1*01</td>\n",
       "      <td>CASSFAGGSYNEQFF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RLRAEAQVK</td>\n",
       "      <td>HLA-A*03:01</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(CASSFAGGSYNEQFF, RLRAEAQVK)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TCR_name        TRBV        TRBJ             TRB_CDR3  TRBC     Epitope  \\\n",
       "0         1   TRBV16*01  TRBJ2-1*01       CASSQSGVGNEQFF   NaN   KLGGALQAK   \n",
       "1         2  TRBV5-1*01  TRBJ1-4*01  CASSGTGTSAFATNEKLFF   NaN   KLGGALQAK   \n",
       "2         3   TRBV27*01  TRBJ1-2*01       CASSPGTGASGYTF   NaN  AVFDRKSDAK   \n",
       "3         4  TRBV7-9*01  TRBJ2-1*01     CASSLADGGGYNEQFF   NaN   KLGGALQAK   \n",
       "4         5  TRBV7-2*01  TRBJ2-1*01      CASSFAGGSYNEQFF   NaN   RLRAEAQVK   \n",
       "\n",
       "           MHC  Binding  task                             combo  \n",
       "0  HLA-A*03:01        1   NaN       (CASSQSGVGNEQFF, KLGGALQAK)  \n",
       "1  HLA-A*03:01        1   NaN  (CASSGTGTSAFATNEKLFF, KLGGALQAK)  \n",
       "2  HLA-A*11:01        1   NaN      (CASSPGTGASGYTF, AVFDRKSDAK)  \n",
       "3  HLA-A*03:01        1   NaN     (CASSLADGGGYNEQFF, KLGGALQAK)  \n",
       "4  HLA-A*03:01        1   NaN      (CASSFAGGSYNEQFF, RLRAEAQVK)  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_allele.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
